resources:
- name: webserver
  endpoint:
    path: /start/webserver
    method: RUN
    data_selector: start
    params:
      config: configs/dbgpt-proxy-ollama.toml
- name: db_gpt_app_database
  endpoint:
    path: /pilot/meta_data/dbgpt.db
    method: GET
- name: deepseek-chat
  endpoint:
    path: /models/deepseek/chat
    method: GET
- name: deepseek-reasoner
  endpoint:
    path: /models/deepseek/reasoner
    method: GET
- name: glm-4-9b-chat-hf
  endpoint:
    path: /models/glm-4-9b-chat-hf
    method: GET
- name: webserver
  endpoint:
    path: /start/webserver
    method: POST
- name: model
  endpoint:
    path: /models
    method: GET
- name: SiliconFlow API
  endpoint:
    path: /cloud/siliconflow.cn/account/ak
    method: GET
- name: AI/ML API
  endpoint:
    path: /cloud/siliconflow.cn/account/ak
    method: GET
- name: examples_hello
  endpoint:
    path: /api/v1/awel/trigger/examples/hello
    method: GET
    data_selector: response
- name: examples_hello
  endpoint:
    path: /api/v1/awel/trigger/examples/hello
    method: GET
    data_selector: response
    params: {}
- name: chat_completion
  endpoint:
    path: /api/v2/chat/completions
    method: POST
    data_selector: choices
    params: {}
- name: chat_completions
  endpoint:
    path: /api/v2/chat/completions
    method: POST
    data_selector: data
    params: {}
- name: get_app
  endpoint:
    path: /api/v2/serve/apps/{app_id}
    method: GET
    data_selector: data
    params:
      app_id: required
- name: list_app
  endpoint:
    path: /api/v2/serve/apps
    method: GET
    data_selector: data
    params: {}
- name: chat_completion
  endpoint:
    path: /api/v2/chat/completions
    method: POST
    data_selector: choices
    params: {}
- name: chat_completions
  endpoint:
    path: /api/v2/chat/completions
    method: POST
- name: get_app
  endpoint:
    path: /api/v2/serve/apps/{app_id}
    method: GET
- name: list_app
  endpoint:
    path: /api/v2/serve/apps
    method: GET
- name: chat_completion
  endpoint:
    path: /api/v2/chat/completions
    method: POST
    data_selector: data
    params: {}
- name: create_flow
  endpoint:
    path: /api/v2/serve/awel/flows
    method: POST
    data_selector: data
    params: {}
- name: update_flow
  endpoint:
    path: /api/v2/serve/awel/flows
    method: PUT
    data_selector: data
    params: {}
- name: delete_flow
  endpoint:
    path: /api/v2/serve/awel/flows/{flow_id}
    method: DELETE
    data_selector: data
    params: {}
- name: get_flow
  endpoint:
    path: /api/v2/serve/awel/flows/{flow_id}
    method: GET
    data_selector: data
    params: {}
- name: list_flow
  endpoint:
    path: /api/v2/serve/awel/flows
    method: GET
    data_selector: data
    params: {}
- name: chat_completions
  endpoint:
    path: /api/v2/chat/completions
    method: POST
- name: list_flows
  endpoint:
    path: /api/v2/serve/awel/flows
    method: GET
- name: chat_completions
  endpoint:
    path: /api/v2/chat/completions
    method: POST
- name: chat_completions
  endpoint:
    path: /chat/completions
    method: POST
- name: chat_completions
  endpoint:
    path: /chat/completions
    method: POST
    data_selector: choices
    params: {}
- name: chat_completions
  endpoint:
    path: /chat/completions
    method: POST
    data_selector: choices
    params: {}
- name: knowledge_space
  endpoint:
    path: /api/v2/serve/knowledge/spaces
    method: POST
    data_selector: Space Object
    params: {}
- name: knowledge_space_update
  endpoint:
    path: /api/v2/serve/knowledge/spaces
    method: PUT
    data_selector: Space Object
    params: {}
- name: knowledge_space_delete
  endpoint:
    path: /api/v2/serve/knowledge/spaces/{id}
    method: DELETE
    data_selector: Space Object
    params: {}
- name: knowledge_space_get
  endpoint:
    path: /api/v2/serve/knowledge/spaces/{id}
    method: GET
    data_selector: Space Object
    params: {}
- name: knowledge_space_list
  endpoint:
    path: /api/v2/serve/knowledge/spaces
    method: GET
    data_selector: Space Object List
    params: {}
- name: create_space
  endpoint:
    path: /api/v2/serve/knowledge/spaces
    method: POST
    data_selector: response
    params: {}
- name: update_space
  endpoint:
    path: /api/v2/serve/knowledge/spaces
    method: PUT
    data_selector: response
    params: {}
- name: delete_space
  endpoint:
    path: /api/v2/serve/knowledge/spaces/{space_id}
    method: DELETE
    data_selector: response
    params: {}
- name: get_space
  endpoint:
    path: /api/v2/serve/knowledge/spaces/{space_id}
    method: GET
    data_selector: response
    params: {}
- name: list_space
  endpoint:
    path: /api/v2/serve/knowledge/spaces
    method: GET
    data_selector: response
    params: {}
- name: chat_completions
  endpoint:
    path: /chat/completions
    method: POST
- name: datasources
  endpoint:
    path: /serve/datasources
    method: GET
- name: chat_completions
  endpoint:
    path: /chat/completions
    method: POST
    data_selector: choices
    params: {}
- name: datasources
  endpoint:
    path: /serve/datasources
    method: GET
    data_selector: datasources
    params: {}
- name: evaluation
  endpoint:
    path: /api/v2/serve/evaluate/evaluation
    method: POST
- name: evaluation
  endpoint:
    path: /api/v2/serve/evaluate/evaluation
    method: POST
    data_selector: data
    params: {}
- name: simple_chat_app
  endpoint:
    path: /dbgpts/simple_chat_app
    method: POST
    data_selector: output.text
- name: dbgpts_simple_chat_app
  endpoint:
    path: /dbgpts/simple_chat_app
    method: POST
notes:
- If you are in the China region, you can add --index-url=<https://pypi.tuna.tsinghua.edu.cn/simple>
  at the end of the command.
- Open your browser and visit http://localhost:5670
- If you are in the China region, you can add --index-url=https://pypi.tuna.tsinghua.edu.cn/simple
  at the end of the command.
- You can specify your embedding model in the configs/dbgpt-proxy-deepseek.toml configuration
  file.
- Default embedding model is BAAI/bge-large-zh-v1.5
- Detailed installation and deployment tutorials can be found in Installation.
- You need to provide a valid API key for the SiliconFlow API or set AIMLAPI_API_KEY
  for the AI/ML API service.
- Requires GPU environment for local model deployment.
- API key must be set for SiliconFlow API.
- You can obtain an API key by signing up at SiliconFlow and creating an API key.
- You can obtain an API key for the SiliconFlow API by signing up.
- Ensure to have the NVIDIA Container Toolkit installed for GPU deployment.
- Requires a valid API key for the SiliconFlow API.
- Ensure that your data is not lost when the container is stopped or removed by mapping
  relevant directories.
- DB-GPT requires Python 3.10 or higher. The default is Python 3.11.
- For Llama-cpp mode, CMAKE_ARGS="-DGGML_CUDA=ON" is automatically set to enable CUDA
  acceleration.
- You can obtain one by signing up at SiliconFlow and creating an API key at API Key.
- DB-GPT requires Python 3.10 or higher. The default is Python 3.11, but you can specify
  a different version.
- 'Common Build Issues: If you encounter CUDA-related errors, try building with a
  different CUDA base image.'
- The test environment allows testing without starting the dbgpt_server
- Production requests must be routed through your own backend server where your API
  key can be securely loaded from an environment variable or key management service.
- Uses API key for authentication.
- If set, partial message deltas will be sent.
- Tokens will be sent as data-only server-sent events as they become available.
- Requires setup of API key for authorization
- Uses API key for authentication
- The evaluation scene key can be 'recall' or 'app'.
- Requires setup of API key in header
- Support for multiple models and multiple inference frameworks
- Lightweight installation with optional dependencies
- Uses OAuth2 with refresh token â€” requires setup of connected app in api
- Some objects may return nulls in deeply nested fields
- DB-GPT will use all available gpu by default.
- 8-bit quantization is enabled by default.
- DB-GPT currently support Chroma(Default), Milvus(>2.1), Weaviate, OceanBase vector
  database.
- If you want to support more vector db, you can integrate yourself.
- AWEL protocol upgrade 2.0 supports more complex orchestration and optimizes front-end
  visualization and interaction capabilities.
- 'Supports the creation and life cycle management of data applications, and supports
  multiple modes to build applications, such as: multi-agent automatic planning mode,
  task flow orchestration mode, single agent mode, and native application mode.'
- If you want to change vector db, Update your .env, set your vector store type, VECTOR_STORE_TYPE=Chroma
  (now only support Chroma and Milvus(>2.1), if you set Milvus, please set MILVUS_URL
  and MILVUS_PORT).
- 'If you want to use OceanBase, please first start a docker container via the following
  command: docker run --name=ob433 -e MODE=slim -p 2881:2881 -d quay.io/oceanbase/oceanbase-ce:4.3.3.0-100000142024101215.'
- Check the connection to OceanBase and set the memory usage ratio for vector data.
- If you use SQLite, you not need to upgrade the database.
- If you use MySQL, you need to upgrade the database.
- This marks the first stable release that will be maintained over an extended period
  within the DB-GPT project.
errors:
- 'REQUEST_LIMIT_EXCEEDED: Throttle API calls or reduce frequency'
- 'QUERY_TIMEOUT: Break down filters or add selectivity'
- '401 Unauthorized: Recheck API key'
- 'Not Enough Memory: Modify MAX_GPU_MEMORY in .env file.'
- '1054: Unknown column ''knowledge_space.context'' in ''field list'''
- Use Mysql, how to use DB-GPT KBQA
auth_info:
  mentioned_objects: []
client:
  base_url: http://localhost:5670
source_metadata: null
