resources:
- name: query_results
  endpoint:
    path: /v1/statement
    method: POST
    data_selector: data
- name: CLI
  endpoint:
    path: /docs/current/client/cli.html
    method: GET
- name: Grafana
  endpoint:
    path: /docs/current/client/grafana.html
    method: GET
- name: Apache Airflow
  endpoint:
    path: /docs/apache-airflow-providers-trino/stable/index.html
    method: GET
- name: Apache DolphinScheduler
  endpoint:
    path: /docs/dolphinscheduler.html
    method: GET
- name: Coginiti
  endpoint:
    path: /databases/trino/
    method: GET
- name: Cube
  endpoint:
    path: /integrations/Trino-Data-API
    method: GET
- name: DBeaver
  endpoint:
    path: /docs/current/client/dbeaver.html
    method: GET
- name: dbt
  endpoint:
    path: /docs/getdbt.com/
    method: GET
- name: DbVisualizer
  endpoint:
    path: /database/trino/
    method: GET
- name: Emacs
  endpoint:
    path: /sql-trino/
    method: GET
- name: FugueSQL
  endpoint:
    path: /tutorials/integrations/warehouses/trino.html
    method: GET
- name: Great Expectations
  endpoint:
    path: /guides/connecting_to_your_data/database/trino/
    method: GET
- name: Harlequin
  endpoint:
    path: /docs/trino/index
    method: GET
- name: Hue
  endpoint:
    path: /administrator/configuration/connectors/#trino
    method: GET
- name: Ibis
  endpoint:
    path: /backends/trino/
    method: GET
- name: IBM Cognos Analytics
  endpoint:
    path: /products/cognos-analytics
    method: GET
- name: JetBrains Datagrip
  endpoint:
    path: /docs/current/client/datagrip.html
    method: GET
- name: Jupy SQL
  endpoint:
    path: /en/latest/integrations/trinodb.html
    method: GET
- name: Logi Symphony
  endpoint:
    path: /logi-symphony/
    method: GET
- name: Looker
  endpoint:
    path: /cloud.google.com/looker/docs/db-config-prestodb-and-trino
    method: GET
- name: Metabase
  endpoint:
    path: /docs/starburst.io/data-consumer/clients/metabase.html
    method: GET
- name: Microstrategy
  endpoint:
    path: /en
    method: GET
- name: Mitzu
  endpoint:
    path: /warehouse-integrations/trino-presto
    method: GET
- name: Mode
  endpoint:
    path: /integrations/trino/
    method: GET
- name: PopSQL
  endpoint:
    path: /docs/connecting-to-trino
    method: GET
- name: Power BI
  endpoint:
    path: /docs/starburst.io/clients/powerbi.html
    method: GET
- name: Querybook
  endpoint:
    path: /docs/starburst.io/data-consumer/clients/querybook.html
    method: GET
- name: Quix
  endpoint:
    path: /docs/presto
    method: GET
- name: Redash
  endpoint:
    path: /
    method: GET
- name: Amazon Redshift
  endpoint:
    path: /docs/current/connector/redshift.html
    method: GET
- name: Apache Cassandra
  endpoint:
    path: /docs/current/connector/cassandra.html
    method: GET
- name: Apache Druid
  endpoint:
    path: /docs/current/connector/druid.html
    method: GET
- name: Apache Ignite
  endpoint:
    path: /docs/current/connector/ignite.html
    method: GET
- name: Apache Kafka
  endpoint:
    path: /docs/current/connector/kafka.html
    method: GET
- name: Apache Pinot
  endpoint:
    path: /docs/current/connector/pinot.html
    method: GET
- name: Clickhouse
  endpoint:
    path: /docs/current/connector/clickhouse.html
    method: GET
- name: Datafaker
  endpoint:
    path: /docs/current/connector/faker.html
    method: GET
- name: Elasticsearch
  endpoint:
    path: /docs/current/connector/elasticsearch.html
    method: GET
- name: Exasol
  endpoint:
    path: /docs/current/connector/exasol.html
    method: GET
- name: Google BigQuery
  endpoint:
    path: /docs/current/connector/bigquery.html
    method: GET
- name: Google Sheets
  endpoint:
    path: /docs/current/connector/googlesheets.html
    method: GET
- name: MariaDB
  endpoint:
    path: /docs/current/connector/mariadb.html
    method: GET
- name: Microsoft SQL Server
  endpoint:
    path: /docs/current/connector/sqlserver.html
    method: GET
- name: MongoDB
  endpoint:
    path: /docs/current/connector/mongodb.html
    method: GET
- name: MySQL
  endpoint:
    path: /docs/current/connector/mysql.html
    method: GET
- name: OpenSearch
  endpoint:
    path: /docs/current/connector/elasticsearch.html
    method: GET
- name: Oracle
  endpoint:
    path: /docs/current/connector/oracle.html
    method: GET
- name: PostgreSQL
  endpoint:
    path: /docs/current/connector/postgresql.html
    method: GET
- name: Prometheus
  endpoint:
    path: /docs/current/connector/prometheus.html
    method: GET
- name: Redis
  endpoint:
    path: /docs/current/connector/redis.html
    method: GET
- name: SingleStore
  endpoint:
    path: /docs/current/connector/singlestore.html
    method: GET
- name: Snowflake
  endpoint:
    path: /docs/current/connector/snowflake.html
    method: GET
- name: TPC
  endpoint:
    path: /docs/current/connector/tpcds.html
    method: GET
- name: Vertica
  endpoint:
    path: /docs/current/connector/vertica.html
    method: GET
- name: JMX
  endpoint:
    path: /docs/current/admin/jmx.html
    method: GET
- name: Kubernetes
  endpoint:
    path: /docs/current/installation/kubernetes.html
    method: GET
- name: OpenLineage
  endpoint:
    path: /docs/current/admin/event-listeners-openlineage.html
    method: GET
- name: Open Policy Agent
  endpoint:
    path: /docs/current/security/opa-access-control.html
    method: GET
- name: OpenTelemetry
  endpoint:
    path: /docs/current/admin/opentelemetry.html
    method: GET
- name: Trino Gateway
  endpoint:
    path: /docs/current/gateway.html
    method: GET
- name: Datadog
  endpoint:
    path: https://docs.datadoghq.com/integrations/trino/
    method: GET
- name: Gurubase
  endpoint:
    path: https://gurubase.io/g/trino
    method: GET
- name: jOOQ
  endpoint:
    path: https://www.jooq.org/
    method: GET
- name: Minitrino
  endpoint:
    path: https://github.com/jefflester/minitrino
    method: GET
- name: RudderStack
  endpoint:
    path: https://www.rudderstack.com/docs/sources/reverse-etl/trino/
    method: GET
- name: SQL Formatter
  endpoint:
    path: https://github.com/sql-formatter-org/sql-formatter/blob/master/README.md
    method: GET
- name: Testcontainers
  endpoint:
    path: https://testcontainers.com/modules/trino/
    method: GET
- name: Trino-lb
  endpoint:
    path: https://github.com/stackabletech/trino-lb
    method: GET
- name: Workload Analyzer
  endpoint:
    path: https://github.com/varadaio/presto-workload-analyzer
    method: GET
- name: data_analysis
  endpoint:
    path: /data-analysis
    method: GET
    data_selector: results
- name: etl_pipelines
  endpoint:
    path: /etl-pipelines
    method: GET
    data_selector: pipelines
- name: participants
  endpoint:
    path: /participants
    method: GET
    data_selector: records
- name: contributors
  endpoint:
    path: /contributors
    method: GET
    data_selector: records
- name: reviewers
  endpoint:
    path: /reviewers
    method: GET
    data_selector: records
- name: maintainers
  endpoint:
    path: /maintainers
    method: GET
    data_selector: records
- name: subproject_maintainers
  endpoint:
    path: /subproject_maintainers
    method: GET
    data_selector: records
- name: language_lead
  endpoint:
    path: /language_lead
    method: GET
    data_selector: records
- name: file_system_lead
  endpoint:
    path: /file_system_lead
    method: GET
    data_selector: records
- name: benevolent_dictators
  endpoint:
    path: /benevolent_dictators
    method: GET
    data_selector: records
- name: functions_and_operators
  endpoint:
    path: /functions/operators
    method: GET
- name: user_defined_functions
  endpoint:
    path: /udf
    method: GET
    data_selector: functions
    params: {}
- name: ALTER BRANCH
  endpoint:
    path: sql/alter-branch.html
    method: GET
- name: ALTER MATERIALIZED VIEW
  endpoint:
    path: sql/alter-materialized-view.html
    method: GET
- name: ALTER SCHEMA
  endpoint:
    path: sql/alter-schema.html
    method: GET
- name: ALTER TABLE
  endpoint:
    path: sql/alter-table.html
    method: GET
- name: ALTER VIEW
  endpoint:
    path: sql/alter-view.html
    method: GET
- name: ANALYZE
  endpoint:
    path: sql/analyze.html
    method: GET
- name: CALL
  endpoint:
    path: sql/call.html
    method: GET
- name: COMMENT
  endpoint:
    path: sql/comment.html
    method: GET
- name: COMMIT
  endpoint:
    path: sql/commit.html
    method: GET
- name: CREATE BRANCH
  endpoint:
    path: sql/create-branch.html
    method: GET
- name: CREATE CATALOG
  endpoint:
    path: sql/create-catalog.html
    method: GET
- name: CREATE FUNCTION
  endpoint:
    path: sql/create-function.html
    method: GET
- name: CREATE MATERIALIZED VIEW
  endpoint:
    path: sql/create-materialized-view.html
    method: GET
- name: CREATE ROLE
  endpoint:
    path: sql/create-role.html
    method: GET
- name: CREATE SCHEMA
  endpoint:
    path: sql/create-schema.html
    method: GET
- name: CREATE TABLE
  endpoint:
    path: sql/create-table.html
    method: GET
- name: CREATE TABLE AS
  endpoint:
    path: sql/create-table-as.html
    method: GET
- name: CREATE VIEW
  endpoint:
    path: sql/create-view.html
    method: GET
- name: DEALLOCATE PREPARE
  endpoint:
    path: sql/deallocate-prepare.html
    method: GET
- name: DELETE
  endpoint:
    path: sql/delete.html
    method: GET
- name: DENY
  endpoint:
    path: sql/deny.html
    method: GET
- name: DESCRIBE
  endpoint:
    path: sql/describe.html
    method: GET
- name: DESCRIBE INPUT
  endpoint:
    path: sql/describe-input.html
    method: GET
- name: DESCRIBE OUTPUT
  endpoint:
    path: sql/describe-output.html
    method: GET
- name: DROP BRANCH
  endpoint:
    path: sql/drop-branch.html
    method: GET
- name: DROP CATALOG
  endpoint:
    path: sql/drop-catalog.html
    method: GET
- name: DROP FUNCTION
  endpoint:
    path: sql/drop-function.html
    method: GET
- name: DROP MATERIALIZED VIEW
  endpoint:
    path: sql/drop-materialized-view.html
    method: GET
- name: DROP ROLE
  endpoint:
    path: sql/drop-role.html
    method: GET
- name: DROP SCHEMA
  endpoint:
    path: sql/drop-schema.html
    method: GET
- name: DROP TABLE
  endpoint:
    path: sql/drop-table.html
    method: GET
- name: DROP VIEW
  endpoint:
    path: sql/drop-view.html
    method: GET
- name: EXECUTE
  endpoint:
    path: sql/execute.html
    method: GET
- name: EXECUTE IMMEDIATE
  endpoint:
    path: sql/execute-immediate.html
    method: GET
- name: EXPLAIN
  endpoint:
    path: sql/explain.html
    method: GET
- name: EXPLAIN ANALYZE
  endpoint:
    path: sql/explain-analyze.html
    method: GET
- name: GRANT privilege
  endpoint:
    path: sql/grant.html
    method: GET
- name: GRANT role
  endpoint:
    path: sql/grant-roles.html
    method: GET
- name: INSERT
  endpoint:
    path: sql/insert.html
    method: GET
- name: MATCH_RECOGNIZE
  endpoint:
    path: sql/match-recognize.html
    method: GET
- name: MERGE
  endpoint:
    path: sql/merge.html
    method: GET
- name: PREPARE
  endpoint:
    path: sql/prepare.html
    method: GET
- name: REFRESH MATERIALIZED VIEW
  endpoint:
    path: sql/refresh-materialized-view.html
    method: GET
- name: RESET SESSION
  endpoint:
    path: sql/reset-session.html
    method: GET
- name: RESET SESSION AUTHORIZATION
  endpoint:
    path: sql/reset-session-authorization.html
    method: GET
- name: REVOKE privilege
  endpoint:
    path: sql/revoke.html
    method: GET
- name: REVOKE role
  endpoint:
    path: sql/revoke-roles.html
    method: GET
- name: ROLLBACK
  endpoint:
    path: sql/rollback.html
    method: GET
- name: SELECT
  endpoint:
    path: sql/select.html
    method: GET
- name: SET PATH
  endpoint:
    path: sql/set-path.html
    method: GET
- name: SET ROLE
  endpoint:
    path: sql/set-role.html
    method: GET
- name: SET SESSION
  endpoint:
    path: sql/set-session.html
    method: GET
- name: SET SESSION AUTHORIZATION
  endpoint:
    path: sql/set-session-authorization.html
    method: GET
- name: SET TIME ZONE
  endpoint:
    path: sql/set-time-zone.html
    method: GET
- name: SHOW BRANCHES
  endpoint:
    path: sql/show-branches.html
    method: GET
- name: SHOW CATALOGS
  endpoint:
    path: sql/show-catalogs.html
    method: GET
- name: SHOW COLUMNS
  endpoint:
    path: sql/show-columns.html
    method: GET
- name: SHOW CREATE FUNCTION
  endpoint:
    path: sql/show-create-function.html
    method: GET
- name: SHOW CREATE MATERIALIZED VIEW
  endpoint:
    path: sql/show-create-materialized-view.html
    method: GET
- name: SHOW CREATE SCHEMA
  endpoint:
    path: sql/show-create-schema.html
    method: GET
- name: SHOW CREATE TABLE
  endpoint:
    path: sql/show-create-table.html
    method: GET
- name: SHOW CREATE VIEW
  endpoint:
    path: sql/show-create-view.html
    method: GET
- name: SHOW FUNCTIONS
  endpoint:
    path: sql/show-functions.html
    method: GET
- name: SHOW GRANTS
  endpoint:
    path: sql/show-grants.html
    method: GET
- name: SHOW ROLE GRANTS
  endpoint:
    path: sql/show-role-grants.html
    method: GET
- name: SHOW ROLES
  endpoint:
    path: sql/show-roles.html
    method: GET
- name: SHOW SCHEMAS
  endpoint:
    path: sql/show-schemas.html
    method: GET
- name: SHOW SESSION
  endpoint:
    path: sql/show-session.html
    method: GET
- name: SHOW STATS
  endpoint:
    path: sql/show-stats.html
    method: GET
- name: SHOW TABLES
  endpoint:
    path: sql/show-tables.html
    method: GET
- name: START TRANSACTION
  endpoint:
    path: sql/start-transaction.html
    method: GET
- name: TRUNCATE
  endpoint:
    path: sql/truncate.html
    method: GET
- name: UPDATE
  endpoint:
    path: sql/update.html
    method: GET
- name: USE
  endpoint:
    path: sql/use.html
    method: GET
- name: VALUES
  endpoint:
    path: sql/values.html
    method: GET
- name: node_properties
  endpoint:
    path: /etc/node.properties
    method: GET
    data_selector: records
    params: {}
- name: jvm_config
  endpoint:
    path: /etc/jvm.config
    method: GET
    data_selector: records
    params: {}
- name: coordinator
  endpoint:
    path: /
    method: GET
    data_selector: ''
    params: {}
- name: worker
  endpoint:
    path: /
    method: GET
    data_selector: ''
    params: {}
- name: catalogs
  endpoint:
    path: /catalogs
    method: GET
    data_selector: catalogs
    params: {}
- name: plugin
  endpoint:
    path: /plugin
    method: GET
- name: ai-functions
  endpoint:
    path: /plugins/ai-functions
    method: GET
    data_selector: records
- name: bigquery
  endpoint:
    path: /plugins/bigquery
    method: GET
    data_selector: records
- name: blackhole
  endpoint:
    path: /plugins/blackhole
    method: GET
    data_selector: records
- name: cassandra
  endpoint:
    path: /plugins/cassandra
    method: GET
    data_selector: records
- name: clickhouse
  endpoint:
    path: /plugins/clickhouse
    method: GET
    data_selector: records
- name: delta-lake
  endpoint:
    path: /plugins/delta-lake
    method: GET
    data_selector: records
- name: druid
  endpoint:
    path: /plugins/druid
    method: GET
    data_selector: records
- name: duckdb
  endpoint:
    path: /plugins/duckdb
    method: GET
    data_selector: records
- name: elasticsearch
  endpoint:
    path: /plugins/elasticsearch
    method: GET
    data_selector: records
- name: example-http
  endpoint:
    path: /plugins/example-http
    method: GET
    data_selector: records
- name: exasol
  endpoint:
    path: /plugins/exasol
    method: GET
    data_selector: records
- name: exchange-filesystem
  endpoint:
    path: /plugins/exchange-filesystem
    method: GET
    data_selector: records
- name: exchange-hdfs
  endpoint:
    path: /plugins/exchange-hdfs
    method: GET
    data_selector: records
- name: faker
  endpoint:
    path: /plugins/faker
    method: GET
    data_selector: records
- name: functions-python
  endpoint:
    path: /plugins/functions-python
    method: GET
    data_selector: records
- name: geospatial
  endpoint:
    path: /plugins/geospatial
    method: GET
    data_selector: records
- name: google-sheets
  endpoint:
    path: /plugins/google-sheets
    method: GET
    data_selector: records
- name: hive
  endpoint:
    path: /plugins/hive
    method: GET
    data_selector: records
- name: http-event-listener
  endpoint:
    path: /plugins/http-event-listener
    method: GET
    data_selector: records
- name: http-server-event-listener
  endpoint:
    path: /plugins/http-server-event-listener
    method: GET
    data_selector: records
- name: hudi
  endpoint:
    path: /plugins/hudi
    method: GET
    data_selector: records
- name: iceberg
  endpoint:
    path: /plugins/iceberg
    method: GET
    data_selector: records
- name: ignite
  endpoint:
    path: /plugins/ignite
    method: GET
    data_selector: records
- name: jmx
  endpoint:
    path: /plugins/jmx
    method: GET
    data_selector: records
- name: kafka
  endpoint:
    path: /plugins/kafka
    method: GET
    data_selector: records
- name: kafka-event-listener
  endpoint:
    path: /plugins/kafka-event-listener
    method: GET
    data_selector: records
- name: loki
  endpoint:
    path: /plugins/loki
    method: GET
    data_selector: records
- name: mariadb
  endpoint:
    path: /plugins/mariadb
    method: GET
    data_selector: records
- name: memory
  endpoint:
    path: /plugins/memory
    method: GET
    data_selector: records
- name: ml
  endpoint:
    path: /plugins/ml
    method: GET
    data_selector: records
- name: mongodb
  endpoint:
    path: /plugins/mongodb
    method: GET
    data_selector: records
- name: mysql
  endpoint:
    path: /plugins/mysql
    method: GET
    data_selector: records
- name: mysql-event-listener
  endpoint:
    path: /plugins/mysql-event-listener
    method: GET
    data_selector: records
- name: opa
  endpoint:
    path: /plugins/opa
    method: GET
    data_selector: records
- name: openlineage
  endpoint:
    path: /plugins/openlineage
    method: GET
    data_selector: records
- name: opensearch
  endpoint:
    path: /plugins/opensearch
    method: GET
    data_selector: records
- name: oracle
  endpoint:
    path: /plugins/oracle
    method: GET
    data_selector: records
- name: password-authenticators
  endpoint:
    path: /plugins/password-authenticators
    method: GET
    data_selector: records
- name: pinot
  endpoint:
    path: /plugins/pinot
    method: GET
    data_selector: records
- name: postgresql
  endpoint:
    path: /plugins/postgresql
    method: GET
    data_selector: records
- name: prometheus
  endpoint:
    path: /plugins/prometheus
    method: GET
    data_selector: records
- name: ranger
  endpoint:
    path: /plugins/ranger
    method: GET
    data_selector: records
- name: redis
  endpoint:
    path: /plugins/redis
    method: GET
    data_selector: records
- name: redshift
  endpoint:
    path: /plugins/redshift
    method: GET
    data_selector: records
- name: resource-group-managers
  endpoint:
    path: /plugins/resource-group-managers
    method: GET
    data_selector: records
- name: session-property-managers
  endpoint:
    path: /plugins/session-property-managers
    method: GET
    data_selector: records
- name: singlestore
  endpoint:
    path: /plugins/singlestore
    method: GET
    data_selector: records
- name: snowflake
  endpoint:
    path: /plugins/snowflake
    method: GET
    data_selector: records
- name: spooling-filesystem
  endpoint:
    path: /plugins/spooling-filesystem
    method: GET
    data_selector: records
- name: sqlserver
  endpoint:
    path: /plugins/sqlserver
    method: GET
    data_selector: records
- name: teradata-functions
  endpoint:
    path: /plugins/teradata-functions
    method: GET
    data_selector: records
- name: thrift
  endpoint:
    path: /plugins/thrift
    method: GET
    data_selector: records
- name: tpcds
  endpoint:
    path: /plugins/tpcds
    method: GET
    data_selector: records
- name: tpch
  endpoint:
    path: /plugins/tpch
    method: GET
    data_selector: records
- name: vertica
  endpoint:
    path: /plugins/vertica
    method: GET
    data_selector: records
- name: exchange_manager
  endpoint:
    path: /server/exchangeManager
    method: POST
    data_selector: configuration
    params:
      exchange_manager: filesystem
      base_directories: s3://exchange-spooling-bucket-1,s3://exchange-spooling-bucket-2
      region: us-west-1
      aws_access_key: example-access-key
      aws_secret_key: example-secret-key
      retry_policy: TASK
- name: resource_groups
  endpoint:
    path: /etc/resource-groups.properties
    method: GET
    data_selector: properties
    params: {}
- name: file_resource_group_manager
  endpoint:
    path: /etc/resource-groups.json
    method: GET
    data_selector: configuration
    params: {}
- name: database_resource_group_manager
  endpoint:
    path: /jdbc:mysql://localhost:3306/resource_groups
    method: GET
    data_selector: configuration
    params: {}
- name: global
  endpoint:
    path: /resource_groups/global
    method: INSERT
    data_selector: resource_groups
    params:
      soft_memory_limit: 80%
      hard_physical_data_scan_limit: 50TB
      hard_concurrency_limit: 100
      max_queued: 1000
      scheduling_policy: weighted
      jmx_export: true
      environment: test_environment
- name: data_definition
  endpoint:
    path: /resource_groups/data_definition
    method: INSERT
    data_selector: resource_groups
    params:
      soft_memory_limit: 10%
      hard_concurrency_limit: 5
      max_queued: 100
      scheduling_weight: 1
      environment: test_environment
      parent: 1
- name: adhoc
  endpoint:
    path: /resource_groups/adhoc
    method: INSERT
    data_selector: resource_groups
    params:
      soft_memory_limit: 10%
      hard_concurrency_limit: 50
      max_queued: 1
      scheduling_weight: 10
      environment: test_environment
      parent: 1
- name: other
  endpoint:
    path: /resource_groups/other
    method: INSERT
    data_selector: resource_groups
    params:
      soft_memory_limit: 10%
      hard_concurrency_limit: 2
      max_queued: 1
      scheduling_weight: 10
      scheduling_policy: weighted_fair
      environment: test_environment
      parent: 3
- name: pipeline
  endpoint:
    path: /resource_groups/pipeline
    method: INSERT
    data_selector: resource_groups
    params:
      soft_memory_limit: 80%
      hard_concurrency_limit: 45
      max_queued: 100
      scheduling_weight: 1
      jmx_export: true
      environment: test_environment
      parent: 1
- name: admin
  endpoint:
    path: /resource_groups/admin
    method: INSERT
    data_selector: resource_groups
    params:
      soft_memory_limit: 100%
      hard_concurrency_limit: 50
      max_queued: 100
      scheduling_policy: query_priority
      environment: test_environment
      jmx_export: true
- name: exchange-manager
  endpoint:
    path: /exchange-manager.properties
    method: GET
    data_selector: ''
    params: {}
- name: query.max-cpu-time
  endpoint:
    data_selector: 1_000_000_000d
- name: query.max-memory-per-node
  endpoint:
    data_selector: (30% of maximum heap size on the node)
- name: query.max-memory
  endpoint:
    data_selector: 20GB
- name: query.max-total-memory
  endpoint:
    data_selector: (query.max-memory * 2)
- name: memory.heap-headroom-per-node
  endpoint:
    data_selector: (30% of maximum heap size on the node)
- name: exchange.deduplication-buffer-size
  endpoint:
    data_selector: 32MB
- name: logging
  endpoint:
    path: /admin/logging
    method: GET
    data_selector: loggers
- name: tracing
  endpoint:
    path: /config.properties
    method: POST
    data_selector: tracing
    params:
      tracing.enabled: 'true'
      tracing.exporter.endpoint: http://observe.example.com:4317
- name: metrics
  endpoint:
    path: /metrics
    method: GET
    data_selector: metrics
- name: Trino coordinator
  endpoint:
    path: /trino/coordinator
    method: HTTPS
    data_selector: config.properties
    params: {}
- name: group_mapping
  endpoint:
    path: /etc/group-provider.properties
    method: GET
    data_selector: group-providers
    params: {}
- name: system_access_control
  endpoint:
    path: /etc/access-control.properties
    method: GET
    data_selector: content
    params: {}
- name: access_control
  endpoint:
    path: /etc/access-control.properties
    method: GET
    data_selector: rules
    params: {}
- name: access_control
  endpoint:
    path: /v1/data/trino/allow
    method: GET
    data_selector: ''
    params: {}
- name: row_filters
  endpoint:
    path: /v1/data/trino/rowFilters
    method: GET
    data_selector: ''
    params: {}
- name: column_mask
  endpoint:
    path: /v1/data/trino/columnMask
    method: GET
    data_selector: ''
    params: {}
- name: batch_column_masks
  endpoint:
    path: /v1/data/trino/batchColumnMasks
    method: GET
    data_selector: ''
    params: {}
- name: batched
  endpoint:
    path: /v1/data/trino/batch
    method: GET
    data_selector: ''
    params: {}
- name: session_property_managers
  endpoint:
    path: /session-property-managers
    method: GET
    data_selector: rules
    params: {}
- name: query_create
  endpoint:
    path: /kafka-event-listener.created-event.topic
    method: POST
    data_selector: ''
    params: {}
- name: query_complete
  endpoint:
    path: /kafka-event-listener.completed-event.topic
    method: POST
    data_selector: ''
    params: {}
- name: sql.forced-session-time-zone
  endpoint:
    path: /sql/forced-session-time-zone
    method: GET
    data_selector: properties
    params: {}
- name: sql.default-catalog
  endpoint:
    path: /sql/default-catalog
    method: GET
    data_selector: properties
    params: {}
- name: sql.default-schema
  endpoint:
    path: /sql/default-schema
    method: GET
    data_selector: properties
    params: {}
- name: sql.default-function-catalog
  endpoint:
    path: /sql/default-function-catalog
    method: GET
    data_selector: properties
    params: {}
- name: sql.default-function-schema
  endpoint:
    path: /sql/default-function-schema
    method: GET
    data_selector: properties
    params: {}
- name: sql.path
  endpoint:
    path: /sql/path
    method: GET
    data_selector: properties
    params: {}
- name: task_properties
  endpoint:
    path: /admin/properties/task
    method: GET
    data_selector: properties
- name: scale_writers
  endpoint:
    params:
      default: 'true'
- name: task_scale_writers_enabled
  endpoint:
    params:
      default: 'true'
- name: writer_scaling_min_data_processed
  endpoint:
    params:
      default: 120MB
- name: regex-library
  endpoint:
    path: /admin/properties/regex-library
    method: GET
    data_selector: allowed_values
    params: {}
- name: re2j.dfa-states-limit
  endpoint:
    path: /admin/properties/re2j.dfa-states-limit
    method: GET
    data_selector: default_value
    params: {}
- name: re2j.dfa-retries
  endpoint:
    path: /admin/properties/re2j.dfa-retries
    method: GET
    data_selector: default_value
    params: {}
- name: EXPLAIN
  endpoint:
    path: /sql/explain
    method: GET
    data_selector: output
- name: EXPLAIN ANALYZE
  endpoint:
    path: /sql/explain-analyze
    method: GET
    data_selector: output
- name: show_stats
  endpoint:
    path: /sql/show_stats
    method: GET
    data_selector: statistics
    params: {}
- name: analyze
  endpoint:
    path: /sql/analyze
    method: POST
    data_selector: results
    params: {}
- name: test_nation
  endpoint:
    path: /example/test/nation
    method: CREATE
    data_selector: rows
    params: {}
- name: users
  endpoint:
    path: /example_keyspace/users
    method: SELECT
    data_selector: '*'
    params: {}
- name: $history
  endpoint:
    path: test_table$history
    method: SELECT
    data_selector: records
- name: $partitions
  endpoint:
    path: test_table$partitions
    method: SELECT
    data_selector: records
- name: $properties
  endpoint:
    path: test_table$properties
    method: SELECT
    data_selector: records
- name: table_changes
  endpoint:
    path: /system/table_changes
    method: SELECT
    data_selector: '*'
    params:
      schema_name: test_schema
      table_name: pages
      since_version: 1
- name: metadata_sheet
  endpoint:
    path: /v4/spreadsheets/{spreadsheetId}
    method: GET
    data_selector: sheets
- name: example
  endpoint:
    path: /services/data/vXX.X/sobjects/example
    method: GET
    data_selector: records
    params: {}
- name: iceberg
  endpoint:
    path: /etc/catalog/example.properties
    method: GET
    data_selector: records
    params: {}
- name: $partitions
  endpoint:
    path: test_table$partitions
    method: SELECT
    data_selector: '*'
- name: $files
  endpoint:
    path: test_table$files
    method: SELECT
    data_selector: '*'
- name: $entries
  endpoint:
    path: test_table$entries
    method: SELECT
    data_selector: '*'
- name: $all_entries
  endpoint:
    path: test_table$all_entries
    method: SELECT
    data_selector: '*'
- name: $refs
  endpoint:
    path: test_table$refs
    method: SELECT
    data_selector: '*'
- name: iceberg_tables
  endpoint:
    path: example.system.iceberg_tables
    method: SELECT
    data_selector: '*'
- name: public
  endpoint:
    path: /public
    method: GET
- name: current
  endpoint:
    path: example.current
    method: SHOW TABLES
    data_selector: ''
- name: history
  endpoint:
    path: example.history
    method: SELECT
    data_selector: ''
- name: kafka
  endpoint:
    path: /etc/catalog/example.properties
    method: GET
    data_selector: records
    params:
      kafka.table-names: table1,table2
      kafka.nodes: host1:port,host2:port
      kafka.config.resources: /etc/kafka-configuration.properties
- name: kafka.table-names
  endpoint:
    path: /kafka/table-names
    method: GET
    data_selector: tables
    params: {}
- name: kafka.table-description-dir
  endpoint:
    path: /kafka/table-description-dir
    method: GET
    data_selector: descriptions
    params: {}
- name: raw
  endpoint:
    data_selector: fields
    params: {}
- name: csv
  endpoint:
    data_selector: fields
    params: {}
- name: json
  endpoint:
    data_selector: fields
    params: {}
- name: avro
  endpoint:
    data_selector: fields
    params: {}
- name: protobuf
  endpoint:
    data_selector: fields
    params: {}
- name: row_decoding
  endpoint:
    path: /row_decoding
    method: GET
    data_selector: decoders
    params: {}
- name: sql_support
  endpoint:
    path: /sql_support
    method: GET
    data_selector: features
    params: {}
- name: iceberg_table
  endpoint:
    path: /path/to/iceberg_table
    method: CREATE
    data_selector: records
    params:
      type: ICEBERG
      format: PARQUET
      partitioning:
      - c1
      - c2
      sorted_by:
      - c3
- name: hive_page_views
  endpoint:
    path: /path/to/hive_page_views
    method: CREATE
    data_selector: records
    params:
      type: HIVE
      format: ORC
      partitioned_by:
      - ds
      - country
      bucketed_by:
      - user_id
      bucket_count: 50
- name: orders
  endpoint:
    path: /orders
    method: GET
    data_selector: '*'
    params: {}
- name: default
  endpoint:
    path: /
    method: GET
    data_selector: hits.hits
    params: {}
- name: system_flush_metadata_cache
  endpoint:
    path: /system/flush_metadata_cache
    method: CALL
    data_selector: result
    params: {}
- name: system_execute
  endpoint:
    path: /system/execute
    method: CALL
    data_selector: result
    params: {}
- name: system_query
  endpoint:
    path: /system/query
    method: SELECT
    data_selector: result
    params: {}
- name: metrics
  endpoint:
    path: /api/v1/query
    method: GET
    data_selector: data
    params:
      query: up
      time: TIMESTAMP
- name: redis.table-names
  endpoint:
    path: ''
    method: ''
    data_selector: ''
    params: {}
- name: snowflake
  endpoint:
    path: /services/data/snowflake
    method: GET
    data_selector: records
    params: {}
- name: metadata.catalogs
  endpoint:
    path: /system/metadata/catalogs
    method: GET
    data_selector: records
- name: metadata.schema_properties
  endpoint:
    path: /system/metadata/schema_properties
    method: GET
    data_selector: records
- name: metadata.table_properties
  endpoint:
    path: /system/metadata/table_properties
    method: GET
    data_selector: records
- name: metadata.materialized_views
  endpoint:
    path: /system/metadata/materialized_views
    method: GET
    data_selector: records
- name: metadata.materialized_view_properties
  endpoint:
    path: /system/metadata/materialized_view_properties
    method: GET
    data_selector: records
- name: metadata.table_comments
  endpoint:
    path: /system/metadata/table_comments
    method: GET
    data_selector: records
- name: runtime.nodes
  endpoint:
    path: /system/runtime/nodes
    method: GET
    data_selector: records
- name: runtime.optimizer_rule_stats
  endpoint:
    path: /system/runtime/optimizer_rule_stats
    method: GET
    data_selector: records
- name: runtime.queries
  endpoint:
    path: /system/runtime/queries
    method: GET
    data_selector: records
- name: runtime.tasks
  endpoint:
    path: /system/runtime/tasks
    method: GET
    data_selector: records
- name: runtime.transactions
  endpoint:
    path: /system/runtime/transactions
    method: GET
    data_selector: records
- name: trinoListSchemaNames
  endpoint:
    path: /trinoListSchemaNames
    method: GET
    data_selector: schemas
    params: {}
- name: trinoListTables
  endpoint:
    path: /trinoListTables
    method: GET
    data_selector: tables
    params: {}
- name: trinoGetTableMetadata
  endpoint:
    path: /trinoGetTableMetadata
    method: GET
    data_selector: metadata
    params: {}
- name: trinoGetSplits
  endpoint:
    path: /trinoGetSplits
    method: GET
    data_selector: splits
    params: {}
- name: trinoGetIndexSplits
  endpoint:
    path: /trinoGetIndexSplits
    method: GET
    data_selector: indexSplits
    params: {}
- name: trinoGetRows
  endpoint:
    path: /trinoGetRows
    method: GET
    data_selector: rows
    params: {}
- name: information_schema
  endpoint:
    path: /SHOW SCHEMAS FROM example
    method: GET
    data_selector: schemas
- name: sf1
  endpoint:
    path: /SHOW SCHEMAS FROM example
    method: GET
    data_selector: schemas
- name: sf10
  endpoint:
    path: /SHOW SCHEMAS FROM example
    method: GET
    data_selector: schemas
- name: sf100
  endpoint:
    path: /SHOW SCHEMAS FROM example
    method: GET
    data_selector: schemas
- name: sf1000
  endpoint:
    path: /SHOW SCHEMAS FROM example
    method: GET
    data_selector: schemas
- name: sf10000
  endpoint:
    path: /SHOW SCHEMAS FROM example
    method: GET
    data_selector: schemas
- name: sf100000
  endpoint:
    path: /SHOW SCHEMAS FROM example
    method: GET
    data_selector: schemas
- name: sf300
  endpoint:
    path: /SHOW SCHEMAS FROM example
    method: GET
    data_selector: schemas
- name: sf3000
  endpoint:
    path: /SHOW SCHEMAS FROM example
    method: GET
    data_selector: schemas
- name: sf30000
  endpoint:
    path: /SHOW SCHEMAS FROM example
    method: GET
    data_selector: schemas
- name: tiny
  endpoint:
    path: /SHOW SCHEMAS FROM example
    method: GET
    data_selector: schemas
- name: information_schema
  endpoint:
    path: /schemas/information_schema
    method: SHOW
    data_selector: schemas
    params: {}
- name: sf1
  endpoint:
    path: /schemas/sf1
    method: SHOW
    data_selector: schemas
    params: {}
- name: sf100
  endpoint:
    path: /schemas/sf100
    method: SHOW
    data_selector: schemas
    params: {}
- name: sf1000
  endpoint:
    path: /schemas/sf1000
    method: SHOW
    data_selector: schemas
    params: {}
- name: sf10000
  endpoint:
    path: /schemas/sf10000
    method: SHOW
    data_selector: schemas
    params: {}
- name: sf100000
  endpoint:
    path: /schemas/sf100000
    method: SHOW
    data_selector: schemas
    params: {}
- name: sf300
  endpoint:
    path: /schemas/sf300
    method: SHOW
    data_selector: schemas
    params: {}
- name: sf3000
  endpoint:
    path: /schemas/sf3000
    method: SHOW
    data_selector: schemas
    params: {}
- name: sf30000
  endpoint:
    path: /schemas/sf30000
    method: SHOW
    data_selector: schemas
    params: {}
- name: tiny
  endpoint:
    path: /schemas/tiny
    method: SHOW
    data_selector: schemas
    params: {}
- name: delete
  endpoint:
    path: /delete
    method: DELETE
    data_selector: rows
    params: {}
- name: truncate_table
  endpoint:
    path: /sql/truncate
    method: POST
    data_selector: results
    params: {}
- name: orders
  endpoint:
    path: /create_table/orders
    method: CREATE
    data_selector: table_definition
    params:
      IF NOT EXISTS: true
      COMMENT: A table to keep track of orders.
- name: bigger_orders
  endpoint:
    path: /create_table/bigger_orders
    method: CREATE
    data_selector: table_definition
    params:
      LIKE: orders
- name: create_table_as
  endpoint:
    path: /sql/create-table-as
    method: CREATE
    data_selector: result
    params: {}
- name: DROP TABLE
  endpoint:
    path: /sql/drop-table
    method: POST
    data_selector: table_name
    params: {}
- name: schema
  endpoint:
    path: /CREATE SCHEMA
    method: POST
    data_selector: schema_creation
    params: {}
- name: drop_schema
  endpoint:
    path: /sql/drop-schema
    method: POST
    data_selector: results
    params: {}
- name: comment
  endpoint:
    path: /COMMENT
    method: POST
    data_selector: records
- name: exclude_columns
  endpoint:
    path: /functions/exclude_columns
    method: GET
    data_selector: records
- name: sequence
  endpoint:
    path: /functions/sequence
    method: GET
    data_selector: records
- name: ai_analyze_sentiment
  endpoint:
    path: /ai/analyze_sentiment
    method: POST
    data_selector: response
    params: {}
- name: ai_classify
  endpoint:
    path: /ai/classify
    method: POST
    data_selector: response
    params: {}
- name: ai_extract
  endpoint:
    path: /ai/extract
    method: POST
    data_selector: response
    params: {}
- name: ai_fix_grammar
  endpoint:
    path: /ai/fix_grammar
    method: POST
    data_selector: response
    params: {}
- name: ai_gen
  endpoint:
    path: /ai/gen
    method: POST
    data_selector: response
    params: {}
- name: ai_mask
  endpoint:
    path: /ai/mask
    method: POST
    data_selector: response
    params: {}
- name: ai_translate
  endpoint:
    path: /ai/translate
    method: POST
    data_selector: response
    params: {}
- name: array_functions
  endpoint:
    path: /functions/array
    method: GET
    data_selector: functions
    params: {}
- name: array_functions
  endpoint:
    path: /functions/array
    method: GET
    data_selector: functions
    params: {}
- name: bit_count
  endpoint:
    path: /functions/bitwise/bit_count
    method: GET
    data_selector: bit_count_function
- name: bitwise_and
  endpoint:
    path: /functions/bitwise/bitwise_and
    method: GET
    data_selector: bitwise_and_function
- name: bitwise_not
  endpoint:
    path: /functions/bitwise/bitwise_not
    method: GET
    data_selector: bitwise_not_function
- name: bitwise_or
  endpoint:
    path: /functions/bitwise/bitwise_or
    method: GET
    data_selector: bitwise_or_function
- name: bitwise_xor
  endpoint:
    path: /functions/bitwise/bitwise_xor
    method: GET
    data_selector: bitwise_xor_function
- name: bitwise_left_shift
  endpoint:
    path: /functions/bitwise/bitwise_left_shift
    method: GET
    data_selector: bitwise_left_shift_function
- name: bitwise_right_shift
  endpoint:
    path: /functions/bitwise/bitwise_right_shift
    method: GET
    data_selector: bitwise_right_shift_function
- name: bitwise_right_shift_arithmetic
  endpoint:
    path: /functions/bitwise/bitwise_right_shift_arithmetic
    method: GET
    data_selector: bitwise_right_shift_arithmetic_function
- name: bar
  endpoint:
    path: /functions/bar
    method: GET
    data_selector: definition
- name: color
  endpoint:
    path: /functions/color
    method: GET
    data_selector: definition
- name: render
  endpoint:
    path: /functions/render
    method: GET
    data_selector: definition
- name: rgb
  endpoint:
    path: /functions/rgb
    method: GET
    data_selector: definition
- name: cast
  endpoint:
    path: /functions/cast
    method: GET
    data_selector: records
- name: try_cast
  endpoint:
    path: /functions/try_cast
    method: GET
    data_selector: records
- name: format
  endpoint:
    path: /functions/format
    method: GET
    data_selector: records
- name: format_number
  endpoint:
    path: /functions/format_number
    method: GET
    data_selector: records
- name: parse_data_size
  endpoint:
    path: /functions/parse_data_size
    method: GET
    data_selector: records
- name: typeof
  endpoint:
    path: /functions/typeof
    method: GET
    data_selector: records
- name: date_and_time_functions
  endpoint:
    path: /functions/datetime
    method: GET
    data_selector: functions
- name: date_trunc
  endpoint:
    path: /functions/date_trunc
    method: GET
    data_selector: records
    params: {}
- name: date_add
  endpoint:
    path: /functions/date_add
    method: GET
    data_selector: records
    params: {}
- name: date_diff
  endpoint:
    path: /functions/date_diff
    method: GET
    data_selector: records
    params: {}
- name: parse_duration
  endpoint:
    path: /functions/parse_duration
    method: GET
    data_selector: records
    params: {}
- name: human_readable_seconds
  endpoint:
    path: /functions/human_readable_seconds
    method: GET
    data_selector: records
    params: {}
- name: date_format
  endpoint:
    path: /functions/date_format
    method: GET
    data_selector: records
    params: {}
- name: date_parse
  endpoint:
    path: /functions/date_parse
    method: GET
    data_selector: records
    params: {}
- name: extract
  endpoint:
    path: /functions/extract
    method: GET
    data_selector: records
    params: {}
- name: decimal_literals
  endpoint:
    path: /functions/decimal/literals
    method: GET
    data_selector: examples
- name: binary_arithmetic_decimal_operators
  endpoint:
    path: /functions/decimal/binary-arithmetic
    method: GET
    data_selector: operations
- name: comparison_operators
  endpoint:
    path: /functions/decimal/comparison
    method: GET
    data_selector: comparisons
- name: unary_decimal_operators
  endpoint:
    path: /functions/decimal/unary
    method: GET
    data_selector: unary_operations
- name: ST_AsBinary
  endpoint:
    path: /functions/geospatial/ST_AsBinary
    method: GET
    data_selector: varbinary
- name: ST_AsText
  endpoint:
    path: /functions/geospatial/ST_AsText
    method: GET
    data_selector: varchar
- name: ST_GeometryFromText
  endpoint:
    path: /functions/geospatial/ST_GeometryFromText
    method: GET
    data_selector: Geometry
- name: ST_GeomFromBinary
  endpoint:
    path: /functions/geospatial/ST_GeomFromBinary
    method: GET
    data_selector: Geometry
- name: ST_GeomFromKML
  endpoint:
    path: /functions/geospatial/ST_GeomFromKML
    method: GET
    data_selector: Geometry
- name: geometry_from_hadoop_shape
  endpoint:
    path: /functions/geospatial/geometry_from_hadoop_shape
    method: GET
    data_selector: Geometry
- name: ST_LineFromText
  endpoint:
    path: /functions/geospatial/ST_LineFromText
    method: GET
    data_selector: LineString
- name: ST_LineString
  endpoint:
    path: /functions/geospatial/ST_LineString
    method: GET
    data_selector: LineString
- name: ST_MultiPoint
  endpoint:
    path: /functions/geospatial/ST_MultiPoint
    method: GET
    data_selector: MultiPoint
- name: ST_Point
  endpoint:
    path: /functions/geospatial/ST_Point
    method: GET
    data_selector: Point
- name: ST_Polygon
  endpoint:
    path: /functions/geospatial/ST_Polygon
    method: GET
    data_selector: Polygon
- name: to_spherical_geography
  endpoint:
    path: /functions/geospatial/to_spherical_geography
    method: GET
    data_selector: SphericalGeography
- name: to_geometry
  endpoint:
    path: /functions/geospatial/to_geometry
    method: GET
    data_selector: Geometry
- name: relationship_tests
  endpoint:
    path: /functions/geospatial/relationship_tests
    method: GET
- name: operations
  endpoint:
    path: /functions/geospatial/operations
    method: GET
- name: accessors
  endpoint:
    path: /functions/geospatial/accessors
    method: GET
- name: aggregations
  endpoint:
    path: /functions/geospatial/aggregations
    method: GET
- name: bing_tiles
  endpoint:
    path: /functions/geospatial/bing_tiles
    method: GET
- name: encoded_polylines
  endpoint:
    path: /functions/geospatial/encoded_polylines
    method: GET
- name: approx_set
  endpoint:
    path: /functions/approx_set
    method: GET
    data_selector: results
    params: {}
- name: cardinality
  endpoint:
    path: /functions/cardinality
    method: GET
    data_selector: results
    params: {}
- name: empty_approx_set
  endpoint:
    path: /functions/empty_approx_set
    method: GET
    data_selector: results
    params: {}
- name: merge
  endpoint:
    path: /functions/merge
    method: GET
    data_selector: results
    params: {}
- name: json_exists
  endpoint:
    path: /json_exists
    method: GET
    data_selector: records
    params: {}
- name: json_query
  endpoint:
    path: /json_query
    method: GET
    data_selector: records
    params: {}
- name: json_value
  endpoint:
    path: /json_value
    method: GET
    data_selector: records
    params: {}
- name: json_table
  endpoint:
    path: /json_table
    method: GET
    data_selector: records
    params: {}
- name: features
  endpoint:
    path: /functions/features
    method: GET
    data_selector: records
    params: {}
- name: learn_classifier
  endpoint:
    path: /functions/learn_classifier
    method: GET
    data_selector: records
    params: {}
- name: classify
  endpoint:
    path: /functions/classify
    method: GET
    data_selector: records
    params: {}
- name: learn_regressor
  endpoint:
    path: /functions/learn_regressor
    method: GET
    data_selector: records
    params: {}
- name: regress
  endpoint:
    path: /functions/regress
    method: GET
    data_selector: records
    params: {}
- name: map_functions
  endpoint:
    path: /functions/map
    method: GET
    data_selector: functions
- name: mathematical_operators
  endpoint:
    path: /functions/math/operators
    method: GET
    data_selector: operators
    params: {}
- name: mathematical_functions
  endpoint:
    path: /functions/math/functions
    method: GET
    data_selector: functions
    params: {}
- name: random_functions
  endpoint:
    path: /functions/math/random
    method: GET
    data_selector: random_functions
    params: {}
- name: trigonometric_functions
  endpoint:
    path: /functions/math/trigonometric
    method: GET
    data_selector: trigonometric_functions
    params: {}
- name: geometric_functions
  endpoint:
    path: /functions/math/geometric
    method: GET
    data_selector: geometric_functions
    params: {}
- name: floating_point_functions
  endpoint:
    path: /functions/math/floating_point
    method: GET
    data_selector: floating_point_functions
    params: {}
- name: base_conversion_functions
  endpoint:
    path: /functions/math/base_conversion
    method: GET
    data_selector: base_conversion_functions
    params: {}
- name: statistical_functions
  endpoint:
    path: /functions/math/statistical
    method: GET
    data_selector: statistical_functions
    params: {}
- name: cumulative_distribution_functions
  endpoint:
    path: /functions/math/cumulative_distribution
    method: GET
    data_selector: cumulative_distribution_functions
    params: {}
- name: qdigest
  endpoint:
    path: /functions/qdigest
    method: GET
    data_selector: functions
- name: set_digest_functions
  endpoint:
    path: /functions/setdigest
    method: GET
    data_selector: functions
    params: {}
- name: system_information
  endpoint:
    path: /system
    method: GET
    data_selector: version
- name: string_functions
  endpoint:
    path: /functions/string
    method: GET
    data_selector: functions
    params: {}
- name: date_functions
  endpoint:
    path: /functions/date
    method: GET
    data_selector: functions
    params: {}
- name: tdigest_agg
  endpoint:
    path: /functions/tdigest_agg
    method: GET
    data_selector: tdigest
    params: {}
- name: uuid_function
  endpoint:
    path: /functions/uuid
    method: GET
    data_selector: uuid
    params: {}
- name: inline_udf
  endpoint:
    path: /udf/inline
    method: GET
    data_selector: functions
    params: {}
- name: catalog_udf
  endpoint:
    path: /udf/catalog
    method: GET
    data_selector: functions
    params: {}
- name: sql_user_defined_functions
  endpoint:
    path: /udf/sql
    method: GET
    data_selector: functions
    params: {}
- name: python_user_defined_functions
  endpoint:
    path: /udf/python
    method: GET
    data_selector: functions
    params: {}
- name: create_function
  endpoint:
    path: /create/function
    method: POST
    data_selector: udf_definition
- name: drop_function
  endpoint:
    path: /sql/drop/function
    method: GET
    data_selector: records
    params: {}
- name: functions
  endpoint:
    path: /functions
    method: GET
    data_selector: functions
    params: {}
- name: globally_available_statements
  endpoint:
    path: /sql/globally-available-statements
    method: GET
    data_selector: statements
    params: {}
- name: catalog_management_statements
  endpoint:
    path: /sql/catalog-management-statements
    method: GET
    data_selector: statements
    params: {}
- name: read_operations
  endpoint:
    path: /sql/read-operations
    method: GET
    data_selector: statements
    params: {}
- name: write_operations
  endpoint:
    path: /sql/write-operations
    method: GET
    data_selector: statements
    params: {}
- name: security_operations
  endpoint:
    path: /sql/security-operations
    method: GET
    data_selector: statements
    params: {}
- name: transactions
  endpoint:
    path: /sql/transactions
    method: GET
    data_selector: statements
    params: {}
- name: create_role
  endpoint:
    path: /sql/create-role
    method: POST
    data_selector: role_creation_response
- name: CALL
  endpoint:
    path: /CALL
    method: POST
    data_selector: procedure_name
    params: {}
- name: deallocate_prepare
  endpoint:
    path: /sql/deallocate-prepare
    method: POST
    data_selector: statement_name
    params: {}
- name: describe_input
  endpoint:
    path: /describe/input
    method: GET
    data_selector: parameters
    params: {}
- name: describe_output
  endpoint:
    path: /describe/output
    method: GET
    data_selector: columns
    params: {}
- name: execute
  endpoint:
    path: /sql/execute
    method: POST
    data_selector: results
- name: execute_immediate
  endpoint:
    path: /sql/execute-immediate
    method: GET
    data_selector: statement
    params: {}
- name: EXPLAIN
  endpoint:
    path: /sql/explain
    method: GET
    data_selector: output
    params: {}
- name: explain_analyze
  endpoint:
    path: /sql/explain-analyze
    method: GET
    data_selector: query_plan
    params: {}
- name: PREPARE
  endpoint:
    path: /sql/prepare
    method: POST
    data_selector: query
    params: {}
- name: reset_session
  endpoint:
    path: /reset/session
    method: POST
    data_selector: session_properties
- name: session_property
  endpoint:
    path: /set/session
    method: SET
    data_selector: session
    params: {}
- name: catalog_session_property
  endpoint:
    path: /set/session/catalog.name
    method: SET
    data_selector: catalog_session
    params: {}
- name: set_time_zone
  endpoint:
    path: /sql/set-time-zone
    method: SET
    data_selector: session
    params: {}
- name: session_properties
  endpoint:
    path: /SHOW SESSION
    method: GET
    data_selector: session_properties
- name: USE
  endpoint:
    path: /USE
    method: GET
    data_selector: records
    params: {}
- name: VALUES
  endpoint:
    path: /VALUES
    method: GET
    data_selector: row
    params: {}
- name: SELECT
  endpoint:
    path: /sql/select
    method: GET
    data_selector: query_results
- name: shipping
  endpoint:
    path: /shipping
    method: SELECT
    data_selector: _col0
    params: {}
- name: customer
  endpoint:
    path: /customer
    method: SELECT
    data_selector: _col0
    params: {}
- name: orders
  endpoint:
    path: /orders
    method: SELECT
    data_selector: _col0
    params: {}
- name: orders
  endpoint:
    path: /orders
    method: SELECT
    data_selector: rows
    params: {}
- name: describe
  endpoint:
    path: /describe
    method: GET
    data_selector: columns
- name: catalogs
  endpoint:
    path: /SHOW_CATALOGS
    method: GET
    data_selector: results
    params: {}
- name: columns
  endpoint:
    path: /SHOW COLUMNS
    method: GET
    data_selector: columns
    params: {}
- name: SHOW CREATE MATERIALIZED VIEW
  endpoint:
    path: /sql/show_create_materialized_view
    method: GET
    data_selector: view_name
- name: show_create_schema
  endpoint:
    path: /sql/show-create-schema
    method: GET
- name: orders
  endpoint:
    path: /SHOW CREATE TABLE sf1.orders
    method: GET
    data_selector: Create Table
- name: create_view
  endpoint:
    path: /sql/show_create_view
    method: GET
    data_selector: view_name
- name: grants
  endpoint:
    path: /SHOW_GRANTS
    method: GET
    data_selector: grants
    params: {}
- name: roles
  endpoint:
    path: /SHOW_ROLES
    method: GET
    data_selector: roles
- name: schemas
  endpoint:
    path: /SHOW SCHEMAS
    method: GET
- name: tables
  endpoint:
    path: /v1/tables
    method: GET
    data_selector: tables
- name: merge
  endpoint:
    path: /sql/merge
    method: GET
    data_selector: records
- name: ALTER TABLE
  endpoint:
    path: /sql/alter-table
    method: POST
    data_selector: results
    params: {}
- name: alter_schema
  endpoint:
    path: /sql/alter-schema
    method: POST
    data_selector: schema_changes
    params: {}
- name: view
  endpoint:
    path: /CREATE_VIEW
    method: CREATE
    data_selector: query
    params: {}
- name: drop_view
  endpoint:
    path: /sql/drop-view
    method: POST
    data_selector: view_name
    params: {}
- name: alter_view
  endpoint:
    path: /sql/alter-view
    method: ALTER
    data_selector: definition
    params: {}
- name: materialized_view
  endpoint:
    path: /create/materialized/view
    method: POST
    data_selector: materialized_views
    params: {}
- name: alter_materialized_view
  endpoint:
    path: /sql/alter_materialized_view
    method: POST
    data_selector: results
- name: drop_materialized_view
  endpoint:
    path: /sql/drop_materialized_view
    method: POST
    data_selector: results
    params:
      view_name: string
- name: refresh_materialized_view
  endpoint:
    path: /refresh/materialized/view
    method: POST
    data_selector: view_name
- name: grant_role
  endpoint:
    path: /sql/grant_role
    method: POST
    data_selector: roles
    params: {}
- name: role_grants
  endpoint:
    path: /sql/show-role-grants
    method: GET
    data_selector: roles
    params: {}
- name: grant_privilege
  endpoint:
    path: /sql/grant
    method: POST
    data_selector: grants
    params: {}
- name: revoke_privilege
  endpoint:
    path: /sql/revoke
    method: POST
    data_selector: response
    params: {}
- name: start_transaction
  endpoint:
    path: /start-transaction
    method: POST
    data_selector: transaction
    params: {}
- name: commit
  endpoint:
    path: /commit
    method: POST
- name: ROLLBACK
  endpoint:
    path: /sql/rollback
    method: POST
    data_selector: null
    params: {}
- name: alter_branch
  endpoint:
    path: /sql/alter-branch
    method: POST
    data_selector: result
- name: create_branch
  endpoint:
    path: /create_branch
    method: CREATE
    data_selector: branch
    params: {}
- name: DROP BRANCH
  endpoint:
    path: /sql/drop-branch
    method: GET
    data_selector: branch_name
    params: {}
- name: reset_session_authorization
  endpoint:
    path: /reset/session/authorization
    method: POST
    data_selector: response
- name: set_path
  endpoint:
    path: /sql/set-path
    method: POST
    data_selector: result
    params: {}
- name: session_authorization
  endpoint:
    path: /set/session/authorization
    method: SET
    data_selector: response
    params: {}
- name: branches
  endpoint:
    path: /SHOW_BRANCHES
    method: GET
    data_selector: branches
- name: SHOW CREATE FUNCTION
  endpoint:
    path: /SHOW CREATE FUNCTION
    method: GET
- name: plugin_metadata
  endpoint:
    path: /plugin/metadata
    method: GET
    data_selector: metadata
    params: {}
- name: plugin
  endpoint:
    path: /plugin
    method: GET
    data_selector: plugins
    params: {}
- name: PasswordAuthenticatorFactory
  endpoint:
    path: /etc/password-authenticator.properties
    method: GET
    data_selector: properties
    params: {}
- name: certificate_authenticator
  endpoint:
    path: /certificate-authenticator
    method: GET
    data_selector: properties
    params: {}
- name: GroupProvider
  endpoint:
    path: /etc/group-provider.properties
    method: GET
    data_selector: properties
    params: {}
notes:
- If the request returns a 429 status code, the client should retry the request using
  the `Retry-After` header value provided.
- Trino needs a data directory for storing logs, etc.
- The user that runs the Trino process must have full read access to the installation
  directory.
- For larger clusters, processing work on the coordinator can impact query performance.
- The image already contains a default configuration to get started
- To avoid having to create catalog files and mount them in the container, you can
  enable dynamic catalog management by setting the CATALOG_MANAGEMENT environmental
  variable to dynamic
- Unlike some Kubernetes applications, where its better to have many small pods,
  Trino works best with fewer pods each having more resources available.
- Every Trino plugin must be in a separate directory underneath the plugin directory.
- Do not put JAR files directly into the plugin directory.
- All authentication requires secure connections using TLS and HTTPS or process forwarding
  enabled.
- Resource groups place limits on resource usage, and can enforce queueing policies
  on queries.
- The configuration is reloaded from the database every second.
- The environment name is 'test_environment', make sure it matches `node.environment`
  in your cluster.
- Fault-tolerant execution is turned off by default.
- Support for fault-tolerant execution of SQL statements varies on a per-connector
  basis.
- This property enables redistribution of data before writing, which can eliminate
  the performance impact of data skew.
- 'The retry policy to use for Fault-tolerant execution. Supports the following values:
  NONE, TASK, QUERY.'
- The shared secret is used to generate authentication cookies for users of the Web
  UI.
- Logging configuration is optional and set in the log.properties file.
- Logging output is file-based with rotated files in var/log.
- Tracing is not enabled by default.
- The exporter endpoint must specify a URL that is accessible from the coordinator
  and all workers of the cluster.
- You have to enable JMX by setting the ports used by the RMI registry and server
  in the config.properties file.
- Many monitoring solutions support JMX.
- The endpoint is protected with the configured authentication.
- User must have read permission to system information on a secured deployment.
- The spooling protocol requires object storage and configuration on the Trino cluster.
- The direct protocol requires no configuration.
- Trino CLI supports many authentication types including Username and password, SSO,
  Certificate, JWT, and Kerberos.
- The CLI can read default values for all options from a file.
- The default value is ALIGNED in interactive mode, and CSV in non-interactive mode.
- The JDBC driver version should be identical to the version of the Trino cluster,
  or newer.
- Older versions typically work, but only a subset is regularly tested.
- Trino includes a native implementation to access Amazon S3 and compatible storage
  systems.
- Activate the native implementation for Google Cloud Storage support.
- Start with simple password file authentication before configuring another provider.
- Trino runs with no security by default.
- All authentication technologies supported by Trino require configuring TLS as the
  foundational layer.
- Best practice is to use an external load balancer to terminate TLS/HTTPS.
- Password protected PEM files are not supported by Trino.
- Certificates without SANs are not supported.
- Keystores always require a password.
- Modern browsers now enforce 398 days as the maximum validity period for a certificate.
- All authentication requires secure connections using TLS and HTTPS or process forwarding
  enabled, and a configured shared secret.
- Using TLS and a configured shared secret is required for password file authentication.
- Using TLS and a configured shared secret is required for LDAP authentication.
- Using TLS and a configured shared secret is required for Salesforce authentication.
- Using TLS is required for OAuth 2.0 authentication.
- Kerberos authentication requires HTTPS access for the Trino coordinator.
- Kerberos configuration changes are made on the Trino coordinator.
- Certificate authentication requires a configured shared secret and TLS.
- The server asks for a certificate from clients, but allows connection if another
  authentication method passes.
- Trino supports Base64 encoded JWTs, but not encrypted JWTs.
- JWT authentication is typically used in addition to other authentication methods.
- Group providers in Trino map usernames onto groups for easier access control and
  resource group management.
- Using multiple access control systems can be very complex to configure and maintain.
- Each system and policy within each system is evaluated for each query, which can
  have a considerable, negative performance impact.
- Access control rules are defined in manually-configured JSON files.
- These rules do not apply to system-defined tables in the information_schema schema.
- Users always have access to functions in the system.builtin schema, and you cannot
  override this behavior by adding a rule.
- Access to a Apache Ranger deployment with the desired authorization policies.
- Access to an audit store using Solr, HDFS, Log4J, or S3 to save audit logs.
- Apache Ranger 2.5.0 and greater include the required Trino service definition.
- Enabling encryption impacts performance.
- By default, internal communication with SSL/TLS enabled uses HTTP/2 for increased
  scalability.
- Secrets support allows the use of environment variables for configuration properties.
- The Web UI can be disabled entirely with the web-ui.enabled property.
- The default configuration file is etc/access-control.properties
- The Preview Web UI is not suitable for production usage, and only available for
  testing and evaluation purposes.
- The spill to disk feature and implementation are a legacy functionality of Trino.
- Consider using Fault-tolerant execution with the task retry policy and a configured
  Exchange manager.
- Enabling spill-to-disk does not guarantee execution of all memory intensive queries.
- All matching rules contribute to constructing a list of session properties.
- Rules are applied in the order they are specified.
- Distributed sort is enabled via the distributed_sort session property, or distributed-sort
  configuration property set in etc/config.properties of the coordinator.
- Distributed sort is enabled by default.
- Dynamic filtering is enabled by default.
- Dynamic filtering optimizations significantly improve the performance of queries
  with selective joins.
- If your cluster is secure, you need to provide a basic-authorization header, or
  satisfy whatever other security you have enabled.
- If you have TLS/HTTPS enabled, you have to ensure the worker certificate is CA signed,
  or trusted by the server calling the shut down endpoint.
- The default System access control does not allow graceful shutdowns.
- Kafka events are sent with additional metadata populated from environment variables.
- Kafka publisher initialization can fail due to network issues reaching the Kafka
  brokers.
- This feature is experimental only. Because of the security implications the syntax
  might change and be backward incompatible.
- Some connectors are known not to release all resources when dropping a catalog that
  uses such connector.
- Default local concurrency for parallel operators is based on the number of physical
  CPUs with a minimum value of 2 and a maximum of 32.
- Trino supports several cost based optimizations.
- Support for pushdown is specific to each connector and the relevant underlying database
  or storage system.
- These optimizations are only available when Fault-tolerant execution is enabled.
- To deactivate all adaptive plan optimizations, set the fault-tolerant-execution-adaptive-query-planning-enabled
  configuration property to false.
- The equivalent session property is fault_tolerant_execution_adaptive_query_planning_enabled.
- By default, Trino enables adaptive reordering of partitioned joins.
- To deactivate this optimization, set the fault-tolerant-execution-adaptive-join-reordering-enabled
  configuration property to false.
- The equivalent session property is fault_tolerant_execution_adaptive_join_reordering_enabled.
- The BigQuery connector can only access a single GCP project.
- Reading from views is disabled by default. In order to enable it, set the bigquery.views-enabled
  configuration property to true.
- Two special partitions __NULL__ and __UNPARTITIONED__ are not supported.
- The connector discards all written data. While read operations are supported, they
  return rows with all NULL values, with the number of rows controlled via table properties.
- Queries without filters containing the partition key result in fetching all partitions.
- IN list filters are only allowed on index columns.
- No other types are supported.
- The connector can natively read the Delta Lake transaction log and thus detect when
  external systems change data.
- The connector supports read and write operations on shallow cloned tables.
- The connector provides the ability to read Change Data Feed (CDF) entries.
- 'Using an in-memory DuckDB database jdbc:duckdb: is not supported.'
- If your Exasol database uses a self-signed TLS certificate you must specify the
  certificates fingerprint in the JDBC URL using parameter fingerprint.
- The metadata sheet must be shared with the service account user, the one for which
  the key credentials file was created.
- After data is written to a table, the table contents are removed from the cache.
- The connector supports accessing various file systems including Azure Storage, Google
  Cloud Storage, S3, and HDFS.
- Fault-tolerant execution of query processing is supported.
- The optimize command is disabled by default, and can be enabled for a catalog with
  the <catalog-name>.non_transactional_optimize_enabled session property.
- For security reasons, the sys system catalog is not accessible.
- Hives timestamp with local zone data type is mapped to timestamp with time zone
  with UTC timezone. It only supports reading values - writing to tables with columns
  of this type is not supported.
- Due to Hive issues HIVE-21002 and HIVE-22167, Trino does not correctly read TIMESTAMP
  values from Parquet, RCBinary, or Avro file formats created by Hive 3.1 or later.
  When reading from these file formats, Trino returns different results than Hive.
- Trino does not support gathering table statistics for Hive transactional tables.
  You must use Hive to gather table statistics with ANALYZE statement after table
  creation.
- Hudi version 0.12.3 or higher is required.
- Data files must be stored in the Parquet file format.
- The Hive metastore catalog is the default implementation.
- You must select and configure one of the supported file systems.
- The Iceberg connector supports Kerberos authentication for the Hive metastore and
  HDFS.
- The Iceberg connector allows you to choose one of several means of providing authorization
  at the catalog level.
- The default value for the threshold is 100MB.
- The default value for retention_threshold is 7d.
- Creating a materialized view does not automatically populate it with data. You must
  run REFRESH MATERIALIZED VIEW to populate data in the materialized view.
- Updating the data in the materialized view can be achieved using the REFRESH MATERIALIZED
  VIEW command.
- Connector requires Ignite version 2.9.0 or later.
- Use secrets to avoid actual values in the catalog properties files.
- Double backslashes are required in MBean names for proper escaping.
- A table definition file must be defined for the encoder to work.
- The raw encoder requires the field size to be known ahead of time.
- If no table definition file exists for a table, the dummy decoder is used, which
  does not expose any columns.
- MariaDB version 10.10 or higher is required.
- Port 3306 is the default port.
- With transactions disabled, no rollback can be performed.
- The query engine does not preserve the order of the results of this function.
- When one worker fails/restarts, all data that was stored in its memory is lost.
- When a query fails for any reason during writing to memory table, the table enters
  an undefined state.
- When the coordinator fails/restarts, all metadata about tables is lost.
- Uses ObjectId for unique identification of documents
- OpenSearch 1.1.0 or higher is required.
- Network access from the Trino coordinator and workers to the OpenSearch nodes is
  required.
- Oracle does not expose metadata comment via REMARKS column by default in JDBC driver.
- The Oracle user must have access to the table in order to access it from Trino.
- Certain JDBC driver settings and logging configurations might cause the comment
  to be removed.
- Trino disables support for Oracle SYNONYM by default.
- Pinot 1.1.0 or higher required
- Network access from the Trino coordinator and workers to the Pinot controller nodes
  is necessary
- Only UPDATE statements with constant assignments and predicates are supported.
- Arithmetic expressions, function calls, and other non-constant UPDATE statements
  are not supported.
- If a WHERE clause is specified, the DELETE operation only works if the predicate
  in the clause can be fully pushed down to the data source.
- The connector does not support renaming tables across multiple schemas.
- The connector supports renaming a schema with the ALTER SCHEMA RENAME statement.
- The query engine does not preserve the order of the results of the query function.
- To connect to SingleStore, you need version 7.8 or higher.
- Network access from the Trino coordinator and workers to SingleStore. Port 3306
  is the default port.
- By default, values that require rounding or truncation to fit will cause a failure
  at runtime.
- The Snowflake connector uses Apache Arrow as the serialization format when reading
  from Snowflake.
- The Snowflake connector can only access a single database within a Snowflake account.
- Data can be corrupted in rare cases when non-transactional insert is enabled.
- The query engine does not preserve the order of results for passthrough queries.
- The connector can query a single database on a given SQL Server instance.
- The JDBC driver automatically uses Transport Layer Security (TLS) encryption and
  certificate validation.
- Some connectors have limited or no support for DELETE.
- Support for table replacement varies across connectors.
- The schema must be empty.
- The optional `IF EXISTS` clause causes the error to be suppressed if the schema
  does not exist.
- Aggregate functions operate on a set of values to compute a single result.
- The SQL standard describes the datetime() JSON path item method and the like_regex()
  JSON path predicate. Trino does not support them.
- The JSON path language is case-sensitive.
- Use quoted identifiers in the PASSING clause.
- 'Most SQL expressions can be used in a lambda body, with a few exceptions: Subqueries
  are not supported.'
- Aggregations are not supported.
- Trino offers several functions that deal with the MinHash technique.
- Set Digest functions can be used to estimate the similarity between sets.
- Functions assume that the input strings contain valid UTF-8 encoded Unicode code
  points.
- The functions operate on Unicode code points and not user visible characters.
- Custom functions can alternatively be written in Java and deployed as a plugin.
- Processing UDFs can potentially be resource intensive on the cluster in terms of
  memory and processing.
- Default language for UDFs is SQL
- UDFs must be declared before they are referenced.
- Recursion cannot be declared or processed.
- Mutual recursion cannot be declared or processed.
- Queries cannot be processed in a UDF.
- Python UDFs run in a sandboxed environment with specific libraries available.
- List functions in schema or all functions in the current session path.
- Use the optional FROM keyword to only list functions in a specific catalog and schema.
- Some connectors do not support role management.
- The output format is not guaranteed to be backward compatible across Trino versions.
- The stats may not be entirely accurate, especially for queries that complete quickly.
- Setting the default time zone for the session has no effect if the sql.forced-session-time-zone
  configuration property is already set.
- The complete CREATE CATALOG query is logged, and visible in the Web UI.
- This command requires the catalog management type to be set to dynamic.
- Ensure that authentication has been enabled before running any of the authorization
  commands.
- Some connectors have no support for SHOW GRANTS.
- Some connectors have limited or no support for UPDATE.
- Any connector can be used as a source table for a MERGE statement.
- Only connectors which support the MERGE statement can be the target of a merge operation.
- The optional GRACE PERIOD clause specifies how long the query materialization is
  used for querying.
- The optional COMMENT clause causes a string comment to be stored with the metadata
  about the materialized view.
- The optional WITH clause is used to define properties for the materialized view
  creation.
- The system access controls as well as the connectors provided by default in Trino
  have no support for DENY.
- Some connectors have no support for GRANT.
- Some connectors have no support for REVOKE.
- The output mode of pattern recognition in window is a combination of ONE ROW PER
  MATCH and WITH UNMATCHED ROWS.
- Plugins must implement the interfaces and override methods defined by the Service
  Provider Interface (SPI).
- All tests must use JUnit 5.
- All tests must use statically imported AssertJ assertions, typically from `org.assertj.core.api.Assertions`.
- Uses OAuth2 with refresh token  requires setup of connected app in api
- This connector is just an example. It supports a very limited set of data types
  and does not support any advanced functions, like predicate or other kind of pushdowns.
- The implementation of PasswordAuthenticatorFactory must be wrapped as a plugin and
  installed on the Trino cluster.
- The coordinator must be configured to use password authentication and have HTTPS
  enabled (or HTTPS forwarding enabled).
- The coordinator must be configured to use certificate authentication and have HTTPS
  enabled.
- The coordinator must be configured to use header authentication and have HTTPS enabled
  (or HTTPS forwarding enabled).
- The group-provider.name property is used by Trino to find a registered GroupProviderFactory
  based on the name returned by GroupProviderFactory.getName().
- Trino uses ANSI SQL syntax and semantics.
errors:
- '502: Intermittent problem processing request'
- '503: Intermittent problem processing request'
- '504: Intermittent problem processing request'
- '429: Throttle API calls or reduce frequency'
- Configuration errors may occur if required tables do not exist.
- This connector does not support query retries
- '401 Unauthorized: Recheck user permissions or authentication configuration'
- 'USER_CANCELED: Client fails to fetch the result set.'
- 'Trust this certificate? [no]:'
- 'java.security.cert.CertificateException: No subject alternative names present'
- 'javax.naming.CommunicationException: simple bind failed: ldapserver:636'
- '401 Unauthorized: Recheck access control configurations'
- 'Out of memory: when the query runner fails to divide intermediate data into chunks
  small enough.'
- Queries may fail with "not enough replicas".
- Retention specified is shorter than the minimum retention configured in the system.
- '401 Unauthorized: Recheck username or password'
- '503 Service Unavailable: Check if OpenSearch is running or if network access is
  blocked'
- Only UPDATE statements with constant assignments and predicates are supported.
- If a WHERE clause is specified, the DELETE operation only works if the predicate
  in the clause can be fully pushed down to the data source.
- DELETE operation only works if the predicate in the clause can be fully pushed down
  to the data source.
- The connector does not support renaming tables across multiple schemas.
- 'REQUEST_LIMIT_EXCEEDED: Throttle API calls or reduce frequency'
- 'QUERY_TIMEOUT: Break down filters or add selectivity'
- '401 Unauthorized: Recheck OAuth scopes or token expiration'
- Input conversion errors, such as malformed JSON
- JSON path evaluation errors, e.g. division by zero
- Returned scalar not convertible to the desired type
auth_info:
  mentioned_objects:
  - OAuth2
  - http-server.authentication.password.user-mapping.pattern
  - http-server.authentication.oauth2.user-mapping.pattern
  - http-server.authentication.certificate.user-mapping.pattern
  - http-server.authentication.header.user-mapping.pattern
  - http-server.authentication.jwt.user-mapping.pattern
  - http-server.authentication.krb5.user-mapping.pattern
  - http-server.authentication.insecure.user-mapping.pattern
client:
  base_url: https://trino.io
  headers:
    Accept: application/json
source_metadata: null
