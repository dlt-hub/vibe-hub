resources:
- name: sample_datasets
  endpoint:
    path: /
    method: GET
    data_selector: data
    params: {}
- name: data
  endpoint:
    path: /v3/table/<database>/<table>
    method: GET
    data_selector: records
    params: {}
- name: sample_datasets
  endpoint:
    path: /sample_datasets
    method: GET
    data_selector: data
    params: {}
- name: databases
  endpoint:
    path: /td/databases
    method: GET
    data_selector: data
- name: tables
  endpoint:
    path: /td/tables
    method: GET
    data_selector: data
- name: jobs
  endpoint:
    path: /td/jobs
    method: GET
    data_selector: data
- name: sample_datasets.nasdaq
  endpoint:
    path: /sample_datasets/nasdaq
    method: GET
    data_selector: records
    params: {}
- name: databases
  endpoint:
    path: /databases
    method: GET
    data_selector: databases
- name: tables
  endpoint:
    path: /tables
    method: GET
    data_selector: tables
- name: QueryEngine
  endpoint:
    path: /pytd/query_engine
    method: GET
notes:
- Set your API key to the environment variable, TD_API_KEY, and endpoint to TD_API_SERVER.
- Uses OAuth2 with refresh token â€” requires setup of connected app in Treasure Data
- There is a known difference to `pandas_td.to_td` function for type conversion.
- Uses environment variables TD_API_KEY and TD_API_SERVER for configuration.
- This method converts the dataframe into a series of key-value pairs and send them
  using the Treasure Data streaming API.
- If no apikey is provided, environment variable TD_API_KEY is used by default.
- Default database name is 'sample_datasets'.
errors:
- 'REQUEST_LIMIT_EXCEEDED: Throttle API calls or reduce frequency'
- 'QUERY_TIMEOUT: Break down filters or add selectivity'
- '401 Unauthorized: Recheck OAuth scopes or token expiration'
- 'API_KEY_NOT_FOUND: Ensure TD_API_KEY environment variable is set.'
auth_info:
  mentioned_objects: []
client:
  base_url: https://api.treasuredata.com/
  headers:
    Accept: application/json
source_metadata: null
