resources:
- name: projects
  endpoint:
    path: /projects
    method: GET
- name: sessions
  endpoint:
    path: /api/sessions
    method: GET
    data_selector: data
    params: {}
- name: users
  endpoint:
    path: /api/users
    method: GET
    data_selector: data
    params: {}
- name: tracing
  endpoint:
    path: /api/v1/traces
    method: GET
    data_selector: records
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
- name: events
  endpoint:
    path: /api/v1/events
    method: POST
    data_selector: data
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
- name: Hobby
  endpoint:
    path: /pricing/hobby
    method: GET
    data_selector: features
    params: {}
- name: Core
  endpoint:
    path: /pricing/core
    method: GET
    data_selector: features
    params: {}
- name: Pro
  endpoint:
    path: /pricing/pro
    method: GET
    data_selector: features
    params: {}
- name: Enterprise
  endpoint:
    path: /pricing/enterprise
    method: GET
    data_selector: features
    params: {}
- name: tracing
  endpoint:
    path: /api/v1/tracing
    method: GET
    data_selector: records
- name: sessions
  endpoint:
    path: /api/sessions
    method: GET
    data_selector: data
- name: users
  endpoint:
    path: /api/users
    method: GET
    data_selector: data
- name: observability
  endpoint:
    path: /api/v1/observability
    method: GET
    data_selector: data
    params: {}
- name: metrics
  endpoint:
    path: /api/v1/metrics
    method: GET
    data_selector: data
    params: {}
- name: start_generation
  endpoint:
    path: /start_generation
    method: POST
    data_selector: LangfuseGeneration
    params: {}
- name: start_as_current_generation
  endpoint:
    path: /start_as_current_generation
    method: POST
    data_selector: LangfuseGeneration
    params: {}
- name: update_current_generation
  endpoint:
    path: /update_current_generation
    method: POST
    data_selector: LangfuseGeneration
    params: {}
- name: update_current_span
  endpoint:
    path: /update_current_span
    method: POST
    data_selector: parameters
    params: {}
- name: update_current_trace
  endpoint:
    path: /update_current_trace
    method: POST
    data_selector: parameters
    params: {}
- name: create_event
  endpoint:
    path: /create_event
    method: POST
    data_selector: parameters
    params: {}
- name: create_trace_id
  endpoint:
    path: /create_trace_id
    method: GET
    data_selector: parameters
    params: {}
- name: create_score
  endpoint:
    path: /create_score
    method: POST
    data_selector: parameters
    params: {}
- name: dataset
  endpoint:
    path: /datasets
    method: GET
    params: {}
- name: dataset_item
  endpoint:
    path: /dataset_items
    method: POST
    params: {}
- name: LangfuseSpan
  endpoint:
    path: /langfuse/span
    method: GET
    data_selector: records
- name: LangfuseEvent
  endpoint:
    path: /langfuse/event
    method: GET
    data_selector: records
- name: create_prompt
  endpoint:
    path: /prompts
    method: POST
    data_selector: prompt
    params: {}
- name: update_prompt
  endpoint:
    path: /prompts/{name}/versions/{version}
    method: PUT
    data_selector: updated_prompt
    params: {}
- name: get_client
  endpoint:
    path: /clients
    method: GET
    data_selector: client_instance
    params: {}
- name: LangfuseSpan
  endpoint:
    path: /start_span
    method: POST
- name: LangfuseGeneration
  endpoint:
    path: /start_generation
    method: POST
- name: LangfuseGeneration
  endpoint:
    path: /start_as_current_generation
    method: POST
    data_selector: generation
    params: {}
- name: create_event
  endpoint:
    path: /create_event
    method: POST
    data_selector: event
    params: {}
- name: generation
  endpoint:
    path: /update
    method: POST
    data_selector: generation
    params: {}
- name: event
  endpoint:
    path: /event
    method: POST
    data_selector: event
    params: {}
- name: metrics
  endpoint:
    path: /api/v1/metrics
    method: GET
    data_selector: data
- name: traces
  endpoint:
    path: /api/v1/traces
    method: GET
    data_selector: data
- name: prompts
  endpoint:
    path: /api/prompts
    method: GET
    data_selector: records
    params: {}
- name: prompts
  endpoint:
    path: /api/public/v2/prompts
    method: POST
    data_selector: null
    params: {}
- name: text_prompt
  endpoint:
    path: /get_prompt/text
    method: GET
    data_selector: prompt
    params: {}
- name: chat_prompt
  endpoint:
    path: /get_prompt/chat
    method: GET
    data_selector: prompt
    params:
      type: chat
- name: prompts
  endpoint:
    path: /api/public/v2/prompts
    method: POST
    data_selector: ''
    params: {}
- name: prompt
  endpoint:
    path: /get_prompt
    method: GET
    data_selector: prompt
- name: prompts
  endpoint:
    path: /api/public/v2/prompts
    method: POST
    data_selector: ''
    params: {}
- name: text_prompt
  endpoint:
    path: /get_prompt
    method: GET
    data_selector: prompt
- name: chat_prompt
  endpoint:
    path: /get_prompt
    method: GET
    data_selector: prompt
- name: prompt
  endpoint:
    path: /api/prompts
    method: GET
    data_selector: prompts
    params: {}
- name: prompt
  endpoint:
    path: /prompts
    method: GET
    data_selector: prompts
- name: evaluation_methods
  endpoint:
    path: /evaluation/methods
    method: GET
    data_selector: methods
- name: dataset_runs
  endpoint:
    path: /dataset/runs
    method: GET
    data_selector: runs
- name: score
  endpoint:
    path: /api/v1/scores
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: organizations
  endpoint:
    path: /organizations
    method: GET
- name: projects
  endpoint:
    path: /projects
    method: GET
- name: roles
  endpoint:
    path: /roles
    method: GET
- name: audit_logs
  endpoint:
    path: /audit-logs
    method: GET
- name: delete_single_trace
  endpoint:
    path: /api/public/traces/{traceId}
    method: DELETE
- name: delete_batch_of_traces
  endpoint:
    path: /api/public/traces
    method: DELETE
- name: llm_connection
  endpoint:
    path: /llm-connections
    method: POST
- name: projects
  endpoint:
    path: /api/public/projects
    method: POST
- name: project_membership
  endpoint:
    path: /api/public/projects/{projectId}/memberships
    method: PUT
- name: scim_users
  endpoint:
    path: /api/public/scim/Users
    method: POST
- name: usage_alerts
  endpoint:
    path: /api/v1/usage-alerts
    method: GET
    data_selector: alerts
    params: {}
- name: api_endpoints
  endpoint:
    path: /api/v1/endpoints
    method: GET
    data_selector: data
- name: traces
  endpoint:
    path: /api/v1/traces
    method: GET
    data_selector: data
    params: {}
- name: observations
  endpoint:
    path: /api/v1/observations
    method: GET
    data_selector: data
    params: {}
- name: Feature requests and bug reports
  endpoint:
    path: /orgs/langfuse/discussions
    method: GET
    data_selector: records
- name: traces
  endpoint:
    path: /api/traces
    method: GET
    data_selector: data
    params: {}
- name: observations
  endpoint:
    path: /api/observations
    method: GET
    data_selector: data
    params: {}
- name: annotation_queue_creation
  endpoint:
    path: /api/annotation_queue
    method: POST
    data_selector: data
    params: {}
- name: session_trace
  endpoint:
    path: /api/sessions/trace
    method: GET
    data_selector: records
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
- name: traces
  endpoint:
    path: /api/public/traces
    method: GET
    data_selector: records
    params: {}
- name: datasets
  endpoint:
    path: /api/public/datasets
    method: GET
    data_selector: records
    params: {}
- name: example_resource
  endpoint:
    path: /api/v1/example
    method: GET
    data_selector: data
    params: {}
- name: annotation_queue
  endpoint:
    path: /api/public/annotation-queues
    method: POST
    data_selector: application/json
- name: comments
  endpoint:
    path: /api/public/comments
    method: GET
    data_selector: data
- name: dataset_items
  endpoint:
    path: /api/public/dataset-items
    method: GET
    data_selector: data
- name: dataset_run_items
  endpoint:
    path: /api/public/dataset-run-items
    method: GET
    data_selector: data
    params:
      datasetId: ''
      runName: ''
- name: datasets
  endpoint:
    path: /api/public/v2/datasets
    method: POST
    data_selector: id
- name: health
  endpoint:
    path: /api/public/health
    method: GET
    data_selector: status
- name: ingestion
  endpoint:
    path: /api/public/ingestion
    method: POST
    data_selector: successes
- name: llm_connections
  endpoint:
    path: /api/public/llm-connections
    method: PUT
    data_selector: id
- name: llm_connections
  endpoint:
    path: /api/public/llm-connections
    method: PUT
    data_selector: null
    params: {}
- name: annotation_queues
  endpoint:
    path: /api/public/annotation-queues
    method: GET
    data_selector: null
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
- name: span_batch
  endpoint:
    path: /api/public/ingestion
    method: POST
    data_selector: data
    params: {}
- name: datasets
  endpoint:
    path: /api/v1/datasets
    method: GET
    data_selector: data
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
- name: metrics
  endpoint:
    path: /api/public/metrics/daily
    method: GET
    data_selector: data
    params: {}
- name: comments
  endpoint:
    path: /api/public/comments
    method: GET
    data_selector: records
    params: {}
- name: traces
  endpoint:
    path: /api/public/traces
    method: GET
    data_selector: records
    params: {}
- name: sessions
  endpoint:
    path: /api/v1/sessions
    method: GET
    data_selector: records
    params: {}
- name: traces
  endpoint:
    path: /api/v1/traces
    method: GET
    data_selector: records
    params: {}
- name: tracing
  endpoint:
    path: /api/v1/tracing
    method: GET
    data_selector: records
- name: evaluations
  endpoint:
    path: /api/v1/evaluations
    method: GET
    data_selector: records
- name: traces
  endpoint:
    path: /api/v1/traces
    method: GET
    data_selector: data
    params:
      incremental: updated_at
- name: scores
  endpoint:
    path: /api/v1/scores
    method: GET
    data_selector: data
    params: {}
- name: prompt
  endpoint:
    path: /get_prompt
    method: GET
    data_selector: prompt
    params: {}
- name: prompts
  endpoint:
    path: /api/public/v2/prompts
    method: POST
    data_selector: data
    params: {}
- name: text_prompt
  endpoint:
    path: /get_prompt/movie-critic
    method: GET
    data_selector: prompt
- name: chat_prompt
  endpoint:
    path: /get_prompt/movie-critic-chat
    method: GET
    data_selector: prompt
- name: evaluation_methods
  endpoint:
    path: /evaluation/methods
    method: GET
- name: dataset_runs
  endpoint:
    path: /dataset/runs
    method: GET
- name: annotation_queues
  endpoint:
    path: /api/annotation_queues
    method: POST
    data_selector: queues
- name: annotation_queues
  endpoint:
    path: /api/annotation_queues
    method: GET
- name: traces
  endpoint:
    path: /api/traces
    method: GET
- name: sessions
  endpoint:
    path: /api/sessions
    method: GET
- name: observations
  endpoint:
    path: /api/observations
    method: GET
- name: datasets
  endpoint:
    path: /api/v1/datasets
    method: GET
    data_selector: datasets
    params: {}
- name: datasets
  endpoint:
    path: /datasets
    method: GET
    data_selector: datasets
    params: {}
- name: metrics
  endpoint:
    path: /api/metrics
    method: GET
    data_selector: records
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: traces
  endpoint:
    path: /traces
    method: GET
    data_selector: traces
    params: {}
- name: postgres
  endpoint:
    path: /postgres
    method: GET
    data_selector: records
    params: {}
- name: clickhouse
  endpoint:
    path: /clickhouse
    method: GET
    data_selector: records
    params: {}
- name: minio
  endpoint:
    path: /minio
    method: GET
    data_selector: records
    params: {}
- name: redis
  endpoint:
    path: /redis
    method: GET
    data_selector: records
    params: {}
- name: traces
  endpoint:
    path: /api/traces
    method: GET
    data_selector: data
    params: {}
- name: metrics
  endpoint:
    path: /api/metrics
    method: GET
    data_selector: data
    params: {}
- name: traces
  endpoint:
    path: /api/traces
    method: GET
    data_selector: data
    params: {}
- name: observations
  endpoint:
    path: /api/observations
    method: GET
    data_selector: data
    params: {}
- name: UI Components
  endpoint:
    path: /api/v1/components
    method: GET
    data_selector: records
- name: bedrock
  endpoint:
    path: /v1/models
    method: GET
    data_selector: models
- name: bedrock_runtime
  endpoint:
    path: /v1/models/{modelId}/invoke
    method: POST
    data_selector: response
- name: anthropic_model
  endpoint:
    path: /v1/chat/completions
    method: POST
    data_selector: choices
    params: {}
- name: dataset
  endpoint:
    path: /get_dataset
    method: GET
    data_selector: items
- name: traces
  endpoint:
    path: /project/{project_id}/traces
    method: GET
    data_selector: traces
- name: traces
  endpoint:
    path: /project/{project_id}/traces
    method: GET
    data_selector: traces
    params: {}
- name: traces
  endpoint:
    path: /api/traces
    method: GET
    data_selector: traces
- name: traces
  endpoint:
    path: /api/v1/traces
    method: GET
    data_selector: data
    params: {}
- name: metrics
  endpoint:
    path: /api/v1/metrics
    method: GET
    data_selector: data
    params: {}
- name: LLM_calls
  endpoint:
    path: /calls
    method: POST
    data_selector: traces
- name: rag_evaluation
  endpoint:
    path: /api/rag/evaluate
    method: POST
    data_selector: results
    params:
      incremental: evaluation_date
- name: restaurant_options
  endpoint:
    path: /restaurants/san_francisco
    method: GET
    data_selector: restaurants
    params: {}
- name: traces
  endpoint:
    path: /api/v1/traces
    method: GET
    data_selector: traces
- name: event
  endpoint:
    path: /api/v1/events
    method: GET
    data_selector: data
    params: {}
- name: evaluations
  endpoint:
    path: /api/evaluations
    method: POST
    data_selector: evaluations
    params: {}
- name: trace
  endpoint:
    path: /traces
    method: POST
    data_selector: data
    params: {}
- name: traces
  endpoint:
    path: /fetch_traces
    method: GET
    data_selector: data
- name: evaluations
  endpoint:
    path: /get_trustworthiness_score
    method: POST
    data_selector: evaluations
- name: traces
  endpoint:
    path: /fetch_traces
    method: POST
    data_selector: data
    params: {}
- name: chat_completion
  endpoint:
    path: /chat/completions
    method: POST
    data_selector: choices
    params: {}
- name: chat_completion
  endpoint:
    path: /chat/completions
    method: POST
    data_selector: choices
    params: {}
- name: find_best_painting
  endpoint:
    path: /find_best_painting
    method: POST
    data_selector: choices
    params: {}
- name: payment_status
  endpoint:
    path: /retrieve_payment_status
    method: POST
- name: stream_completion
  endpoint:
    path: /stream_mistral_completion
    method: POST
- name: find_best_five_painter
  endpoint:
    path: /stream_find_best_five_painter_from
    method: POST
- name: mistral_completion
  endpoint:
    path: /mistral/completion
    method: POST
    data_selector: response
    params: {}
- name: stream_mistral_completion
  endpoint:
    path: /v1/stream
    method: POST
    data_selector: response
    params: {}
- name: mistral_completion
  endpoint:
    path: /v1/completions
    method: POST
    data_selector: response
    params: {}
- name: payment_transaction
  endpoint:
    path: /payment/transactions
    method: GET
    data_selector: data
    params: {}
- name: retrieve_payment_status
  endpoint:
    path: /retrieve_payment_status
    method: POST
    data_selector: status
    params: {}
- name: retrieve_payment_date
  endpoint:
    path: /retrieve_payment_date
    method: POST
    data_selector: date
    params: {}
- name: chat_completions
  endpoint:
    path: /v1/chat/completions
    method: POST
    data_selector: choices
    params: {}
- name: chat_completions
  endpoint:
    path: /v1/chat/completions
    method: POST
    data_selector: model
    params: {}
- name: chat_completions
  endpoint:
    path: /v1/chat/completions
    method: POST
    data_selector: choices
    params: {}
- name: chat_completions
  endpoint:
    path: /v1/chat/completions
    method: POST
    data_selector: messages
- name: chat_completions
  endpoint:
    path: /v1/chat/completions
    method: POST
    data_selector: choices
    params: {}
- name: chat_completions
  endpoint:
    path: /v1/chat/completions
    method: POST
    data_selector: choices
    params: {}
- name: assistant_response
  endpoint:
    path: /assistant/response
    method: POST
    data_selector: response
    params: {}
- name: assistants
  endpoint:
    path: /beta/assistants/create
    method: POST
    data_selector: assistant
    params: {}
- name: threads
  endpoint:
    path: /beta/threads
    method: POST
    data_selector: thread
    params: {}
- name: messages
  endpoint:
    path: /beta/threads/messages
    method: GET
    data_selector: messages
    params: {}
- name: runs
  endpoint:
    path: /beta/threads/runs
    method: POST
    data_selector: run
    params: {}
- name: chat
  endpoint:
    path: /chat/completions
    method: POST
    data_selector: choices
    params: {}
- name: chat_completions
  endpoint:
    path: /chat/completions
    method: POST
    data_selector: choices
    params: {}
- name: tracing
  endpoint:
    path: /api/tracing
    method: POST
- name: traces
  endpoint:
    path: /traces
    method: GET
    data_selector: traces
- name: events
  endpoint:
    path: /api/event
    method: POST
    data_selector: events
    params: {}
- name: metrics
  endpoint:
    path: /api/public/metrics
    method: GET
    data_selector: data
    params: {}
- name: daily_metrics
  endpoint:
    path: /api/public/metrics/daily
    method: GET
    data_selector: data
    params: {}
- name: cognee
  endpoint:
    path: /api/cognee
    method: POST
    data_selector: data
    params: {}
- name: scrape_website
  endpoint:
    path: /scrape
    method: POST
    data_selector: result
- name: Milvus
  endpoint:
    path: /milvus
    method: GET
    data_selector: records
    params: {}
- name: document
  endpoint:
    path: /documents
    method: POST
    data_selector: records
- name: query
  endpoint:
    path: /query
    method: POST
    data_selector: response
- name: sessions
  endpoint:
    path: /api/v1/sessions
    method: GET
    data_selector: data
    params: {}
- name: users
  endpoint:
    path: /api/v1/users
    method: GET
    data_selector: data
    params: {}
- name: ideas
  endpoint:
    path: /orgs/langfuse/discussions
    method: GET
    data_selector: discussions
    params: {}
- name: traces
  endpoint:
    path: /api/public/otel/v1/traces
    method: POST
- name: dataset_experiments
  endpoint:
    path: /datasets/experiments
    method: POST
    data_selector: results
    params: {}
- name: traces
  endpoint:
    path: /api/public/otel
    method: POST
    data_selector: traces
    params: {}
- name: gen_ai.client.token.usage
  endpoint:
    path: /v1/token_usage
    method: GET
    data_selector: data_points
    params: {}
- name: gen_ai.client.operation.duration
  endpoint:
    path: /v1/operation_duration
    method: GET
    data_selector: data_points
    params: {}
- name: gen_ai.server.time_to_first_token
  endpoint:
    path: /v1/time_to_first_token
    method: GET
    data_selector: data_points
    params: {}
- name: gen_ai.total.requests
  endpoint:
    path: /v1/total_requests
    method: GET
    data_selector: data_points
    params: {}
- name: gen_ai.usage.output_tokens
  endpoint:
    path: /v1/output_tokens
    method: GET
    data_selector: data_points
    params: {}
- name: gen_ai.usage.input_tokens
  endpoint:
    path: /v1/input_tokens
    method: GET
    data_selector: data_points
    params: {}
- name: gen_ai.usage.cost
  endpoint:
    path: /v1/cost
    method: GET
    data_selector: data_points
    params: {}
- name: gen_ai.client.token.usage
  endpoint:
    path: /v1/metrics/gen_ai/client/token/usage
    method: GET
    data_selector: data_points
    params: {}
- name: gen_ai.client.operation.duration
  endpoint:
    path: /v1/metrics/gen_ai/client/operation/duration
    method: GET
    data_selector: data_points
    params: {}
- name: gen_ai.server.time_to_first_token
  endpoint:
    path: /v1/metrics/gen_ai/server/time_to_first_token
    method: GET
    data_selector: data_points
    params: {}
- name: gen_ai.total.requests
  endpoint:
    path: /v1/metrics/gen_ai/total/requests
    method: GET
    data_selector: data_points
    params: {}
- name: gen_ai.usage.output_tokens
  endpoint:
    path: /v1/metrics/gen_ai/usage/output_tokens
    method: GET
    data_selector: data_points
    params: {}
- name: gen_ai.usage.input_tokens
  endpoint:
    path: /v1/metrics/gen_ai/usage/input_tokens
    method: GET
    data_selector: data_points
    params: {}
- name: gen_ai.usage.cost
  endpoint:
    path: /v1/metrics/gen_ai/usage/cost
    method: GET
    data_selector: data_points
    params: {}
- name: gen_ai.client.token.usage
  endpoint:
    path: /gen_ai/token_usage
    method: GET
    data_selector: data_points
    params: {}
- name: gen_ai.server.time_to_first_token
  endpoint:
    path: /gen_ai/time_to_first_token
    method: GET
    data_selector: data_points
    params: {}
- name: gen_ai.total.requests
  endpoint:
    path: /gen_ai/total_requests
    method: GET
    data_selector: data_points
    params: {}
- name: gen_ai.usage.output_tokens
  endpoint:
    path: /gen_ai/output_tokens
    method: GET
    data_selector: data_points
    params: {}
- name: gen_ai.usage.input_tokens
  endpoint:
    path: /gen_ai/input_tokens
    method: GET
    data_selector: data_points
    params: {}
- name: gen_ai.usage.cost
  endpoint:
    path: /gen_ai/cost
    method: GET
    data_selector: data_points
    params: {}
- name: gen_ai.client.token.usage
  endpoint:
    method: GET
    data_selector: data_points
- name: gen_ai.client.operation.duration
  endpoint:
    method: GET
    data_selector: data_points
- name: gen_ai.server.time_to_first_token
  endpoint:
    method: GET
    data_selector: data_points
- name: gen_ai.total.requests
  endpoint:
    method: GET
    data_selector: data_points
- name: gen_ai.usage.output_tokens
  endpoint:
    method: GET
    data_selector: data_points
- name: gen_ai.usage.input_tokens
  endpoint:
    method: GET
    data_selector: data_points
- name: gen_ai.usage.cost
  endpoint:
    method: GET
    data_selector: data_points
- name: gen_ai.client.token.usage
  endpoint:
    path: /v1/usage/token
    method: GET
    data_selector: data
- name: gen_ai.client.operation.duration
  endpoint:
    path: /v1/usage/duration
    method: GET
    data_selector: data
- name: gen_ai.server.time_to_first_token
  endpoint:
    path: /v1/usage/first_token
    method: GET
    data_selector: data
- name: gen_ai.total.requests
  endpoint:
    path: /v1/usage/requests
    method: GET
    data_selector: data
- name: gen_ai.usage.output_tokens
  endpoint:
    path: /v1/usage/output_tokens
    method: GET
    data_selector: data
- name: gen_ai.usage.input_tokens
  endpoint:
    path: /v1/usage/input_tokens
    method: GET
    data_selector: data
- name: gen_ai.usage.cost
  endpoint:
    path: /v1/usage/cost
    method: GET
    data_selector: data
- name: gen_ai.client.token.usage
  endpoint:
    path: /metrics/gen_ai.client.token.usage
    method: GET
    data_selector: data_points
    params: {}
- name: gen_ai.client.operation.duration
  endpoint:
    path: /metrics/gen_ai.client.operation.duration
    method: GET
    data_selector: data_points
    params: {}
- name: gen_ai.server.time_to_first_token
  endpoint:
    path: /metrics/gen_ai.server.time_to_first_token
    method: GET
    data_selector: data_points
    params: {}
- name: gen_ai.total.requests
  endpoint:
    path: /metrics/gen_ai.total.requests
    method: GET
    data_selector: data_points
    params: {}
- name: gen_ai.usage.output_tokens
  endpoint:
    path: /metrics/gen_ai.usage.output_tokens
    method: GET
    data_selector: data_points
    params: {}
- name: gen_ai.usage.input_tokens
  endpoint:
    path: /metrics/gen_ai.usage.input_tokens
    method: GET
    data_selector: data_points
    params: {}
- name: gen_ai.usage.cost
  endpoint:
    path: /metrics/gen_ai.usage.cost
    method: GET
    data_selector: data_points
    params: {}
- name: gen_ai.server.time_to_first_token
  endpoint:
    path: /gen_ai/server/time_to_first_token
    method: GET
    data_selector: data_points
- name: gen_ai.total.requests
  endpoint:
    path: /gen_ai/total/requests
    method: GET
    data_selector: data_points
- name: gen_ai.usage.output_tokens
  endpoint:
    path: /gen_ai/usage/output_tokens
    method: GET
    data_selector: data_points
- name: gen_ai.usage.input_tokens
  endpoint:
    path: /gen_ai/usage/input_tokens
    method: GET
    data_selector: data_points
- name: gen_ai.usage.cost
  endpoint:
    path: /gen_ai/usage/cost
    method: GET
    data_selector: data_points
- name: chat_completion
  endpoint:
    path: /v1/chat/completions
    method: POST
    data_selector: choices
    params: {}
- name: gen_ai.client.token.usage
  endpoint:
    path: /gen_ai/client/token/usage
    method: GET
    data_selector: data_points
    params: {}
- name: gen_ai.client.operation.duration
  endpoint:
    path: /gen_ai/client/operation/duration
    method: GET
    data_selector: data_points
    params: {}
- name: gen_ai.server.time_to_first_token
  endpoint:
    path: /gen_ai/server/time_to_first_token
    method: GET
    data_selector: data_points
    params: {}
- name: gen_ai.total.requests
  endpoint:
    path: /gen_ai/total/requests
    method: GET
    data_selector: data_points
    params: {}
- name: gen_ai.usage.output_tokens
  endpoint:
    path: /gen_ai/usage/output_tokens
    method: GET
    data_selector: data_points
    params: {}
- name: gen_ai.usage.input_tokens
  endpoint:
    path: /gen_ai/usage/input_tokens
    method: GET
    data_selector: data_points
    params: {}
- name: gen_ai.usage.cost
  endpoint:
    path: /gen_ai/usage/cost
    method: GET
    data_selector: data_points
    params: {}
- name: issues
  endpoint:
    path: /langfuse/langfuse/issues
    method: GET
    data_selector: issues
    params: {}
- name: Enterprise License Key
  endpoint:
    path: /self-hosting/license-key
    method: GET
- name: bullmq
  endpoint:
    path: /api/admin/bullmq
    method: GET
    data_selector: job counts for all queues
    params: {}
- name: manage_jobs
  endpoint:
    path: /api/admin/bullmq
    method: POST
    data_selector: jobs management
    params: {}
- name: traces
  endpoint:
    path: /api/v1/traces
    method: GET
    data_selector: data
    params: {}
- name: langfuse_s3_event_upload
  endpoint:
    path: /s3/event/upload
    method: POST
    data_selector: records
- name: langfuse_s3_batch_export
  endpoint:
    path: /s3/batch/export
    method: POST
    data_selector: records
- name: langfuse_s3_media_upload
  endpoint:
    path: /s3/media/upload
    method: POST
    data_selector: records
- name: ClickHouse
  endpoint:
    path: /clickhouse
    method: GET
- name: S3
  endpoint:
    path: /s3
    method: GET
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: minio_backup_sync
  endpoint:
    path: /backup
    method: POST
    data_selector: jobs
    params:
      schedule: 0 3 * * *
- name: ClickHouse
  endpoint:
    path: /clickhouse
    method: GET
- name: Postgres
  endpoint:
    path: /postgres
    method: GET
- name: MinIO
  endpoint:
    path: /minio
    method: GET
- name: OTEL_EXPORTER_OTLP_ENDPOINT
  endpoint:
    path: /v1/traces
    method: POST
    data_selector: traces
- name: web_container_health_check
  endpoint:
    path: /api/public/health
    method: GET
    data_selector: null
    params: {}
- name: web_container_readiness_check
  endpoint:
    path: /api/public/ready
    method: GET
    data_selector: null
    params: {}
- name: worker_container_health_check
  endpoint:
    path: /api/health
    method: GET
    data_selector: null
    params: {}
- name: api_key_caching
  endpoint:
    path: /api/key/caching
    method: GET
    data_selector: data
    params:
      enabled: 'true'
      ttl_seconds: 300
- name: prompt_caching
  endpoint:
    path: /api/prompt/caching
    method: GET
    data_selector: data
    params:
      enabled: 'true'
      ttl_seconds: 300
- name: custom_base_path
  endpoint:
    path: /self-hosting/custom-base-path
    method: GET
    data_selector: records
    params: {}
- name: langfuse
  endpoint:
    path: /langfuse
    method: GET
    data_selector: resources
- name: langfuse
  endpoint:
    path: /services/data/vXX.X/sobjects/Langfuse
    method: GET
- name: langfuse
  endpoint:
    path: /
    method: GET
    data_selector: records
- name: aws_eks_cluster.langfuse
- name: aws_eks_fargate_profile.namespaces
- name: aws_rds_cluster.postgres
- name: aws_elasticache_replication_group.redis
- name: aws_s3_bucket.langfuse
- name: aws_acm_certificate.cert
- name: aws_route53_zone.zone
- name: aws_iam_role.eks
- name: aws_iam_role.fargate
- name: aws_security_group.eks
- name: aws_security_group.postgres
- name: aws_security_group.redis
- name: aws_security_group.vpc_endpoints
- name: langfuse
  endpoint:
    path: module/langfuse
    method: GET
    data_selector: records
- name: langfuse
  endpoint:
    path: /self-hosting/gcp
    method: GET
    data_selector: module
    params: {}
- name: google_container_cluster.langfuse
  endpoint:
    path: /google/container/cluster
    method: GET
- name: google_container_node_pool.default
  endpoint:
    path: /google/container/node_pool
    method: GET
- name: google_sql_database_instance.postgres
  endpoint:
    path: /google/sql/database/instance
    method: GET
- name: google_sql_database.langfuse
  endpoint:
    path: /google/sql/database
    method: GET
- name: google_sql_user.langfuse
  endpoint:
    path: /google/sql/user
    method: GET
- name: google_redis_instance.redis
  endpoint:
    path: /google/redis/instance
    method: GET
- name: google_storage_bucket.langfuse
  endpoint:
    path: /google/storage/bucket
    method: GET
- name: google_compute_managed_ssl_certificate.cert
  endpoint:
    path: /google/compute/managed_ssl_certificate
    method: GET
- name: google_dns_managed_zone.zone
  endpoint:
    path: /google/dns/managed_zone
    method: GET
- name: google_dns_record_set.langfuse
  endpoint:
    path: /google/dns/record_set
    method: GET
- name: google_service_account.gke
  endpoint:
    path: /google/service/account
    method: GET
- name: google_project_iam_member.gke
  endpoint:
    path: /google/project/iam/member
    method: GET
- name: google_compute_firewall.gke
  endpoint:
    path: /google/compute/firewall
    method: GET
- name: google_compute_firewall.postgres
  endpoint:
    path: /google/compute/firewall/postgres
    method: GET
- name: google_compute_firewall.redis
  endpoint:
    path: /google/compute/firewall/redis
    method: GET
- name: google_compute_network.vpc
  endpoint:
    path: /google/compute/network
    method: GET
- name: google_compute_subnetwork.subnet
  endpoint:
    path: /google/compute/subnetwork
    method: GET
- name: google_kms_key_ring.langfuse
  endpoint:
    path: /google/kms/key_ring
    method: GET
- name: google_kms_crypto_key.langfuse
  endpoint:
    path: /google/kms/crypto_key
    method: GET
- name: kubernetes_namespace.langfuse
  endpoint:
    path: /kubernetes/namespace
    method: GET
- name: kubernetes_secret.langfuse
  endpoint:
    path: /kubernetes/secret
    method: GET
- name: helm_release.ingress_nginx
  endpoint:
    path: /helm/release/ingress_nginx
    method: GET
- name: helm_release.cert_manager
  endpoint:
    path: /helm/release/cert_manager
    method: GET
- name: random_password.database
  endpoint:
    path: /random/password/database
    method: GET
- name: tls_private_key.langfuse
  endpoint:
    path: /tls/private_key
    method: GET
- name: langfuse_web
  endpoint:
    path: /run-langfuse-web
    method: POST
    data_selector: response
    params:
      DATABASE_URL: postgresql://hello
      NEXTAUTH_URL: http://localhost:3000
      NEXTAUTH_SECRET: mysecret
      SALT: mysalt
      ENCRYPTION_KEY: '0000000000000000000000000000000000000000000000000000000000000000'
      CLICKHOUSE_URL: http://clickhouse:8123
      CLICKHOUSE_USER: clickhouse
      CLICKHOUSE_PASSWORD: clickhouse
      REDIS_HOST: localhost
      REDIS_PORT: '6379'
      REDIS_AUTH: redis
      LANGFUSE_S3_EVENT_UPLOAD_BUCKET: my-bucket
      LANGFUSE_S3_EVENT_UPLOAD_REGION: us-east-1
      LANGFUSE_S3_EVENT_UPLOAD_ACCESS_KEY_ID: AKIAIOSFODNN7EXAMPLE
      LANGFUSE_S3_EVENT_UPLOAD_SECRET_ACCESS_KEY: bPxRfiCYEXAMPLEKEY
- name: langfuse_worker
  endpoint:
    path: /run-langfuse-worker
    method: POST
    data_selector: response
    params:
      DATABASE_URL: postgresql://hello
      NEXTAUTH_URL: http://localhost:3000
      SALT: mysalt
      ENCRYPTION_KEY: '0000000000000000000000000000000000000000000000000000000000000000'
      CLICKHOUSE_URL: http://clickhouse:8123
      CLICKHOUSE_USER: clickhouse
      CLICKHOUSE_PASSWORD: clickhouse
      REDIS_HOST: localhost
      REDIS_PORT: '6379'
      REDIS_AUTH: redis
      LANGFUSE_S3_EVENT_UPLOAD_BUCKET: my-bucket
      LANGFUSE_S3_EVENT_UPLOAD_REGION: us-east-1
      LANGFUSE_S3_EVENT_UPLOAD_ACCESS_KEY_ID: AKIAIOSFODNN7EXAMPLE
      LANGFUSE_S3_EVENT_UPLOAD_SECRET_ACCESS_KEY: bPxRfiCYEXAMPLEKEY
- name: clickhouse
  endpoint:
    path: /clickhouse
    method: GET
    data_selector: records
- name: s3
  endpoint:
    path: /etc/clickhouse-server/config.d/s3disk.xml
    method: POST
    data_selector: disk
    params: {}
- name: blob_storage_disk
  endpoint:
    path: /etc/clickhouse-server/config.d/azuredisk.xml
    method: POST
    data_selector: disk
    params: {}
- name: redis_cluster
  endpoint:
    path: /services/data/v3/sobjects/RedisCluster
    method: GET
    data_selector: records
    params: {}
- name: OpenAI
  endpoint:
    path: /openai
    method: GET
- name: Azure OpenAI
  endpoint:
    path: /azure-openai
    method: GET
- name: Anthropic
  endpoint:
    path: /anthropic
    method: GET
- name: Google Vertex
  endpoint:
    path: /google-vertex
    method: GET
- name: Amazon Bedrock
  endpoint:
    path: /amazon-bedrock
    method: GET
- name: roles
  endpoint:
    path: /api/v1/roles
    method: GET
    data_selector: roles
    params: {}
- name: permissions
  endpoint:
    path: /api/v1/permissions
    method: GET
    data_selector: permissions
    params: {}
- name: data_retention
  endpoint:
    path: /services/data/vXX.X/sobjects/DataRetention
    method: GET
    data_selector: records
    params: {}
- name: organization
  endpoint:
    path: /services/data/v3.0/organization
    method: POST
    data_selector: resource
    params:
      LANGFUSE_INIT_ORG_ID: my-org
      LANGFUSE_INIT_ORG_NAME: My Org
- name: project
  endpoint:
    path: /services/data/v3.0/project
    method: POST
    data_selector: resource
    params:
      LANGFUSE_INIT_PROJECT_ID: my-project
      LANGFUSE_INIT_PROJECT_NAME: My Project
      LANGFUSE_INIT_PROJECT_PUBLIC_KEY: lf_pk_1234567890
      LANGFUSE_INIT_PROJECT_SECRET_KEY: lf_sk_1234567890
- name: user
  endpoint:
    path: /services/data/v3.0/user
    method: POST
    data_selector: resource
    params:
      LANGFUSE_INIT_USER_EMAIL: user@example.com
      LANGFUSE_INIT_USER_NAME: John Doe
      LANGFUSE_INIT_USER_PASSWORD: password123
- name: UI Customization
  endpoint:
    path: /self-hosting/ui-customization
    method: GET
    data_selector: configuration
- name: Co-branding
  endpoint:
    path: /self-hosting/ui-customization/co-branding
    method: GET
    data_selector: branding
- name: LLM API/Gateway Connection defaults
  endpoint:
    path: /self-hosting/ui-customization/llm-api-gateway
    method: GET
    data_selector: llm_connection
- name: Product Module Visibility
  endpoint:
    path: /self-hosting/ui-customization/product-module-visibility
    method: GET
    data_selector: module_visibility
- name: organizations
  endpoint:
    path: /organizations
    method: POST
- name: organization_api_keys
  endpoint:
    path: /organization_api_keys
    method: POST
- name: upgrade_guide
  endpoint:
    path: /self-hosting/upgrade
    method: GET
- name: versioning
  endpoint:
    path: /self-hosting/versioning
    method: GET
- name: release_notes
  endpoint:
    path: /self-hosting/release-notes
    method: GET
- name: ingestion
  endpoint:
    path: /api/public/ingestion
    method: POST
    data_selector: event
    params: {}
- name: scores
  endpoint:
    path: /api/public/scores
    method: POST
    data_selector: id
    params: {}
- name: models
  endpoint:
    path: /api/models
    method: POST
    data_selector: data
- name: database
  endpoint:
    path: /postgresql
    method: POST
    data_selector: data
    params: {}
- name: health_check
  endpoint:
    path: /api/public/health
    method: GET
    data_selector: status
- name: readiness_check
  endpoint:
    path: /api/public/ready
    method: GET
    data_selector: status
- name: langfuse
  endpoint:
    path: /
    method: GET
    data_selector: records
    params: {}
- name: langfuse
  endpoint:
    path: /api/langfuse
    method: GET
    data_selector: records
    params: {}
- name: account_creation
  endpoint:
    path: /auth/sign-up
    method: GET
- name: docs
  endpoint:
    path: /docs
    method: GET
    data_selector: records
- name: traces
  endpoint:
    path: /api/public/traces
    method: GET
    data_selector: data
    params: {}
- name: prompts
  endpoint:
    path: /api/public/prompts
    method: GET
    data_selector: data
    params: {}
- name: evaluations
  endpoint:
    path: /api/public/evaluations
    method: GET
    data_selector: data
    params: {}
- name: Daily Metrics API
  endpoint:
    path: /docs/analytics/daily-metrics-api
    method: GET
- name: usageDetails
  endpoint:
    path: /usageDetails
    method: GET
    data_selector: usage
    params: {}
- name: costDetails
  endpoint:
    path: /costDetails
    method: GET
    data_selector: cost
    params: {}
- name: usage_metrics
  endpoint:
    path: /api/v1/usage_metrics
    method: GET
    data_selector: data
- name: completion
  endpoint:
    path: /v1/complete
    method: POST
    data_selector: response.content
    params: {}
- name: usage
  endpoint:
    path: /api/public/models
    method: GET
    data_selector: usage_details
    params: {}
- name: usageDetails
  endpoint:
    path: /usageDetails
    method: POST
    data_selector: usage
    params: {}
- name: costDetails
  endpoint:
    path: /costDetails
    method: POST
    data_selector: cost
    params: {}
- name: annotation_queue_assignments
  endpoint:
    path: /api/annotation-queue-assignments
    method: POST
    data_selector: data
    params: {}
- name: prompt_notifications
  endpoint:
    path: /slack/prompt_notifications
    method: POST
    data_selector: notifications
    params: {}
- name: sessions
  endpoint:
    path: /api/sessions
    method: GET
    data_selector: sessions
- name: datasets
  endpoint:
    path: /datasets
    method: GET
    data_selector: datasets
    params: {}
- name: prompt_content
  endpoint:
    path: /api/v1/prompts/search
    method: GET
    data_selector: prompts
    params: {}
- name: Dataset Runs
  endpoint:
    path: /docs/evaluation/dataset-runs
    method: GET
- name: prompt_changes
  endpoint:
    path: /webhooks/prompt-changes
    method: POST
    data_selector: data
    params: {}
- name: prompts
  endpoint:
    path: /api/prompts
    method: GET
    data_selector: prompts
    params: {}
- name: prompt_management
  endpoint:
    path: /prompts
    method: GET
    data_selector: prompts
    params: {}
- name: histogram_charts
  endpoint:
    path: /docs/analytics/custom-dashboards
    method: GET
    data_selector: charts
    params: {}
- name: custom_dashboards
  endpoint:
    path: /docs/metrics/features/custom-dashboards
    method: GET
    data_selector: widgets
    params: {}
- name: annotation_queues
  endpoint:
    path: /api/public/annotation-queues
    method: GET
    data_selector: ''
    params: {}
- name: comments
  endpoint:
    path: /api/public/comments
    method: GET
    data_selector: ''
    params: {}
- name: dataset_items
  endpoint:
    path: /api/public/dataset-items
    method: GET
    data_selector: ''
    params: {}
- name: dataset_run_items
  endpoint:
    path: /api/public/dataset-run-items
    method: post
- name: dataset_run_items_list
  endpoint:
    path: /api/public/dataset-run-items
    method: get
    params:
      datasetId: string
      runName: string
- name: datasets_list
  endpoint:
    path: /api/public/v2/datasets
    method: get
- name: datasets_create
  endpoint:
    path: /api/public/v2/datasets
    method: post
- name: datasets_get
  endpoint:
    path: /api/public/v2/datasets/{datasetName}
    method: get
- name: datasets_getRuns
  endpoint:
    path: /api/public/datasets/{datasetName}/runs
    method: get
- name: datasets_deleteRun
  endpoint:
    path: /api/public/datasets/{datasetName}/runs/{runName}
    method: delete
- name: health_check
  endpoint:
    path: /api/public/health
    method: get
- name: ingestion_batch
  endpoint:
    path: /api/public/ingestion/batch
    method: POST
    data_selector: successes
    params: {}
- name: llm_connections
  endpoint:
    path: /api/public/llm-connections
    method: GET
    data_selector: llmConnections
    params: {}
- name: media
  endpoint:
    path: /api/public/media
    method: POST
    data_selector: uploadUrl
    params: {}
- name: metrics
  endpoint:
    path: /api/public/metrics
    method: GET
    data_selector: metricsData
    params: {}
- name: models
  endpoint:
    path: /api/public/models
    method: get
- name: observations
  endpoint:
    path: /api/public/observations
    method: get
- name: organizations_memberships
  endpoint:
    path: /api/public/organizations/memberships
    method: get
- name: projects
  endpoint:
    path: /api/public/projects
    method: get
- name: scores
  endpoint:
    path: /scores
    method: POST
- name: scoreById
  endpoint:
    path: /scores/{scoreId}
    method: GET
- name: deleteScore
  endpoint:
    path: /scores/{scoreId}
    method: DELETE
- name: sessions
  endpoint:
    path: /sessions
    method: GET
- name: sessionById
  endpoint:
    path: /sessions/{sessionId}
    method: GET
- name: traces
  endpoint:
    path: /traces
    method: GET
- name: traceById
  endpoint:
    path: /traces/{traceId}
    method: GET
- name: projectApiKeys
  endpoint:
    path: /api/public/projects/{projectId}/apiKeys
    method: get
    params:
      projectId: required
- name: projectApiKey
  endpoint:
    path: /api/public/projects/{projectId}/apiKeys/{apiKeyId}
    method: delete
    params:
      projectId: required
      apiKeyId: required
- name: scimUsers
  endpoint:
    path: /api/public/scim/Users
    method: get
    params: {}
- name: scimUser
  endpoint:
    path: /api/public/scim/Users/{userId}
    method: get
    params:
      userId: required
- name: Session
  endpoint:
    path: /sessions
    method: GET
    data_selector: records
- name: Observation
  endpoint:
    path: /observations
    method: GET
    data_selector: records
- name: Score
  endpoint:
    path: /scores
    method: GET
    data_selector: records
- name: IngestionSuccess
  endpoint:
    path: /ingestion/success
    method: POST
    data_selector: successes
- name: IngestionError
  endpoint:
    path: /ingestion/error
    method: POST
    data_selector: errors
- name: GetMediaUploadUrlResponse
  endpoint:
    path: /media/upload/url
    method: GET
    data_selector: uploadUrl
- name: Comment
  endpoint:
    path: ''
    method: ''
    data_selector: ''
    params: {}
- name: Dataset
  endpoint:
    path: ''
    method: ''
    data_selector: ''
    params: {}
- name: DatasetItem
  endpoint:
    path: ''
    method: ''
    data_selector: ''
    params: {}
- name: DatasetRunItem
  endpoint:
    path: ''
    method: ''
    data_selector: ''
    params: {}
- name: DatasetRun
  endpoint:
    path: ''
    method: ''
    data_selector: ''
    params: {}
- name: DatasetRunWithItems
  endpoint:
    path: ''
    method: ''
    data_selector: ''
    params: {}
- name: Model
  endpoint:
    path: ''
    method: ''
    data_selector: ''
    params: {}
- name: ObservationLevel
  endpoint:
    path: ''
    method: ''
    data_selector: ''
    params: {}
- name: IngestionEvent
  endpoint:
    path: ''
    method: ''
    data_selector: ''
    params: {}
- name: ScoreBody
  endpoint:
    path: ''
    method: ''
    data_selector: ''
    params: {}
- name: Observations
  endpoint:
    path: /observations
    method: GET
    data_selector: data
- name: Memberships
  endpoint:
    path: /memberships
    method: GET
    data_selector: memberships
- name: OrganizationProjects
  endpoint:
    path: /organization/projects
    method: GET
    data_selector: projects
- name: Traces
  endpoint:
    path: /traces
    method: GET
    data_selector: data
    params: {}
- name: PaginatedSessions
  endpoint:
    path: /paginated_sessions
    method: GET
    data_selector: data
    params: {}
- name: CreateScoreRequest
  endpoint:
    path: /create_score
    method: POST
    data_selector: id
    params: {}
- name: Dataset Run Items
  endpoint:
    path: /api/public/dataset-run-items
    method: POST
- name: Datasets
  endpoint:
    path: /api/public/v2/datasets
    method: GET
- name: Health
  endpoint:
    path: /api/public/health
    method: GET
- name: Ingestion
  endpoint:
    path: /api/public/ingestion
    method: POST
- name: ingestion
  endpoint:
    path: /api/public/ingestion
    method: POST
    data_selector: successes
    params: {}
- name: llm-connections
  endpoint:
    path: /api/public/llm-connections
    method: GET
    data_selector: ''
    params: {}
- name: media
  endpoint:
    path: /api/public/media/:mediaId
    method: GET
    data_selector: ''
    params: {}
- name: metrics
  endpoint:
    path: /api/public/metrics
    method: GET
    data_selector: ''
    params: {}
- name: models
  endpoint:
    path: /api/public/models
    method: POST
    data_selector: ''
    params: {}
- name: observations
  endpoint:
    path: /api/public/observations/:observationId
    method: GET
    data_selector: ''
    params: {}
- name: organizations
  endpoint:
    path: /api/public/organizations/memberships
    method: GET
    data_selector: ''
    params: {}
- name: List Queues
  endpoint:
    path: /api/public/annotation-queues
    method: GET
    data_selector: ''
    params:
      page: ''
      limit: ''
- name: Create Queue
  endpoint:
    path: /api/public/annotation-queues
    method: POST
    data_selector: ''
    params: {}
- name: Get Queue
  endpoint:
    path: /api/public/annotation-queues/:queueId
    method: GET
    data_selector: ''
    params: {}
- name: List Queue Items
  endpoint:
    path: /api/public/annotation-queues/:queueId/items
    method: GET
    data_selector: ''
    params:
      status: ''
      page: ''
      limit: ''
- name: Get Queue Item
  endpoint:
    path: /api/public/annotation-queues/:queueId/items/:itemId
    method: GET
    data_selector: ''
    params: {}
- name: Create Queue Item
  endpoint:
    path: /api/public/annotation-queues/:queueId/items
    method: POST
    data_selector: ''
    params: {}
- name: Update Queue Item
  endpoint:
    path: /api/public/annotation-queues/:queueId/items/:itemId
    method: PATCH
    data_selector: ''
    params: {}
- name: Delete Queue Item
  endpoint:
    path: /api/public/annotation-queues/:queueId/items/:itemId
    method: DELETE
    data_selector: ''
    params: {}
- name: Create Queue Assignment
  endpoint:
    path: /api/public/annotation-queues/:queueId/assignments
    method: POST
    data_selector: ''
    params: {}
- name: Delete Queue Assignment
  endpoint:
    path: /api/public/annotation-queues/:queueId/assignments
    method: DELETE
    data_selector: ''
    params: {}
- name: Create Comment
  endpoint:
    path: /api/public/comments
    method: POST
    data_selector: ''
    params: {}
- name: Get Comments
  endpoint:
    path: /api/public/comments
    method: GET
    data_selector: ''
    params:
      page: ''
      limit: ''
      objectType: ''
      objectId: ''
      authorUserId: ''
- name: Get Comment By Id
  endpoint:
    path: /api/public/comments/:commentId
    method: GET
    data_selector: ''
    params: {}
- name: Create Dataset Item
  endpoint:
    path: /api/public/dataset-items
    method: POST
    data_selector: ''
    params: {}
- name: Get Dataset Item
  endpoint:
    path: /api/public/dataset-items/:id
    method: GET
    data_selector: ''
    params: {}
- name: List Dataset Items
  endpoint:
    path: /api/public/dataset-items
    method: GET
    data_selector: ''
    params:
      datasetName: ''
      sourceTraceId: ''
      sourceObservationId: ''
      page: ''
      limit: ''
- name: scores
  endpoint:
    path: /api/public/v2/scores
    method: GET
    params:
      limit: ''
- name: score
  endpoint:
    path: /api/public/scores
    method: POST
- name: sessions
  endpoint:
    path: /api/public/sessions
    method: GET
    params:
      limit: ''
- name: traces
  endpoint:
    path: /api/public/traces
    method: GET
    params:
      limit: ''
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
notes:
- Rate limit exceed using Langfuse Python SDK
- Authenticate with the API using Basic Auth. The API keys are available in the Langfuse
  project settings.
- Requires setup of connected app in Langfuse
- May have limitations on data exports and API rate limits
- Requires a valid OAuth2 token for API access.
- Fully open source with public API for custom integrations
- Designed with minimal performance overhead
- Uses OAuth2 with refresh token  requires setup of connected app in api
- Uses OAuth2 with refresh token  requires setup of connected app in Langfuse
- Uses OAuth2 with refresh token requires setup of connected app in api
- Uses OAuth2 with refresh token  requires setup of connected app in api
- Some objects like Contact may return nulls in deeply nested fields
- Bug in exporting the traces to json.
- Langfuse not capturing cost and usage for the Native providers like OPENAI but only
  for models imported via Langchain.
- Is there any good way to ingest clickhouse data to gcs?
- I am unable to run the lanfuse project locally.
- Is it possible to disable observations and just keep traces?
- flowise environment variable data is not reflecting in the langfuse.
- Total Cost not displaying in traces list
- Running all pytest tests in a single trace
- Migration of Clickhouse to new location
- Tutorials/Instructions for Langfuse deployment to Azure Webapp without container
  registry or terraform
- How to track scores through session Id?
- Can't get traces for a WebSocket server
- Standard Deviation of the aggregated metrics
- LLm connection for vertex ai Models
- langfuse support Redis sentinel mode?
- Can one license key be used in multiple Langfuse deployments?
- No historical data visible after v2v3 migration (migrations finished successfully)
- Subtool/internal function calls not being traced with default configuration of langfuse
  with langgraph.
- Missing table in clickhouse
- Force running clickhouse migration again
- Some objects may return nulls in deeply nested fields
- This is mostly caused by the database being unavailable
- Okta auth got `read ECONNRESET`
- Ensure to handle rate limits appropriately.
- Review the API documentation for detailed usage.
- Uses OAuth2 with refresh token  requires setup of connected app in langfuse
- Some endpoints may have rate limits
- Get started on the Hobby plan for free. No credit card required.
- For production projects, consider the Core plan or higher.
- Langfuse is GDPR compliant, offering data retention and deletion capabilities.
- Requires the setup of connected app in Langfuse
- Langfuse is an open source LLM observability platform.
- Supports multiple modalities and models.
- Add your Langfuse credentials as environment variables.
- In short-lived environments (e.g. serverless functions), make sure to always call
  langfuse.shutdownAsync() at the end to await all pending requests.
- Uses OAuth2 with refresh token, requires setup of connected app in Langfuse
- Uses API key authentication
- Ensure public_key and secret_key are provided or set as environment variables
- Configuration is flexible through either direct parameters or environment variables
- Defaults for timeout, debug, tracing_enabled, flush_at, flush_interval, media_upload_thread_count,
  sample_rate, and environment can be set via environment variables
- The API requires setup of connected app in Langfuse
- This method is blocking. It is discouraged to use it in production code.
- Standard span implementation for general operations in Langfuse.
- Handles both synchronous and asynchronous functions for observability.
- Disables tracing when multiple projects exist without explicit key to prevent cross-project
  data leakage.
- This method creates a new child generation span and sets it as the current span
  within a context manager.
- Specialized span implementation for AI model generations in Langfuse.
- The SDK was rewritten in v2 and released on December 18, 2023.
- Uses OAuth2 with refresh token  requires setup of connected app in Langfuse.
- Uses API key for authentication.
- Requires API key for access.
- Uses API key for authentication
- Ensure to set region-specific base URL for correct access
- Langfuse supports both text and chat prompts.
- Evaluation is crucial for improving the accuracy and robustness of language models.
- Successful evaluation blends online and offline evaluations.
- Metrics can be sliced and diced via the customizable dashboards and the metrics
  API.
- API Keys are used to authenticate with the Langfuse API.
- Audit logs provide a complete audit trail for security monitoring, compliance reporting,
  and forensic analysis.
- Most deletions in Langfuse happen instantly, but the deletion of tracing data does
  not.
- Removing those records from our data warehouse is a resource intensive operation
  and, therefore, we rate limit how many deletions we process at any point in time.
- Data retention is configured on a project level, and we accept a number of days
  with a minimum of 3 days.
- 'This feature is currently available for the adapters for: Anthropic, OpenAI, AWS
  (Amazon Bedrock)'
- LLM connections are used to call models in the Langfuse Playground or for LLM-as-a-Judge
  evaluations.
- Uses OpenID Connect with Okta as an identity provider
- User provisioning is supported via SCIM 2.0
- Requires organization-scoped API key for certain endpoints
- Supports SCIM-compliant user provisioning
- Usage alerts are temporarily disabled on Langfuse Cloud due to issues with the payment
  provider.
- Existing alerts will not be triggered and new alerts cannot be configured.
- Applications that handle sensitive information will often need to use anonymize
  and deanonymize functionality to comply with data privacy policies such as HIPAA
  or GDPR.
- Exposing PII to LLMs can pose serious security and privacy risks, such as violating
  contractual obligations or regulatory compliance requirements.
- Transient error Internal Server Error encountered while exporting span batch
- 'Please check your request and contact support: https://langfuse.com/support.'
- Uses OAuth2 with authorization code flow.
- Check user permissions for accessing specific traces
- Allow API auth customization
- Ability to customize API authentication
- Langfuse uses the streamableHttp protocol to communicate with the MCP server.
- Requires setup of OAuth2 credentials.
- Langfuse is an open-source project and we are building in public.
- Provide a postgres url for DATABASE_URL.
- Self-Hosted Backups
- Requires OAuth2 setup in Langfuse
- Some responses may have missing fields
- Requires OAuth2 authentication with refresh token
- Ensure correct permissions are set for API access
- API supports filtering sessions by metadata items.
- Disable authentication in self-hosted deployments
- Langfuse is built for developers.
- Langfuse has open APIs to integrate with your infrastructure.
- Langfuse is built in the open and utilizes an open-source strategy.
- Requires OAuth2 authentication setup
- Rate limits may apply to API calls
- Langfuse is the fastest growing open source LLM observability platform.
- 'Multi-Modal: Langfuse supports text, images, audio, and more.'
- 'Multi-Model: Langfuse supports all major LLM providers.'
- 'Framework Agnostic: Langfuse supports LangChain, OpenAI, LlamaIndex, and more.'
- 'Language Agnostic: Langfuse supports Python, JavaScript, and more.'
- Requires setup of API credentials in project settings
- API requires setup of API credentials in project settings.
- Create new API credentials in the project settings.
- Datasets serve as the data input of Dataset Runs
- Requires OAuth2 authentication to access the API.
- Metrics can be sliced and diced via customizable dashboards and the metrics API.
- Integration is compatible with OpenAI SDK versions >=0.27.8
- Use Langfuse with OpenAI SDK versions >=0.27.8.
- Supports async functions and streaming for OpenAI SDK versions >=1.0.0.
- Supports async functions and streaming for OpenAI SDK versions >=1.0.0
- Integration by default creates a single trace for each OpenAI call.
- Can group multiple OpenAI calls into a single trace.
- OpenAI returns token usage on streamed responses only when in stream_options the
  include_usage parameter is set to True.
- Since OpenAI beta APIs are changing frequently across versions, we fully support
  only the stable APIs in the OpenAI SDK.
- Get your Langfuse credentials from the Langfuse dashboard.
- Global settings like sample_rate, tracing_enabled must be set when initializing
  the Langfuse client via Langfuse() constructor or environment variables
- Python SDK v3 introduces a new observability API
- Flush events in short-lived scripts using langfuse.flush()
- Each invocation will end up on its own trace.
- 'Get keys for your project from the project settings page: https://cloud.langfuse.com'
- LiteLLM is an open source proxy server to manage auth, loadbalancing, and spend
  tracking across more than 100 LLMs.
- 'The integration supports all use cases of Flowise, including: interactively in
  the UI, API, and embeds.'
- Get API keys from project settings in Langfuse
- API keys from project settings in Langfuse
- Test connectivity using the provided command.
- Access the demo project by creating a free account (no credit card required). Select
  the EU instance since the demo is not currently available on the US instance.
- Langfuse can be procured through the AWS Marketplace or per invoice.
- Langfuse provides a powerful API for integration and automation.
- We do not process sensitive personal information.
- We do not receive any information from third parties.
- ISO 27001 certified
- Langfuse is committed to complying with the General Data Protection Regulation (GDPR).
- Langfuse Cloud is aligned with HIPAA, enabling healthcare organizations and partners
  to use Langfuse while adhering to the requirements of HIPAA.
- Building on Langfuse we have achieved a 50% deflection rate of conversations that
  don't go to humans.
- Scaling AI-powered first level merchant support from 1,000 to 600,000 monthly conversations.
- OAuth2 implementation requires setup in the Langfuse dashboard.
- Uses OAuth2 with refresh token  requires setup of connected app in Langfuse
- Uses AWS credentials for authentication.
- AWS access key and secret access key are required for authentication.
- Ensure that the correct AWS region is specified.
- Requires setup of environment variables for LANGFUSE_PUBLIC_KEY and LANGFUSE_SECRET_KEY
- Get keys for your project from the project settings page
- Sign in with your AWS Role that has access to Amazon Bedrock.
- Get keys for your project from the project settings page.
- You can monitor cost and token usage of your Bedrock calls in Langfuse.
- Native integrations with LLM application frameworks and the LiteLLM proxy will automatically
  report token usage to Langfuse.
- Use Anthropic's OpenAI-compatible endpoints via Langfuses OpenAI SDK wrapper.
- Last updated on July 29, 2025
- Langfuse does not support gRPC for the OpenTelemetry endpoint.
- Get your Langfuse API keys by signing up for Langfuse Cloud or self-hosting Langfuse.
- The disable_batch flag is set to true to process traces immediately.
- Last updated on August 20, 2025
- Linking the Langfuse Prompt and the Generation is currently not possible. This is
  on our roadmap.
- Configure environment variables for Langfuse API keys.
- You must set HAYSTACK_CONTENT_TRACING_ENABLED before importing LangfuseConnector.
- This guide uses our Python SDK v2. We have a new, improved SDK available based on
  OpenTelemetry. Please check out the SDK v3 for a more powerful and simpler to use
  SDK.
- LiteLLM relies on the Langfuse Python SDK v2. It is currently not compatible with
  the newer Python SDK v3.
- Create a project in Langfuse Cloud or self-host Langfuse and copy your API keys.
- LANGFUSE_PUBLIC_KEY, LANGFUSE_SECRET_KEY, and LANGFUSE_HOST must be set
- To add additional trace attributes like tags or metadata or use LlamaIndex Workflows
  together with other Langfuse features please refer to the guide.
- Flush events in short-lived applications
- The telemetry.serviceName field must be set to 'ai' for the LangfuseExporter.
- Requires a connected app for OAuth2 authentication
- Mirascope simplifies the development of applications using Large Language Models
  (LLMs) by providing an intuitive interface similar to standard Python coding practices.
- Base64 encode your Langfuse public and secret key
- Ensure that your credentials are correct and follow this troubleshooting guide
- Pipecat supports OpenTelemetry tracing
- OTLP endpoint defaults to localhost:4317 if not set
- Langfuse integrates with Ragas for evaluating RAG pipelines.
- Langfuse client is authenticated and ready!
- Set up your Langfuse API keys by signing up for a free Langfuse Cloud account or
  by self-hosting Langfuse.
- Spring AI needs a reactive web server to run for some reason
- Ensure your agent definition matches your project structure.
- The key change is adding the LangfuseExporter and the telemetryExporter option.
- Requires setup of OAuth2 credentials in Langfuse
- This guide requires a Cleanlab TLM API key.
- 'This guide requires four API keys: Langfuse Public Key, Langfuse Secret Key, OpenAI
  API Key, Cleanlab TLM API Key.'
- Requires a Cleanlab TLM API key for access.
- Evaluate all traces run in the past 24 hours
- TLM requires the entire input to the LLM to be provided.
- Always include any system prompts, context, or other information that was originally
  provided to the LLM to generate the response.
- Langfuse can handle numerical, boolean and categorical (string) scores.
- Integrating Databricks with Langfuse enables you to trace your applications built
  with Databricks, experiment with prompts in the Langfuse Playground and benchmark
  your models through rigorous evaluations.
- Langfuse is also natively integrated with LangChain, LlamaIndex, LiteLLM, and other
  frameworks.
- Langfuse is also natively integrated with various frameworks like LangChain and
  LlamaIndex.
- Get keys for your project from https://cloud.langfuse.com
- Obtain an access token from https://huggingface.co/settings/tokens
- Langfuse is natively integrated with various frameworks.
- Mistral SDK integration enhances logging and tracing.
- Langfuse is natively integrated with several frameworks including LangChain and
  LlamaIndex.
- Langfuse is natively integrated with various frameworks including LangChain and
  LlamaIndex.
- Streaming responses are handled in real-time with the @observe decorator.
- Uses @observe decorator to capture input and output details.
- This API supports function calling capabilities.
- Check the Novita AI Documentation for further details on available models and API
  options.
- Visit Langfuse to learn more about monitoring and tracing capabilities for your
  LLM applications.
- Use the Langfuse cloud version for this example.
- Initialize the Langfuse client with your API keys from the project settings in the
  Langfuse UI
- Uses API keys for authentication.
- Use the OpenAI format with modified hostname for API calls.
- Uses OpenAI compatible API endpoint.
- Configure the OpenAI client to use http://localhost:11434/v1 as base url
- Ensure all traces are sent to Langfuse
- Uses OpenAI model 'openai-main/gpt-4o' for completions
- Ensure you have a TrueFoundry Account with at least one model provider and generate
  a Personal Access Token.
- Langfuse configuration keys must be set up for proper integration.
- All other features of Langfuse will work as expected, including prompt management,
  evaluations, custom dashboards, and advanced observability features.
- Every Langdock assistant execution is automatically traced and visualized.
- Activate analytics in the About tab in the Settings for traces to be sent.
- If you are on an older Ragflow version please upgrade to benefit from the Langfuse
  integration.
- Once youve added your credentials, you should start seeing traces in your Langfuse
  dashboard for every conversation your agents have.
- Coval integrates natively with Langfuse, enabling direct trace transmission for
  advanced voice agent debugging.
- Please check that you have correctly entered the PostHog hostname and API key in
  your Langfuse project settings.
- If you use the PostHog free-tier, please make sure that you have not exceeded the
  event limits as PostHog drops events when the limit is reached.
- This API is a legacy API. For new use cases, please use the Metrics API instead.
- Sign up at Langfuse Cloud to create a new project and copy your public and secret
  API keys.
- Inferable will only send metadata about LLM calls and function calls by default.
- 'Complete Observability: Full visibility into agent behavior and tool usage'
- 'Performance Optimization: Identify bottlenecks in tool execution and context handling'
- 'Debugging Support: Trace failures and understand agent decision-making'
- 'Security Monitoring: Track data access patterns and tool permissions'
- 'Cost Management: Monitor token usage and API call patterns'
- This guide uses our Python SDK v2. We have a new, improved SDK available based on
  OpenTelemetry.
- Uses OpenAI for embeddings and chat completions.
- Integrate Promptfoo with Langfuse to take advantage of Langfuses prompt management
  features during your Promptfoo evaluations.
- Update prompts without redeploying your application.
- Integrate Promptfoo with Langfuse to manage prompts efficiently.
- Requires setup of connected app in langfuse
- Some discussions may return nulls in deeply nested fields
- Python SDK v3 requires Langfuse platform version >= 3.63.0 for traces to be correctly
  processed.
- Langfuse aims to be compliant with the OpenTelemetry GenAI semantic conventions.
- Langfuse does not support gRPC for the OpenTelemetry endpoint. Please use HTTP/protobuf
  instead.
- Uses Basic Authentication with public and secret keys
- Overriding of current TracerProvider is not allowed
- 'Valid config keys have changed in V2: ''fields'' has been removed'
- Uses OpenAI SDK for integration.
- Uses OAuth2 with refresh token.
- Measures number of input and output tokens used
- Time to generate first token for successful responses
- Number of requests to GenAI
- Number of completion tokens processed
- Number of prompt tokens processed
- The distribution of GenAI request costs
- Uses OAuth2 with refresh token - requires setup of connected app in api
- Configure Langfuse authentication by combining your public and secret keys into
  a Base64-encoded token.
- Using disable_batch=True is recommended if you run this code in a notebook as traces
  are sent immediately without waiting for batching.
- Enhanced observability in LLMs significantly improves AI debugging by providing
  comprehensive insights into model behavior.
- OTLPSpanExporter() uses the endpoint and headers from the environment variables.
- The API supports various issue types and statuses.
- We recommend that you use at least 4 cores and 16 GiB of memory, e.g. a t3.xlarge
  on AWS.
- Ensure to stop the VM instance in your cloud provider interface to avoid unnecessary
  costs.
- All core Langfuse features and APIs are available in Langfuse OSS (MIT licensed)
  without any limits.
- When running Langfuse self-hosted, you use the same deployment infrastructure as
  Langfuse Cloud. There are no scalability limitations between the different versions.
- This API is meant for administrative purpose by instance owners and may change at
  any point in time.
- We recommend not to develop against this API or build significant logic around it.
- The content-type and payload is required, but not evaluated within the request.
- Ensure to handle rate limiting as per API guidelines
- Sharding the queues is an advanced feature and should only be used if you have a
  high Redis CPU load and have followed the above recommendations.
- Once you have sharded your queue, do *not* reduce the number of Shards.
- LLM tracing data may contain large payloads due to inputs and outputs being tracked.
- ClickHouse stores observability data within its system tables.
- Uses environment variables for AWS and MinIO credentials
- Backup strategies are essential for protecting your Langfuse data and ensuring business
  continuity.
- MinIO is only relevant for self-hosted deployments that dont use cloud storage
  services.
- Langfuse does not handle HTTPS directly; it's managed at the infrastructure level.
- Database-level encryption is recommended for a secure production deployment.
- Langfuse uses OpenTelemetry to provide observability into the application.
- 'Default Behavior: This endpoint only checks if the API is running and does not
  validate database connectivity to allow serving traffic even when the database is
  temporarily unavailable.'
- Caching features are enabled by default and can be configured or disabled as needed.
- You need to build the image from source with the NEXT_PUBLIC_BASE_PATH environment
  variable set at build time.
- 'Update the secrets in the docker-compose.yml and then run the langfuse docker compose
  using: docker compose up'
- After about 2-3 minutes, the langfuse-web-1 container should log Ready.
- By default, the chart will deploy the Langfuse application containers and data stores.
- For production environments, we recommend to adjust the parameters in the values.yaml.
- This module is a pre-release version and its interface may change.
- Due to a race-condition between the Fargate Profile creation and the Kubernetes
  pod scheduling, on the initial system creation the CoreDNS containers, and the ClickHouse
  containers must be restarted.
- Getting an ERR_SSL_VERSION_OR_CIPHER_MISMATCH error after installation on the HTTPS
  endpoint.
- For production environments, we recommend to use at least 2 CPUs and 4 GB of RAM
  for all containers.
- You should have at least two instances of the Langfuse Web container for high availability.
- For auto-scaling, we recommend to add instances once the CPU utilization exceeds
  50% on either container.
- Set the max-old-space-size via the NODE_OPTIONS environment variable on both the
  Langfuse Web and Worker containers.
- Langfuse does not support multi-shard clusters, this value must be set to 1.
- A minimum of 3 replicas for production setups is recommended.
- Langfuse expects UTC as the default timezone.
- If CLICKHOUSE_CLUSTER_ENABLED is set to true, default is used as the cluster name.
- Langfuse supports ClickHouse versions >= 24.3.
- Ensure that the storage class has allowVolumeExpansion = true as observability workloads
  tend to be very disk heavy.
- Do not enable bucket versioning.
- Do not enable lifecycle policies for deletion.
- Enable lifecycle policies for aborted multi-part uploads.
- For every ~100000 events per minute we recommend about 1GB of memory for the Redis
  instance.
- Langfuse expects that the provided user has access to all keys and commands within
  the given database, i.e. the access control should be defined as `on ~* +@all`.
- We do not extensively test new Langfuse releases with Valkey, but have not encountered
  any issues in internal experiments using it.
- At least version 7 is required and the instance must have `maxmemory-policy=noeviction`
  configured.
- For production deployments, we recommend using 3 master nodes with 1 replica each
  (6 nodes total) for high availability.
- Langfuse uses the AWS SDK internally to connect to blob storages, as most providers
  provide an S3-compatible interface.
- If Langfuse is running on an AWS instance, we recommend to use an IAM role on the
  Langfuse container to access S3.
- To use the Data Retention feature in a self-hosted environment, you need to grant
  `s3:DeleteObject` to the Langfuse IAM role on all buckets.
- Note that Langfuse only issues delete statements on the API.
- If you use versioned buckets, delete markers and non-current versions need to be
  removed manually or with a lifecycle rule.
- Ensure your IAM role or user has the necessary permissions to use the specified
  KMS key.
- GCS does not implement all functions of the S3 API.
- There may be issues around DeleteObject requests.
- Langfuse requires a persistent Postgres database to store its state.
- Langfuse supports Postgres versions >= 12 and uses the public schema in the selected
  database.
- Langfuse expects that its infrastructure components default to UTC.
- Without specifying AUTH_WORKOS_ORGANIZATION_ID or AUTH_WORKOS_CONNECTION_ID, users
  will see two login options and must provide their organization or connection ID.
- If you specify either variable, only one login button appears with that default
  setting. You cannot specify both variables simultaneously.
- Uses masking functions to redact sensitive information.
- Masking sensitive data is a crucial step in responsible application development.
- Start with a single Langfuse deployment and evaluate its scalability and data isolation
  capabilities.
- API Keys are used to authenticate with the Langfuse API. They are associated with
  a project and can be used to access the projects data programmatically.
- Requires proper OAuth2 setup to access RBAC features
- By default, Langfuse stores event data indefinitely.
- Langfuse does not require internet access.
- Some optional components, like the LLM Playground and LLM-evals require access to
  an LLM API/Gateway.
- Configure optional default organization for new users. When users create an account
  they will be automatically added to this organization.
- Role of the user in the default organization (if set). Possible values are OWNER,
  ADMIN, MEMBER, VIEWER.
- Configure optional default project for new users. When users create an account they
  will be automatically added to this project.
- Role of the user in the default project (if set). Possible values are OWNER, ADMIN,
  MEMBER, VIEWER.
- You must create an organization to initialize a project.
- If you use LANGFUSE_INIT_* in Docker Compose, do not double-quote the values.
- This is only available in the Enterprise Edition.
- By default, all users who have access to a Langfuse instance can create new organizations.
- The Organization Management API allows administrators to manage organizations.
- Background migrations are enabled by default and can be disabled by setting LANGFUSE_ENABLE_BACKGROUND_MIGRATIONS=false.
  This is not recommended as it may leave the application in an inconsistent state
  where the UI and API does not reflect the current state of the data correctly.
- The /api/public/ingestion endpoint is asynchronous.
- The /api/public/scores endpoint is now asynchronous.
- If transactional emails are configured on your instance via the SMTP_CONNECTION_URL
  and EMAIL_FROM_ADDRESS environments, users can reset their password by using the
  'Forgot password' link on the login page.
- The container is stateless, allowing you to autoscale it based on actual resource
  usage.
- Langfuse requires a persistent Postgres database to store its state. You can use
  a managed service on AWS, Azure, or GCP, or host it yourself. Once the database
  is ready, keep the connection string handy. At least version 12 is required.
- We follow semantic versioning for Langfuse releases, i.e. breaking changes are only
  introduced in a new major version.
- Email/password authentication is enabled by default.
- If transactional emails are configured on your instance via the SMTP_CONNECTION_URL
  and EMAIL_FROM_ADDRESS environments, users can reset their password by using the
  Forgot password link on the login page.
- We follow semantic versioning for Langfuse releases.
- HTTPS is strongly recommended for encryption in transit.
- For large deployments, configure the database user with long timeouts as migrations
  might need a while to complete.
- Set NEXTAUTH_URL to http://localhost:3000. This is a placeholder, well update it
  later.
- We recommend automated updates within a major version to benefit from the latest
  features, bug fixes, and security patches.
- Ensure that the OAuth provider is configured correctly.
- Have a look at the other optional environment variables in the table above and set
  them if needed to configure your deployment.
- This setup is not suitable for production use as the database is not persistent
  and environment variables are not kept secret.
- OAuth2 requires setup of connected app in Langfuse
- Append .md to any docs URL to fetch the page as Markdown.
- Open-source platform with public API for custom integrations
- Designed for minimal performance overhead
- Ingested usage and cost are prioritized over inferred usage and cost.
- Langfuse tracks the usage and costs of your LLM generations and provides breakdowns
  by usage types.
- Enable non-technical users to trigger external experiment pipelines directly from
  the Langfuse UI on datasets.
- 10-second timeout with status feedback
- Create test cases for your application with real production traces
- Requires OAuth2 setup for API access
- Structured Output Support is crucial for the system to correctly interpret the evaluation
  results from the LLM judge.
- HMAC SHA256 signature verification via x-langfuse-signature header
- High availability with error handling and retry mechanisms
- Pivot tables provide a flexible way to summarize and analyze data.
- This feature is experimental, so results may vary depending on your codebase complexity.
- Use the drop-in replacement for the OpenAI Python SDK to get full observability.
- In short-lived environments (e.g. serverless functions), make sure to always call
  `langfuse.shutdownAsync()` at the end to await all pending requests.
- Ensure to use UUID v4 for event identification.
- Timestamps must be in ISO 8601 format.
- If you encounter api issues due to too large page sizes, try to reduce the limit.
- 5MB per request and 5MB per response
- Rate limits are applied per-organization.
errors:
- Rate limit exceed using Langfuse Python SDK
- 'REQUEST_LIMIT_EXCEEDED: Throttle API calls or reduce frequency'
- 'QUERY_TIMEOUT: Break down filters or add selectivity'
- '401 Unauthorized: Recheck OAuth scopes or token expiration'
- '400 Bad Request: Check request parameters.'
- '401 Unauthorized: Token may be expired or invalid.'
- '500 Internal Server Error: Retry the request.'
- 'ERROR:langfuse:status_code: 404, body: {''message'': ''Trace not found within authorized
  project'', ''error'': ''LangfuseNotFoundError''}'
- 'langfuse.api.resources.commons.errors.not_found_error.NotFoundError: status_code:
  404, body: {''message'': ''Observation not found''}'
- '401 Unauthorized: Verify your authentication details.'
- '403 Forbidden: You do not have permission to access this resource.'
- 'Authentication error: Langfuse client initialized without public_key or secret_key'
- '401 Unauthorized: Check your token and scopes'
- '429 Too Many Requests: Reduce the rate of requests'
- '401 Unauthorized: Recheck OAuth scopes or token expiration.'
- '401 Unauthorized: Recheck API key validity.'
- '429 Too Many Requests: Throttle API calls or reduce frequency'
- '500 Internal Server Error: Retry the request after a short delay'
- 502 Errors on /api/public/ingestion
- Required database environment variables are not set
- '403 Forbidden: Verify user permissions'
- '404 Not Found: Check the endpoint path'
- '500 Internal Server Error: Retry the request'
- 'UnauthorizedError: No authorization header After Switching to Headless Initialization'
- '401 Unauthorized: Check your OAuth token.'
- '400: Bad Request'
- '401: Unauthorized'
- '403: Forbidden'
- '404: Not Found'
- '405: Method Not Allowed'
- '503: Service Unavailable'
- '502: Bad Gateway'
- '401 Unauthorized: Check your credentials and permissions'
- '404 Not Found: Verify the endpoint URL'
- '429 Too Many Requests: Reduce the frequency of requests'
- '401 Unauthorized: Check your OAuth token'
- '403 Forbidden: Insufficient permissions'
- '401 Unauthorized: Check your authentication credentials.'
- '404 Not Found: The requested resource does not exist.'
- 'RATE_LIMIT_EXCEEDED: Reduce frequency of requests'
- 'INVALID_REQUEST: Check request parameters'
- '401 Unauthorized: Verify access token'
- '401 Unauthorized: Check API keys and permissions.'
- Debug mode can be enabled to get more information about requests and responses
- '401 Unauthorized: Check OAuth token validity.'
- '429 Too Many Requests: Rate limit exceeded.'
- '4xx errors: Upgrade your deployment to the latest version.'
- '401 Unauthorized: Check your credentials and scopes'
- '429 Too Many Requests: Rate limit exceeded'
- '401 Unauthorized: Check your API key or token'
- '401 Unauthorized: Check API keys.'
- If you encounter 4xx errors while self-hosting Langfuse, please upgrade your deployment
  to the latest version.
- the JSON object must be str, bytes or bytearray, not NoneType
- '401 Unauthorized: Check your credentials'
- '200 OK: API is functioning normally'
- '503 Service Unavailable: API is not functioning or database is unreachable'
- 'Invalid API key: Check if the API key is valid or has been disabled.'
- 'Cache miss: Requested data is not available in cache.'
- CoreDNS containers, and the ClickHouse containers must be restarted
- 'NOT_ENOUGH_SPACE: Ensure persistent volume claims need to be expanded.'
- 'driver: bad connection in line 0: Ensure CLICKHOUSE_MIGRATION_SSL is set and access
  permissions are correct.'
- 'Code: 80. DB::Exception: Its not initial query. ON CLUSTER is not allowed for
  Replicated database.'
- 'error: driver: bad connection in line 0: Ensure that the CLICKHOUSE_MIGRATION_SSL
  flag is set.'
- 'Code: 80. DB::Exception: Its not initial query. ON CLUSTER is not allowed for
  Replicated database. (INCORRECT_QUERY): Set CLICKHOUSE_CLUSTER_ENABLED=false for
  now.'
- Ensure all cluster nodes are accessible from your Langfuse containers
- Use the same authentication credentials across all cluster nodes
- Monitor cluster health and handle node failures appropriately
- '401 Unauthorized: Check your OAuth2 token'
- '403 Forbidden: You do not have permission to access this resource'
- '400 Bad Request: Invalid data retention period.'
- '403 Forbidden: Insufficient permissions to change data retention settings.'
- '207: Event accepted, processing queued.'
- '200: Score created successfully.'
- '200 OK: Both the API is functioning normally and a successful connection to the
  database was made.'
- '503 Service Unavailable: Either the API is not functioning or it couldnt establish
  a connection to the database.'
- '200 OK: The application is ready to serve traffic.'
- '500 Internal Server Error: The application received a SIGTERM or SIGINT and should
  not receive traffic.'
- 'REQUEST_LIMIT_EXCEEDED: Reduce API call frequency'
- 'QUERY_TIMEOUT: Simplify queries or increase selectivity'
- '401 Unauthorized: Verify OAuth scopes or token validity'
- '401 Unauthorized: Recheck OAuth credentials'
- '404 Not Found: Verify the endpoint path'
- '207: Partial success with errors'
- '400: Bad request'
- '404: Not found'
- '405: Method not allowed'
- '400 Bad Request: Check your request payload for missing required fields.'
- '404 Not Found: Ensure the endpoint URL is correct.'
- 'HTTP status code 429: Retry-After response header with the number of seconds to
  wait before retrying'
auth_info:
  mentioned_objects:
  - OauthToken
  - AuthProvider
  - NamedCredential
  - Okta
  - SAML
  - SCIM
  - OAuthToken
  - OAuth2
  - Google
  - GitHub
  - Azure AD
  - Auth0
  - AWS Cognito
  - LangfuseClient
  - LANGFUSE_PUBLIC_KEY
  - LANGFUSE_SECRET_KEY
  - Auth.js
  - AUTH0
  - COGNITO
  - AZURE_AD
  - GITHUB
  - GITHUB_ENTERPRISE
  - GITLAB
  - GOOGLE
  - KEYCLOAK
  - OKTA
  - ADMIN_API_KEY
client:
  base_url: https://cloud.langfuse.com
  auth:
    type: oauth2
    flow: refresh_token
    token_url: https://login.api.langfuse.com/services/oauth2/token
    client_id: '{{ dlt.secrets[''api_client_id''] }}'
    client_secret: '{{ dlt.secrets[''api_client_secret''] }}'
    refresh_token: '{{ dlt.secrets[''api_refresh_token''] }}'
    location: header
    header_name: Authorization
  headers:
    Accept: application/json
source_metadata: null
