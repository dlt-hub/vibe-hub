resources:
- name: project_info
  endpoint:
    path: /api/scraper/project
    method: GET
- name: project_status
  endpoint:
    path: /api/scraper/project/status
    method: POST
- name: connectors
  endpoint:
    path: /api/scraper/project/connectors
    method: GET
- name: remove_proxies
  endpoint:
    path: /api/scraper/project/proxies/remove
    method: POST
- name: sources
  endpoint:
    path: /api/scraper/project/connectors/<uuid of the connector>/sources
    method: GET
- name: freeproxies
  endpoint:
    path: /api/scraper/project/connectors/<uuid of the connector>/freeproxies
    method: GET
- name: add_freeproxies
  endpoint:
    path: /api/scraper/project/connectors/<uuid of the connector>/freeproxies
    method: POST
- name: remove_freeproxies
  endpoint:
    path: /api/scraper/project/connectors/<uuid of the connector>/freeproxies/remove
    method: POST
- name: repositories
  endpoint:
    path: /user/repos
    method: GET
    data_selector: repositories
    params: {}
- name: issues
  endpoint:
    path: /repos/{owner}/{repo}/issues
    method: GET
    data_selector: issues
    params: {}
- name: proxy_types
  endpoint:
    path: /api/proxy-types
    method: GET
    data_selector: proxies
    params: {}
- name: proxy_credentials
  endpoint:
    path: /settings
    method: GET
    data_selector: credentials
    params: {}
- name: commander
  endpoint:
    path: /api
    method: POST
    data_selector: services
    params: {}
- name: master
  endpoint:
    path: /api
    method: POST
    data_selector: services
    params: {}
- name: refresh
  endpoint:
    path: /api
    method: POST
    data_selector: services
    params: {}
- name: haproxy
  endpoint:
    path: /usr/local/etc/haproxy/haproxy.cfg
    method: GET
    data_selector: configuration
    params: {}
- name: proxy_list
  endpoint:
    path: /api.proxyscrape.com/v3/free-proxy-list/get
    method: GET
- name: Residential Proxies
  endpoint:
    path: /l/decodo-dashboard
    method: GET
    data_selector: proxies
    params: {}
- name: Mobile Proxies
  endpoint:
    path: /l/decodo-dashboard
    method: GET
    data_selector: proxies
    params: {}
- name: ISP Proxies - Pay/GB
  endpoint:
    path: /l/decodo-dashboard
    method: GET
    data_selector: proxies
    params: {}
- name: ISP Proxies - Dedicated ISP
  endpoint:
    path: /l/decodo-dashboard
    method: GET
    data_selector: proxies
    params: {}
- name: Datacenter Proxies - Pay/GB
  endpoint:
    path: /l/decodo-dashboard
    method: GET
    data_selector: proxies
    params: {}
- name: Datacenter Proxies - Pay/IP
  endpoint:
    path: /l/decodo-dashboard
    method: GET
    data_selector: proxies
    params: {}
- name: Dynamic IP
  endpoint:
    path: /l/massive
    method: POST
- name: project
  endpoint:
    path: /cloud/project
    method: GET
- name: project_details
  endpoint:
    path: /cloud/project/*
    method: GET
- name: project_actions
  endpoint:
    path: /cloud/project/{projectId}/*
    method: POST
- name: delete_project
  endpoint:
    path: /cloud/project/{projectId}/*
    method: DELETE
- name: Residential Proxies
  endpoint:
    path: /connectors/oxylabs/residential
    method: POST
    data_selector: user
    params: {}
- name: ISP Proxies
  endpoint:
    path: /connectors/oxylabs/isp
    method: POST
    data_selector: user
    params: {}
- name: Mobile Proxies
  endpoint:
    path: /connectors/oxylabs/mobile
    method: POST
    data_selector: user
    params: {}
- name: Datacenter Proxies
  endpoint:
    path: /connectors/oxylabs/datacenter
    method: POST
    data_selector: user
    params: {}
- name: Dedicated Datacenter Proxies
  endpoint:
    path: /connectors/oxylabs/dedicated-datacenter
    method: POST
    data_selector: user
    params: {}
- name: Ping Proxies
  endpoint:
    path: /l/pingproxies
    method: GET
- name: proxies
  endpoint:
    path: /proxies
    method: GET
    data_selector: proxies
- name: xproxy_admin
  endpoint:
    path: /xproxy/admin
    method: GET
- name: fingerprint
  endpoint:
    path: /fingerprint
    method: GET
    data_selector: data
notes:
- Basic authentication transmits the username and password in the Authorization header
  of a request, encoded using Base64.
- Uses OAuth2 with refresh token — requires setup of GitHub app
- Some endpoints may have rate limits depending on the access token
- Scrapoxy is free, only pay for support.
- 150M+ proxy IPs from 195 countries
- Oxylabs Residential Proxy pool is ethically procured from carefully selected partners.
- Cookies are small text files that get stored on a user's device when they visit
  a website.
- Fast and reliable proxies with a 1 Gbps high-speed channel, ensuring high throughput,
  minimal latency, and a stable connection.
- 99% uptime guarantees consistent service and minimized downtime.
- Access proxies from over 220 countries.
- Scrapoxy requires a minimum number of proxies to maintain a stable connection; otherwise,
  all requests will fail.
- Scrapoxy typically uses a username:password combination to select the appropriate
  project and as a security measure to prevent unauthorized access to the master.
- This program requires a technical integration.
- A one-time, non-negotiable fee of $2,000 covers the development of a connector.
- Use a separate instance for running Scrapoxy at scale.
- Don’t run VPNs or complicated network setups on the same machine.
- To start Scrapoxy, it is mandatory to set the secrets BACKEND_JWT_SECRET and FRONTEND_JWT_SECRET.
- 'Scrapoxy supports 2 modes for maintaining sticky sessions: through headers or cookies.'
- Cookie injection is particularly crucial when using a headless browser (Playwright
  or Puppeteer) alongside a residential network to prevent IP rotation between requests.
- Using this connector with Pay-Per-GB subscriptions without proper configuration
  can lead to substantial costs.
- When setting up the connector in multiple regions, assign a unique Image ID and
  distinct Tag for each region. Without this, connectors may interfere with each other,
  shutting down instances from the same provider.
- It may take Azure up to 10 minutes to reflect the changes.
- To prevent rate limit issues, please set the Proxies Timeout to 30 seconds.
- Active Decodo subscription is required.
- Switching product types requires copying new username and password.
- Most default values can be retained if suitable for the use case.
- When setting up the connector in multiple regions, assign a unique Tag for each
  region.
- An active Evomi subscription is required.
- An active GCP subscription is required.
- An active Geonode subscription is required.
- An active Live Proxies subscription is required.
- An active NetNut subscription is required.
- Scrapoxy supports only Nimble IP.
- An active Oxylabs subscription is required.
- You need to create a new credential for each type of product.
- An active ProxyEmpire subscription is required.
- Scrapoxy supports only Private Unmetered Residential proxies.
- An active Rayobyte subscription is required.
- An active subscription to Scaleway is required.
- An active subscription to Tencent Cloud is required.
- When accessing regions other than Hong Kong, Tencent Cloud will require you to complete
  verification, either through personal ID verification or by submitting company registration
  details.
- Be aware that XProxy employees have SSH root access to the material, and the password
  cannot be changed.
- When using the Zyte API, you need to enable sticky sessions with an HTTP header
  or cookie because the cookie jar is linked to the Zyte session and its outbound
  IP. If you try to send the cookie through a different proxy, the Zyte API will remove
  it.
- Only one login and password is allowed per installation.
- Google only accepts HTTPS URLS.
- Scrapoxy will automatically bootstrap the Github authentication
- Scrapoxy periodically sends requests to the fingerprint server to verify connectivity
  and collect GEO information.
- Self-hosting the Fingerprint Server is not permitted.
- Scrapoxy is free for both personal and commercial usage under the 'Community' package,
  which is provided by default.
- Subscriptions will be automatically renewed for the same duration unless the User
  cancels the auto-renewal through their account on https://scrapoxy.io.
- Payment management is handled and billed by Stripe, third-party providers of CoreDump
  Engineering.
- You must comply with all applicable laws and regulations with regard to economic
  sanctions, export controls, import regulations, restrictive measures, and trade
  embargoes.
- You declare and warrant that You are not a person targeted by Sanctions.
- You agree that You will not download or otherwise export or re-export the Software
  or any related technical data directly or indirectly to any person targeted by Sanctions.
- User should inform the Provider without delay regarding Articles L420-1 and following
  of the French Commercial Code.
- The Agreement constitutes the entire agreement between the Parties.
- The Agreement is subject to French law.
- We may update this Privacy Policy from time to time.
- The updated version will be indicated by an updated 'Revised' date.
- Uses essential cookies to make the site work.
- Cookies are used for analytics and user experience improvements.
errors:
- '403 Forbidden: Check your permissions or rate limits'
- '404 Not Found: Verify the endpoint and parameters'
- '401 Unauthorized: Recheck OAuth token or scopes'
- no such file or directory, open 'scrapoxy.json'
- 'JwtInvalidError: JWT is invalid: JWT missing'
- 'no_token: Authentication token is missing in the header request. Add the Proxy-Authorization
  header with the token formatted as Basic BASE64(USERNAME:PASSWORD).'
- 'no_project: The token exists but does not match any project (invalid token). Verify
  the username and password in the Project Settings.'
- 'no_proxy: Authentication is successful, but no proxies are currently online.'
- 'wrong_url: The URL sent to Scrapoxy is incorrect. This error occurs when Scrapoxy
  is requested to collect an empty URL or a URL without a hostname.'
- 'cannot_scaleup: This error occurs when attempting to scale the project due to a
  connectivity issue between the commander, master, or database.'
- 'build_request/build_connect: This occurs when the master tries to create a request
  and the connectors do not exist or the request parameters are incompatible with
  the connector.'
- 'socket_error: This occurs during a CONNECT request when there is a problem with
  the relaying socket.'
- 'write_error: This occurs during a CONNECT request when sending HTTP headers on
  a closed socket.'
- 'request_error: This occurs when the scraper triggers an error on the outbound stream
  due to various issues.'
- 'response_error: This can originate from the target website or the connector and
  can be due to various issues.'
auth_info:
  mentioned_objects:
  - OauthToken
  - Username
  - Password
client:
  base_url: http://localhost:8890
  auth:
    type: basic
source_metadata: null
