resources:
- name: spark_nlp_installation
  endpoint:
    path: /install
    method: GET
    data_selector: records
    params: {}
- name: spark-nlp
  endpoint:
    path: /spark-nlp
    method: GET
    data_selector: records
    params: {}
- name: explain_document_ml
  endpoint:
    path: /pretrained_pipelines/explain_document_ml
    method: GET
    data_selector: results
    params: {}
- name: dependency_parse
  endpoint:
    path: /pretrained_pipelines/dependency_parse
    method: GET
    data_selector: results
    params: {}
- name: check_spelling
  endpoint:
    path: /pretrained_pipelines/check_spelling
    method: GET
    data_selector: results
    params: {}
- name: match_datetime
  endpoint:
    path: /pretrained_pipelines/match_datetime
    method: GET
    data_selector: results
    params: {}
- name: explain_document_ml
  endpoint:
    path: /pretrained/explain_document_ml
    method: GET
    data_selector: pipeline
    params: {}
- name: dependency_parse
  endpoint:
    path: /pretrained/dependency_parse
    method: GET
    data_selector: pipeline
    params: {}
- name: check_spelling
  endpoint:
    path: /pretrained/check_spelling
    method: GET
    data_selector: pipeline
    params: {}
- name: match_datetime
  endpoint:
    path: /pretrained/match_datetime
    method: GET
    data_selector: pipeline
    params: {}
- name: POS Dataset
  endpoint:
    path: ./src/main/resources/anc-pos-corpus
    method: GET
    data_selector: corpus data
- name: CoNLL Dataset
  endpoint:
    path: ./src/main/resources/conll2003/eng.train
    method: GET
    data_selector: corpus data
- name: CoNLLU Dataset
  endpoint:
    path: src/test/resources/conllu/en.test.conllu
    method: GET
    data_selector: corpus data
- name: Spell Checkers Dataset
  endpoint:
    path: ./sherlockholmes.txt
    method: GET
    data_selector: corpus data
- name: PubTator Dataset
  endpoint:
    path: ./src/test/resources/corpus_pubtator.txt
    method: GET
    data_selector: corpus data
- name: POS Dataset
  endpoint:
    path: ./src/main/resources/anc-pos-corpus
    method: GET
    data_selector: records
- name: CoNLL Dataset
  endpoint:
    path: ./src/main/resources/conll2003/eng.train
    method: GET
    data_selector: records
- name: CoNLLU Dataset
  endpoint:
    path: src/test/resources/conllu/en.test.conllu
    method: GET
    data_selector: records
- name: Spell Checkers Dataset
  endpoint:
    path: ./sherlockholmes.txt
    method: GET
    data_selector: records
- name: PubTator Dataset
  endpoint:
    path: ./src/test/resources/corpus_pubtator.txt
    method: GET
    data_selector: records
- name: LightPipeline
  endpoint:
    path: /light_pipeline
    method: POST
    data_selector: annotate
- name: PretrainedPipeline
  endpoint:
    path: /pretrained_pipeline
    method: POST
    data_selector: annotate
- name: mlflow_models
  endpoint:
    path: /mlflow/models
    method: GET
    data_selector: models
    params: {}
- name: spark_nlp_properties
  endpoint:
    path: /sparknlp/properties
    method: GET
    data_selector: properties
- name: pipelines
  endpoint:
    path: /pipelines
    method: GET
- name: models
  endpoint:
    path: /models
    method: GET
- name: explain_document_ml
  endpoint:
    path: /pretrained_pipeline/explain_document_ml
    method: GET
    data_selector: annotations
    params: {}
- name: pretrained_pipeline
  endpoint:
    path: /pretrained/pipeline
    method: GET
    data_selector: pipelines
- name: available_models
  endpoint:
    path: /models/available
    method: GET
    data_selector: models
- name: available_annotators
  endpoint:
    path: /annotators/available
    method: GET
    data_selector: annotators
- name: explain_document_ml
  endpoint:
    path: /pretrained/explain_document_ml
    method: GET
    data_selector: annotations
- name: explain_document_ml
  endpoint:
    path: /explain_document_ml
    method: POST
    data_selector: annotations
- name: explain_document_ml
  endpoint:
    path: /public/GRAMMAR_EN/
    method: GET
    data_selector: annotations
- name: explain_document_ml
  endpoint:
    path: /public/GRAMMAR_EN/
    method: GET
    data_selector: annotations
- name: text_classification
  endpoint:
    path: /docs/en/tasks/text_classification
    method: GET
- name: token_classification
  endpoint:
    path: /docs/en/tasks/token_classification
    method: GET
- name: zero_shot_classification
  endpoint:
    path: /docs/en/tasks/zero_shot_classification
    method: GET
- name: text_generation
  endpoint:
    path: /docs/en/tasks/text_generation
    method: GET
- name: question_answering
  endpoint:
    path: /docs/en/tasks/question_answering
    method: GET
- name: table_question_answering
  endpoint:
    path: /docs/en/tasks/table_question_answering
    method: GET
- name: summarization
  endpoint:
    path: /docs/en/tasks/summarization
    method: GET
- name: translation
  endpoint:
    path: /docs/en/tasks/translation
    method: GET
- name: text_preprocessing
  endpoint:
    path: /docs/en/tasks/text_preprocessing
    method: GET
- name: image_text_to_text
  endpoint:
    path: /docs/en/tasks/image_text_to_text
    method: GET
- name: image_classification
  endpoint:
    path: /docs/en/tasks/image_classification
    method: GET
- name: image_captioning
  endpoint:
    path: /docs/en/tasks/image_captioning
    method: GET
- name: zero_shot_image_classification
  endpoint:
    path: /docs/en/tasks/zero_shot_image_classification
    method: GET
- name: automatic_speech_recognition
  endpoint:
    path: /docs/en/tasks/automatic_speech_recognition
    method: GET
- name: AutoGGUFEmbeddings
  endpoint:
    path: /auto_gguf_embeddings
    method: GET
    data_selector: results
- name: AutoGGUFModel
  endpoint:
    path: /auto_gguf_model
    method: GET
    data_selector: results
- name: AutoGGUFReranker
  endpoint:
    path: /auto_gguf_reranker
    method: GET
    data_selector: results
- name: AutoGGUFVisionModel
  endpoint:
    path: /auto_gguf_vision_model
    method: GET
    data_selector: results
- name: BGEEmbeddings
  endpoint:
    path: /bge_embeddings
    method: GET
    data_selector: results
- name: BigTextMatcher
  endpoint:
    path: /big_text_matcher
    method: GET
    data_selector: results
- name: Chunk2Doc
  endpoint:
    path: /chunk2doc
    method: GET
    data_selector: results
- name: ChunkEmbeddings
  endpoint:
    path: /chunk_embeddings
    method: GET
    data_selector: results
- name: ChunkTokenizer
  endpoint:
    path: /chunk_tokenizer
    method: GET
    data_selector: results
- name: Chunker
  endpoint:
    path: /chunker
    method: GET
    data_selector: results
- name: ClassifierDL
  endpoint:
    path: /classifier_dl
    method: GET
    data_selector: results
- name: ContextSpellChecker
  endpoint:
    path: /context_spell_checker
    method: GET
    data_selector: results
- name: Date2Chunk
  endpoint:
    path: /date2chunk
    method: GET
    data_selector: results
- name: DateMatcher
  endpoint:
    path: /date_matcher
    method: GET
    data_selector: results
- name: DependencyParser
  endpoint:
    path: /dependency_parser
    method: GET
    data_selector: results
- name: Doc2Chunk
  endpoint:
    path: /doc2chunk
    method: GET
    data_selector: results
- name: Doc2Vec
  endpoint:
    path: /doc2vec
    method: GET
    data_selector: results
- name: DocumentAssembler
  endpoint:
    path: /document_assembler
    method: GET
    data_selector: results
- name: DocumentCharacterTextSplitter
  endpoint:
    path: /document_character_text_splitter
    method: GET
    data_selector: results
- name: DocumentNormalizer
  endpoint:
    path: /document_normalizer
    method: GET
    data_selector: results
- name: DocumentSimilarityRanker
  endpoint:
    path: /document_similarity_ranker
    method: GET
    data_selector: results
- name: DocumentTokenSplitter
  endpoint:
    path: /document_token_splitter
    method: GET
    data_selector: results
- name: EntityRuler
  endpoint:
    path: /entity_ruler
    method: GET
    data_selector: results
- name: EmbeddingsFinisher
  endpoint:
    path: /embeddings_finisher
    method: GET
    data_selector: results
- name: Finisher
  endpoint:
    path: /finisher
    method: GET
    data_selector: results
- name: GraphExtraction
  endpoint:
    path: /graph_extraction
    method: GET
    data_selector: results
- name: GraphFinisher
  endpoint:
    path: /graph_finisher
    method: GET
    data_selector: results
- name: ImageAssembler
  endpoint:
    path: /image_assembler
    method: GET
    data_selector: results
- name: LanguageDetectorDL
  endpoint:
    path: /language_detector_dl
    method: GET
    data_selector: results
- name: Lemmatizer
  endpoint:
    path: /lemmatizer
    method: GET
    data_selector: results
- name: MultiClassifierDL
  endpoint:
    path: /multi_classifier_dl
    method: GET
    data_selector: results
- name: MultiDateMatcher
  endpoint:
    path: /multi_date_matcher
    method: GET
    data_selector: results
- name: MultiDocumentAssembler
  endpoint:
    path: /multi_document_assembler
    method: GET
    data_selector: results
- name: NGramGenerator
  endpoint:
    path: /ngram_generator
    method: GET
    data_selector: results
- name: NerConverter
  endpoint:
    path: /ner_converter
    method: GET
    data_selector: results
- name: NerCrf
  endpoint:
    path: /ner_crf
    method: GET
    data_selector: results
- name: NerDL
  endpoint:
    path: /ner_dl
    method: GET
    data_selector: results
- name: NerOverwriter
  endpoint:
    path: /ner_overwriter
    method: GET
    data_selector: results
- name: Normalizer
  endpoint:
    path: /normalizer
    method: GET
    data_selector: results
- name: NorvigSweeting Spellchecker
  endpoint:
    path: /norvig_sweeting_spellchecker
    method: GET
    data_selector: results
- name: POSTagger (Part of speech tagger)
  endpoint:
    path: /pos_tagger
    method: GET
    data_selector: results
- name: PromptAssembler
  endpoint:
    path: /prompt_assembler
    method: GET
    data_selector: results
- name: Reader2Doc
  endpoint:
    path: /reader2doc
    method: GET
    data_selector: results
- name: Reader2Image
  endpoint:
    path: /reader2image
    method: GET
    data_selector: results
- name: Reader2Table
  endpoint:
    path: /reader2table
    method: GET
    data_selector: results
- name: ReaderAssembler
  endpoint:
    path: /reader_assembler
    method: GET
    data_selector: results
- name: RecursiveTokenizer
  endpoint:
    path: /recursive_tokenizer
    method: GET
    data_selector: results
- name: RegexMatcher
  endpoint:
    path: /regex_matcher
    method: GET
    data_selector: results
- name: RegexTokenizer
  endpoint:
    path: /regex_tokenizer
    method: GET
    data_selector: results
- name: SentenceDetector
  endpoint:
    path: /sentence_detector
    method: GET
    data_selector: results
- name: SentenceDetectorDL
  endpoint:
    path: /sentence_detector_dl
    method: GET
    data_selector: results
- name: SentenceEmbeddings
  endpoint:
    path: /sentence_embeddings
    method: GET
    data_selector: results
- name: SentimentDL
  endpoint:
    path: /sentiment_dl
    method: GET
    data_selector: results
- name: SentimentDetector
  endpoint:
    path: /sentiment_detector
    method: GET
    data_selector: results
- name: Stemmer
  endpoint:
    path: /stemmer
    method: GET
    data_selector: results
- name: StopWordsCleaner
  endpoint:
    path: /stop_words_cleaner
    method: GET
    data_selector: results
- name: SymmetricDelete Spellchecker
  endpoint:
    path: /symmetric_delete_spellchecker
    method: GET
    data_selector: results
- name: TextMatcher
  endpoint:
    path: /text_matcher
    method: GET
    data_selector: results
- name: Token2Chunk
  endpoint:
    path: /token2chunk
    method: GET
    data_selector: results
- name: TokenAssembler
  endpoint:
    path: /token_assembler
    method: GET
    data_selector: results
- name: Tokenizer
  endpoint:
    path: /tokenizer
    method: GET
    data_selector: results
- name: TypedDependencyParser
  endpoint:
    path: /typed_dependency_parser
    method: GET
    data_selector: results
- name: ViveknSentiment
  endpoint:
    path: /vivekn_sentiment
    method: GET
    data_selector: results
- name: WordEmbeddings
  endpoint:
    path: /word_embeddings
    method: GET
    data_selector: results
- name: Word2Vec
  endpoint:
    path: /word2vec
    method: GET
    data_selector: results
- name: WordSegmenter
  endpoint:
    path: /word_segmenter
    method: GET
    data_selector: results
- name: YakeKeywordExtraction
  endpoint:
    path: /yake_keyword_extraction
    method: GET
    data_selector: results
- name: auto_gguf_embeddings
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/embeddings/auto_gguf_embeddings/index.html
    method: GET
    data_selector: embeddings
    params: {}
- name: auto_gguf_model
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/seq2seq/auto_gguf_model/index.html
    method: GET
    data_selector: completions
    params: {}
- name: auto_gguf_reranker
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/seq2seq/auto_gguf_reranker/index.html
    method: GET
    data_selector: reranked_documents
    params: {}
- name: AutoGGUFEmbeddings
  endpoint:
    path: /autoggufembeddings
    method: GET
    data_selector: records
- name: AutoGGUFModel
  endpoint:
    path: /autoggufmodel
    method: GET
    data_selector: records
- name: AutoGGUFReranker
  endpoint:
    path: /autoggufreranker
    method: GET
    data_selector: records
- name: BGEEmbeddings
  endpoint:
    path: /bgeembeddings
    method: GET
    data_selector: records
- name: BigTextMatcher
  endpoint:
    path: /bigtextmatcher
    method: GET
    data_selector: records
- name: Chunker
  endpoint:
    path: /chunker
    method: GET
    data_selector: records
- name: ClassifierDL
  endpoint:
    path: /classifierdl
    method: GET
    data_selector: records
- name: DateMatcher
  endpoint:
    path: /datematcher
    method: GET
    data_selector: records
- name: DependencyParser
  endpoint:
    path: /dependencparser
    method: GET
    data_selector: records
- name: DocumentAssembler
  endpoint:
    path: /documentassembler
    method: GET
    data_selector: records
- name: EntityRuler
  endpoint:
    path: /entityruler
    method: GET
    data_selector: records
- name: SentenceDetector
  endpoint:
    path: /sentencedetector
    method: GET
    data_selector: records
- name: SentimentDL
  endpoint:
    path: /sentimentdl
    method: GET
    data_selector: records
- name: Tokenizer
  endpoint:
    path: /tokenizer
    method: GET
    data_selector: records
- name: image
  endpoint:
    path: /api/image
    method: POST
    data_selector: results
- name: entity
  endpoint:
    path: /src/test/resources/entity-extractor/test-phrases.txt
    method: GET
    data_selector: result
    params: {}
- name: Chunker
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/chunker/index.html#sparknlp.annotator.chunker.Chunker
    method: GET
- name: context_spell_checker
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/spell_check/context_spell_checker/index.html#sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerModel
    method: GET
    data_selector: records
- name: date2chunk
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/date2_chunk/index.html#sparknlp.annotator.date2_chunk.Date2Chunk
    method: GET
    data_selector: records
- name: dependency_parser
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/dependency/dependency_parser/index.html#sparknlp.annotator.dependency.dependency_parser.DependencyParserApproach
    method: GET
    data_selector: records
- name: doc2chunk
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/base/doc2_chunk/index.html#sparknlp.base.doc2_chunk.Doc2Chunk
    method: GET
    data_selector: records
- name: Doc2VecApproach
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/embeddings/doc2vec/index.html#sparknlp.annotator.embeddings.doc2vec.Doc2VecApproach
    method: GET
- name: Doc2VecModel
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/embeddings/doc2vec/index.html#sparknlp.annotator.embeddings.doc2vec.Doc2VecModel
    method: GET
- name: document_normalizer
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/document_normalizer/index.html#sparknlp.annotator.document_normalizer.DocumentNormalizer
    method: GET
    data_selector: records
- name: embeddings_finisher
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/base/embeddings_finisher/index.html#sparknlp.base.embeddings_finisher.EmbeddingsFinisher
    method: GET
    data_selector: records
- name: graph_extraction
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/graph_extraction/index.html#sparknlp.annotator.graph_extraction.GraphExtraction
    method: GET
    data_selector: graph
    params: {}
- name: graph_finisher
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/base/graph_finisher/index.html#sparknlp.base.graph_finisher.GraphFinisher
    method: GET
    data_selector: graph_finished
    params: {}
- name: image_assembler
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/base/image_assembler/index.html#sparknlp.base.image_assembler.ImageAssembler
    method: GET
    data_selector: image_assembler
    params: {}
- name: language_detector
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/ld_dl/language_detector_dl/index.html#sparknlp.annotator.ld_dl.language_detector_dl.LanguageDetectorDL
    method: GET
    data_selector: language
    params: {}
- name: lemmatizer
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/lemmatizer/index.html#sparknlp.annotator.lemmatizer.Lemmatizer
    method: GET
    data_selector: token
    params: {}
- name: document_assembler
  endpoint:
    path: /api/document_assembler
    method: POST
    data_selector: records
    params: {}
- name: sentence_detector
  endpoint:
    path: /api/sentence_detector
    method: POST
    data_selector: records
    params: {}
- name: tokenizer
  endpoint:
    path: /api/tokenizer
    method: POST
    data_selector: records
    params: {}
- name: lemmatizer
  endpoint:
    path: /api/lemmatizer
    method: POST
    data_selector: records
    params: {}
- name: multi_classifier_dl
  endpoint:
    path: /api/multi_classifier_dl
    method: POST
    data_selector: records
    params: {}
- name: MultiDateMatcher
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/matcher/multi_date_matcher/index.html
    method: GET
    data_selector: records
- name: MultiDocumentAssembler
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/base/multi_document_assembler/index.html
    method: GET
    data_selector: records
- name: NGramGenerator
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/n_gram_generator/index.html
    method: GET
    data_selector: records
- name: NerConverter
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/ner/ner_converter/index.html
    method: GET
    data_selector: records
- name: NerCrf
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/ner/ner_crf/index.html
    method: GET
    data_selector: records
- name: ner_crf
  endpoint:
    path: /ner/crf
    method: POST
    data_selector: results
- name: ner_dl
  endpoint:
    path: /ner/dl
    method: POST
    data_selector: results
- name: normalizer
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/normalizer/index.html#sparknlp.annotator.normalizer.Normalizer
    method: GET
    data_selector: result
    params: {}
- name: PerceptronApproach
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/pos/perceptron/index.html#sparknlp.annotator.pos.perceptron.PerceptronApproach
    method: GET
    data_selector: records
- name: PromptAssembler
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/base/prompt_assembler/index.html#sparknlp.base.prompt_assembler.PromptAssembler
    method: GET
    data_selector: records
- name: document
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/reader/reader2doc/index.html
    method: GET
    data_selector: document
    params: {}
- name: image
  endpoint:
    path: /api/image
    method: POST
    data_selector: image_data
    params:
      contentPath: path/to/image/files
- name: RegexTokenizer
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/token/regex_tokenizer/index.html#sparknlp.annotator.token.regex_tokenizer.RegexTokenizer
    method: GET
    data_selector: records
    params: {}
- name: SentenceDetector
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/sentence/sentence_detector/index.html#sparknlp.annotator.sentence.sentence_detector.SentenceDetector
    method: GET
    data_selector: records
    params: {}
- name: SentenceDetectorDL
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/sentence/sentence_detector_dl/index.html#sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLApproach
    method: GET
    data_selector: records
    params: {}
- name: SentenceEmbeddings
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/embeddings/sentence_embeddings/index.html#sparknlp.annotator.embeddings.sentence_embeddings.SentenceEmbeddings
    method: GET
    data_selector: records
    params: {}
- name: SentimentDL
  endpoint:
    path: /sentimentdl
    method: GET
    data_selector: records
- name: StopWordsCleaner
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/stop_words_cleaner/index.html#sparknlp.annotator.stop_words_cleaner.StopWordsCleaner
    method: GET
    data_selector: records
    params: {}
- name: SymmetricDeleteApproach
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/spell_check/symmetric_delete/index.html#sparknlp.annotator.spell_check.symmetric_delete.SymmetricDeleteApproach
    method: GET
    data_selector: records
    params: {}
- name: TextMatcher
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/matcher/text_matcher/index.html#sparknlp.annotator.matcher.text_matcher.TextMatcher
    method: GET
    data_selector: records
    params: {}
- name: Token2Chunk
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/base/token2_chunk/index.html#sparknlp.annotator.token.token2_chunk.Token2Chunk
    method: GET
    data_selector: records
    params: {}
- name: TokenAssembler
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/base/token_assembler/index.html#sparknlp.base.token_assembler.TokenAssembler
    method: GET
    data_selector: records
    params: {}
- name: Tokenizer
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/token/tokenizer/index.html#sparknlp.annotator.token.tokenizer.Tokenizer
    method: GET
    data_selector: records
    params: {}
- name: TypedDependencyParser
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/dependency/typed_dependency_parser/index.html#sparknlp.annotator.dependency.typed_dependency_parser.TypedDependencyParserApproach
    method: GET
    data_selector: records
    params: {}
- name: ViveknSentiment
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/sentiment/vivekn_sentiment/index.html#sparknlp.annotator.sentiment.vivekn_sentiment.ViveknSentimentApproach
    method: GET
    data_selector: records
    params: {}
- name: Word2VecApproach
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/embeddings/word2vec/index.html#sparknlp.annotator.embeddings.word2vec.Word2VecApproach
    method: GET
    data_selector: records
    params: {}
- name: Word2VecModel
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/embeddings/word2vec/index.html#sparknlp.annotator.embeddings.word2vec.Word2VecModel
    method: GET
    data_selector: records
    params: {}
- name: WordEmbeddings
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/embeddings/word_embeddings/index.html#sparknlp.annotator.embeddings.word_embeddings.WordEmbeddings
    method: GET
    data_selector: records
    params: {}
- name: WordEmbeddingsModel
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/embeddings/word_embeddings/index.html#sparknlp.annotator.embeddings.word_embeddings.WordEmbeddingsModel
    method: GET
    data_selector: records
    params: {}
- name: WordSegmenter
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/ws/word_segmenter/index.html#sparknlp.annotator.ws.word_segmenter.WordSegmenterApproach
    method: GET
    data_selector: records
    params: {}
- name: YakeKeywordExtraction
  endpoint:
    path: /api/keyword-extraction/yake
    method: POST
    data_selector: keywords
    params:
      threshold: 0.6
      minNGrams: 2
      nKeywords: 10
- name: albert_embeddings
  endpoint:
    path: /api/albert_embeddings
    method: GET
    data_selector: records
- name: xlnet_embeddings
  endpoint:
    path: /api/xlnet_embeddings
    method: GET
    data_selector: records
- name: question_answering
  endpoint:
    path: /api/albert/question_answering
    method: POST
    data_selector: results
    params: {}
- name: BartTransformer
  endpoint:
    path: ''
    method: ''
    data_selector: ''
    params: {}
- name: BertForQuestionAnswering
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/classifier_dl/bert_for_question_answering/index.html#sparknlp.annotator.classifier_dl.bert_for_question_answering.BertForQuestionAnswering
    method: GET
    data_selector: results
    params: {}
- name: BertForSequenceClassification
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/classifier_dl/bert_for_sequence_classification/index.html#sparknlp.annotator.classifier_dl.bert_for_sequence_classification.BertForSequenceClassification
    method: GET
    data_selector: results
    params: {}
- name: BertForTokenClassification
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/classifier_dl/bert_for_token_classification/index.html#sparknlp.annotator.classifier_dl.bert_for_token_classification.BertForTokenClassification
    method: GET
    data_selector: results
    params: {}
- name: BertForZeroShotClassification
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/classifier_dl/bert_for_zero_shot_classification/index.html#sparknlp.annotator.classifier_dl.bert_for_zero_shot_classification.BertForZeroShotClassification
    method: GET
    data_selector: results
    params: {}
- name: BertSentenceEmbeddings
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/embeddings/bert_sentence_embeddings/index.html#sparknlp.annotator.embeddings.bert_sentence_embeddings.BertSentenceEmbeddings
    method: GET
    data_selector: results
    params: {}
- name: NerDLModel
  endpoint:
    path: /ner_model
    method: POST
    data_selector: result
    params:
      input: text
- name: CamemBertForQuestionAnswering
  endpoint:
    path: /camembert/question_answering
    method: POST
    data_selector: answer
    params:
      question: question
      context: context
- name: CamemBertForSequenceClassification
  endpoint:
    path: /camembert/sequence_classification
    method: POST
    data_selector: label
    params:
      text: text
- name: camembert_token_classifier
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/classifier_dl/camembert_for_token_classification/index.html#sparknlp.annotator.classifier_dl.camembert_for_token_classification.CamemBertForTokenClassification
    method: GET
    data_selector: records
- name: trainingData
  endpoint:
    path: /src/test/resources/conll2003/eng.train
    method: GET
    data_selector: records
- name: DistilBertEmbeddings
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/embeddings/distil_bert_embeddings/index.html#sparknlp.annotator.embeddings.distil_bert_embeddings.DistilBertEmbeddings
    method: GET
    data_selector: records
    params: {}
- name: DistilBertForQuestionAnswering
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/classifier_dl/distil_bert_for_question_answering/index.html#sparknlp.annotator.classifier_dl.distil_bert_for_question_answering.DistilBertForQuestionAnswering
    method: GET
    data_selector: records
    params: {}
- name: DistilBertForSequenceClassification
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/classifier_dl/distil_bert_for_sequence_classification/index.html#sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification.DistilBertForSequenceClassification
    method: GET
    data_selector: records
    params: {}
- name: DistilBertForTokenClassification
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/classifier_dl/distil_bert_for_token_classification/index.html#sparknlp.annotator.classifier_dl.distil_bert_for_token_classification.DistilBertForTokenClassification
    method: GET
- name: DistilBertForZeroShotClassification
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/classifier_dl/distil_bert_for_zero_shot_classification/index.html#sparknlp.annotator.classifier_dl.distil_bert_for_zero_shot_classification.DistilBertForZeroShotClassification
    method: GET
- name: E5Embeddings
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/embeddings/e5_embeddings/index.html#sparknlp.annotator.embeddings.e5_embeddings.E5Embeddings
    method: GET
- name: E5VEmbeddings
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/cv/e5v_embeddings/index.html#sparknlp.annotator.cv.e5v_embeddings.E5VEmbeddings
    method: GET
- name: image_captioning
  endpoint:
    path: /image/captioning
    method: POST
    data_selector: result
    params: {}
- name: AutoGGUFEmbeddings
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/embeddings/auto_gguf_embeddings/index.html
    method: GET
    data_selector: records
    params: {}
- name: AutoGGUFModel
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/seq2seq/auto_gguf_model/index.html
    method: GET
    data_selector: records
    params: {}
- name: AutoGGUFReranker
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/seq2seq/auto_gguf_reranker/index.html
    method: GET
    data_selector: records
    params: {}
- name: instructor_embeddings
  endpoint:
    path: /api/instructor_embeddings
    method: GET
    data_selector: embeddings
    params: {}
- name: default_model
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/seq2seq/auto_gguf_vision_model/index.html
    method: GET
    data_selector: model
    params: {}
- name: LongformerForQuestionAnswering
  endpoint:
    path: /LongformerForQuestionAnswering
    method: GET
    data_selector: result
    params: {}
- name: LongformerForSequenceClassification
  endpoint:
    path: /LongformerForSequenceClassification
    method: GET
    data_selector: result
    params: {}
- name: LongformerForTokenClassification
  endpoint:
    path: /LongformerForTokenClassification
    method: GET
    data_selector: result
    params: {}
- name: image
  endpoint:
    path: /api/image
    method: GET
    data_selector: results
    params: {}
- name: chunk
  endpoint:
    path: /api/chunk
    method: POST
    data_selector: results
    params: {}
- name: document
  endpoint:
    path: /api/document
    method: GET
    data_selector: results
    params: {}
- name: translation
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/seq2seq/marian_transformer/index.html#sparknlp.annotator.seq2seq.marian_transformer.MarianTransformer
    method: GET
    data_selector: result
- name: visualQA
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/cv/paligemma_for_multimodal/index.html#sparknlp.annotator.cv.paligemma_for_multimodal.PaliGemmaForMultiModal
    method: GET
    data_selector: models
    params: {}
- name: context_spell_checker
  endpoint:
    path: /api/spellcheck
    method: POST
    data_selector: results
    params: {}
- name: token_classifier
  endpoint:
    path: /models/roberta_for_token_classification
    method: GET
    data_selector: result
    params: {}
- name: context_spell_checker
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/spell_check/context_spell_checker/index.html
    method: GET
    data_selector: records
    params: {}
- name: date2chunk
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/date2_chunk/index.html
    method: GET
    data_selector: records
    params: {}
- name: dependency_parser
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/dependency/dependency_parser/index.html
    method: GET
    data_selector: records
    params: {}
- name: doc2chunk
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/base/doc2_chunk/index.html
    method: GET
    data_selector: records
    params: {}
- name: document
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/embeddings/doc2vec/index.html#sparknlp.annotator.embeddings.doc2vec.Doc2VecApproach
    method: GET
    data_selector: result
    params: {}
- name: doc2vecmodel
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/embeddings/doc2vec/index.html#sparknlp.annotator.embeddings.doc2vec.Doc2VecModel
    method: GET
    data_selector: result
    params: {}
- name: RoBertaForZeroShotClassification
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/classifier_dl/roberta_for_zero_shot_classification/index.html#sparknlp.annotator.classifier_dl.roberta_bert_for_zero_shot_classification.RoBertaForZeroShotClassification
    method: GET
    data_selector: records
    params: {}
- name: RoBertaSentenceEmbeddings
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/embeddings/roberta_sentence_embeddings/index.html#sparknlp.annotator.embeddings.roberta_sentence_embeddings.RoBertaSentenceEmbeddings
    method: GET
    data_selector: records
    params: {}
- name: SmolVLMTransformer
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/cv/smolvlm_transformer/index.html#sparknlp.annotator.cv.smolvlm_transformer.SmolVLMTransformer
    method: GET
    data_selector: records
    params: {}
- name: SpanBertCoref
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/coref/spanbert_coref/index.html#python.sparknlp.annotator.coref.spanbert_coref.SpanBertCorefModel
    method: GET
    data_selector: records
    params: {}
- name: document_normalizer
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/document_normalizer/index.html#sparknlp.annotator.document_normalizer.DocumentNormalizer
    method: GET
    data_selector: records
- name: SwinForImageClassification
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/cv/swin_for_image_classification/index.html#sparknlp.annotator.cv.swin_for_image_classification.SwinForImageClassification
    method: GET
- name: embeddings
  endpoint:
    path: ''
    method: ''
    data_selector: ''
    params: {}
- name: graph_extraction
  endpoint:
    path: /api/graph_extraction
    method: GET
    data_selector: graph
- name: uae_embeddings
  endpoint:
    path: /models/uae_embeddings
    method: GET
    data_selector: embeddings
    params: {}
- name: lemmatizer
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/lemmatizer/index.html
    method: GET
    data_selector: results
    params: {}
- name: multiClassifierDL
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/classifier_dl/multi_classifier_dl/index.html
    method: GET
    data_selector: results
    params: {}
- name: image_captioning
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/cv/vision_encoder_decoder_for_image_captioning/index.html
    method: GET
    data_selector: result
- name: question_answering
  endpoint:
    path: /api/question_answering
    method: POST
    data_selector: result
- name: MultiDateMatcher
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/matcher/multi_date_matcher/index.html#sparknlp.annotator.matcher.multi_date_matcher.MultiDateMatcher
    method: GET
    data_selector: records
    params: {}
- name: MultiDocumentAssembler
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/base/multi_document_assembler/index.html#sparknlp.base.multi_document_assembler.MultiDocumentAssembler
    method: GET
    data_selector: records
    params: {}
- name: NGramGenerator
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/n_gram_generator/index.html#sparknlp.annotator.n_gram_generator.NGramGenerator
    method: GET
    data_selector: records
    params: {}
- name: NerConverter
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/ner/ner_converter/index.html#sparknlp.annotator.ner.ner_converter.NerConverter
    method: GET
    data_selector: records
    params: {}
- name: NerCrf
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/ner/ner_crf/index.html#sparknlp.annotator.ner.ner_crf.NerCrfApproach
    method: GET
    data_selector: records
    params: {}
- name: XlmRoBertaForTokenClassification
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/classifier_dl/xlm_roberta_for_token_classification/index.html#sparknlp.annotator.classifier_dl.xlm_roberta_for_token_classification.XlmRoBertaForTokenClassification
    method: GET
    data_selector: records
    params: {}
- name: XlmRoBertaForZeroShotClassification
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/classifier_dl/xlm_roberta_for_zero_shot_classification/index.html#sparknlp.annotator.classifier_dl.xlm_roberta_for_zero_shot_classification.XlmRoBertaForZeroShotClassification
    method: GET
    data_selector: records
    params: {}
- name: XlmRoBertaSentenceEmbeddings
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/embeddings/xlm_roberta_sentence_embeddings/index.html#sparknlp.annotator.embeddings.xlm_roberta_sentence_embeddings.XlmRoBertaSentenceEmbeddings
    method: GET
    data_selector: records
    params: {}
- name: XlnetEmbeddings
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/embeddings/xlnet_embeddings/index.html#sparknlp.annotator.embeddings.xlnet_embeddings.XlnetEmbeddings
    method: GET
    data_selector: records
    params: {}
- name: xlnet_embeddings
  endpoint:
    path: /xlnet_embeddings
    method: GET
    data_selector: results
- name: conll
  endpoint:
    path: /src/test/resources/conll2003/eng.train
    method: GET
    data_selector: records
    params: {}
- name: zero_shot_ner
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/ner/zero_shot_ner_model/index.html
    method: GET
    data_selector: results
    params: {}
- name: normalizer
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/normalizer/index.html#sparknlp.annotator.normalizer.Normalizer
    method: GET
    data_selector: result
    params: {}
- name: norvig_sweeting
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/spell_check/norvig_sweeting/index.html#sparknlp.annotator.spell_check.norvig_sweeting.NorvigSweetingApproach
    method: GET
    data_selector: result
    params: {}
- name: Reader2Image
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/reader/Reader2Image/index.html
    method: GET
    data_selector: records
- name: document
  endpoint:
    path: ''
    method: ''
    data_selector: ''
    params: {}
- name: SentimentDLApproach
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/classifier_dl/sentiment_dl/index.html#sparknlp.annotator.classifier_dl.sentiment_dl.SentimentDLApproach
    method: GET
    data_selector: records
    params: {}
- name: SentimentDetector
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/sentiment/sentiment_detector/index.html#sparknlp.annotator.sentiment.sentiment_detector.SentimentDetector
    method: GET
    data_selector: records
    params: {}
- name: StopWordsCleaner
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/stop_words_cleaner/index.html#sparknlp.annotator.stop_words_cleaner.StopWordsCleaner
    method: GET
    data_selector: records
- name: SymmetricDeleteApproach
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/spell_check/symmetric_delete/index.html#sparknlp.annotator.spell_check.symmetric_delete.SymmetricDeleteApproach
    method: GET
    data_selector: records
- name: TextMatcher
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/matcher/text_matcher/index.html#sparknlp.annotator.matcher.text_matcher.TextMatcher
    method: GET
    data_selector: records
- name: Token2Chunk
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/base/token2_chunk/index.html#sparknlp.annotator.token.token2_chunk.Token2Chunk
    method: GET
    data_selector: records
- name: TokenAssembler
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/base/token_assembler/index.html#sparknlp.base.token_assembler.TokenAssembler
    method: GET
    data_selector: records
- name: Tokenizer
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/token/tokenizer/index.html#sparknlp.annotator.token.tokenizer.Tokenizer
    method: GET
    data_selector: records
    params: {}
- name: AlbertEmbeddings
  endpoint:
    path: /HuggingFace in Spark NLP - ALBERT
    method: GET
- name: AlbertForQuestionAnswering
  endpoint:
    path: /HuggingFace in Spark NLP - AlbertForQuestionAnswering
    method: GET
- name: AlbertForSequenceClassification
  endpoint:
    path: /HuggingFace in Spark NLP - AlbertForSequenceClassification
    method: GET
- name: AlbertForTokenClassification
  endpoint:
    path: /HuggingFace in Spark NLP - AlbertForTokenClassification
    method: GET
- name: BertEmbeddings
  endpoint:
    path: /HuggingFace in Spark NLP - BERT
    method: GET
- name: BertForQuestionAnswering
  endpoint:
    path: /HuggingFace in Spark NLP - BertForQuestionAnswering
    method: GET
- name: BertForSequenceClassification
  endpoint:
    path: /HuggingFace in Spark NLP - BertForSequenceClassification
    method: GET
- name: BertForTokenClassification
  endpoint:
    path: /HuggingFace in Spark NLP - BertForTokenClassification
    method: GET
- name: BertForZeroShotClassification
  endpoint:
    path: /HuggingFace in Spark NLP - BertForZeroShotClassification
    method: GET
- name: BertSentenceEmbeddings
  endpoint:
    path: /HuggingFace in Spark NLP - BERT Sentence
    method: GET
- name: BertSentenceEmbeddings - Fine Tuned
  endpoint:
    path: /Fine Tuned Sentence Bert in Spark NLP
    method: GET
- name: CamemBertEmbeddings
  endpoint:
    path: /HuggingFace in Spark NLP - CamemBERT
    method: GET
- name: CamemBertForQuestionAnswering
  endpoint:
    path: /HuggingFace in Spark NLP - CamemBertForQuestionAnswering
    method: GET
- name: CamemBertForSequenceClassification
  endpoint:
    path: /HuggingFace in Spark NLP - CamemBertForSequenceClassification
    method: GET
- name: CamemBertForTokenClassification
  endpoint:
    path: /HuggingFace in Spark NLP - CamemBertForTokenClassification
    method: GET
- name: ConvNextForImageClassification
  endpoint:
    path: /HuggingFace in Spark NLP - ConvNextForImageClassification
    method: GET
- name: DeBertaEmbeddings
  endpoint:
    path: /HuggingFace in Spark NLP - DeBERTa
    method: GET
- name: DeBertaForQuestionAnswering
  endpoint:
    path: /HuggingFace in Spark NLP - DeBertaForQuestionAnswering
    method: GET
- name: DistilBertEmbeddings
  endpoint:
    path: /HuggingFace in Spark NLP - DistilBERT
    method: GET
- name: DistilBertForQuestionAnswering
  endpoint:
    path: /HuggingFace in Spark NLP - DistilBertForQuestionAnswering
    method: GET
- name: DistilBertForSequenceClassification
  endpoint:
    path: /HuggingFace in Spark NLP - DistilBertForSequenceClassification
    method: GET
- name: DistilBertForTokenClassification
  endpoint:
    path: /HuggingFace in Spark NLP - DistilBertForTokenClassification
    method: GET
- name: DistilBertForZeroClassification
  endpoint:
    path: /HuggingFace in Spark NLP - DistilBertForZeroClassification
    method: GET
- name: DistilBertForZeroShotClassification
  endpoint:
    path: /HuggingFace in Spark NLP - DistilBertForZeroShotClassification
    method: GET
- name: LongformerEmbeddings
  endpoint:
    path: /HuggingFace in Spark NLP - Longformer
    method: GET
- name: LongformerForQuestionAnswering
  endpoint:
    path: /HuggingFace in Spark NLP - LongformerForQuestionAnswering
    method: GET
- name: LongformerForSequenceClassification
  endpoint:
    path: /HuggingFace in Spark NLP - LongformerForSequenceClassification
    method: GET
- name: RoBertaEmbeddings
  endpoint:
    path: /HuggingFace in Spark NLP - RoBERTa
    method: GET
- name: RoBertaForQuestionAnswering
  endpoint:
    path: /HuggingFace in Spark NLP - RoBertaForQuestionAnswering
    method: GET
- name: RoBertaForSequenceClassification
  endpoint:
    path: /HuggingFace in Spark NLP - RoBertaForSequenceClassification
    method: GET
- name: RoBertaForTokenClassification
  endpoint:
    path: /HuggingFace in Spark NLP - RoBertaForTokenClassification
    method: GET
- name: RoBertaForZeroShotClassification
  endpoint:
    path: /HuggingFace in Spark NLP - RoBertaForZeroShotClassification
    method: GET
- name: SwinForImageClassification
  endpoint:
    path: /HuggingFace in Spark NLP - SwinForImageClassification
    method: GET
- name: ViTForImageClassification
  endpoint:
    path: /HuggingFace in Spark NLP - ViTForImageClassification
    method: GET
- name: WhisperForCTC
  endpoint:
    path: /HuggingFace in Spark NLP - WhisperForCTC
    method: GET
- name: YakeKeywordExtraction
  endpoint:
    path: ''
    method: ''
    data_selector: ''
    params: {}
- name: AlbertEmbeddings
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/embeddings/albert_embeddings/index.html#sparknlp.annotator.embeddings.albert_embeddings.AlbertEmbeddings
    method: GET
    data_selector: records
    params: {}
- name: XlnetEmbeddings
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/embeddings/xlnet_embeddings/index.html#sparknlp.annotator.embeddings.xlnet_embeddings.XlnetEmbeddings
    method: GET
    data_selector: records
    params: {}
- name: POS Dataset
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/pos/index.html#sparknlp.training.pos.POS
    method: GET
    data_selector: records
    params: {}
- name: CoNLL Dataset
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/conll/index.html#sparknlp.training.conll.CoNLL
    method: GET
    data_selector: records
    params: {}
- name: CoNLL-U Dataset
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/conllu/index.html#sparknlp.training.conllu.CoNLLU
    method: GET
    data_selector: records
    params: {}
- name: question_answering
  endpoint:
    path: /api/question_answering
    method: POST
    data_selector: results
    params: {}
- name: POS Dataset
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/pos/index.html
    method: GET
- name: CoNLL Dataset
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/conll/index.html
    method: GET
- name: CoNLL-U Dataset
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/conllu/index.html
    method: GET
- name: Spell Checkers Dataset
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/spellcheck/index.html
    method: GET
- name: document
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/seq2seq/bart_transformer/index.html#sparknlp.annotator.seq2seq.bart_transformer.BartTransformer
    method: GET
    data_selector: ''
    params: {}
- name: pipeline
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/seq2seq/bart_transformer/index.html#sparknlp.annotator.seq2seq.bart_transformer.BartTransformer
    method: GET
    data_selector: ''
    params: {}
- name: dependency_parser
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/dependency/dependency_parser
    method: GET
    data_selector: records
    params: {}
- name: BertForQuestionAnswering
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/classifier_dl/bert_for_question_answering/index.html#sparknlp.annotator.classifier_dl.bert_for_question_answering.BertForQuestionAnswering
    method: GET
    data_selector: records
- name: BertForSequenceClassification
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/classifier_dl/bert_for_sequence_classification/index.html#sparknlp.annotator.classifier_dl.bert_for_sequence_classification.BertForSequenceClassification
    method: GET
    data_selector: records
- name: BertForTokenClassification
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/classifier_dl/bert_for_token_classification/index.html#sparknlp.annotator.classifier_dl.bert_for_token_classification.BertForTokenClassification
    method: GET
    data_selector: records
- name: BertForZeroShotClassification
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/classifier_dl/bert_for_zero_shot_classification/index.html#sparknlp.annotator.classifier_dl.bert_for_zero_shot_classification.BertForZeroShotClassification
    method: GET
    data_selector: records
- name: BertSentenceEmbeddings
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/embeddings/bert_sentence_embeddings/index.html#sparknlp.annotator.embeddings.bert_sentence_embeddings.BertSentenceEmbeddings
    method: GET
    data_selector: records
- name: POS Dataset
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/pos/index.html#sparknlp.training.pos.POS
    method: GET
    data_selector: records
    params: {}
- name: CoNLL Dataset
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/conll/index.html#sparknlp.training.conll.CoNLL
    method: GET
    data_selector: records
    params: {}
- name: CoNLL-U Dataset
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/conllu/index.html#sparknlp.training.conllu.CoNLLU
    method: GET
    data_selector: records
    params: {}
- name: PubTator Dataset
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/pub_tator/index.html#sparknlp.training.pub_tator.PubTator
    method: GET
    data_selector: records
    params: {}
- name: DependencyParserApproach
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/dependency/dependency_parser/index.html#sparknlp.annotator.dependency.dependency_parser.DependencyParserApproach
    method: GET
    data_selector: records
    params: {}
- name: NerDLModel
  endpoint:
    path: /pretrained/ner_conll_xlnet_base_cased/en
    method: GET
    data_selector: result
    params: {}
- name: CamemBertEmbeddings
  endpoint:
    path: /pretrained/camembert_base/en
    method: GET
    data_selector: result
    params: {}
- name: CamemBertForQuestionAnswering
  endpoint:
    path: /pretrained/camembert_base_qa_fquad
    method: GET
    data_selector: result
    params: {}
- name: CamemBertForSequenceClassification
  endpoint:
    path: /pretrained/camembert_base_sequence_classifier_allocine
    method: GET
    data_selector: result
    params: {}
- name: input_annotator
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/lemmatizer/index.html#sparknlp.annotator.lemmatizer.Lemmatizer
    method: GET
- name: output_annotator
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/lemmatizer/index.html#sparknlp.annotator.lemmatizer.Lemmatizer
    method: GET
- name: camembert_token_classifier
  endpoint:
    path: /api/camembert/token_classifier
    method: GET
    data_selector: results
- name: POS Dataset
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/pos/index.html#sparknlp.training.pos.POS
    method: GET
    data_selector: records
    params: {}
- name: CoNLL Dataset
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/conll/index.html#sparknlp.training.conll.CoNLL
    method: GET
    data_selector: records
    params: {}
- name: CoNLL-U Dataset
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/conllu/index.html#sparknlp.training.conllu.CoNLLU
    method: GET
    data_selector: records
    params: {}
- name: PubTator Dataset
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/pub_tator/index.html#sparknlp.training.pub_tator.PubTator
    method: GET
    data_selector: records
    params: {}
- name: train_corpus
  endpoint:
    path: ./sherlockholmes.txt
    method: GET
    data_selector: text
    params: {}
- name: deberta_for_question_answering
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/classifier_dl/deberta_for_question_answering
    method: GET
    data_selector: result
    params: {}
- name: deberta_for_sequence_classification
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/classifier_dl/deberta_for_sequence_classification
    method: GET
    data_selector: result
    params: {}
- name: deberta_for_token_classification
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/classifier_dl/deberta_for_token_classification
    method: GET
    data_selector: result
    params: {}
- name: SentenceDetectorDLModel
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/sentence/sentence_detector_dl/index.html#sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLApproach
    method: GET
    data_selector: model
    params: {}
- name: DistilBertEmbeddings
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/embeddings/distil_bert_embeddings/index.html#sparknlp.annotator.embeddings.distil_bert_embeddings.DistilBertEmbeddings
    method: GET
    data_selector: records
- name: DistilBertForQuestionAnswering
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/classifier_dl/distil_bert_for_question_answering/index.html#sparknlp.annotator.classifier_dl.distil_bert_for_question_answering.DistilBertForQuestionAnswering
    method: GET
    data_selector: records
- name: DistilBertForSequenceClassification
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/classifier_dl/distil_bert_for_sequence_classification/index.html#sparknlp.annotator.classifier_dl.distil_bert_for_sequence_classification.DistilBertForSequenceClassification
    method: GET
    data_selector: records
- name: POS Dataset
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/pos/index.html
    method: GET
    data_selector: records
    params: {}
- name: CoNLL Dataset
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/conll/index.html
    method: GET
    data_selector: records
    params: {}
- name: CoNLL-U Dataset
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/conllu/index.html
    method: GET
    data_selector: records
    params: {}
- name: PubTator Dataset
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/pub_tator/index.html
    method: GET
    data_selector: records
    params: {}
- name: dependency_parser
  endpoint:
    path: /api/dependency/parser
    method: POST
    data_selector: results
    params: {}
- name: DistilBertForTokenClassification
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/classifier_dl/distil_bert_for_token_classification
    method: GET
    data_selector: models
    params: {}
- name: DistilBertForZeroShotClassification
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/classifier_dl/distil_bert_for_zero_shot_classification
    method: GET
    data_selector: models
    params: {}
- name: E5Embeddings
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/embeddings/e5_embeddings
    method: GET
    data_selector: models
    params: {}
- name: E5VEmbeddings
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/cv/e5v_embeddings
    method: GET
    data_selector: models
    params: {}
- name: POS Dataset
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/pos/index.html#sparknlp.training.pos.POS
    method: GET
    data_selector: records
    params: {}
- name: CoNLL Dataset
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/conll/index.html#sparknlp.training.conll.CoNLL
    method: GET
    data_selector: records
    params: {}
- name: CoNLL-U Dataset
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/conllu/index.html#sparknlp.training.conllu.CoNLLU
    method: GET
    data_selector: records
    params: {}
- name: PubTator Dataset
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/pub_tator/index.html#sparknlp.training.pub_tator.PubTator
    method: GET
    data_selector: records
    params: {}
- name: corpus
  endpoint:
    path: /corpus
    method: GET
    data_selector: data
    params: {}
- name: GPT2Transformer
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/seq2seq/gpt2_transformer/index.html#sparknlp.annotator.seq2seq.gpt2_transformer.GPT2Transformer
    method: GET
    data_selector: records
- name: pipeline
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/dependency/typed_dependency_parser/index.html
    method: GET
    data_selector: pipeline
    params: {}
- name: WordSegmenter
  endpoint:
    path: /api/com/johnsnowlabs/nlp/annotators/ws/WordSegmenterApproach
    method: GET
    data_selector: records
    params: {}
- name: ContextSpellChecker
  endpoint:
    path: /api/com/johnsnowlabs/nlp/annotators/spell/context/ContextSpellCheckerApproach
    method: GET
    data_selector: records
    params: {}
- name: instructor_embeddings
  endpoint:
    path: /api/instructor_embeddings
    method: GET
    data_selector: embeddings
    params: {}
- name: token_classification
  endpoint:
    path: /api/token_classification
    method: POST
    data_selector: result
    params: {}
- name: POS Dataset
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/pos/index.html
    method: GET
    data_selector: records
    params: {}
- name: CoNLL Dataset
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/conll/index.html
    method: GET
    data_selector: records
    params: {}
- name: CoNLL-U Dataset
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/conllu/index.html
    method: GET
    data_selector: records
    params: {}
- name: PubTator Dataset
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/pub_tator/index.html
    method: GET
    data_selector: records
    params: {}
- name: MPNetEmbeddings
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/embeddings/mpnet_embeddings/index.html#sparknlp.annotator.embeddings.mpnet_embeddings.MPNetEmbeddings
    method: GET
    data_selector: records
- name: MPNetForQuestionAnswering
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/classifier_dl/mpnet_for_question_answering/index.html#sparknlp.annotator.classifier_dl.mpnet_for_question_answering.MPNetForQuestionAnswering
    method: GET
    data_selector: records
- name: MPNetForSequenceClassification
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/classifier_dl/mpnet_for_sequence_classification/index.html#sparknlp.annotator.classifier_dl.mpnet_for_sequence_classification.MPNetForSequenceClassification
    method: GET
    data_selector: records
- name: marian
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/seq2seq/marian_transformer/index.html#sparknlp.annotator.seq2seq.marian_transformer.MarianTransformer
    method: GET
    data_selector: records
- name: DependencyParserApproach
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/dependency/dependency_parser/index.html#sparknlp.annotator.dependency.dependency_parser.DependencyParserApproach
    method: GET
    data_selector: records
- name: Lemmatizer
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/lemmatizer/index.html#sparknlp.annotator.lemmatizer.Lemmatizer
    method: GET
    data_selector: records
- name: PerceptronApproach
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/pos/perceptron/index.html#sparknlp.annotator.pos.perceptron.PerceptronApproach
    method: GET
    data_selector: records
- name: SentenceDetectorDLApproach
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/sentence/sentence_detector_dl/index.html#sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLApproach
    method: GET
    data_selector: records
- name: PaliGemma
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/cv/paligemma_for_multimodal/index.html#sparknlp.annotator.cv.paligemma_for_multimodal.PaliGemmaForMultiModal
    method: GET
    data_selector: models
    params: {}
- name: token_classification
  endpoint:
    path: /roberta/token/classification
    method: POST
    data_selector: result
    params: {}
- name: TypedDependencyParserApproach
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/dependency/typed_dependency_parser/index.html
    method: GET
- name: WordSegmenterApproach
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/ws/word_segmenter/index.html
    method: GET
- name: ContextSpellCheckerApproach
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/spell_check/context_spell_checker/index.html
    method: GET
- name: RoBertaForZeroShotClassification
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/classifier_dl/roberta_for_zero_shot_classification/index.html#sparknlp.annotator.classifier_dl.roberta_bert_for_zero_shot_classification.RoBertaForZeroShotClassification
    method: GET
    data_selector: records
    params: {}
- name: NorvigSweetingApproach
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/spell_check/norvig_sweeting/index.html#sparknlp.annotator.spell_check.norvig_sweeting.NorvigSweetingApproach
    method: GET
    data_selector: records
    params: {}
- name: SymmetricDeleteApproach
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/spell_check/symmetric_delete/index.html#sparknlp.annotator.spell_check.symmetric_delete.SymmetricDeleteApproach
    method: GET
    data_selector: records
    params: {}
- name: NerCrfApproach
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/ner/ner_crf/index.html#sparknlp.annotator.ner.ner_crf.NerCrfApproach
    method: GET
    data_selector: records
    params: {}
- name: image_classifier
  endpoint:
    path: /api/path/to/image_classifier
    method: POST
    data_selector: results
- name: POS Dataset
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/pos/index.html
    method: GET
- name: CoNLL Dataset
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/conll/index.html
    method: GET
- name: CoNLL-U Dataset
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/conllu/index.html
    method: GET
- name: PubTator Dataset
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/pub_tator/index.html
    method: GET
- name: uae_large_v1
  endpoint:
    path: /api/com/johnsnowlabs/nlp/embeddings/UAEEmbeddings
    method: GET
    data_selector: records
    params: {}
- name: dependency_parser
  endpoint:
    path: /dependency/parser
    method: POST
    data_selector: parser_result
- name: image_captioning
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/cv/vision_encoder_decoder_for_image_captioning/index.html#sparknlp.annotator.cv.vision_encoder_decoder_for_image_captioning.VisionEncoderDecoderForImageCaptioning
    method: GET
    data_selector: records
    params: {}
- name: Input Annotator Types
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/dependency/typed_dependency_parser/index.html
    method: GET
    data_selector: Input Annotator Types
    params: {}
- name: Output Annotator Type
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/dependency/typed_dependency_parser/index.html
    method: GET
    data_selector: Output Annotator Type
    params: {}
- name: trainingData
  endpoint:
    path: src/test/resources/conll2003/eng.train
    method: GET
    data_selector: records
- name: Input Annotator Types
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/ner/ner_dl/index.html#sparknlp.annotator.ner.ner_dl.NerDLApproach
    method: GET
    data_selector: DOCUMENT, TOKEN, WORD_EMBEDDINGS
    params: {}
- name: Output Annotator Type
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/ner/ner_dl/index.html#sparknlp.annotator.ner.ner_dl.NerDLApproach
    method: GET
    data_selector: NAMED_ENTITY
    params: {}
- name: question_answering
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/classifier_dl/xlm_roberta_for_question_answering/index.html
    method: GET
    data_selector: result
- name: sequence_classification
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/classifier_dl/xlm_roberta_for_sequence_classification/index.html
    method: GET
    data_selector: result
- name: POS Dataset
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/pos/index.html
    method: GET
    data_selector: records
    params: {}
- name: CoNLL Dataset
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/conll/index.html
    method: GET
    data_selector: records
    params: {}
- name: CoNLL-U Dataset
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/conllu/index.html
    method: GET
    data_selector: records
    params: {}
- name: PubTator Dataset
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/pub_tator/index.html
    method: GET
    data_selector: records
    params: {}
- name: XlmRoBertaForTokenClassification
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/classifier_dl/xlm_roberta_for_token_classification/index.html#sparknlp.annotator.classifier_dl.xlm_roberta_for_token_classification.XlmRoBertaForTokenClassification
    method: GET
    data_selector: records
- name: XlmRoBertaForZeroShotClassification
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/classifier_dl/xlm_roberta_for_zero_shot_classification/index.html#sparknlp.annotator.classifier_dl.xlm_roberta_for_zero_shot_classification.XlmRoBertaForZeroShotClassification
    method: GET
    data_selector: records
- name: XlmRoBertaSentenceEmbeddings
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/embeddings/xlm_roberta_sentence_embeddings/index.html#sparknlp.annotator.embeddings.xlm_roberta_sentence_embeddings.XlmRoBertaSentenceEmbeddings
    method: GET
    data_selector: records
- name: XlnetEmbeddings
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/embeddings/xlnet_embeddings/index.html#sparknlp.embeddings.xlnet_embeddings.XlnetEmbeddings
    method: GET
    data_selector: records
- name: pubtatorDataSet
  endpoint:
    path: /src/test/resources/corpus_pubtator_sample.txt
    method: GET
    data_selector: records
- name: trainCorpus
  endpoint:
    path: ./sherlockholmes.txt
    method: GET
    data_selector: text
- name: xlnet_embeddings
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/embeddings/xlnet_embeddings/index.html#sparknlp.annotator.embeddings.xlnet_embeddings.XlnetEmbeddings
    method: GET
    data_selector: ''
    params: {}
- name: xlnet_for_sequence_classification
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/classifier_dl/xlnet_for_sequence_classification/index.html#sparknlp.annotator.classifier_dl.xlnet_for_sequence_classification.XlnetForSequenceClassification
    method: GET
    data_selector: ''
    params: {}
- name: xlnet_for_token_classification
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/classifier_dl/xlnet_for_token_classification/index.html#sparknlp.annotator.classifier_dl.xlnet_for_token_classification.XlnetForTokenClassification
    method: GET
    data_selector: ''
    params: {}
- name: typed_dependency_parser
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/dependency/typed_dependency_parser/index.html#sparknlp.annotator.dependency.typed_dependency_parser.TypedDependencyParserApproach
    method: GET
- name: word_segmenter
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/ws/word_segmenter/index.html#sparknlp.annotator.ws.word_segmenter.WordSegmenterApproach
    method: GET
- name: context_spell_checker
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/spell_check/context_spell_checker/index.html#sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach
    method: GET
- name: norvig_sweeting
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/spell_check/norvig_sweeting/index.html#sparknlp.annotator.spell_check.norvig_sweeting.NorvigSweetingApproach
    method: GET
- name: symmetric_delete
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/spell_check/symmetric_delete/index.html#sparknlp.annotator.spell_check.symmetric_delete.SymmetricDeleteApproach
    method: GET
- name: ner_crf
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/ner/ner_crf/index.html#sparknlp.annotator.ner.ner_crf.NerCrfApproach
    method: GET
- name: ZeroShotNerModel
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/ner/zero_shot_ner_model/index.html#sparknlp.annotator.ner.zero_shot_ner_model.ZeroShotNerModel
    method: GET
    data_selector: models
    params: {}
- name: ner_model
  endpoint:
    path: /ner_model
    method: POST
    data_selector: results
    params: {}
- name: classifier_model
  endpoint:
    path: /classifier_model
    method: POST
    data_selector: results
    params: {}
- name: SENTENCE_EMBEDDINGS
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/classifier_dl/multi_classifier_dl/index.html#sparknlp.annotator.classifier_dl.multi_classifier_dl.MultiClassifierDLApproach
    method: GET
- name: CATEGORY
  endpoint:
    path: /api/com/johnsnowlabs/nlp/annotators/classifier/dl/MultiClassifierDLApproach
    method: GET
- name: POS Dataset
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/pos/index.html
    method: GET
    data_selector: records
    params: {}
- name: CoNLL Dataset
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/conll/index.html
    method: GET
    data_selector: records
    params: {}
- name: CoNLL-U Dataset
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/conllu/index.html
    method: GET
    data_selector: records
    params: {}
- name: PubTator Dataset
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/pub_tator/index.html
    method: GET
    data_selector: records
    params: {}
- name: DependencyParserApproach
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/dependency/dependency_parser/index.html
    method: GET
- name: Lemmatizer
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/lemmatizer/index.html
    method: GET
- name: PerceptronApproach
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/pos/perceptron/index.html
    method: GET
- name: SentenceDetectorDLApproach
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/sentence/sentence_detector_dl/index.html
    method: GET
- name: TypedDependencyParser
  endpoint:
    path: /docs/en/annotators#dependencyparser
    method: GET
- name: CoNLL
  endpoint:
    path: /conll
    method: GET
    data_selector: records
    params: {}
- name: training_data
  endpoint:
    path: /src/test/resources/classifier/e2e.csv
    method: GET
    data_selector: records
    params: {}
- name: ViveknSentimentApproach
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/sentiment/vivekn_sentiment/index.html#sparknlp.annotator.sentiment.vivekn_sentiment.ViveknSentimentApproach
    method: GET
- name: ViveknSentimentApproach
  endpoint:
    path: /api/com/johnsnowlabs/nlp/annotators/sda/vivekn/ViveknSentimentApproach
    method: GET
- name: AlbertEmbeddings
  endpoint:
    path: /HuggingFace in Spark NLP - ALBERT
    method: GET
- name: AlbertForQuestionAnswering
  endpoint:
    path: /HuggingFace in Spark NLP - AlbertForQuestionAnswering
    method: GET
- name: AlbertForSequenceClassification
  endpoint:
    path: /HuggingFace in Spark NLP - AlbertForSequenceClassification
    method: GET
- name: AlbertForTokenClassification
  endpoint:
    path: /HuggingFace in Spark NLP - AlbertForTokenClassification
    method: GET
- name: BertEmbeddings
  endpoint:
    path: /HuggingFace in Spark NLP - BERT
    method: GET
- name: BertForQuestionAnswering
  endpoint:
    path: /HuggingFace in Spark NLP - BertForQuestionAnswering
    method: GET
- name: BertForSequenceClassification
  endpoint:
    path: /HuggingFace in Spark NLP - BertForSequenceClassification
    method: GET
- name: BertForTokenClassification
  endpoint:
    path: /HuggingFace in Spark NLP - BertForTokenClassification
    method: GET
- name: BertForZeroShotClassification
  endpoint:
    path: /HuggingFace in Spark NLP - BertForZeroShotClassification
    method: GET
- name: BertSentenceEmbeddings
  endpoint:
    path: /HuggingFace in Spark NLP - BERT Sentence
    method: GET
- name: BertSentenceEmbeddings - Fine Tuned
  endpoint:
    path: /Fine Tuned Sentence Bert in Spark NLP
    method: GET
- name: CamemBertEmbeddings
  endpoint:
    path: /HuggingFace in Spark NLP - CamemBERT
    method: GET
- name: CamemBertForQuestionAnswering
  endpoint:
    path: /HuggingFace in Spark NLP - CamemBertForQuestionAnswering
    method: GET
- name: CamemBertForSequenceClassification
  endpoint:
    path: /HuggingFace in Spark NLP - CamemBertForSequenceClassification
    method: GET
- name: CamemBertForTokenClassification
  endpoint:
    path: /HuggingFace in Spark NLP - CamemBertForTokenClassification
    method: GET
- name: ConvNextForImageClassification
  endpoint:
    path: /HuggingFace in Spark NLP - ConvNextForImageClassification
    method: GET
- name: DeBertaEmbeddings
  endpoint:
    path: /HuggingFace in Spark NLP - DeBERTa
    method: GET
- name: DeBertaForQuestionAnswering
  endpoint:
    path: /HuggingFace in Spark NLP - DeBertaForQuestionAnswering
    method: GET
- name: DistilBertEmbeddings
  endpoint:
    path: /HuggingFace in Spark NLP - DistilBERT
    method: GET
- name: DistilBertForQuestionAnswering
  endpoint:
    path: /HuggingFace in Spark NLP - DistilBertForQuestionAnswering
    method: GET
- name: DistilBertForSequenceClassification
  endpoint:
    path: /HuggingFace in Spark NLP - DistilBertForSequenceClassification
    method: GET
- name: DistilBertForTokenClassification
  endpoint:
    path: /HuggingFace in Spark NLP - DistilBertForTokenClassification
    method: GET
- name: LongformerEmbeddings
  endpoint:
    path: /HuggingFace in Spark NLP - Longformer
    method: GET
- name: LongformerForQuestionAnswering
  endpoint:
    path: /HuggingFace in Spark NLP - LongformerForQuestionAnswering
    method: GET
- name: LongformerForSequenceClassification
  endpoint:
    path: /HuggingFace in Spark NLP - LongformerForSequenceClassification
    method: GET
- name: RoBertaEmbeddings
  endpoint:
    path: /HuggingFace in Spark NLP - RoBERTa
    method: GET
- name: RoBertaForQuestionAnswering
  endpoint:
    path: /HuggingFace in Spark NLP - RoBertaForQuestionAnswering
    method: GET
- name: RoBertaForSequenceClassification
  endpoint:
    path: /HuggingFace in Spark NLP - RoBertaForSequenceClassification
    method: GET
- name: RoBertaForTokenClassification
  endpoint:
    path: /HuggingFace in Spark NLP - RoBertaForTokenClassification
    method: GET
- name: SwinForImageClassification
  endpoint:
    path: /HuggingFace in Spark NLP - SwinForImageClassification
    method: GET
- name: ViTForImageClassification
  endpoint:
    path: /HuggingFace in Spark NLP - ViTForImageClassification
    method: GET
- name: WhisperForCTC
  endpoint:
    path: /HuggingFace in Spark NLP - WhisperForCTC
    method: GET
- name: POS
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/pos/index.html#sparknlp.training.pos.POS
    method: GET
    data_selector: records
    params: {}
- name: CoNLL
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/conll/index.html#sparknlp.training.conll.CoNLL
    method: GET
    data_selector: records
    params: {}
- name: CoNLLU
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/conllu/index.html#sparknlp.training.conllu.CoNLLU
    method: GET
    data_selector: records
    params: {}
- name: PubTator
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/pub_tator/index.html#sparknlp.training.pub_tator.PubTator
    method: GET
    data_selector: records
    params: {}
- name: train_corpus
  endpoint:
    path: ./sherlockholmes.txt
    method: GET
    data_selector: text
    params: {}
- name: document
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/dependency/typed_dependency_parser/index.html#sparknlp.annotator.dependency.typed_dependency_parser.TypedDependencyParserApproach
    method: GET
    data_selector: records
- name: token
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/dependency/typed_dependency_parser/index.html#sparknlp.annotator.dependency.typed_dependency_parser.TypedDependencyParserApproach
    method: GET
    data_selector: records
- name: XlmRoBertaEmbeddings
  endpoint:
    path: https://github.com/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/HuggingFace%20in%20Spark%20NLP%20-%20XLM-RoBERTa.ipynb
    method: GET
    data_selector: records
- name: XlmRobertaForQuestionAnswering
  endpoint:
    path: https://github.com/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/HuggingFace%20in%20Spark%20NLP%20-%20XlmRobertaForQuestionAnswering.ipynb
    method: GET
    data_selector: records
- name: XlmRoBertaForSequenceClassification
  endpoint:
    path: https://github.com/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/HuggingFace%20in%20Spark%20NLP%20-%20BertForSequenceClassification.ipynb
    method: GET
    data_selector: records
- name: XlmRoBertaForTokenClassification
  endpoint:
    path: https://github.com/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/HuggingFace%20in%20Spark%20NLP%20-%20XlmRoBertaForTokenClassification.ipynb
    method: GET
    data_selector: records
- name: XlnetEmbeddings
  endpoint:
    path: https://github.com/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/HuggingFace%20in%20Spark%20NLP%20-%20XLNet.ipynb
    method: GET
    data_selector: records
- name: XlnetForSequenceClassification
  endpoint:
    path: https://github.com/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/HuggingFace%20in%20Spark%20NLP%20-%20XlnetForSequenceClassification.ipynb
    method: GET
    data_selector: records
- name: T5Transformer
  endpoint:
    path: https://github.com/JohnSnowLabs/spark-nlp/blob/master/examples/python/transformers/HuggingFace%20in%20Spark%20NLP%20-%20T5.ipynb
    method: GET
    data_selector: records
- name: smallCorpus
  endpoint:
    path: /src/test/resources/classifier/e2e.csv
    method: GET
    data_selector: records
    params: {}
- name: POS Dataset
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/pos/index.html#sparknlp.training.pos.POS
    method: GET
    data_selector: records
    params: {}
- name: CoNLL Dataset
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/conll/index.html#sparknlp.training.conll.CoNLL
    method: GET
    data_selector: records
    params: {}
- name: CoNLL-U Dataset
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/conllu/index.html#sparknlp.training.conllu.CoNLLU
    method: GET
    data_selector: records
    params: {}
- name: ViveknSentimentApproach
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/sentiment/vivekn_sentiment/index.html#sparknlp.annotator.sentiment.vivekn_sentiment.ViveknSentimentApproach
    method: GET
    data_selector: ''
    params: {}
- name: Doc2VecApproach
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/embeddings/doc2vec/index.html#sparknlp.annotator.embeddings.doc2vec.Doc2VecApproach
    method: GET
    data_selector: ''
    params: {}
- name: Word2VecApproach
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/embeddings/word2vec/index.html#sparknlp.annotator.embeddings.word2vec.Word2VecApproach
    method: GET
    data_selector: ''
    params: {}
- name: AlbertForTokenClassification
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/classifier_dl/albert_for_token_classification/index.html#sparknlp.annotator.classifier_dl.albert_for_token_classification.AlbertForTokenClassification
    method: GET
    data_selector: ''
    params: {}
- name: POS Dataset
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/pos/index.html#sparknlp.training.pos.POS
    method: GET
    data_selector: records
    params: {}
- name: CoNLL Dataset
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/conll/index.html#sparknlp.training.conll.CoNLL
    method: GET
    data_selector: records
    params: {}
- name: CoNLL-U Dataset
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/conllu/index.html#sparknlp.training.conllu.CoNLLU
    method: GET
    data_selector: records
    params: {}
- name: Spell Checkers Dataset
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/conllu/index.html#sparknlp.training.conllu.CoNLLU
    method: GET
    data_selector: records
    params: {}
- name: Dependency
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/dependency/dependency_parser/index.html#sparknlp.annotator.dependency.dependency_parser.DependencyParserApproach
    method: GET
- name: POS Dataset
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/pos/index.html
    method: GET
    data_selector: records
    params: {}
- name: CoNLL Dataset
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/conll/index.html
    method: GET
    data_selector: records
    params: {}
- name: CoNLL-U Dataset
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/conllu/index.html
    method: GET
    data_selector: records
    params: {}
- name: PubTator Dataset
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/pub_tator/index.html
    method: GET
    data_selector: records
    params: {}
- name: DependencyParserApproach
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/dependency/dependency_parser/index.html#sparknlp.annotator.dependency.dependency_parser.DependencyParserApproach
    method: GET
- name: POS Dataset
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/pos/index.html#sparknlp.training.pos.POS
    method: GET
- name: CoNLL Dataset
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/conll/index.html#sparknlp.training.conll.CoNLL
    method: GET
- name: CoNLL-U Dataset
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/conllu/index.html#sparknlp.training.conllu.CoNLLU
    method: GET
- name: PubTator Dataset
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/pub_tator/index.html#sparknlp.training.pub_tator.PubTator
    method: GET
- name: TypedDependencyParserApproach
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/dependency/typed_dependency_parser/index.html
    method: GET
    data_selector: records
- name: WordSegmenterApproach
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/ws/word_segmenter/index.html
    method: GET
    data_selector: records
- name: ContextSpellCheckerApproach
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/spell_check/context_spell_checker/index.html
    method: GET
    data_selector: records
- name: NorvigSweetingApproach
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/spell_check/norvig_sweeting/index.html
    method: GET
    data_selector: records
- name: SymmetricDeleteApproach
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/spell_check/symmetric_delete/index.html
    method: GET
    data_selector: records
- name: NerCrfApproach
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/ner/ner_crf/index.html
    method: GET
    data_selector: records
- name: Input Annotator Types
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/lemmatizer/index.html#sparknlp.annotator.lemmatizer.Lemmatizer
    method: GET
    data_selector: TOKEN
    params: {}
- name: Output Annotator Type
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/lemmatizer/index.html#sparknlp.annotator.lemmatizer.Lemmatizer
    method: GET
    data_selector: TOKEN
    params: {}
- name: document_assembler
  endpoint:
    path: /document_assembler
    method: POST
    data_selector: records
    params: {}
- name: sentence_detector
  endpoint:
    path: /sentence_detector
    method: POST
    data_selector: records
    params: {}
- name: tokenizer
  endpoint:
    path: /tokenizer
    method: POST
    data_selector: records
    params: {}
- name: pos_tagger
  endpoint:
    path: /pos_tagger
    method: POST
    data_selector: records
    params: {}
- name: ner_tagger
  endpoint:
    path: /ner_tagger
    method: POST
    data_selector: records
    params: {}
- name: pipeline
  endpoint:
    path: /pipeline
    method: POST
    data_selector: records
    params: {}
- name: POS Dataset
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/pos/index.html#sparknlp.training.pos.POS
    method: GET
    data_selector: dataset
    params: {}
- name: CoNLL Dataset
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/conll/index.html#sparknlp.training.conll.CoNLL
    method: GET
    data_selector: dataset
    params: {}
- name: CoNLL-U Dataset
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/conllu/index.html#sparknlp.training.conllu.CoNLLU
    method: GET
    data_selector: dataset
    params: {}
- name: PubTator Dataset
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/pub_tator/index.html#sparknlp.training.pub_tator.PubTator
    method: GET
    data_selector: dataset
    params: {}
- name: spell_checkers_dataset
  endpoint:
    path: ./sherlockholmes.txt
    method: GET
    data_selector: text
    params: {}
- name: dependency_parser
  endpoint:
    path: ./src/test/resources/parser/unlabeled/dependency_treebank
    method: GET
    data_selector: dependency
    params: {}
- name: lemmatizer
  endpoint:
    path: ./src/test/resources/lemma-corpus-small/lemmas_small.txt
    method: GET
    data_selector: lemma
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: sentence_detector
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/sentence/sentence_detector_dl/index.html#sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLApproach
    method: GET
    data_selector: DOCUMENT
    params: {}
- name: XlmRoBertaForTokenClassification
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/classifier_dl/xlm_roberta_for_token_classification/index.html#sparknlp.annotator.classifier_dl.xlm_roberta_for_token_classification.XlmRoBertaForTokenClassification
    method: GET
    data_selector: records
- name: POS
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/pos/index.html
    method: GET
    data_selector: records
    params: {}
- name: CoNLL
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/conll/index.html
    method: GET
    data_selector: records
    params: {}
- name: CoNLLU
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/conllu/index.html
    method: GET
    data_selector: records
    params: {}
- name: PubTator
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/pub_tator/index.html
    method: GET
    data_selector: records
    params: {}
- name: pubtator_dataset
  endpoint:
    path: /pubtator
    method: GET
    data_selector: records
    params: {}
- name: POS
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/pos/index.html#sparknlp.training.pos.POS
    method: GET
    data_selector: records
- name: CoNLL
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/conll/index.html#sparknlp.training.conll.CoNLL
    method: GET
    data_selector: records
- name: CoNLLU
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/conllu/index.html#sparknlp.training.conllu.CoNLLU
    method: GET
    data_selector: records
- name: PubTator
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/pub_tator/index.html#sparknlp.training.pub_tator.PubTator
    method: GET
    data_selector: records
- name: POS Dataset
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/pos/index.html#sparknlp.training.pos.POS
    method: GET
    data_selector: records
    params: {}
- name: CoNLL Dataset
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/conll/index.html#sparknlp.training.conll.CoNLL
    method: GET
    data_selector: records
    params: {}
- name: CoNLL-U Dataset
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/conllu/index.html#sparknlp.training.conllu.CoNLLU
    method: GET
    data_selector: records
    params: {}
- name: PubTator Dataset
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/pub_tator/index.html#sparknlp.training.pub_tator.PubTator
    method: GET
    data_selector: records
    params: {}
- name: DependencyParserApproach
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/dependency/dependency_parser/index.html
    method: GET
    data_selector: records
    params: {}
- name: Lemmatizer
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/lemmatizer/index.html
    method: GET
    data_selector: records
    params: {}
- name: PerceptronApproach
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/pos/perceptron/index.html
    method: GET
    data_selector: records
    params: {}
- name: SentenceDetectorDLApproach
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/sentence/sentence_detector_dl/index.html
    method: GET
    data_selector: records
    params: {}
- name: TypedDependencyParser
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/dependency/typed_dependency_parser/index.html
    method: GET
    data_selector: records
    params: {}
- name: TypedDependencyParserApproach
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/dependency/typed_dependency_parser/index.html#sparknlp.annotator.dependency.typed_dependency_parser.TypedDependencyParserApproach
    method: GET
- name: WordSegmenterApproach
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/ws/word_segmenter/index.html#sparknlp.annotator.ws.word_segmenter.WordSegmenterApproach
    method: GET
- name: ContextSpellCheckerApproach
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/spell_check/context_spell_checker/index.html#sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach
    method: GET
- name: NorvigSweetingApproach
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/spell_check/norvig_sweeting/index.html#sparknlp.annotator.spell_check.norvig_sweeting.NorvigSweetingApproach
    method: GET
- name: SymmetricDeleteApproach
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/spell_check/symmetric_delete/index.html#sparknlp.annotator.spell_check.symmetric_delete.SymmetricDeleteApproach
    method: GET
- name: NerCrfApproach
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/ner/ner_crf/index.html#sparknlp.annotator.ner.ner_crf.NerCrfApproach
    method: GET
- name: WordSegmenter
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/ws/word_segmenter/index.html#sparknlp.annotator.ws.word_segmenter.WordSegmenterApproach
    method: GET
    data_selector: records
- name: ContextSpellChecker
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/spell_check/context_spell_checker/index.html#sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach
    method: GET
    data_selector: records
- name: document
  endpoint:
    path: /document
    method: POST
    data_selector: records
- name: sentence
  endpoint:
    path: /sentence
    method: POST
    data_selector: records
- name: token
  endpoint:
    path: /token
    method: POST
    data_selector: records
- name: pos
  endpoint:
    path: /pos
    method: POST
    data_selector: records
- name: ner
  endpoint:
    path: /ner
    method: POST
    data_selector: records
- name: text_representation
  endpoint:
    path: /api/spark-nlp/text-representation
    method: POST
    data_selector: result
    params: {}
- name: sentiment_analysis
  endpoint:
    path: /api/spark-nlp/sentiment-analysis
    method: POST
    data_selector: result
    params: {}
- name: token_classification
  endpoint:
    path: /api/token_classification
    method: POST
    data_selector: results
    params: {}
- name: POS Dataset
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/pos/index.html#sparknlp.training.pos.POS
    method: GET
    data_selector: records
    params: {}
- name: CoNLL Dataset
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/conll/index.html#sparknlp.training.conll.CoNLL
    method: GET
    data_selector: records
    params: {}
- name: CoNLL-U Dataset
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/conllu/index.html#sparknlp.training.conllu.CoNLLU
    method: GET
    data_selector: records
    params: {}
- name: PubTator Dataset
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/pub_tator/index.html#sparknlp.training.pub_tator.PubTator
    method: GET
    data_selector: records
    params: {}
- name: dependency_parser
  endpoint:
    path: /api/dependency-parser
    method: GET
    data_selector: records
    params: {}
- name: token_classifier
  endpoint:
    path: /services/data/vXX.X/sobjects/TokenClassifier
    method: GET
    data_selector: records
    params: {}
- name: TypedDependencyParser
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/dependency/typed_dependency_parser/index.html#sparknlp.annotator.dependency.typed_dependency_parser.TypedDependencyParserApproach
    method: GET
- name: WordSegmenterApproach
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/ws/word_segmenter/index.html#sparknlp.annotator.ws.word_segmenter.WordSegmenterApproach
    method: GET
- name: ContextSpellCheckerApproach
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/spell_check/context_spell_checker/index.html#sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach
    method: GET
- name: NorvigSweetingApproach
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/spell_check/norvig_sweeting/index.html#sparknlp.annotator.spell_check.norvig_sweeting.NorvigSweetingApproach
    method: GET
    data_selector: records
    params: {}
- name: SymmetricDeleteApproach
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/spell_check/symmetric_delete/index.html#sparknlp.annotator.spell_check.symmetric_delete.SymmetricDeleteApproach
    method: GET
    data_selector: records
    params: {}
- name: NerCrfApproach
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/ner/ner_crf/index.html#sparknlp.annotator.ner.ner_crf.NerCrfApproach
    method: GET
    data_selector: records
    params: {}
- name: POS Dataset
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/pos/index.html#sparknlp.training.pos.POS
    method: GET
    data_selector: records
    params: {}
- name: CoNLL Dataset
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/conll/index.html#sparknlp.training.conll.CoNLL
    method: GET
    data_selector: records
    params: {}
- name: CoNLL-U Dataset
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/conllu/index.html#sparknlp.training.conllu.CoNLLU
    method: GET
    data_selector: records
    params: {}
- name: PubTator Dataset
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/pub_tator/index.html#sparknlp.training.pub_tator.PubTator
    method: GET
    data_selector: records
    params: {}
- name: POS Dataset
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/pos/index.html
    method: GET
    data_selector: records
    params: {}
- name: CoNLL Dataset
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/conll/index.html
    method: GET
    data_selector: records
    params: {}
- name: CoNLL-U Dataset
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/conllu/index.html
    method: GET
    data_selector: records
    params: {}
- name: PubTator Dataset
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/pub_tator/index.html
    method: GET
    data_selector: records
    params: {}
- name: dependency_parser
  endpoint:
    path: /api/dependency-parser
    method: POST
    data_selector: dependencies
    params: {}
- name: typed_dependency_parser
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/dependency/typed_dependency_parser/index.html
    method: GET
    data_selector: records
- name: TypedDependencyParserApproach
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/dependency/typed_dependency_parser/index.html#sparknlp.annotator.dependency.typed_dependency_parser.TypedDependencyParserApproach
    method: GET
- name: WordSegmenterApproach
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/ws/word_segmenter/index.html#sparknlp.annotator.ws.word_segmenter.WordSegmenterApproach
    method: GET
- name: ContextSpellCheckerApproach
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/spell_check/context_spell_checker/index.html#sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach
    method: GET
- name: NorvigSweetingApproach
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/spell_check/norvig_sweeting/index.html#sparknlp.annotator.spell_check.norvig_sweeting.NorvigSweetingApproach
    method: GET
- name: SymmetricDeleteApproach
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/spell_check/symmetric_delete/index.html#sparknlp.annotator.spell_check.symmetric_delete.SymmetricDeleteApproach
    method: GET
- name: NerCrfApproach
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/ner/ner_crf/index.html#sparknlp.annotator.ner.ner_crf.NerCrfApproach
    method: GET
- name: document
  endpoint:
    path: src/test/resources/conll2003/eng.train
    method: GET
    data_selector: records
- name: document
  endpoint:
    path: /document
    method: GET
    data_selector: records
    params: {}
- name: sentence
  endpoint:
    path: /sentence
    method: GET
    data_selector: records
    params: {}
- name: token
  endpoint:
    path: /token
    method: GET
    data_selector: records
    params: {}
- name: pos
  endpoint:
    path: /pos
    method: GET
    data_selector: records
    params: {}
- name: label
  endpoint:
    path: /label
    method: GET
    data_selector: records
    params: {}
- name: training_data
  endpoint:
    path: /examples/python/training/english/sentiment-detection/VivekNarayanSentimentApproach.ipynb
    method: GET
    data_selector: results
    params: {}
- name: Input Annotator Types
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/ner/ner_dl/index.html#sparknlp.annotator.ner.ner_dl.NerDLApproach
    method: GET
    data_selector: Input Annotator Types
    params: {}
- name: Output Annotator Type
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/ner/ner_dl/index.html#sparknlp.annotator.ner.ner_dl.NerDLApproach
    method: GET
    data_selector: Output Annotator Type
    params: {}
- name: document
  endpoint:
    path: /services/data/vXX.X/sobjects/Document
    method: GET
    data_selector: records
    params: {}
- name: POS Dataset
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/pos/index.html#sparknlp.training.pos.POS
    method: GET
    data_selector: records
    params: {}
- name: CoNLL Dataset
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/conll/index.html#sparknlp.training.conll.CoNLL
    method: GET
    data_selector: records
    params: {}
- name: CoNLL-U Dataset
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/conllu/index.html#sparknlp.training.conllu.CoNLLU
    method: GET
    data_selector: records
    params: {}
- name: PubTator Dataset
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/pub_tator/index.html#sparknlp.training.pub_tator.PubTator
    method: GET
    data_selector: records
    params: {}
- name: document
  endpoint:
    path: /services/data/vXX.X/sobjects/Document
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: token
  endpoint:
    path: /services/data/vXX.X/sobjects/Token
    method: GET
    data_selector: records
    params: {}
- name: DependencyParserApproach
  endpoint:
    path: https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/parser/dep/DependencyParserApproach.scala
    method: GET
    data_selector: records
- name: Lemmatizer
  endpoint:
    path: https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/Lemmatizer.scala
    method: GET
    data_selector: records
- name: PerceptronApproach
  endpoint:
    path: https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/pos/perceptron/PerceptronApproach.scala
    method: GET
    data_selector: records
- name: SentenceDetectorDLApproach
  endpoint:
    path: https://github.com/JohnSnowLabs/spark-nlp/tree/master/src/main/scala/com/johnsnowlabs/nlp/annotators/sentence_detector_dl/SentenceDetectorDLApproach.scala
    method: GET
    data_selector: records
- name: POS Dataset
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/pos/index.html#sparknlp.training.pos.POS
    method: GET
    data_selector: records
    params: {}
- name: CoNLL Dataset
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/conll/index.html#sparknlp.training.conll.CoNLL
    method: GET
    data_selector: records
    params: {}
- name: CoNLL-U Dataset
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/conllu/index.html#sparknlp.training.conllu.CoNLLU
    method: GET
    data_selector: records
    params: {}
- name: PubTator Dataset
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/pub_tator/index.html#sparknlp.training.pub_tator.PubTator
    method: GET
    data_selector: records
    params: {}
- name: train_corpus
  endpoint:
    path: ./src/test/resources/corpus_pubtator_sample.txt
    method: GET
    data_selector: doc_id
    params: {}
- name: typed_dependency_parser
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/dependency/typed_dependency_parser/index.html
    method: GET
    data_selector: records
- name: word_segmenter
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/ws/word_segmenter/index.html
    method: GET
    data_selector: records
- name: context_spell_checker
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/spell_check/context_spell_checker/index.html
    method: GET
    data_selector: records
- name: norvig_sweeting
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/spell_check/norvig_sweeting/index.html
    method: GET
    data_selector: records
- name: symmetric_delete
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/spell_check/symmetric_delete/index.html
    method: GET
    data_selector: records
- name: ner_crf
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/ner/ner_crf/index.html
    method: GET
    data_selector: records
- name: dependency
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/dependency/typed_dependency_parser/index.html#sparknlp.annotator.dependency.typed_dependency_parser.TypedDependencyParserApproach
    method: GET
- name: word_segmenter
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/ws/word_segmenter/index.html#sparknlp.annotator.ws.word_segmenter.WordSegmenterApproach
    method: GET
- name: trainingData
  endpoint:
    path: /src/test/resources/conll2003/eng.train
    method: READ
    data_selector: rows
- name: document
  endpoint:
    path: /document
    method: GET
    data_selector: records
    params: {}
- name: sentence
  endpoint:
    path: /sentence
    method: GET
    data_selector: records
    params: {}
- name: token
  endpoint:
    path: /token
    method: GET
    data_selector: records
    params: {}
- name: pos
  endpoint:
    path: /pos
    method: GET
    data_selector: records
    params: {}
- name: label
  endpoint:
    path: /label
    method: GET
    data_selector: records
    params: {}
- name: input_annotator
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/classifier_dl/multi_classifier_dl/index.html#sparknlp.annotator.classifier_dl.multi_classifier_dl.MultiClassifierDLApproach
    method: GET
    data_selector: SENTENCE_EMBEDDINGS
    params: {}
- name: output_annotator
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/classifier_dl/multi_classifier_dl/index.html#sparknlp.annotator.classifier_dl.multi_classifier_dl.MultiClassifierDLApproach
    method: GET
    data_selector: CATEGORY
    params: {}
- name: POS Dataset
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/pos/index.html
    method: GET
    data_selector: records
    params: {}
- name: CoNLL Dataset
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/conll/index.html
    method: GET
    data_selector: records
    params: {}
- name: CoNLL-U Dataset
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/conllu/index.html
    method: GET
    data_selector: records
    params: {}
- name: PubTator Dataset
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/pub_tator/index.html
    method: GET
    data_selector: records
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: dependency_treebank
  endpoint:
    path: src/test/resources/parser/unlabeled/dependency_treebank
    method: GET
    data_selector: records
    params: {}
- name: ConllU_format
  endpoint:
    path: src/test/resources/conllu_format
    method: GET
    data_selector: records
    params: {}
- name: document
  endpoint:
    path: /services/data/vXX.X/sobjects/Document
    method: GET
    data_selector: records
    params: {}
- name: document_assembler
  endpoint:
    path: /setInputCol
    method: GET
    data_selector: result
    params: {}
- name: tokenizer
  endpoint:
    path: /setInputCols
    method: GET
    data_selector: result
    params: {}
- name: token_classifier
  endpoint:
    path: /loadSavedModel
    method: GET
    data_selector: result
    params: {}
- name: TypedDependencyParserApproach
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/dependency/typed_dependency_parser/index.html#sparknlp.annotator.dependency.typed_dependency_parser.TypedDependencyParserApproach
    method: GET
- name: WordSegmenterApproach
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/ws/word_segmenter/index.html#sparknlp.annotator.ws.word_segmenter.WordSegmenterApproach
    method: GET
- name: ContextSpellCheckerApproach
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/spell_check/context_spell_checker/index.html#sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach
    method: GET
- name: NorvigSweetingApproach
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/spell_check/norvig_sweeting/index.html#sparknlp.annotator.spell_check.norvig_sweeting.NorvigSweetingApproach
    method: GET
- name: SymmetricDeleteApproach
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/spell_check/symmetric_delete/index.html#sparknlp.annotator.spell_check.symmetric_delete.SymmetricDeleteApproach
    method: GET
- name: NerCrfApproach
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/ner/ner_crf/index.html#sparknlp.annotator.ner.ner_crf.NerCrfApproach
    method: GET
- name: document
  endpoint:
    path: /document
    method: GET
    data_selector: records
- name: sentence
  endpoint:
    path: /sentence
    method: GET
    data_selector: records
- name: token
  endpoint:
    path: /token
    method: GET
    data_selector: records
- name: pos
  endpoint:
    path: /pos
    method: GET
    data_selector: records
- name: ner
  endpoint:
    path: /ner
    method: GET
    data_selector: records
- name: POS Dataset
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/pos/index.html#sparknlp.training.pos.POS
    method: GET
- name: CoNLL Dataset
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/conll/index.html#sparknlp.training.conll.CoNLL
    method: GET
- name: CoNLL-U Dataset
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/conllu/index.html#sparknlp.training.conllu.CoNLLU
    method: GET
- name: PubTator Dataset
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/pub_tator/index.html#sparknlp.training.pub_tator.PubTator
    method: GET
- name: trainDataset
  endpoint:
    path: src/test/resources/classifier/e2e.csv
    method: GET
    data_selector: records
    params:
      header: 'true'
      inferSchema: 'true'
      mode: DROPMALFORMED
- name: smallCorpus
  endpoint:
    path: src/test/resources/classifier/e2e.csv
    method: GET
    data_selector: records
    params:
      header: 'true'
      inferSchema: 'true'
      mode: DROPMALFORMED
- name: corpus_pubtator_sample
  endpoint:
    path: ./src/test/resources/corpus_pubtator_sample.txt
    method: GET
    data_selector: records
- name: sherlockholmes
  endpoint:
    path: ./sherlockholmes.txt
    method: GET
    data_selector: text
- name: dependency_treebank
  endpoint:
    path: src/test/resources/parser/unlabeled/dependency_treebank
    method: GET
    data_selector: dependency
- name: lemmas_small
  endpoint:
    path: src/test/resources/lemma-corpus-small/lemmas_small.txt
    method: GET
    data_selector: lemma
- name: anc_pos_corpus_small
  endpoint:
    path: src/test/resources/anc-pos-corpus-small/test-training.txt
    method: GET
    data_selector: tags
- name: train
  endpoint:
    path: train.txt
    method: GET
    data_selector: sentences
- name: ViveknSentimentApproach
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/sentiment/vivekn_sentiment/index.html#sparknlp.annotator.sentiment.vivekn_sentiment.ViveknSentimentApproach
    method: GET
- name: Doc2VecApproach
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/embeddings/doc2vec/index.html#sparknlp.annotator.embeddings.doc2vec.Doc2VecApproach
    method: GET
- name: Word2VecApproach
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/embeddings/word2vec/index.html#sparknlp.annotator.embeddings.word2vec.Word2VecApproach
    method: GET
- name: AlbertForTokenClassification
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/albert/albert_for_token_classification/index.html#sparknlp.annotator.albert.AlbertForTokenClassification
    method: GET
- name: TypedDependencyParser
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/dependency/typed_dependency_parser/index.html#sparknlp.annotator.dependency.typed_dependency_parser.TypedDependencyParserApproach
    method: GET
- name: trainingData
  endpoint:
    path: /src/test/resources/conll2003/eng.train
    method: GET
    data_selector: records
    params: {}
- name: POS Dataset
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/pos/index.html#sparknlp.training.pos.POS
    method: GET
    data_selector: records
    params: {}
- name: CoNLL Dataset
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/conll/index.html#sparknlp.training.conll.CoNLL
    method: GET
    data_selector: records
    params: {}
- name: CoNLL-U Dataset
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/conllu/index.html#sparknlp.training.conllu.CoNLLU
    method: GET
    data_selector: records
    params: {}
- name: PubTator Dataset
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/pub_tator/index.html#sparknlp.training.pub_tator.PubTator
    method: GET
    data_selector: records
    params: {}
- name: sentiment_analysis
  endpoint:
    path: /sentiment
    method: POST
    data_selector: result_sentiment
    params: {}
- name: Input Annotator Types
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/dependency/typed_dependency_parser/index.html#sparknlp.annotator.dependency.typed_dependency_parser.TypedDependencyParserApproach
    method: GET
    data_selector: records
    params: {}
- name: Output Annotator Type
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/dependency/typed_dependency_parser/index.html#sparknlp.annotator.dependency.typed_dependency_parser.TypedDependencyParserApproach
    method: GET
    data_selector: records
    params: {}
- name: token_classification
  endpoint:
    path: /services/data/vXX.X/sobjects/TokenClassification
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: token_classifier
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/classifier_dl/roberta_for_token_classification/index.html#sparknlp.annotator.classifier_dl.roberta_for_token_classification.RoBertaForTokenClassification
    method: GET
    data_selector: result
    params: {}
- name: document_assembler
  endpoint:
    path: /document/assembler
    method: POST
    data_selector: records
    params: {}
- name: sentence_detector
  endpoint:
    path: /sentence/detector
    method: POST
    data_selector: records
    params: {}
- name: tokenizer
  endpoint:
    path: /tokenizer
    method: POST
    data_selector: records
    params: {}
- name: pos_tagger
  endpoint:
    path: /pos/tagger
    method: POST
    data_selector: records
    params: {}
- name: word_embeddings
  endpoint:
    path: /word/embeddings
    method: POST
    data_selector: records
    params: {}
- name: ner_tagger
  endpoint:
    path: /ner/tagger
    method: POST
    data_selector: records
    params: {}
- name: pipeline
  endpoint:
    path: /pipeline
    method: POST
    data_selector: records
    params: {}
- name: trainDataset
  endpoint:
    path: /src/test/resources/classifier/e2e.csv
    method: GET
    data_selector: records
    params: {}
- name: smallCorpus
  endpoint:
    path: /src/test/resources/classifier/e2e.csv
    method: GET
    data_selector: records
    params: {}
- name: POS Dataset
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/pos/index.html#sparknlp.training.pos.POS
    method: GET
    data_selector: records
    params: {}
- name: CoNLL Dataset
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/conll/index.html#sparknlp.training.conll.CoNLL
    method: GET
    data_selector: records
    params: {}
- name: CoNLL-U Dataset
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/conllu/index.html#sparknlp.training.conllu.CoNLLU
    method: GET
    data_selector: records
    params: {}
- name: PubTator Dataset
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/pub_tator/index.html#sparknlp.training.pub_tator.PubTator
    method: GET
    data_selector: records
    params: {}
- name: ViveknSentimentApproach
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/sentiment/vivekn_sentiment/index.html#sparknlp.annotator.sentiment.vivekn_sentiment.ViveknSentimentApproach
    method: GET
    data_selector: records
    params: {}
- name: Doc2VecApproach
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/embeddings/doc2vec/index.html#sparknlp.annotator.embeddings.doc2vec.Doc2VecApproach
    method: GET
    data_selector: records
    params: {}
- name: Word2VecApproach
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/embeddings/word2vec/index.html#sparknlp.annotator.embeddings.word2vec.Word2VecApproach
    method: GET
    data_selector: records
    params: {}
- name: AlbertForTokenClassification
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/classifier_dl/albert_for_token_classification/index.html#sparknlp.annotator.classifier_dl.albert_for_token_classification.AlbertForTokenClassification
    method: GET
    data_selector: records
    params: {}
- name: DependencyParserApproach
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/dependency/dependency_parser/index.html#sparknlp.annotator.dependency.dependency_parser.DependencyParserApproach
    method: GET
- name: Lemmatizer
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/lemmatizer/index.html#sparknlp.annotator.lemmatizer.Lemmatizer
    method: GET
- name: PerceptronApproach
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/pos/perceptron/index.html#sparknlp.annotator.pos.perceptron.PerceptronApproach
    method: GET
- name: SentenceDetectorDLApproach
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/sentence/sentence_detector_dl/index.html#sparknlp.annotator.sentence.sentence_detector_dl.SentenceDetectorDLApproach
    method: GET
- name: POS Dataset
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/pos/index.html#sparknlp.training.pos.POS
    method: GET
    data_selector: records
    params: {}
- name: CoNLL Dataset
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/conll/index.html#sparknlp.training.conll.CoNLL
    method: GET
    data_selector: records
    params: {}
- name: CoNLL-U Dataset
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/conllu/index.html#sparknlp.training.conllu.CoNLLU
    method: GET
    data_selector: records
    params: {}
- name: PubTator Dataset
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/pub_tator/index.html#sparknlp.training.pub_tator.PubTator
    method: GET
    data_selector: records
    params: {}
- name: TypedDependencyParserApproach
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/dependency/typed_dependency_parser/index.html#sparknlp.annotator.dependency.typed_dependency_parser.TypedDependencyParserApproach
    method: GET
- name: document
  endpoint:
    path: /document
    method: GET
    data_selector: records
- name: sentence
  endpoint:
    path: /sentence
    method: GET
    data_selector: records
- name: token
  endpoint:
    path: /token
    method: GET
    data_selector: records
- name: pos
  endpoint:
    path: /pos
    method: GET
    data_selector: records
- name: label
  endpoint:
    path: /label
    method: GET
    data_selector: records
- name: ViveknSentimentApproach
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/sentiment/vivekn_sentiment/index.html#sparknlp.annotator.sentiment.vivekn_sentiment.ViveknSentimentApproach
    method: GET
    data_selector: result
    params: {}
- name: Doc2VecApproach
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/embeddings/doc2vec/index.html#sparknlp.annotator.embeddings.doc2vec.Doc2VecApproach
    method: GET
    data_selector: result
    params: {}
- name: Word2VecApproach
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/embeddings/word2vec/index.html#sparknlp.annotator.embeddings.word2vec.Word2VecApproach
    method: GET
    data_selector: result
    params: {}
- name: AlbertForTokenClassification
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/classifier_dl/albert_for_token_classification/index.html#sparknlp.annotator.classifier_dl.albert_for_token_classification.AlbertForTokenClassification
    method: GET
    data_selector: result
    params: {}
- name: TypedDependencyParserApproach
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/dependency/typed_dependency_parser/index.html#sparknlp.annotator.dependency.typed_dependency_parser.TypedDependencyParserApproach
    method: GET
    data_selector: records
    params: {}
- name: WordSegmenterApproach
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/ws/word_segmenter/index.html#sparknlp.annotator.ws.word_segmenter.WordSegmenterApproach
    method: GET
    data_selector: records
    params: {}
- name: ContextSpellCheckerApproach
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/spell_check/context_spell_checker/index.html#sparknlp.annotator.spell_check.context_spell_checker.ContextSpellCheckerApproach
    method: GET
    data_selector: records
    params: {}
- name: NorvigSweetingApproach
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/spell_check/norvig_sweeting/index.html#sparknlp.annotator.spell_check.norvig_sweeting.NorvigSweetingApproach
    method: GET
    data_selector: records
    params: {}
- name: SymmetricDeleteApproach
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/spell_check/symmetric_delete/index.html#sparknlp.annotator.spell_check.symmetric_delete.SymmetricDeleteApproach
    method: GET
    data_selector: records
    params: {}
- name: NerCrfApproach
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/ner/ner_crf/index.html#sparknlp.annotator.ner.ner_crf.NerCrfApproach
    method: GET
    data_selector: records
    params: {}
- name: document
  endpoint:
    path: /services/data/vXX.X/sobjects/document
    method: GET
    data_selector: records
    params: {}
- name: token
  endpoint:
    path: /services/data/vXX.X/sobjects/token
    method: GET
    data_selector: records
    params: {}
- name: trainingData
  endpoint:
    path: src/test/resources/conll2003/eng.train
    method: GET
- name: sentimentData
  endpoint:
    path: src/test/resources/classifier/sentiment.csv
    method: GET
- name: multiLabelData
  endpoint:
    path: src/test/resources/classifier/e2e.csv
    method: GET
- name: token_classifier
  endpoint:
    path: ''
    method: ''
    data_selector: ''
    params: {}
- name: XlmRoBertaForTokenClassification
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/classifier_dl/xlm_roberta_for_token_classification/index.html
    method: GET
    data_selector: records
    params: {}
- name: POS Dataset
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/pos/index.html
    method: GET
    data_selector: records
    params: {}
- name: CoNLL Dataset
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/conll/index.html
    method: GET
    data_selector: records
    params: {}
- name: CoNLL-U Dataset
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/conllu/index.html
    method: GET
    data_selector: records
    params: {}
- name: PubTator Dataset
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/pub_tator/index.html
    method: GET
    data_selector: records
    params: {}
- name: dependency_parser
  endpoint:
    path: /dependency/parser
    method: POST
    data_selector: results
- name: lemmatizer
  endpoint:
    path: /lemmatizer
    method: POST
    data_selector: results
- name: perceptron
  endpoint:
    path: /perceptron
    method: POST
    data_selector: results
- name: sentence_detector
  endpoint:
    path: /sentence/detector
    method: POST
    data_selector: results
- name: Dependency Parser
  endpoint:
    path: /docs/en/annotators#dependency-parsers
    method: GET
    data_selector: dependency
    params: {}
- name: Named Entity Recognition
  endpoint:
    path: /docs/en/annotators
    method: GET
    data_selector: entities
    params: {}
- name: Entity Resolution
  endpoint:
    path: /docs/en/annotators
    method: GET
    data_selector: resolution
    params: {}
- name: Assertion Status
  endpoint:
    path: /docs/en/annotators
    method: GET
    data_selector: assertion
    params: {}
- name: TypedDependencyParserApproach
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/dependency/typed_dependency_parser/index.html#sparknlp.annotator.dependency.typed_dependency_parser.TypedDependencyParserApproach
    method: GET
    data_selector: ''
    params: {}
- name: TypedDependencyParserApproach
  endpoint:
    path: /api/com/johnsnowlabs/nlp/annotators/parser/typdep/TypedDependencyParserApproach
    method: GET
    data_selector: ''
    params: {}
- name: experiment_tracking
  endpoint:
    path: /mlflow/experiments
    method: GET
    data_selector: experiments
- name: model_serving
  endpoint:
    path: /mlflow/models
    method: POST
    data_selector: models
- name: run_now
  endpoint:
    path: /api/2.1/jobs/run-now
    method: POST
- name: get_output
  endpoint:
    path: /2.1/jobs/runs/get-output
    method: GET
- name: document
  endpoint:
    path: /document
    method: GET
    data_selector: records
- name: sentence
  endpoint:
    path: /sentence
    method: GET
    data_selector: records
- name: token
  endpoint:
    path: /token
    method: GET
    data_selector: records
- name: pos
  endpoint:
    path: /pos
    method: GET
    data_selector: records
- name: label
  endpoint:
    path: /label
    method: GET
    data_selector: records
- name: sentiment_analysis
  endpoint:
    path: /sentiment
    method: POST
    data_selector: results
    params: {}
- name: document
  endpoint:
    path: /api/document
    method: POST
    data_selector: result
    params: {}
- name: POS
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/pos/index.html
    method: GET
- name: CoNLL
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/conll/index.html
    method: GET
- name: CoNLLU
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/conllu/index.html
    method: GET
- name: PubTator
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/pub_tator/index.html
    method: GET
- name: spell_checkers_dataset
  endpoint:
    path: /path/to/spell_checkers_dataset
    method: GET
    data_selector: records
    params: {}
- name: text_processing
  endpoint:
    path: /path/to/text_processing
    method: GET
    data_selector: records
    params: {}
- name: typed_dependency_parser
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/dependency/typed_dependency_parser/index.html#sparknlp.annotator.dependency.typed_dependency_parser.TypedDependencyParserApproach
    method: GET
    data_selector: records
    params: {}
- name: document_assembler
  endpoint:
    path: /documentAssembler
    method: POST
    data_selector: records
- name: sentence_detector
  endpoint:
    path: /sentenceDetector
    method: POST
    data_selector: records
- name: tokenizer
  endpoint:
    path: /tokenizer
    method: POST
    data_selector: records
- name: pos_tagger
  endpoint:
    path: /posTagger
    method: POST
    data_selector: records
- name: ner_tagger
  endpoint:
    path: /nerTagger
    method: POST
    data_selector: records
- name: sentiment_analysis
  endpoint:
    path: /sentiment_analysis
    method: POST
    data_selector: results
    params: {}
- name: token_classification
  endpoint:
    path: /token_classification
    method: POST
    data_selector: results
    params: {}
- name: word_embeddings
  endpoint:
    path: /word_embeddings
    method: POST
    data_selector: embeddings
    params: {}
- name: BertForSequenceClassification
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/classifier_dl/bert_for_sequence_classification/index.html
    method: GET
- name: token_classifier
  endpoint:
    path: /path/to/endpoint
    method: POST
    data_selector: result
    params: {}
- name: POS
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/pos/index.html#sparknlp.training.pos.POS
    method: GET
- name: CoNLL
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/conll/index.html#sparknlp.training.conll.CoNLL
    method: GET
- name: CoNLLU
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/conllu/index.html#sparknlp.training.conllu.CoNLLU
    method: GET
- name: PubTator
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/pub_tator/index.html#sparknlp.training.pub_tator.PubTator
    method: GET
- name: spell_checkers_corpus
  endpoint:
    path: /spell_checkers_corpus
    method: GET
    data_selector: data
    params: {}
- name: dependency_parser
  endpoint:
    path: /dependency_parser
    method: GET
    data_selector: data
    params: {}
- name: lemmatizer
  endpoint:
    path: /lemmatizer
    method: GET
    data_selector: data
    params: {}
- name: perceptron_pos_tagger
  endpoint:
    path: /perceptron_pos_tagger
    method: GET
    data_selector: data
    params: {}
- name: sentence_detector_dl
  endpoint:
    path: /sentence_detector_dl
    method: GET
    data_selector: data
    params: {}
- name: typed_dependency_parser
  endpoint:
    path: /typed_dependency_parser
    method: GET
    data_selector: data
    params: {}
- name: TypedDependencyParserApproach
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/dependency/typed_dependency_parser/index.html#sparknlp.annotator.dependency.typed_dependency_parser.TypedDependencyParserApproach
    method: GET
    data_selector: records
    params: {}
- name: document
  endpoint:
    path: /src/test/resources/conll2003/eng.train
    method: GET
    data_selector: records
- name: sentiment_analysis
  endpoint:
    path: /sentiment/analyze
    method: POST
    data_selector: results
- name: BertForSequenceClassification
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/classifier_dl/bert_for_sequence_classification/index.html
    method: GET
    data_selector: records
- name: token_classifier
  endpoint:
    path: /model/token_classifier
    method: POST
    data_selector: labels
    params: {}
- name: POS Dataset
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/pos/index.html
    method: GET
    data_selector: records
- name: CoNLL Dataset
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/conll/index.html
    method: GET
    data_selector: records
- name: CoNLL-U Dataset
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/conllu/index.html
    method: GET
    data_selector: records
- name: PubTator Dataset
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/pub_tator/index.html
    method: GET
    data_selector: records
- name: TypedDependencyParserApproach
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/dependency/typed_dependency_parser/index.html#sparknlp.annotator.dependency.typed_dependency_parser.TypedDependencyParserApproach
    method: GET
    data_selector: ''
    params: {}
- name: document_assembler
  endpoint:
    path: /nlp/documentAssembler
    method: POST
    data_selector: records
    params: {}
- name: sentence_detector
  endpoint:
    path: /nlp/sentenceDetector
    method: POST
    data_selector: records
    params: {}
- name: tokenizer
  endpoint:
    path: /nlp/tokenizer
    method: POST
    data_selector: records
    params: {}
- name: pos_tagger
  endpoint:
    path: /nlp/posTagger
    method: POST
    data_selector: records
    params: {}
- name: word_embeddings
  endpoint:
    path: /nlp/wordEmbeddings
    method: POST
    data_selector: records
    params: {}
- name: ner_tagger
  endpoint:
    path: /nlp/nerTagger
    method: POST
    data_selector: records
    params: {}
- name: pipeline
  endpoint:
    path: /nlp/pipeline
    method: POST
    data_selector: records
    params: {}
- name: sentiment_analysis
  endpoint:
    path: /api/sentiment
    method: POST
    data_selector: results
    params: {}
- name: bert_for_sequence_classification
  endpoint:
    path: /api/bert_for_sequence_classification
    method: GET
    data_selector: result
- name: document
  endpoint:
    path: /document
    method: POST
    data_selector: result
    params: {}
- name: token
  endpoint:
    path: /token
    method: POST
    data_selector: result
    params: {}
- name: RoBertaForTokenClassification
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/classifier_dl/roberta_for_token_classification/index.html#sparknlp.annotator.classifier_dl.roberta_for_token_classification.RoBertaForTokenClassification
    method: GET
    data_selector: records
- name: POS Dataset
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/pos/index.html
    method: GET
    data_selector: records
    params: {}
- name: CoNLL Dataset
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/conll/index.html
    method: GET
    data_selector: records
    params: {}
- name: CoNLL-U Dataset
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/conllu/index.html
    method: GET
    data_selector: records
    params: {}
- name: PubTator Dataset
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/training/pub_tator/index.html
    method: GET
    data_selector: records
    params: {}
- name: dependency_parser
  endpoint:
    path: /dependency/parser
    method: POST
    data_selector: results
- name: typed_dependency_parser
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/dependency/typed_dependency_parser/index.html#sparknlp.annotator.dependency.typed_dependency_parser.TypedDependencyParserApproach
    method: GET
    data_selector: records
    params: {}
- name: ner_dl_approach
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/ner/ner_dl/index.html
    method: GET
    data_selector: records
    params: {}
- name: classifier_dl_approach
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/classifier_dl/classifier_dl/index.html
    method: GET
    data_selector: records
    params: {}
- name: multi_classifier_dl_approach
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/classifier_dl/multi_classifier_dl/index.html
    method: GET
    data_selector: records
    params: {}
- name: ViveknSentimentApproach
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/sentiment/vivekn_sentiment/index.html
    method: GET
    data_selector: result
    params: {}
- name: Doc2VecApproach
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/embeddings/doc2vec/index.html
    method: GET
    data_selector: result
    params: {}
- name: Word2VecApproach
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/embeddings/word2vec/index.html
    method: GET
    data_selector: result
    params: {}
- name: AlbertForTokenClassification
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/classifier_dl/albert_for_token_classification/index.html
    method: GET
    data_selector: result
    params: {}
- name: BertForSequenceClassification
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/classifier_dl/bert_for_sequence_classification/index.html
    method: GET
    data_selector: records
- name: token_classifier
  endpoint:
    path: /api/python/reference/autosummary/sparknlp/annotator/classifier_dl/roberta_for_token_classification/index.html#sparknlp.annotator.classifier_dl.roberta_for_token_classification.RoBertaForTokenClassification
    method: GET
    data_selector: ''
    params: {}
- name: token_classifier
  endpoint:
    path: /loadSavedModel
    method: GET
    data_selector: model
    params: {}
- name: DependencyParser
  endpoint:
    path: /docs/en/annotators#dependency-parsers
    method: GET
- name: NerVisualizer
  endpoint:
    path: /docs/en/annotators
    method: GET
- name: EntityResolverVisualizer
  endpoint:
    path: /docs/en/annotators
    method: GET
- name: AssertionVisualizer
  endpoint:
    path: /docs/en/annotators
    method: GET
- name: run_job
  endpoint:
    path: /api/2.1/jobs/run-now
    method: POST
    data_selector: run
    params:
      job_id: '[job_id]'
- name: get_job_output
  endpoint:
    path: /2.1/jobs/runs/get-output
    method: GET
    data_selector: notebook_output
notes:
- It is recommended to have basic knowledge of the framework and a working environment
  before using Spark NLP.
- Built with ONNX 1.17.0 and TensorFlow 2.7.1 deep learning engines.
- Minimum required NVIDIA GPU drivers version 450.80.02 or higher.
- Spark NLP 6.2.0 is built with ONNX 1.17.0 and TensorFlow 2.7.1 deep learning engines.
- 'The minimum following NVIDIA software are only required for GPU support: NVIDIA
  GPU drivers version 450.80.02 or higher, CUDA Toolkit 11.2, cuDNN SDK 8.1.0.'
- Spark NLP 6.2.0 has been built on top of Apache Spark 3.4 while fully supports Apache
  Spark 3.0.x, 3.1.x, 3.2.x, 3.3.x, 3.4.x, and 3.5.x
- spark-nlp by default is based on pyspark 3.x
- Spark NLP library and all the pre-trained models/pipelines can be used entirely
  offline with no access to the Internet.
- EMR 6.1.0 and 6.1.1 are not supported.
- To log a Spark NLP annotator, it will need an 'outputLogPath' parameter, as the
  CometLogger reads the log file generated during the training process.
- Experiments can also be defined to be run offline.
- Uses MLFlow for experiment tracking - requires setup of MLFlow server
- To use the comet logger, you need to set up an account and install comet.
- Logging params, artifacts, metrics and charts in MLFlow
- Registered model 'NER_base_2048_mlflow' already exists. Creating a new version of
  this model...
- MLFlow is integrated in Databricks, so you will be able to track your experiments
  in any Databricks environment.
- Last updated Nov 21, 2021
- Waiting up to 300 seconds for model version to finish creation.
- Uses OAuth2 with refresh token  requires setup of connected app in api
- Some objects like Contact may return nulls in deeply nested fields
- If this is an existing cluster, after adding new configs or changing existing properties
  you need to restart it.
- Explain Document ML is a pretrained pipeline that does a little bit of everything
  NLP related.
- Pretrained pipelines are available for various NLP tasks
- The explain_document_ml pipeline can annotate text with various NLP features
- Necessary imports include general Spark NLP transformers and concepts, while annotator._
  includes all annotators.
- Pretrained pipelines require downloading from servers.
- Tokens may be returned in a complex structure; use Finisher to simplify.
- LightPipeline computes everything locally in parallel for small amounts of data.
- RecursivePipeline allows a Pipeline to know about itself on every stage task.
- LightPipeline computes everything locally in parallel for fast results with small
  data.
- RecursivePipeline allows a Spark ML Pipeline to know about itself on every Pipeline
  Stage task.
- Spark NLP is the central hub for all your State of the Art Natural Language Processing
  needs.
- Uses GPU inference with this annotator
- Requires setting a query for reranking tasks
- To use GPU inference with this annotator, make sure to use the Spark NLP GPU package
  and set the number of GPU layers with the `setNGpuLayers` method.
- When using larger models, we recommend adjusting GPU usage with `setNCtx` and `setNGpuLayers`
  according to your hardware to avoid out-of-memory errors.
- Uses TextMatcher for entity extraction.
- For extended examples see the Examples and the ChunkerTestSpec.
- Uses Word2Vec implemented in Spark ML with skip-gram model and hierarchical softmax
  method.
- Can apply lower case normalization.
- Extracts embeddings into a more easily usable form.
- The lemmatizer requires a dictionary file for operation.
- Neural Network architecture is Char CNNs - BiLSTM - CRF that achieves state-of-the-art
  in most datasets.
- Removes all dirty characters from text following a regex pattern and transforms
  words based on a provided dictionary
- For pretrained models please see the Models Hub.
- For extended examples of usage, see the Examples.
- Supports multiple document formats including PDF, Word, and Excel.
- Default behavior is to output one document per row.
- Supports multiple image formats including .png, .jpg, .pdf, etc.
- This annotator accepts a label column of a single item in either type of String,
  Int, Float, or Double. So positive sentiment can be expressed as either "positive"
  or 0, negative sentiment as "negative" or 1.
- This class represents a non fitted tokenizer.
- The algorithm is based on the paper 'Fast and accurate sentiment classification
  using an enhanced Naive Bayes model'.
- Yake is a corpus-independent keyword extraction algorithm.
- Document should be processed through a Sentence Boundary Detector and then a tokenizer.
- Pretrained models can be loaded with 'pretrained' of the companion object.
- Default model is 'albert_base_qa_squad2'
- This is a very computationally expensive module especially on larger sequence. The
  use of an accelerator such as GPU is recommended.
- Supports both Python and Scala APIs
- Pretrained models available for various tasks
- Florence-2 is an advanced vision foundation model from Microsoft that uses a prompt-based
  approach
- Pretrained models can be loaded with `pretrained` of the companion object
- This is a very computationally expensive module especially on larger sequence.
- The use of an accelerator such as GPU is recommended.
- To use GPU inference with this annotator, make sure to use the Spark NLP GPU package
  and set the number of GPU layers with the setNGpuLayers method.
- When using larger models, we recommend adjusting GPU usage with setNCtx and setNGpuLayers
  according to your hardware to avoid out-of-memory errors.
- Pretrained models can be loaded with `pretrained` of the companion object.
- Models from the HuggingFace  Transformers library are also compatible with Spark
  NLP 
- Tokenizes and flattens extracted NER chunks.
- Default model is 'paligemma_3b_pt_224_int4' if no name is provided.
- Spell Checking is a sequence to sequence mapping problem.
- The default model is `roberta_base_token_classifier_conll03`.
- This is the instantiated model of the Doc2VecApproach.
- Some models may require additional setup and configuration.
- The default model is "image_classifier_swin_base_patch_4_window_7_224", if no name
  is provided.
- 'Input Annotator Types: DOCUMENT, TOKEN, NAMED_ENTITY'
- 'Output Annotator Type: NODE'
- The default model is 'uae_large_v1', if no name is provided.
- This is a very computationally expensive module especially on larger batch sizes.
  The use of an accelerator such as GPU is recommended.
- Default model is 'xlm_roberta_base_qa_squad2' if no name is provided.
- The default model is 'xlnet_base_cased', if no name is provided.
- Extracts Named Entities based on a CRF Model.
- This Named Entity recognition annotator allows for a generic model to be trained
  by utilizing a CRF machine learning algorithm.
- The default model is 'ner_crf', if no name is provided.
- Uses pretrained models from HuggingFace and TF Hub
- Supports various transformer architectures
- Requires stems, hence tokens.
- Removes all dirty characters from text following a regex pattern.
- Averaged Perceptron model to tag words part-of-speech.
- Sets a POS tag to each word within a sentence.
- Supports multiple document formats including PDF, Word, Excel, and more.
- Supports extraction of images from various document formats.
- All these APIs receive regular expressions so please make sure that you escape special
  characters according to Java conventions.
- This model requires input tokenization with SentencePiece model, which is provided
  by Spark-NLP.
- No additional training data is needed.
- Additional training data is not needed, the dependency parser relies on the dependency
  tree bank / CoNLL-U only.
- Uses CamemBERT for Named-Entity-Recognition tasks.
- Currently, only the CNN model is supported for training.
- The default model is 'distilbert_base_cased' for embeddings.
- The default model is 'distilbert_base_cased_qa_squad2' for question answering.
- The default model is 'distilbert_base_sequence_classifier_imdb' for sequence classification.
- Uses E5 embeddings for multimodal tasks.
- Florence-2 is an advanced vision foundation model from Microsoft that uses a prompt-based
  approach to handle tasks like image captioning, object detection, segmentation,
  OCR, and more.
- The dependency parser relies on the dependency tree bank / CoNLL-U only.
- Additional training data is not needed, the dependency parser relies on CoNLL-U
  only.
- Requires a training dataset consisting of Part-Of-Speech tags
- 'Input Annotator Types: DOCUMENT'
- 'Output Annotator Type: TOKEN'
- This annotator can be used for Named Entity Recognition tasks.
- The default model is "roberta_base_zero_shot_classifier_nli", if no name is provided.
- A dictionary of correct spellings must be provided with setDictionary as a text
  file.
- Inspired by Norvig model and SymSpell.
- The parser requires the dependant tokens beforehand.
- Default model is 'xlm_roberta_base_qa_squad2' for question answering.
- For sequence classification, default model is 'xlm_roberta_base_sequence_classifier_imdb'.
- No additional training data is needed for the dependency parser.
- This CoNLL dataset already includes a sentence, token, POS tags and label column
  with their respective annotator types.
- Uses Spark NLP for text classification
- Requires setup of connected app in API
- If a custom dataset is used, these need to be defined.
- The lemma dictionary must be provided as a delimited text file.
- Each extracted sentence can be returned in an Array or exploded to separate rows,
  if explodeSentences is set to true.
- This annotator needs to be trained externally using the transformers library.
- Corpus data can be read as a spark dataframe from a plain text file.
- Model needs to be trained with the transformers library.
- This dataset includes annotations for sentences, tokens, POS tags, and labels.
- The analyzer requires sentence boundaries to give a score in context.
- Tokenization is needed to make sure tokens are within bounds.
- Uses external training with transformers library.
- Additional training data is not needed.
- The dependency parser relies on CoNLL-U only.
- Uses CoNLL-U format for training.
- 'The required training data can be set in two different ways: Dependency treebank
  in the Penn Treebank format or Dataset in the CoNLL-U format.'
- The model needs to be trained with the transformers library.
- Afterwards it can be loaded into the scala version of Spark NLP.
- For an extended example see the Examples.
- The model requires a column for normalized text and a label column.
- Sentiment labels are either 'positive' or 'negative'.
- The algorithm requires sentence boundaries and tokenization.
- Uses external transformers library for training
- Requires model checkpoint to be loaded
- Needs to be trained externally using the transformers library.
- Spark NLP Display is an open-source python library for visualizing the annotations
  generated with Spark NLP.
- The ability to quickly visualize the entities/relations/assertion statuses is a
  very useful feature for speeding up the development process.
- This approach does not allow you to customize your endpoints, it uses Databricks
  JOBS API ones
- Requires some time and expertise in Databricks to configure everything properly
- This dataset includes a sentence, token, POS tags and label column with their respective
  annotator types.
- Uses TensorFlow for Deep Learning tasks
- oneDNN optimizations are experimental and need manual enabling
- Uses external transformer library for training.
- Requires sentence boundaries and tokenization.
- Assembly command creates a fat jars, that includes all dependencies within
- Third party projects need to be installed separately to be used.
- 100%! Free forever including any commercial use.
- Spark NLP is an open-source library and can be used freely. Its released under
  the Apache License 2.0.
- Requires specific text formats for dependency parsing and lemmatization.
- Uses state-of-the-art models for NLP tasks
- Supports various input formats like CoNLL and CSV
- The pipeline requires proper training data formats for each model.
- Trains a sentiment analyser inspired by the algorithm by Vivek Narayanan
- 'The required training data can be set in two different ways (only one can be chosen
  for a particular model): Dependency treebank in the Penn Treebank format set with
  setDependencyTreeBank. Dataset in the CoNLL-U format set with setConllU.'
- Uses CoNLL dataset format for training.
- The training data needs to consist of a column for normalized text and a label column
- Afterwards it can be loaded into the Scala version of Spark NLP.
- After training, the model checkpoint can be loaded by this annotator.
- The parser requires the dependant tokens beforehand with e.g. DependencyParser.
- After the training process is done, the model checkpoint can be loaded by this annotator.
- Spark NLP 4.0 comes with massive optimizations for GPU and modern CPUs for most
  of our Transformer-based annotators.
- The oneAPI Deep Neural Network Library (oneDNN) optimizations are now available
  in Spark NLP 4.0.0.
- Third party projects can integrate with Spark NLP. These packages need to be installed
  separately to be used.
- Spark NLP is an open-source library and can be used freely.
- The core library is open-source under the Apache License 2.0.
errors:
- '400 Bad Request: Check your request syntax'
- '404 Not Found: Resource not found'
- Waiting up to 300 seconds for model version to finish creation.
- '400 Bad Request: Check input format and required fields'
- '401 Unauthorized: Invalid API key or missing credentials'
- '500 Internal Server Error: Server-side issue, try again later'
- 'Unsupported format: Ensure the file type is supported by Reader2Doc.'
- 'MODEL_NOT_FOUND: Please check if the model name is correct.'
- '400 Bad Request: Check your input data format'
- '401 Unauthorized: Invalid API key or token'
- '404 Not Found: Endpoint does not exist'
- 'ModelNotFound: Ensure the model name is correct and available in the Models Hub'
- 'InputMismatch: Check that input types match the expected DOCUMENT and TOKEN types'
- 'MODEL_NOT_FOUND: Ensure the model name is correct and available.'
- 'REQUEST_LIMIT_EXCEEDED: Throttle API calls or reduce frequency'
- '401 Unauthorized: Recheck OAuth scopes or token expiration'
- 'INVALID_INPUT: Check input document and token annotations.'
- 'QUERY_TIMEOUT: Break down filters or add selectivity'
- '400 Bad Request: Check the input format and fields.'
- '401 Unauthorized: Ensure proper API key or token is provided.'
- '400 Bad Request: Check input format and required fields.'
- '401 Unauthorized: Verify API key.'
- 'MODEL_NOT_FOUND: Ensure the model exists at the specified path'
- 'MODEL_NOT_FOUND: Ensure the model path is correct.'
- 'INVALID_INPUT: Check input data structure.'
- '400 Bad Request: Check the input format and required fields'
- '401 Unauthorized: Recheck API key or token expiration'
- 'MODEL_NOT_FOUND: Check if the model name is correct.'
auth_info:
  mentioned_objects:
  - OauthToken
  - AuthProvider
  - NamedCredential
  - XlmRoBertaForQuestionAnswering
  - XlmRoBertaForSequenceClassification
  - DocumentAssembler
  - Tokenizer
  - RoBertaForTokenClassification
client:
  base_url: https://sparknlp.org
  headers:
    Accept: application/json
source_metadata: null
