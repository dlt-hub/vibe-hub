resources:
- name: resources
  endpoint:
    path: /compute/resources
    method: GET
- endpoint:
    params:
      page: page
      size: size
- name: Application Servers
  endpoint:
    path: /itcare-api/compute/application_servers
    method: GET
- name: Backup Policies
  endpoint:
    path: /itcare-api/compute/backup_policies
    method: GET
- name: Containers
  endpoint:
    path: /itcare-api/compute/containers
    method: GET
- name: Environments
  endpoint:
    path: /itcare-api/compute/environments
    method: GET
- name: Instances
  endpoint:
    path: /itcare-api/compute/instances
    method: GET
- name: Platform
  endpoint:
    path: /itcare-api/compute/platform
    method: GET
- name: Resource Filters
  endpoint:
    path: /itcare-api/compute/resource_filters
    method: GET
- name: Resource Types
  endpoint:
    path: /itcare-api/compute/resource_types
    method: GET
- name: Resources
  endpoint:
    path: /itcare-api/compute/resources
    method: GET
- name: Services
  endpoint:
    path: /itcare-api/compute/services
    method: GET
- name: Statuses
  endpoint:
    path: /itcare-api/compute/statuses
    method: GET
- name: Tag Keys
  endpoint:
    path: /itcare-api/compute/tag_keys
    method: GET
- name: Tag Values
  endpoint:
    path: /itcare-api/compute/tag_values
    method: GET
- name: Types
  endpoint:
    path: /itcare-api/compute/types
    method: GET
- name: Apache Kafka
  endpoint:
    path: /itcare-api-reference/messaging/messaging-messagebrokers-apachekafka
    method: GET
- name: Message Brokers
  endpoint:
    path: /itcare-api-reference/messaging/messaging-messagebrokers-messagebrokers
    method: GET
- name: RabbitMQ
  endpoint:
    path: /itcare-api-reference/messaging/messaging-messagebrokers-rabbitmq
    method: GET
- name: Application Servers
  endpoint:
    path: /itcare-api/reference/compute/compute-applicationservers
    method: GET
- name: Backup Policies
  endpoint:
    path: /itcare-api/reference/compute/compute-backuppolicies
    method: GET
- name: Containers
  endpoint:
    path: /itcare-api/reference/compute/compute-containers
    method: GET
- name: Environments
  endpoint:
    path: /itcare-api/reference/compute/compute-environments
    method: GET
- name: Instances
  endpoint:
    path: /itcare-api/reference/compute/compute-instances
    method: GET
- name: Platform
  endpoint:
    path: /itcare-api/reference/compute/compute-platform
    method: GET
- name: Resource Filters
  endpoint:
    path: /itcare-api/reference/compute/compute-resourcefilters
    method: GET
- name: Resource Types
  endpoint:
    path: /itcare-api/reference/compute/compute-resourcetypes
    method: GET
- name: Resources
  endpoint:
    path: /itcare-api/reference/compute/compute-resources
    method: GET
- name: Services
  endpoint:
    path: /itcare-api/reference/compute/compute-services
    method: GET
- name: Statuses
  endpoint:
    path: /itcare-api/reference/compute/compute-statuses
    method: GET
- name: Tag Keys
  endpoint:
    path: /itcare-api/reference/compute/compute-tagkeys
    method: GET
- name: Tag Values
  endpoint:
    path: /itcare-api/reference/compute/compute-tagvalues
    method: GET
- name: Types
  endpoint:
    path: /itcare-api/reference/compute/compute-types
    method: GET
- name: hardwares
  endpoint:
    path: /itcare-api/reference/hardwares/hardwares-hardwares
    method: GET
    data_selector: records
- name: topology
  endpoint:
    path: /itcare-api/reference/topology
    method: GET
- name: apache_kafka
  endpoint:
    path: /itcare-api-reference/messaging/messaging-messagebrokers-apachekafka
    method: GET
- name: message_brokers
  endpoint:
    path: /itcare-api-reference/messaging/messaging-messagebrokers-messagebrokers
    method: GET
- name: rabbitmq
  endpoint:
    path: /itcare-api-reference/messaging/messaging-messagebrokers-rabbitmq
    method: GET
- name: Virtual instances
  endpoint:
    path: /compute/virtual-instances
    method: GET
- name: Containers (K8s)
  endpoint:
    path: /compute/containers-k8s
    method: GET
- name: Matomo
  endpoint:
    path: /analytics/matomo
    method: GET
- name: MariaDB
  endpoint:
    path: /databases/mariadb
    method: GET
    data_selector: records
- name: OpenSearch
  endpoint:
    path: /databases/opensearch
    method: GET
    data_selector: records
- name: PostgreSQL
  endpoint:
    path: /databases/postgresql
    method: GET
    data_selector: records
- name: Redis
  endpoint:
    path: /databases/redis
    method: GET
    data_selector: records
- name: SQL Server
  endpoint:
    path: /databases/sql-server
    method: GET
    data_selector: records
- name: Apache Kafka
  endpoint:
    path: /messaging/apache-kafka
    method: GET
    data_selector: records
- name: RabbitMQ
  endpoint:
    path: /messaging/rabbitmq
    method: GET
    data_selector: records
- name: GlusterFS
  endpoint:
    path: /storage/glusterfs
    method: GET
    data_selector: records
- name: Object Storage
  endpoint:
    path: /storage/object-storage
    method: GET
    data_selector: records
- name: mariadb
  endpoint:
    path: /databases/mariadb
    method: GET
    data_selector: records
- name: opensearch
  endpoint:
    path: /databases/opensearch
    method: GET
    data_selector: records
- name: postgresql
  endpoint:
    path: /databases/postgresql
    method: GET
    data_selector: records
- name: redis
  endpoint:
    path: /databases/redis
    method: GET
    data_selector: records
- name: sql_server
  endpoint:
    path: /databases/sql-server
    method: GET
    data_selector: records
- name: apache_kafka
  endpoint:
    path: /messaging/apache-kafka
    method: GET
    data_selector: records
- name: rabbitmq
  endpoint:
    path: /messaging/rabbitmq
    method: GET
    data_selector: records
- name: glusterfs
  endpoint:
    path: /storage/glusterfs
    method: GET
    data_selector: records
- name: object_storage
  endpoint:
    path: /storage/object-storage
    method: GET
    data_selector: records
- name: virtual_instances
  endpoint:
    path: /compute/virtual-instances
    method: GET
    data_selector: instances
    params: {}
- name: virtual_instance
  endpoint:
    path: /compute/virtual-instances
    method: GET
    data_selector: resources
- name: containers
  endpoint:
    path: /compute/containers
    method: GET
    data_selector: records
- name: kubernetes_topologies
  endpoint:
    path: /compute/containers-k8s/k8s-features
    method: GET
    data_selector: topologies
    params: {}
- name: compute_topology
  endpoint:
    path: /compute/topology
    method: GET
    data_selector: compute_topology
    params: {}
- name: virtual_instance
  endpoint:
    path: /compute/virtual-instances
    method: GET
    data_selector: instances
    params: {}
- name: virtual_instances
  endpoint:
    path: /compute/virtual-instances
    method: GET
    data_selector: instances
    params: {}
- name: mariadb_replica_request
  endpoint:
    path: /itcare/mariadb/replica/request
    method: POST
    data_selector: ticket
    params: {}
- name: OpenSearch Cluster
  endpoint:
    path: /databases/opensearch
    method: GET
    data_selector: cluster_info
- name: virtual_instance
  endpoint:
    path: /compute/virtual-instances
    method: GET
    data_selector: records
    params: {}
- name: containers
  endpoint:
    path: /compute/containers-k8s
    method: GET
    data_selector: clusters
    params: {}
- name: databases
  endpoint:
    path: /databases/postgresql
    method: GET
    data_selector: databases
    params: {}
- name: mariadb
  endpoint:
    path: /databases/mariadb
    method: GET
    data_selector: records
- name: databases
  endpoint:
    path: /databases
    method: GET
    data_selector: records
- name: PostgreSQL Upgrade Request
  endpoint:
    path: /support?createTicket=true&requestTypeIndex=3&formName=DB_POSTGRES&step=Request
    method: POST
- name: redis_instance
  endpoint:
    path: /databases/redis
    method: GET
    data_selector: instances
    params: {}
- name: PostgreSQL Instances
  endpoint:
    path: /databases/postgresql
    method: GET
    data_selector: instances
- name: redis_instance
  endpoint:
    path: /databases/redis
    method: GET
    data_selector: instances
- name: redis_cluster
  endpoint:
    path: /databases/redis/cluster
    method: GET
    data_selector: clusters
- name: instances
  endpoint:
    path: /databases/sql-server/instances
    method: GET
    data_selector: instances
    params: {}
- name: versions
  endpoint:
    path: /databases/sql-server/versions
    method: GET
    data_selector: versions
    params: {}
- name: database
  endpoint:
    path: /databases
    method: GET
    data_selector: databases
- name: Standalone instance
  endpoint:
    path: /databases/redis/standalone-instance
    method: GET
    data_selector: instance_details
- name: Sentinel cluster
  endpoint:
    path: /databases/redis/sentinel-cluster
    method: GET
    data_selector: cluster_details
- name: sql_server_upgrade
  endpoint:
    path: /databases/sql-server/upgrade
    method: GET
    data_selector: upgrade_process
    params: {}
- name: standalone_redis
  endpoint:
    path: /databases/redis/standalone
    method: GET
    data_selector: instances
- name: redis_cluster
  endpoint:
    path: /databases/redis/cluster
    method: GET
    data_selector: instances
- name: Kafka Cluster
  endpoint:
    path: /messaging/apache-kafka
    method: GET
- name: instances
  endpoint:
    path: /databases/sql-server/instances
    method: GET
    data_selector: records
- name: backups
  endpoint:
    path: /databases/sql-server/backups
    method: GET
    data_selector: records
- name: monitoring
  endpoint:
    path: /databases/sql-server/monitoring
    method: GET
    data_selector: records
- name: prometheus_metrics
  endpoint:
    path: /metrics
    method: GET
    data_selector: metrics
- name: admin
  endpoint:
    path: /
    method: GET
    data_selector: admin
- name: rest_api
  endpoint:
    path: /api
    method: GET
    data_selector: api
- name: default_configuration
  endpoint:
    path: /messaging/apache-kafka/default-configuration
    method: GET
    data_selector: parameters
    params: {}
- name: custom_configuration
  endpoint:
    path: /messaging/apache-kafka/custom-configuration
    method: GET
    data_selector: parameters
    params: {}
- name: management_ui
  endpoint:
    path: /api
    method: GET
- name: DDoS Protection
  endpoint:
    path: /api/ddos/protection
    method: GET
    data_selector: features
    params: {}
- name: Bot Defense Actions
  endpoint:
    path: /api/bot-defense/actions
    method: POST
    data_selector: actions
    params: {}
- name: management_ui
  endpoint:
    path: /api
    method: GET
- name: database_masking
  endpoint:
    path: /security/data-masking
    method: GET
    data_selector: results
    params: {}
- name: GlusterFS
  endpoint:
    path: /storage/glusterfs
    method: GET
- name: send_sms
  endpoint:
    path: /send_sms
    method: POST
- name: retrieve_status
  endpoint:
    path: /retrieve_status
    method: GET
- name: cluster
  endpoint:
    path: /storage/glusterfs
    method: POST
    data_selector: clusters
    params: {}
- name: DDoS Protection
  endpoint:
    path: /security/bot-defense/ddos-protection
    method: GET
    data_selector: features
    params: {}
- name: Bot Defense
  endpoint:
    path: /security/bot-defense
    method: GET
    data_selector: features
    params: {}
- name: GlusterFS
  endpoint:
    path: /storage/glusterfs
    method: GET
    data_selector: records
- name: storage_volumes
  endpoint:
    path: /storage/glusterfs
    method: GET
    data_selector: volumes
- name: cluster
  endpoint:
    path: /storage/glusterfs
    method: POST
- name: presigned_url
  endpoint:
    path: /storage/object-storage/presigned-url
    method: POST
    data_selector: presigned_url_details
    params:
      security_credentials: required
      bucket_name: required
      object_key: required
      http_method: PUT
      expiration_time: required
- name: bucket_policy
  endpoint:
    path: /storage/object-storage/bucket-policies
    method: POST
    data_selector: bucket_policy_details
    params: {}
- name: lifecycle_configuration
  endpoint:
    path: /storage/object-storage/lifecycle-configuration
    method: POST
    data_selector: lifecycle_configuration_details
    params: {}
- name: object_lock
  endpoint:
    path: /storage/object-storage/object-lock
    method: POST
    data_selector: object_lock_details
    params: {}
notes:
- The page Authentication gathers all the information necessary for the discovery
  and the good use of the ITCare API.
- Multi-factor authentication is available and mandatory for certain high privilege
  actions.
- The carbon footprint calculation is an integral part of the Enercare project, based
  on the energy consumption distribution of services.
- The energy consumption of each piece of equipment is collected every minute.
- PUE is calculated daily for the data centers we operate and monthly for colocation
  data centers.
- Uses OAuth2 with refresh token — requires setup of connected app in api
- JSON does not natively support the Date/Time format. All parameters tagged as Date
  by the API are therefore strings in ISO8601 format.
- Each API request must contain an 'Authorization' header embedding an access token
  previously obtained through credentials.
- Some methods return paginated results.
- The parameters *Cookies*, *Headers* are optional.
- Last updated 24 days ago
- Requires setup of connected app in api
- Several Cloud Native products are available in the cegedim.cloud catalog.
- Patch Parties happen every quarter on Sundays, so 4 times per year.
- QA Patch Party happens first during business hours on Thursdays and is only applicable
  to non-production environments.
- Production Patch Party happens 3 weeks after the QA Patch Party on Sundays and is
  only applicable to production environments.
- Certain configuration parameters can be modified at the customer's request.
- Matomo is deployed on-premise in cegedim.cloud's data centers and is provided as
  a service.
- 'cegedim.cloud guarantees the following level of managed service: deployment of
  instances, maintenance in operational condition, flexibility, security and monitoring
  are thus ensured by our experts.'
- Plugins installation and Matomo upgrades can be done by the customer in autonomy.
- Resize is available in ITCare self-service but only allows resizing UP.
- Virtual Instances support Linux, Windows, and AIX operating systems.
- Patch Parties happen every quarter on Sundays
- QA Patch Party happens first during business hours on Thursdays and is only applicable
  to non-production environments
- Production Patch Party happens 3 weeks after the QA Patch Party on Sundays and is
  only applicable to production environments
- Backup is an option that can be enabled for your Virtual Instance. In a production
  environment, the backup option will always be toggled on, by default, in ITCare.
- Monitoring is provided if the option has been toggled. In a production environment,
  the monitoring toggle is always activated by default.
- Customer can create resources directly through ITCare, using self-service and pay-per-usage.
- Matomo is deployed on-premise in cegedim.cloud 's data centers and is provided as
  a service.
- cegedim.cloud provides managed Kubernetes clusters with built-in highest level of
  security and resilience.
- Access to your Matomo instance is done securely through HTTPS.
- Supports a variety of operating systems such as Linux, Windows, and AIX.
- Billing is processed monthly based on the number of instances and additional costs.
- You can use ITCare in case of a need of a specific configuration
- For more information regarding the hardening of Kubernetes, please follow this page
  Hardening
- For more information regarding the persistant solution available for cegedim.cloud's
  Kubernetes clusters, please follow this page Persistent Storage
- Authentication to the virtual instance is Active Directory based for Linux and Windows
  (not AIX).
- MariaDB is deployed on-premise in cegedim.cloud's data centers.
- To request the addition of a MariaDB read-only replica, you need to create a request
  ticket via ITCare.
- Please allow up to 10 working days for your request to be processed.
- OpenSearch is deployed as a cluster on-premise in our data centers.
- The minimum number of node for a cluster is 3 servers but not recommended for production.
  It is advised to deploy at least 5 or more nodes for Production use.
- Direct root login is disabled on all Linux virtual instances
- Authentication can be configured on request to accept Active Directory as an authentication
  backend.
- Authorizations can be configured on request to accept Active Directory as a backend
  role provider.
- TLS/SSL is activated by default for incoming and internal network flows.
- Managed Kubernetes clusters with built-in highest level of security and resilience
- Support for StateFul Application and persistent volumes with Auto-Provisioning and
  High Availability
- Cluster creation can take up to 2 hours based on the current load on automation.
- The cluster will then be displayed in your Global Service, in the left control panel,
  under the related cluster section.
- PostgreSQL is currently the leading open source RDBMS (Relational Database Management
  System), with a wide range of features and a large community supporting it.
- Billing is processed monthly and based on the number of instances plus supplementary
  costs for storage, backup and 24x7 monitoring.
- Two pods of 2 namespaces that belong to the same Rancher Project can fully communicate
  between them.
- Two pods of 2 namespaces that belong to two different Rancher Project cannot communicate
  unless user defines a Network Policy dedicated for this need.
- Pods from Rancher Project named System can communicate to pods from other Rancher
  Projects.
- Pods can only send requests to servers of the same VLAN, unless a specific network
  opening rule is configured between the two VLANs.
- Pods cannot send requests to Internet unless, a proxy is setup inside the pod or
  specific network opening rule is configured for the related VLAN.
- Requests toward kube api-server can be reverse-proxied by Rancher URL.
- Workload hosted by pods cannot be directly accessible from outside of K8S cluster,
  but via ingress layer for HTTP protocol or via a NodePort service for TCP protocol
  with a respective Load Balancer.
- A K8s cluster comes with an Elastic Secured Endpoint, managed by F5 appliances,
  exposing the K8s workload to the cegedim internal network (once you're connected
  to Cegedim LAN, either physically or through VPN)
- 'You can use ITCare in case of a need of a specific configuration: Exposing your
  workloads to the Internet or private link, Using a specific FQDN to deploy your
  workload, Using a specific certificate to deploy your workload, Using Traefik as
  Ingress Provider instead of nginx, Adding other Ingress Providers, Accessing resources
  outside of cluster'
- Customer can perform action autonomously.
- SSH access is disabled and reserved to cegedim.cloud administrators.
- The long term support (LTS) can be deployed in self-service using ITCare.
- Provisioning can take up to 2 hours based on the current load on automation.
- The minimum number of node for a cluster is 3 servers but not recommended for production.
- It is advised to deploy at least 5 or more nodes for Production use.
- The update of a PostgreSQL PaaS is the responsibility of cegedim.cloud and can be
  requested via a request ticket submitted from ITCare.
- It is recommended that you upgrade your non-production environments first in order
  to estimate the downtime generated by the operation and to test your applications
  using the new engine version.
- Authentication uses OpenSearch internal security system.
- Redis 6 ACL is used for authentication.
- Passwords are hashed with SHA-256.
- PostgreSQL is deployed on-premise in cegedim.cloud's data centers.
- Provisioning can take up to 2 hours, depending on the current automation load.
- Passwords are not saved by cegedim.cloud. Be sure to save your password!
- The update of a Redis PaaS is the responsibility of cegedim.cloud and can be requested
  via a request ticket submitted from ITCare.
- The user must have access to the cloud of the source farm and the destination farm.
- Only SQL Server 2022 Enterprise edition is available for self-service provisioning.
- The update of a PostgreSQL PaaS is the responsibility of cegedim.cloud and can be
  requested via a request ticket submitted from ITCare, specifying a time slot for
  the operation.
- The passive node cannot execute SQL queries, reports, or user workloads.
- The name of the virtual machine provisioned is restricted to 13 characters maximum.
- 'Redis is self-service deployable via our cloud platform management tool: ITCare.'
- cegedim.cloud will NOT save this password so please save it somewhere safe in your
  vault.
- Upgrades of SQL Server clusters older than version 2016 are not supported by cegedim.cloud.
- Major version upgrades require a new PaaS instance to be provisioned.
- Delivered clusters are secured for both inter-broker and client <-> broker communications
- Self-service deployment of a minimum 3-node cluster in version 3.6.0 is available
- The default cluster sizing includes 3 brokers provisionned over 3 Availability Zones.
- The default configuration also ensure that the replication factor is set to 3 for
  topics and the minimum in-sync replica has to be 2.
- SQL Server 2022 Enterprise edition is available for self-service provisioning.
- SQL Server PaaS runs exclusively in a Windows environment.
- Instance login is configured by default in mixed mode.
- Passwords are not saved by cegedim.cloud.
- This action is not recoverable!
- cegedim.cloud will NOT save the administrator password so please save it somewhere
  safe in your vault.
- Version 1.5.0 and above must be used to support SASL_SSL authentication.
- Migration from Apache Kafka clusters operating in ZooKeeper mode to KRaft mode is
  not supported by cegedim.cloud.
- Upgrading the Debian Linux distribution from Debian 10 to Debian 12 can also be
  requested through an ITCare ticket.
- Major version upgrades require a different approach, namely the full reprovisioning
  of the environment.
- The default protocol supported is AMQP (other protocols can be enabled on request).
- TLS/SSL can be activated for the AMQP protocol at the time of provisioning, or later
  on request.
- Delivered clusters are secured for both inter-broker and client <-> broker communications,
  with SASL_SSL.
- Sizing can be configured to suit your needs.
- TLS/SSL can be activated for AMQP protocol at provisioning or afterwards.
- The default cluster sizing includes 3 brokers provisioned over 3 Availability Zones.
- The replication factor is set to 3 for topics and the minimum in-sync replica has
  to be 2.
- Debian version upgrades must be performed sequentially.
- RabbitMQ version upgrades must be performed sequentially.
- The request for an access account to the service is done directly in the ITCare
  portal through the service detail page.
- You can also request an account by creating a support request in ITCare.
- All requests to Vortext API is made by HTTP protocol, using TLSv1 transport encryption.
- Each request is completely stateless.
- Customer can activate or deactivate Bot Defense
- Customer can add or delete IP address on whitelist
- Customer can deploy a strict or standard profile
- Customer can activate the Bot Defense in transparent or blocking mode
- Modification requires a request via a ticket
- Modification of rabbitmq.conf and other internal settings are performed by cegedim.cloud
  on request.
- The standard profile is not recommended if DDoS attacks are in progress.
- The strict profile can lead to the appearance of false positives and therefore requires
  greater monitoring.
- An e-mail notification will be sent when the service is activated.
- An e-mail notification will be sent when the cluster is shut down.
- An e-mail notification will be sent when all nodes have been resized.
- An e-mail notification will be sent when the cluster is deleted.
- Designate someone with good knowledge of the privacy challenges of the project database.
- The deliverable is the database containing the masked data.
- All stable feature flags must be enabled before and after each upgrade.
- Scalable network filesystem that aggregates disk storage resources from multiple
  servers into a single global namespace.
- Suitable for unstructured data such as documents, images, audio and video files,
  and log files.
- Password provided by the customer at creation time is not stored anywhere by cegedim.cloud.
- Data is transferred using HTTPS, so all transferred data is encrypted over the network.
- Data is also encrypted server-side, on disks.
- Access to Buckets is done using an Object User.
- S3 Bucket logging is not supported.
- Modification of the configuration requires a ticket
- Highly secure open-source solution that complies with HDS requirements
- 'Sovereign hosting: storage located in France in cegedim.cloud datacentres'
- Logs are secured in Splunk and managed in ITCare.
- On ITCare, there is a specific dashboard to get a visibility on your traffic.
- The default admin_client account is provisioned by default.
- Scalability
- Handles thousands of clients
- POSIX compatible
- Can use any ondisk filesystem that supports extended attributes
- Accessible using industry standard protocols like NFS and SMB
- Provides replication, quotas, Geo-replication, snapshots and bitrot detection
- Allows optimization for different workloads
- Open Source
- Storage volumes can be added at your discretion in self-service using ITCare.
- It is recommended not to go over 2 TB.
- An e-mail notification will be sent when the volume has been created.
- An e-mail notification will be sent when the volume has been deleted.
- An e-mail notification will be sent when the volume has been resized.
- cegedim.cloud Object Storage Service is only available through the protocol HTTPS
  on port 443.
- 'Authentication for local accounts (e.g.: admin_client) are protected by TOTP.'
- 'The API is resource centric: the main entry point of the API could be /compute/resources.'
errors:
- 'REQUEST_LIMIT_EXCEEDED: Throttle API calls or reduce frequency'
- '401 Unauthorized: Recheck OAuth scopes or token expiration'
- '400: Bad query - Syntax or consistency error in the query. Must be corrected by
  the issuer'
- '401: Unauthenticated access to the resource'
- '403: Unauthorized access'
- '404: Non-existent resource'
- '409: Conflict'
- '422: Inconsistent data'
- '500: Fatal API error'
- '503: Service temporarily unavailable'
- 'QUERY_TIMEOUT: Break down filters or add selectivity'
- 'Exceeded Maximum Shard Limit: Each node has a default shard limit of 1000 shards.'
- 'USER_NOT_AUTHORIZED: Ensure the user has the correct permissions.'
- 'INVALID_CREDENTIALS: Check the provided SQL role credentials.'
- Exceeding the shard limit of 1000 shards per node will result in an error.
- 'Unauthorized: Check your credentials.'
- 'Connection Timeout: Ensure the Redis server is reachable.'
- 'Unauthorized: Check username or password'
- 'Timeout: Check network configuration or Redis instance status'
- The duration of an update is variable and depends on the topology.
- Temporary unavailability of SQL Server during reboot
- Failure to rejoin the AlwaysOn cluster
- Data corruption if backups are invalid
- 'Connection timeout: Check the Redis instance host or port'
- 'Authentication failed: Ensure the correct username and password are used'
- OS upgrades is required only if the PaaS Redis 6.2 was provisionned before May 31,
  2024.
- Availability 99.8%
- 'Authorization required: Verify Active Directory permissions'
- 'Connection timeout: Check network settings and firewall rules'
- '401 Unauthorized: Recheck password or user permissions'
- '403 Forbidden: Check access rights or policies'
- '401 Unauthorized: Recheck user credentials and permissions'
- 'UNAUTHORIZED: Recheck authentication credentials'
- Messages older than 28 days will expire automatically
- 'Unauthorized: Access key or secret key is invalid.'
- 'BucketNotFound: The specified bucket does not exist.'
auth_info:
  mentioned_objects:
  - super user local account
  - OpenOIDC
  - LDAP
  - Public and Private Key
  - sql role
  - admin
  - cgdm_admin
  - monitoring
  - keystore
  - property file
client:
  base_url: https://api.cegedim.cloud
  auth:
    type: oauth2
    flow: refresh_token
source_metadata: null
