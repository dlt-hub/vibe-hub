resources:
- name: generation
  endpoint:
    path: /api/v1/generation
    method: GET
    data_selector: usage
    params: {}
- name: chat_completions
  endpoint:
    path: /api/v1/chat/completions
    method: POST
    data_selector: choices
- name: completions
  endpoint:
    path: /completions
    method: POST
    data_selector: response
    params: {}
- name: chat_completions
  endpoint:
    path: /chat/completions
    method: POST
    data_selector: response
    params: {}
- name: models
  endpoint:
    path: /api/v1/models
    method: GET
    data_selector: models
    params: {}
- name: models
  endpoint:
    path: /docs/api-reference/list-available-models
    method: GET
    data_selector: data
- name: model_routing
  endpoint:
    path: /api/v1/model-routing
    method: POST
- name: provider
  endpoint:
    params: {}
- name: Provider Preferences Schema
  endpoint:
    path: /definitions/Provider Preferences Schema
    method: GET
    data_selector: properties
    params: {}
- name: chat_completions
  endpoint:
    path: /chat/completions
    method: POST
- name: completion
  endpoint:
    path: /completion
    method: POST
- name: presets
  endpoint:
    path: /settings/presets
    method: GET
    data_selector: presets
    params: {}
- name: search_gutenberg_books
  endpoint:
    path: /books
    method: GET
    data_selector: results
    params: {}
- name: api_keys
  endpoint:
    path: /api/v1/keys
    method: GET
    data_selector: data
- name: create_key
  endpoint:
    path: /api/v1/keys
    method: POST
    data_selector: data
- name: get_key
  endpoint:
    path: /api/v1/keys/{key_hash}
    method: GET
    data_selector: data
- name: update_key
  endpoint:
    path: /api/v1/keys/{key_hash}
    method: PATCH
    data_selector: data
- name: delete_key
  endpoint:
    path: /api/v1/keys/{key_hash}
    method: DELETE
    data_selector: data
- name: chat_completions
  endpoint:
    path: /chat/completions
    method: POST
    data_selector: choices
    params:
      stream: 'true'
- name: rate_limits
  endpoint:
    path: /api/v1/key
    method: GET
    data_selector: data
    params: {}
- name: completion
  endpoint:
    path: /api/v1/completions
    method: POST
    data_selector: choices
    params: {}
- name: chat_completion
  endpoint:
    path: /api/v1/chat/completions
    method: POST
    data_selector: choices
- name: generation
  endpoint:
    path: /generation
    method: GET
    data_selector: data
    params:
      id: id
- name: models
  endpoint:
    path: /models
    method: GET
    data_selector: data
    params: {}
- name: endpoints
  endpoint:
    path: /models/:author/:slug/endpoints
    method: GET
- name: list_models_filtered_by_user_provider_preferences
  endpoint:
    path: /api/v1/models/user
    method: GET
    data_selector: data
- name: providers
  endpoint:
    path: /api/v1/providers
    method: GET
    data_selector: data
- name: credits
  endpoint:
    path: /api/v1/credits
    method: GET
    data_selector: data
    params: {}
- name: create_coinbase_charge
  endpoint:
    path: /api/v1/credits/coinbase
    method: POST
    data_selector: data
    params: {}
- name: credit_purchase
  endpoint:
    path: /api/v1/credits/coinbase
    method: POST
    data_selector: data
    params: {}
- name: credits
  endpoint:
    path: /api/v1/credits
    method: GET
    data_selector: data
    params: {}
- name: swapAndTransferUniswapV3TokenPreApproved
  endpoint:
    path: swapAndTransferUniswapV3TokenPreApproved
    method: function
- name: sweepETH
  endpoint:
    path: sweepETH
    method: function
- name: sweepETHAmount
  endpoint:
    path: sweepETHAmount
    method: function
- name: sweepToken
  endpoint:
    path: sweepToken
    method: function
- name: sweepTokenAmount
  endpoint:
    path: sweepTokenAmount
    method: function
- name: transferNative
  endpoint:
    path: transferNative
    method: function
- name: transferOwnership
  endpoint:
    path: transferOwnership
    method: function
- name: transferToken
  endpoint:
    path: transferToken
    method: function
- name: transferTokenPreApproved
  endpoint:
    path: transferTokenPreApproved
    method: function
- name: unpause
  endpoint:
    path: unpause
    method: function
- name: unregisterOperator
  endpoint:
    path: unregisterOperator
    method: function
- name: unwrapAndTransfer
  endpoint:
    path: unwrapAndTransfer
    method: function
- name: unwrapAndTransferPreApproved
  endpoint:
    path: unwrapAndTransferPreApproved
    method: function
- name: chat_completions
  endpoint:
    path: /chat/completions
    method: POST
    data_selector: choices
- name: chat_completions
  endpoint:
    path: /chat/completions
    method: POST
    data_selector: choices
    params: {}
- name: chat_completion
  endpoint:
    path: /chat/completions
    method: POST
    data_selector: choices
    params:
      usage: include
- name: generation
  endpoint:
    path: /generation
    method: GET
    data_selector: usage
    params: {}
- name: activity
  endpoint:
    path: /activity
    method: GET
- name: generations
  endpoint:
    path: /generations
    method: POST
- name: model
  endpoint:
    path: /models
    method: GET
    data_selector: models
- name: streamText
  endpoint:
    path: /streamText
    method: POST
    data_selector: response
    params: {}
- name: assistant
  endpoint:
    path: /api/agents/assistant/generate
    method: POST
    data_selector: response.text
- name: OpenRouter
  endpoint:
    path: /api
    method: GET
- name: gpt-oss-20b
  endpoint:
    path: /models/openai/gpt-oss-20b
    method: GET
    data_selector: data
    params: {}
- name: deepseek_chat_v3_1
  endpoint:
    path: /deepseek/deepseek-chat-v3.1
    method: GET
    data_selector: data
- name: deepseek_chat_v3_1_thinking
  endpoint:
    path: /deepseek/deepseek-chat-v3.1:thinking
    method: GET
    data_selector: data
- name: deepseek_v3_1_base
  endpoint:
    path: /deepseek/deepseek-v3.1-base
    method: GET
    data_selector: data
- name: 'Baidu: ERNIE 4.5 300B A47B'
  endpoint:
    path: /some/endpoint/path
    method: GET
    data_selector: records
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: Mistral Magistral
  endpoint:
    path: /mistral/magistral-medium-2506
    method: GET
    data_selector: output
    params: {}
- name: gemini
  endpoint:
    path: /gemini/v1/model
    method: GET
    data_selector: model
    params: {}
- name: model_description
  endpoint:
    path: /models/thudm/glm-4-32b
    method: GET
    data_selector: description
    params: {}
- name: DeepCoder-14B-Preview
  endpoint:
    path: /deepcoder-14b-preview
    method: GET
    data_selector: records
- name: Kimi VL A3B Thinking
  endpoint:
    path: /kimi-vl-a3b-thinking
    method: GET
    data_selector: records
- name: Typhoon2 70B Instruct
  endpoint:
    path: /deepseek/deepseek-chat-v3
    method: GET
    data_selector: records
- name: 'Google: Gemini 2.5 Pro Experimental'
  endpoint:
    path: /google/gemini-2.5-pro-exp-03-25
    method: GET
    data_selector: records
- name: deepseek_model
  endpoint:
    path: /deepseek/models
    method: GET
    data_selector: models
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: 'DeepSeek: R1'
  endpoint:
    path: /deepseek/r1
    method: GET
    data_selector: results
- name: mistral_pixtral_large
  endpoint:
    path: /mistral/pixtral-large
    method: GET
    data_selector: records
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: command_r
  endpoint:
    path: /v1/command_r
    method: POST
    data_selector: data
    params: {}
- name: model_info
  endpoint:
    path: /v1/models
    method: GET
    data_selector: data
- name: gpt_3.5_turbo
  endpoint:
    path: /v1/engines/gpt-3.5-turbo/completions
    method: POST
    data_selector: choices
    params: {}
- name: gpt_4
  endpoint:
    path: /v1/engines/gpt-4/completions
    method: POST
    data_selector: choices
    params: {}
- name: chat_completion
  endpoint:
    path: /chat/completions
    method: POST
    data_selector: choices
    params: {}
notes:
- OpenRouter normalizes the schema across models and providers
- Streaming is supported for all models
- OpenRouter uses API keys passed as Bearer tokens for accessing the completions API.
- The Models API returns a standardized JSON response format that provides comprehensive
  metadata for each available model.
- Default behavior is to load balance requests across providers.
- OpenRouter is designed with performance as a top priority.
- Under typical production conditions, OpenRouter adds approximately 40ms of latency
  to your requests.
- Most providers automatically enable prompt caching.
- Gemini models have typically have a 4096 token minimum for cache write to occur.
- Structured outputs allow you to enforce specific JSON Schema validation on model
  responses
- 'Always set strict: true to ensure the model follows your schema exactly'
- Models may take longer to respond due to additional reasoning steps
- Token usage will be higher due to the reasoning process
- The quality of reasoning depends on the model’s capabilities
- Some models may be better suited for this approach than others
- The tools parameter must be included in every request to validate the tool schema
- All OpenRouter endpoints with 8k (8,192 tokens) or less context length will default
  to using middle-out.
- The web search plugin uses your OpenRouter credits and charges $4 per 1000 results.
- Zero completion insurance is automatically enabled for all accounts and requires
  no configuration.
- Provisioning keys cannot be used to make API calls to OpenRouter’s completion endpoints
  - they are exclusively for key management operations.
- Streaming responses useful for building chat interfaces.
- OpenRouter occasionally sends comments to prevent connection timeouts.
- API keys on OpenRouter are more powerful than keys used directly for model APIs.
- You must protect your API keys and never commit them to public repositories.
- OpenRouter will default to the values listed below if certain parameters are absent
  from your request.
- Bearer authentication of the form Bearer <token>, where token is your auth token.
- 'Authorization string required: Bearer authentication of the form Bearer <token>,
  where token is your auth token.'
- supported_parameters is a union of all parameters supported by all providers for
  this model. There may not be a single provider which offers all of the listed parameters
  for a model.
- Creates and hydrates a Coinbase Commerce charge for cryptocurrency payments
- Using provider keys enables direct control over rate limits and costs via your provider
  account.
- The cost of using custom provider keys on OpenRouter is 5% of what the same model/provider
  would cost normally on OpenRouter.
- Currently, we only support Ethereum (1), Polygon (137), Base (8453) chains
- Values are cached, and may be up to 60 seconds stale.
- For maximum security, set code_challenge_method to S256 and set code_challenge to
  the base64 encoding of the sha256 hash of code_verifier.
- If your app is a local-first app or otherwise doesn’t have a public URL, it is recommended
  to test with http://localhost:3000 as the callback and referrer URLs.
- Organizations enable teams and companies to collaborate effectively by sharing credits,
  managing API keys centrally, and tracking usage across all team members.
- Reasoning tokens are included in the response by default if the model decides to
  output them.
- Some reasoning models do not return their reasoning tokens.
- Enabling usage accounting will add a few hundred milliseconds to the last response
  as the API calculates token counts and costs.
- User tracking allows you to specify an arbitrary string identifier for your end-users
  in API requests.
- PydanticAI provides a high-level interface for working with various LLM providers,
  including OpenRouter.
- Integrate OpenRouter with Mastra to access a variety of AI models through a unified
  interface.
- Model uses a Mixture-of-Experts (MoE) architecture.
- Optimized for lower-latency inference.
- Uses OAuth2 with refresh token — requires setup of connected app in api
- Some objects like Contact may return nulls in deeply nested fields
- General purpose use requiring longer thought processing and better accuracy than
  with non-reasoning LLMs.
- Gemini 2.5 Pro is designed for advanced reasoning, coding, mathematics, and scientific
  tasks.
- It employs 'thinking' capabilities to enhance accuracy and nuanced context handling.
- Model is optimized for code generation and structured reasoning tasks.
- DeepSeek R1 Distill Qwen 1.5B is a distilled large language model based on Qwen
  2.5 Math 1.5B.
- The model leverages fine-tuning from DeepSeek R1's outputs, enabling competitive
  performance comparable to larger frontier models.
- Uses OAuth2 with refresh token â€” requires setup of connected app in api
- Performance on par with OpenAI o1, but open-sourced.
- Available for research and educational use under Mistral Research License and for
  commercial purposes under Mistral Commercial License.
- Usage of this model is subject to Meta's Acceptable Use Policy
- Usage of Gemma is subject to Google's Gemma Terms of Use.
- Optimized for language tasks including code generation, text generation, and problem
  solving.
- Training data up to Sep 2021.
- OpenRouter provides a unified API that gives you access to hundreds of AI models
  through a single endpoint.
errors:
- 'REQUEST_LIMIT_EXCEEDED: Throttle API calls or reduce frequency'
- 'QUERY_TIMEOUT: Break down filters or add selectivity'
- '401 Unauthorized: Recheck API key validity'
- '401 Unauthorized: Check your API key.'
- 'Cache writes: charged at the original input token price plus 5 minutes of cache
  storage.'
- 'Cache reads: charged at 0.25x the original input token cost.'
- 'Model doesn’t support structured outputs: The request will fail with an error indicating
  lack of support'
- 'Invalid schema: The model will return an error if your JSON Schema is invalid'
- Connection errors may occur if the payload is not JSON compliant.
- '402: Insufficient credits'
- If your key has been exposed, delete the compromised key and create a new one.
- '400: Bad Request (invalid or missing params, CORS)'
- '401: Invalid credentials (OAuth session expired, disabled/invalid API key)'
- '402: Your account or API key has insufficient credits. Add more credits and retry
  the request.'
- '403: Your chosen model requires moderation and your input was flagged'
- '408: Your request timed out'
- '429: You are being rate limited'
- '502: Your chosen model is down or we received an invalid response from it'
- '503: There is no available model provider that meets your routing requirements'
- 200 Successful
- 400 Bad Request Error
- 401 Unauthorized Error
- '200 Successful: Charge created successfully'
- '400 Invalid code_challenge_method: Make sure you’re using the same code challenge
  method in step 1 as in step 2.'
- '403 Invalid code or code_verifier: Make sure your user is logged in to OpenRouter,
  and that code_verifier and code_challenge_method are correct.'
- '405 Method Not Allowed: Make sure you’re using POST and HTTPS for your request.'
- '400 Bad Request: Check your request parameters.'
- '401 Unauthorized: Ensure your API key or token is valid.'
- '403 Forbidden: You do not have permission to access this resource.'
- 401 Authentication issues
- 402 Payment failures
- 404 Model not found
- 500+ All server errors
- '401 Unauthorized: Recheck API key or token expiration'
- '401 Unauthorized: Recheck OAuth scopes or token expiration'
- '400 Bad Request: Check input parameters.'
- '401 Unauthorized: Verify your API key and permissions.'
- '429 Too Many Requests: Slow down your requests.'
- '400 Bad Request: Check request parameters'
- '401 Unauthorized: Invalid API key'
- '429 Too Many Requests: Rate limit exceeded'
auth_info:
  mentioned_objects:
  - API keys
  - OauthToken
  - AuthProvider
  - NamedCredential
client:
  base_url: https://openrouter.ai/api/v1
  auth:
    type: apikey
    location: header
    header_name: Authorization
  headers:
    HTTP-Referer: <YOUR_SITE_URL>
    X-Title: <YOUR_SITE_NAME>
source_metadata: null
