resources:
- name: chat_completions
  endpoint:
    path: /models/<model_version_id>/proxy/v1/chat/completions
    method: POST
- name: text_completion
  endpoint:
    path: /models/<model_version_id>/proxy/v1
    method: POST
- name: sequence_classification
  endpoint:
    path: /models/<model_version_id>/proxy/v1/classify
    method: POST
- name: automatic_speech_recognition
  endpoint:
    path: /models/<model_version_id>/proxy/v1/transcript
    method: POST
- name: text_to_speech
  endpoint:
    path: /models/<model_version_id>/proxy/v1/generate-speech
    method: POST
- name: text_to_image
  endpoint:
    path: /models/<model_version_id>/proxy/v1/generate-image
    method: POST
- name: translation
  endpoint:
    path: /models/<model_version_id>/proxy/v1/translate
    method: POST
- name: reranking_embedding_classification
  endpoint:
    path: /models/<model_version_id>/proxy/v1
    method: POST
- name: classical_ml_prediction
  endpoint:
    path: /models/<model_version_id>/proxy/v1/predict
    method: POST
- name: chat_completions
  endpoint:
    path: /models/<model_version_id>/proxy/v1/chat/completions
    method: POST
    data_selector: choices
- name: text_completion_vllm
  endpoint:
    path: /models/<model_version_id>/proxy/v1
    method: POST
    data_selector: choices
- name: text_completion_tgi
  endpoint:
    path: /models/<model_version_id>/proxy/v1
    method: POST
    data_selector: choices
- name: sequence_classification
  endpoint:
    path: /models/<model_version_id>/proxy/classify
    method: POST
    data_selector: classification
- name: automatic_speech_recognition
  endpoint:
    path: /models/<model_version_id>/proxy/transcript
    method: POST
    data_selector: text
- name: text_to_speech
  endpoint:
    path: /models/<model_version_id>/proxy/generate-speech
    method: POST
- name: text_to_image
  endpoint:
    path: /models/<model_version_id>/proxy/generate-image
    method: POST
- name: translation
  endpoint:
    path: /models/<model_version_id>/proxy/translate
    method: POST
    data_selector: translation
- name: reranking_embedding_classification
  endpoint:
    path: /models/<model_version_id>/proxy/v1
    method: POST
- name: predict
  endpoint:
    path: /models/<model_version_id>/proxy/predict
    method: POST
notes:
- Token-Based Auth – Generate unique tokens to secure your model endpoints.
- Default request timeout is 120 seconds.
- Default timeout is 120 seconds; can be overridden via OICM-Request-TimeOut header.
- Store tokens securely and rotate them to avoid expiry.
- Token-Based Security – Authenticate using secure tokens generated in the model’s
  settings.
- Tokens can be created with different expiration periods
- The platform supports multiple active tokens for different applications or use cases
- By default, requests have a timeout of 120 seconds.
- The value should be the request timeout in seconds.
- RayServe is the only supported model server for model bundles.
errors:
- Invalid Token – Verify token is active and not expired.
- Incorrect Model Version ID – Double-check the ID in your workspace.
- Request Format – Confirm JSON structure matches endpoint specs.
- Permission Errors – Ensure the token grants appropriate permissions.
auth_info:
  mentioned_objects: []
client:
  base_url: https://oicm.docs.openinnovation.ai
  auth:
    type: oauth2
source_metadata: null
