resources:
- name: percona_server_mongodb_cluster
  endpoint:
    path: /apis/psmdb.percona.com/v1/namespaces/default/perconaservermongodbs
    method: POST
    data_selector: body
- name: perconaservermongodb
  endpoint:
    path: /apis/psmdb.percona.com/v1/namespaces/default/perconaservermongodbs
    method: GET
    data_selector: rows
    params:
      limit: '500'
- name: percona_server_mongodb
  endpoint:
    path: /apis/psmdb.percona.com/v1/namespaces/default/perconaservermongodbs/my-cluster-name
    method: GET
    data_selector: metadata
- name: percona_server_mongodb
  endpoint:
    path: /apis/psmdb.percona.com/v1/namespaces/default/perconaservermongodbs/my-cluster-name
    method: PATCH
    data_selector: spec
    params:
      size: '5'
- name: backup
  endpoint:
    path: /apis/psmdb.percona.com/v1/namespaces/default/perconaservermongodbbackups
    method: POST
    data_selector: spec
    params: {}
- name: restore
  endpoint:
    path: /apis/psmdb.percona.com/v1/namespaces/default/perconaservermongodbrestores
    method: POST
    data_selector: spec
    params: {}
- name: PMM
  endpoint:
    path: /new/category/percona-monitoring-and-management/
    method: GET
- name: Percona Everest
  endpoint:
    path: /new/category/percona-everest/
    method: GET
- name: pg_tde
  endpoint:
    path: /new/category/postgresql/
    method: GET
- name: OpenID Connect
  endpoint:
    path: /new/category/mongodb/
    method: GET
- name: Percona Distribution for PostgreSQL
  endpoint:
    path: /percona-distribution-for-postgresql
    method: GET
- name: Percona Transparent Data Encryption for PostgreSQL
  endpoint:
    path: /pg-tde
    method: GET
- name: Percona Operator for PostgreSQL
  endpoint:
    path: /percona-operator-for-postgresql
    method: GET
- name: Monitoring PostgreSQL with PMM
  endpoint:
    path: /percona-monitoring-and-management
    method: GET
- name: Query Performance Monitoring for PostgreSQL
  endpoint:
    path: /pg-stat-monitor
    method: GET
- name: MySQL Amazon Aurora Details
  endpoint:
    path: reference/dashboards/dashboard-mysql-amazon-aurora-details.html
    method: GET
- name: MySQL Command/Handler Counters Compare
  endpoint:
    path: reference/dashboards/dashboard-mysql-command-handler-counters-compare.html
    method: GET
- name: MySQL InnoDB Compression Details
  endpoint:
    path: reference/dashboards/dashboard-mysql-innodb-compression-details.html
    method: GET
- name: MySQL InnoDB Details
  endpoint:
    path: reference/dashboards/dashboard-mysql-innodb-details.html
    method: GET
- name: MySQL MyISAM/Aria Details
  endpoint:
    path: reference/dashboards/dashboard-mysql-myisam-aria-details.html
    method: GET
- name: MySQL MyRocks Details
  endpoint:
    path: reference/dashboards/dashboard-mysql-myrocks-details.html
    method: GET
- name: MySQL Instance Summary
  endpoint:
    path: reference/dashboards/dashboard-mysql-instance-summary.html
    method: GET
- name: MySQL Instances Compare
  endpoint:
    path: reference/dashboards/dashboard-mysql-instances-compare.html
    method: GET
- name: MySQL Instances Overview
  endpoint:
    path: reference/dashboards/dashboard-mysql-instances-overview.html
    method: GET
- name: MySQL Wait Event Analyses Details
  endpoint:
    path: reference/dashboards/dashboard-mysql-wait-event-analyses-details.html
    method: GET
- name: MySQL Performance Schema Details
  endpoint:
    path: reference/dashboards/dashboard-mysql-performance-schema-details.html
    method: GET
- name: MySQL Query Response Time Details
  endpoint:
    path: reference/dashboards/dashboard-mysql-query-response-time-details.html
    method: GET
- name: MySQL Replication Summary
  endpoint:
    path: reference/dashboards/dashboard-mysql-replication-summary.html
    method: GET
- name: MySQL Group Replication Summary
  endpoint:
    path: reference/dashboards/dashboard-mysql-group-replication-summary.html
    method: GET
- name: MySQL Table Details
  endpoint:
    path: reference/dashboards/dashboard-mysql-table-details.html
    method: GET
- name: MySQL User Details
  endpoint:
    path: reference/dashboards/dashboard-mysql-user-details.html
    method: GET
- name: MySQL TokuDB Details
  endpoint:
    path: reference/dashboards/dashboard-mysql-tokudb-details.html
    method: GET
- name: perconapgclusters
  endpoint:
    path: /perconapgclusters
    method: POST
    data_selector: data
- name: perconapgbackups
  endpoint:
    path: /perconapgbackups
    method: POST
    data_selector: data
- name: perconapgrestores
  endpoint:
    path: /perconapgrestores
    method: POST
    data_selector: data
- name: perconapgclusters
  endpoint:
    path: /apis/pgv2.percona.com/v1/perconapgclusters
    method: GET
    data_selector: items
- name: perconapgbackups
  endpoint:
    path: /apis/pgv2.percona.com/v1/perconapgbackups
    method: GET
    data_selector: items
- name: perconapgrestores
  endpoint:
    path: /apis/pgv2.percona.com/v1/perconapgrestores
    method: GET
    data_selector: items
- name: perconapgupgrades
  endpoint:
    path: /apis/pgv2.percona.com/v1/perconapgupgrades
    method: GET
    data_selector: items
- name: pg-operator
  endpoint:
    path: /pg-operator
    method: GET
    data_selector: status
    params: {}
- name: pg-db
  endpoint:
    path: /pg-db
    method: GET
    data_selector: status
    params: {}
- name: pgBouncer
  endpoint:
    path: /secrets/<cluster_name>-pguser-<cluster_name>
    method: GET
    data_selector: data.pgbouncer-uri
    params: {}
- name: Library
  endpoint:
    path: /insert/data
    method: POST
    data_selector: INSERT INTO LIBRARY(id, name, short_description, author, description,
      content, last_updated, created)
    params: {}
- name: backup
  endpoint:
    path: /deploy/backup.yaml
    method: POST
    data_selector: metadata
    params: {}
- name: pmm_client
  endpoint:
    path: /graph/api/auth/keys
    method: POST
    data_selector: key
    params: {}
- name: PostgreSQL
  endpoint:
    path: /supported-versions
    method: GET
    data_selector: versions
- name: pgBouncer
  endpoint:
    path: /supported-versions/pgBouncer
    method: GET
    data_selector: versions
- name: Patroni
  endpoint:
    path: /supported-versions/Patroni
    method: GET
    data_selector: versions
- name: PostGIS
  endpoint:
    path: /supported-versions/PostGIS
    method: GET
    data_selector: versions
- name: perconapgcluster
  endpoint:
    path: /cr.yaml
    method: POST
    data_selector: cluster1
- name: postgresql_cluster
  endpoint:
    path: /deploy/cr.yaml
    method: POST
    data_selector: cluster
    params: {}
- name: postgres-operator
  endpoint:
    path: bundle.yaml
    method: POST
    data_selector: customresourcedefinition
    params: {}
- name: Percona Distribution for PostgreSQL
  endpoint:
    path: cr.yaml
    method: POST
    data_selector: perconapgcluster
    params: {}
- name: PerconaPGCluster
  endpoint:
    path: /deploy/cr.yaml
    method: POST
    data_selector: custom_resource
    params: {}
- name: custom_resource_definition
  endpoint:
    path: /deploy/crd.yaml
    method: POST
    data_selector: apply
    params: {}
- name: role_based_access_control
  endpoint:
    path: /deploy/rbac.yaml
    method: POST
    data_selector: apply
    params: {}
- name: operator
  endpoint:
    path: /deploy/operator.yaml
    method: POST
    data_selector: apply
    params: {}
- name: database_cluster
  endpoint:
    path: /deploy/cr.yaml
    method: POST
    data_selector: apply
    params: {}
- name: users
  endpoint:
    path: /users
    method: GET
    data_selector: users
- name: databases
  endpoint:
    path: /databases
    method: GET
    data_selector: databases
- name: pgBouncer
  endpoint:
    path: /proxy/pgBouncer
    method: GET
    data_selector: replicas
    params:
      expose.type: LoadBalancer
- name: ha
  endpoint:
    path: /cluster/ha
    method: GET
    data_selector: active primary
    params:
      expose.type: LoadBalancer
- name: dynamicConfiguration
  endpoint:
    path: /patroni.dynamicConfiguration
    method: PATCH
    data_selector: parameters
    params: {}
- name: pg_hba
  endpoint:
    path: /patroni.dynamicConfiguration/postgresql/pg_hba
    method: PATCH
    data_selector: pg_hba
    params: {}
- name: proxy.pgBouncer
  endpoint:
    path: deploy/cr.yaml
    method: POST
    data_selector: affinity.podAntiAffinity
- name: backups.pgbackrest.repoHost
  endpoint:
    path: deploy/cr.yaml
    method: POST
    data_selector: topologySpreadConstraints
- name: pgv2.percona.com/version
  endpoint:
    path: /api/v2/version
    method: GET
    data_selector: version
- name: app.kubernetes.io/instance
  endpoint:
    path: /api/v2/instances
    method: GET
    data_selector: instances
- name: app.kubernetes.io/managed-by
  endpoint:
    path: /api/v2/managed-by
    method: GET
    data_selector: managedBy
- name: app.kubernetes.io/component
  endpoint:
    path: /api/v2/component
    method: GET
    data_selector: component
- name: app.kubernetes.io/part-of
  endpoint:
    path: /api/v2/part-of
    method: GET
    data_selector: partOf
- name: app.kubernetes.io/name
  endpoint:
    path: /api/v2/name
    method: GET
    data_selector: name
- name: backup
  endpoint:
    path: /backups.html
    method: GET
    data_selector: backups
    params: {}
- name: restore
  endpoint:
    path: /backups-restore.html
    method: GET
    data_selector: restore
    params: {}
- name: backup_configuration
  endpoint:
    path: /spec/backups/pgbackrest/repos
    method: POST
    data_selector: repos
- name: standby_configuration
  endpoint:
    path: /spec/standby
    method: PATCH
    data_selector: enabled
- name: create_replication_user
  endpoint:
    path: /create_replication_user
    method: POST
    data_selector: CREATE ROLE _crunchyrepl WITH LOGIN REPLICATION
- name: pgBackRest repository
  endpoint:
    path: /deploy/cr.yml
    method: GET
    data_selector: backups.pgbackrest.repos
    params: {}
- name: repo1
  endpoint:
    path: /pgbackrest/postgres-operator/cluster1/repo1
    method: GET
    data_selector: volumeClaimSpec
    params: {}
- name: repo2
  endpoint:
    path: /pgbackrest/postgres-operator/cluster1/repo2
    method: GET
    data_selector: s3
    params:
      bucket: <YOUR_AWS_S3_BUCKET_NAME>
      region: <YOUR_AWS_S3_REGION>
- name: repo3
  endpoint:
    path: /pgbackrest/postgres-operator/cluster1/repo3
    method: GET
    data_selector: gcs
    params:
      bucket: <YOUR_GCS_BUCKET_NAME>
- name: repo4
  endpoint:
    path: /pgbackrest/postgres-operator/cluster1/repo4
    method: GET
    data_selector: azure
    params:
      container: <YOUR_AZURE_CONTAINER>
- name: backups
  endpoint:
    path: /deploy/cr.yaml
    method: POST
    data_selector: backups.pgbackrest.repos
    params: {}
- name: backup
  endpoint:
    path: /deploy/backup.yaml
    method: POST
    data_selector: spec
    params:
      pgCluster: cluster1
      repoName: repo1
- name: restore
  endpoint:
    path: /deploy/restore.yaml
    method: POST
    data_selector: spec
    params: {}
- name: backup_storage_configuration
  endpoint:
    path: /backup-storage-configuration
    method: GET
    data_selector: configuration
    params: {}
- name: backup_retention
  endpoint:
    path: /backups
    method: POST
    data_selector: backups.pgbackrest.global
    params:
      repo1-retention-full: '14'
      repo1-retention-full-type: time
      repo1-retention-diff: '3'
- name: disable_backups
  endpoint:
    path: /backups/disable
    method: PATCH
    data_selector: spec
    params:
      backups.enabled: 'false'
- name: main_pgbackrest
  endpoint:
    path: /deploy/cr.yaml
    method: POST
    data_selector: spec.backups.pgbackrest.repos
    params: {}
- name: standby_pgbackrest
  endpoint:
    path: /deploy/cr.yaml
    method: POST
    data_selector: spec.backups.pgbackrest.repos
    params:
      standby:
        enabled: true
        repoName: repo1
- name: standby_cluster
  endpoint:
    path: /deploy/cr.yaml
    method: POST
    data_selector: perconapgcluster.pg.percona.com/standby
    params: {}
- name: dr_cluster
  endpoint:
    path: /dr-cr.yaml
    method: POST
    data_selector: perconapgcluster.pg.percona.com/standby
    params: {}
- name: instances
  endpoint:
    path: /spec/instances
    method: GET
    data_selector: instances
- name: sidecar_container
  endpoint:
    path: /add/sidecar/container
    method: POST
    data_selector: sidecars
    params: {}
- name: pmm_client
  endpoint:
    path: /graph/api/auth/keys
    method: POST
    data_selector: ''
    params: {}
- name: custom_resource_options
  endpoint:
    path: deploy/cr.yaml
    method: GET
    data_selector: options
- name: databaseInitSQL
  endpoint:
    path: /path/to/configmap
    method: POST
    data_selector: data.init.sql
    params: {}
- name: patroni_switchover
  endpoint:
    path: /patroni/switchover
    method: PATCH
    data_selector: spec.patroni.switchover
    params:
      enabled: 'true'
      targetInstance: cluster1-instance1-bmdp
- name: extensions
  endpoint:
    path: /custom-extensions
    method: GET
    data_selector: extensions
    params: {}
- name: operator
  endpoint:
    path: /deploy/bundle.yaml
    method: POST
- name: cluster
  endpoint:
    path: /deploy/cr.yaml
    method: POST
- name: tablespace
  endpoint:
    path: /tablespaces
    method: POST
    data_selector: tablespace
    params: {}
- name: PostGIS-enabled database cluster
  endpoint:
    path: /deploy/cr.yaml
    method: POST
    data_selector: metadata.name
    params: {}
- name: Custom Resource
  endpoint:
    path: /pg
    method: DELETE
    data_selector: resources
    params: {}
- name: Deployments
  endpoint:
    path: /deploy
    method: DELETE
    data_selector: resources
    params: {}
- name: Custom Resource Definition
  endpoint:
    path: /crd
    method: DELETE
    data_selector: resources
    params: {}
- name: Persistent Volume Claims
  endpoint:
    path: /pvc
    method: DELETE
    data_selector: resources
    params: {}
- name: Secrets
  endpoint:
    path: /secrets
    method: DELETE
    data_selector: resources
    params: {}
- name: Version Service
  endpoint:
    path: /check.percona.com
    method: GET
- name: PerconaPGCluster
  endpoint:
    path: /pg
    method: GET
    data_selector: cluster
    params: {}
- name: PerconaPGBackup
  endpoint:
    path: /pg-backup
    method: GET
    data_selector: backup
    params: {}
- name: PerconaPGRestore
  endpoint:
    path: /pg-restore
    method: GET
    data_selector: restore
    params: {}
- name: Persistent Volume Claims
  endpoint:
    path: /persistent-volumes-claims
    method: GET
    data_selector: items
- name: Persistent Volumes
  endpoint:
    path: /persistent-volumes
    method: GET
    data_selector: items
- name: Storage Classes
  endpoint:
    path: /storage-classes
    method: GET
    data_selector: items
- name: reinitialize_replicas
  endpoint:
    path: /reinitialize
    method: POST
    data_selector: result
    params: {}
- name: pgbackrest
  endpoint:
    path: /backups/pgbackrest
    method: GET
    data_selector: records
- name: postgresCluster
  endpoint:
    path: /dataSource/postgresCluster
    method: GET
- name: pgbackrest
  endpoint:
    path: /dataSource/pgbackrest
    method: GET
- name: volumes
  endpoint:
    path: /dataSource/volumes
    method: GET
- name: instances
  endpoint:
    path: /dataSource/instances
    method: GET
- name: backup
  endpoint:
    path: /dataSource/backup
    method: GET
- name: pmm
  endpoint:
    path: /dataSource/pmm
    method: GET
- name: proxy
  endpoint:
    path: /dataSource/proxy
    method: GET
- name: patroni
  endpoint:
    path: /dataSource/patroni
    method: GET
- name: customExtensions
  endpoint:
    path: /dataSource/customExtensions
    method: GET
- name: postgresCluster
  endpoint:
    path: /datasource/postgresCluster
    method: GET
- name: backups_pgbackrest_repo
  endpoint:
    path: /backups/pgbackrest/repo
    method: GET
    data_selector: records
- name: backups_pgbackrest_manual
  endpoint:
    path: /backups/pgbackrest/manual
    method: GET
    data_selector: records
- name: PerconaPGBackup
  endpoint:
    path: /deploy/backup.yaml
    method: POST
    data_selector: metadata
    params: {}
- name: restore
  endpoint:
    path: /deploy/restore.yaml
    method: POST
    data_selector: spec
    params: {}
- name: Secrets
  endpoint:
    path: /api/v1/secrets
    method: GET
    data_selector: items
    params: {}
- name: PostgreSQL
  endpoint:
    path: /versions/compatibility/postgresql
    method: GET
- name: pgBackRest
  endpoint:
    path: /versions/compatibility/pgbackrest
    method: GET
- name: pgBouncer
  endpoint:
    path: /versions/compatibility/pgbouncer
    method: GET
- name: release_notes
  endpoint:
    path: /Kubernetes-Operator-for-PSMONGODB-RN1.21.0.html
    method: GET
- name: mongo_backup
  endpoint:
    path: /backup
    method: GET
    data_selector: backup_records
    params: {}
- name: mongo_monitoring
  endpoint:
    path: /monitoring
    method: GET
    data_selector: monitoring_records
    params: {}
- name: psmdb-operator
  endpoint:
    path: /psmdb-operator
    method: GET
    data_selector: status
- name: psmdb-db
  endpoint:
    path: /psmdb-db
    method: GET
    data_selector: status
- name: admin
  endpoint:
    path: /admin
    method: GET
    data_selector: records
- name: test_collection
  endpoint:
    path: /test
    method: POST
    data_selector: acknowledged
    params: {}
- name: backup
  endpoint:
    path: /deploy/backup/backup.yaml
    method: POST
    data_selector: backup
    params: {}
- name: PMM Client
  endpoint:
    path: /graph/api/auth/keys
    method: POST
    data_selector: key
    params: {}
- name: officially_supported_platforms
  endpoint:
    path: /System-Requirements.html#officially-supported-platforms
    method: GET
    data_selector: platforms
    params: {}
- name: resource_limits
  endpoint:
    path: /System-Requirements.html#resource-limits
    method: GET
    data_selector: limits
    params: {}
- name: installation_guidelines
  endpoint:
    path: /System-Requirements.html#installation-guidelines
    method: GET
    data_selector: installation_options
    params: {}
- name: operator_deployment
  endpoint:
    path: /bundle.yaml
    method: GET
- name: mongodb_cluster_deployment
  endpoint:
    path: /cr-minimal.yaml
    method: GET
- name: GKE Cluster
  endpoint:
    path: /container/clusters
    method: POST
    data_selector: clusters
    params:
      project: <project ID>
      zone: us-central1-a
      cluster_version: '1.33'
      machine_type: n1-standard-4
      num_nodes: 3
- name: mongodb_cluster
  endpoint:
    path: /deploy/cr.yaml
    method: GET
- name: operator_deployment
  endpoint:
    path: /deploy/bundle.yaml
    method: GET
- name: percona-server-mongodb-operator
  endpoint:
    path: /deploy/bundle.yaml
    method: GET
    data_selector: serverside-applied
- name: my-cluster-name
  endpoint:
    path: /deploy/cr.yaml
    method: GET
    data_selector: created
- name: operator_deployment
  endpoint:
    path: /bundle.yaml
    method: GET
- name: mongodb_cluster
  endpoint:
    path: /cr.yaml
    method: GET
- name: cluster
  endpoint:
    path: /deploy/cr.yaml
    method: POST
- name: secrets
  endpoint:
    path: /deploy/secrets.yaml
    method: POST
- name: rbac
  endpoint:
    path: /deploy/rbac.yaml
    method: POST
- name: PerconaServerMongoDB
  endpoint:
    path: /deploy/cr.yaml
    method: POST
    data_selector: spec
    params: {}
- name: custom_resource_definition
  endpoint:
    path: /apis/apiextensions.k8s.io/v1/customresourcedefinitions/perconaservermongodbs.psmdb.percona.com/status
    method: PATCH
    data_selector: status.storedVersions
    params: {}
- name: operator_deployment
  endpoint:
    path: /apis/apps/v1/namespaces/default/deployments/percona-server-mongodb-operator
    method: PATCH
    data_selector: spec.template.spec.containers
    params: {}
- name: pmm_client
  endpoint:
    path: /apis/percona.com/v1/psmdb/my-cluster-name
    method: PATCH
    data_selector: spec.pmm.image
    params: {}
- name: Custom Resource
  endpoint:
    path: /check/percona/versions/v1/psmdb-operator/1.21.0
    method: GET
    data_selector: versions[].matrix
- name: psmdb
  endpoint:
    path: /psmdb
    method: PATCH
    data_selector: spec
    params:
      crVersion: 1.21.0
      image: percona/percona-server-mongodb:8.0.12-4
      backup:
        image: percona/percona-backup-mongodb:2.11.0
      pmm:
        image: percona/pmm-client:2.44.1
      logcollector:
        image: percona/fluentbit:{{ fluentbitrecommended }}
- name: psmdb_operator
  endpoint:
    path: /versions/v1/psmdb-operator/1.21.0
    method: GET
    data_selector: versions[].matrix
- name: operator
  endpoint:
    path: /percona/percona-server-mongodb-operator
    method: PATCH
    data_selector: spec
    params:
      initImage: registry.connect.redhat.com/percona/percona-server-mongodb-operator@sha256:201092cf97c9ceaaaf3b60dd1b24c7c5228d35aab2674345893f4cd4d9bb0e2e
- name: cluster
  endpoint:
    path: /psmdb/my-cluster-name
    method: PATCH
    data_selector: spec
    params:
      crVersion: 1.21.0
      image: registry.connect.redhat.com/percona/percona-server-mongodb-operator-containers@sha256:5d29132a60b89e660ab738d463bcc0707a17be73dc955aa8da9e50bed4d9ad3e
      initImage: registry.connect.redhat.com/percona/percona-server-mongodb-operator@sha256:8adc57e9445cfcea1ae02798a8f9d6a4958ac89f0620b9c6fa6cf969545dd23f
      pmm:
        image: registry.connect.redhat.com/percona/percona-server-mongodb-operator-containers@sha256:165f97cdae2b6def546b0df7f50d88d83c150578bdb9c992953ed866615016f1
      backup:
        image: registry.connect.redhat.com/percona/percona-server-mongodb-operator-containers@sha256:a73889d61e996bc4fbc6b256a1284b60232565e128a64e4f94b2c424966772eb
- name: users
  endpoint:
    path: /deploy/cr.yaml
    method: POST
    data_selector: users
    params: {}
- name: users
  endpoint:
    path: /create-users
    method: POST
    data_selector: users
    params: {}
- name: users
  endpoint:
    path: /create-users
    method: POST
    data_selector: users
    params: {}
- name: system_users
  endpoint:
    path: /admin/system_users
    method: GET
    data_selector: users
- name: mongodb_backup
  endpoint:
    path: /MONGODB_BACKUP_USER
    method: GET
    data_selector: user
    params: {}
- name: mongodb_database_admin
  endpoint:
    path: /MONGODB_DATABASE_ADMIN_USER
    method: GET
    data_selector: user
    params: {}
- name: mongodb_cluster_admin
  endpoint:
    path: /MONGODB_CLUSTER_ADMIN_USER
    method: GET
    data_selector: user
    params: {}
- name: mongodb_cluster_monitor
  endpoint:
    path: /MONGODB_CLUSTER_MONITOR_USER
    method: GET
    data_selector: user
    params: {}
- name: mongodb_user_admin
  endpoint:
    path: /MONGODB_USER_ADMIN_USER
    method: GET
    data_selector: user
    params: {}
- name: pmm_server
  endpoint:
    path: /PMM_SERVER_USER
    method: GET
    data_selector: user
    params: {}
- name: MongoDB configuration options
  endpoint:
    path: /changing-mongodb-options
    method: GET
    data_selector: configuration
- name: backup_configuration
  endpoint:
    path: /deploy/cr.yaml
    method: POST
    data_selector: spec.backup.configuration
    params: {}
- name: node_selector
  endpoint:
    path: nodeSelector
    method: GET
    data_selector: 'disktype: ssd'
- name: affinity
  endpoint:
    path: affinity
    method: GET
    data_selector: antiAffinityTopologyKey
    params:
      values:
      - kubernetes.io/hostname
      - topology.kubernetes.io/zone
      - topology.kubernetes.io/region
      - none
- name: tolerations
  endpoint:
    path: tolerations
    method: GET
    data_selector: key
    params:
      effect:
      - NoSchedule
      - PreferNoSchedule
      - NoExecute
- name: priority_class
  endpoint:
    path: /priorityClasses
    method: POST
    data_selector: priorityClassName
    params: {}
- name: pod_disruption_budget
  endpoint:
    path: /podDisruptionBudgets
    method: POST
    data_selector: podDisruptionBudget
    params:
      maxUnavailable: 1
- name: replsets
  endpoint:
    path: /replsets
    method: GET
- name: services
  endpoint:
    path: /services
    method: GET
- name: custom_resource_definition
  endpoint:
    path: /crd/perconaservermongodbs.psmdb.percona.com
    method: GET
    data_selector: metadata.labels
    params: {}
- name: pod_annotations
  endpoint:
    path: /pod/{resource-name}
    method: GET
    data_selector: metadata.annotations
    params: {}
- name: sharded_cluster
  endpoint:
    path: /services/mongos
    method: GET
- name: replica_set
  endpoint:
    path: /services/mongod
    method: GET
- name: replsets
  endpoint:
    path: /replsets
    method: GET
    data_selector: members
- name: sharded_cluster
  endpoint:
    path: /deploy/cr.yaml
    method: GET
    data_selector: sharding
    params:
      sharding.enabled: 'true'
- name: disable_tls_new_cluster
  endpoint:
    path: /deploy/cr.yaml
    method: PATCH
    data_selector: spec
    params:
      tls.mode: disabled
      unsafeFlags.tls: true
- name: disable_tls_running_cluster
  endpoint:
    path: /deploy/cr.yaml
    method: PATCH
    data_selector: spec
    params:
      tls.mode: disabled
      unsafeFlags.tls: true
- name: re_enable_tls
  endpoint:
    path: /deploy/cr.yaml
    method: PATCH
    data_selector: spec
    params:
      tls.mode: preferTLS
      unsafeFlags.tls: false
- name: encryption_key_secret
  endpoint:
    path: /deploy/cr.yaml
    method: POST
    data_selector: secrets.encryptionKey
- name: secrets
  endpoint:
    path: secret
    method: POST
- name: backup_storage
  endpoint:
    path: /backups/storage
    method: GET
    data_selector: backups
    params: {}
- name: backup_types
  endpoint:
    path: /backups/types
    method: GET
    data_selector: types
    params: {}
- name: backup_storages
  endpoint:
    path: /backup/storages
    method: POST
    data_selector: storages
    params: {}
- name: gcs
  endpoint:
    path: /deploy/cr.yaml
    method: POST
    data_selector: storages
    params:
      type: gcs
      bucket: < GCS-BACKUP-BUCKET-NAME-HERE>
      credentialsSecret: gcp-cs-secret
- name: azure_blob
  endpoint:
    path: /deploy/backup-azure.yaml
    method: POST
    data_selector: storages
    params:
      type: azure
      credentialsSecret: my-cluster-azure-secret
      container: <your-container-name>
      prefix: psmdb
- name: filesystem
  endpoint:
    path: /deploy/cr.yaml
    method: POST
    data_selector: storages
    params:
      type: filesystem
      path: /mnt/nfs/
- name: storages
  endpoint:
    path: /deploy/cr.yaml
    method: GET
    data_selector: storages
    params: {}
- name: Backup
  endpoint:
    path: /deploy/backup/backup.yaml
    method: POST
    data_selector: metadata
    params: {}
- name: backup
  endpoint:
    path: /deploy/cr.yaml
    method: POST
    data_selector: backup.storages.my-s3
    params: {}
- name: PerconaServerMongoDBRestore
  endpoint:
    path: /deploy/backup/restore.yaml
    method: POST
    data_selector: spec
    params: {}
- name: restore
  endpoint:
    path: /restore
    method: POST
    data_selector: spec
    params: {}
- name: restore
  endpoint:
    path: /deploy/backup/restore.yaml
    method: POST
    data_selector: spec
    params: {}
- name: restore
  endpoint:
    path: /deploy/backup/restore.yaml
    method: GET
    data_selector: spec
    params: {}
- name: Replica Set Instances
  endpoint:
    path: /spec/replsets
    method: GET
    data_selector: resources
    params: {}
- name: Main cluster
  endpoint:
    path: /replication-main
    method: GET
- name: Replica cluster
  endpoint:
    path: /replication-replica
    method: GET
- name: ServiceExport
  endpoint:
    path: /serviceexport
    method: GET
    data_selector: services
    params: {}
- name: ServiceImport
  endpoint:
    path: /serviceimport
    method: GET
    data_selector: services
    params: {}
- name: ClusterProperty
  endpoint:
    path: /about.k8s.io/v1alpha1/ClusterProperty
    method: POST
    data_selector: value
    params: {}
- name: main-cluster
  endpoint:
    path: /psmdb/perconaservermongodbs.psmdb.percona.com
    method: POST
    data_selector: status
    params: {}
- name: replica_cluster
  endpoint:
    path: /v1/PerconaServerMongoDB
    method: POST
    data_selector: spec
    params:
      unmanaged: 'true'
      multiCluster.enabled: true
      updateStrategy: RollingUpdate
      secrets.users: my-cluster-name-secrets
      secrets.encryptionKey: my-cluster-name-mongodb-encryption-key
      secrets.ssl: replica-cluster-ssl
      secrets.sslInternal: replica-cluster-ssl-internal
- name: services
  endpoint:
    path: /services
    method: GET
    data_selector: services
    params: {}
- name: Main site
  endpoint:
    path: /replication-main.html
    method: GET
    data_selector: details
    params: {}
- name: Replica sites
  endpoint:
    path: /replication-replica.html
    method: GET
    data_selector: details
    params: {}
- name: PMM Client
  endpoint:
    path: /graph/api/auth/keys
    method: POST
    data_selector: key
    params:
      name: operator
      role: Admin
- name: sidecar
  endpoint:
    path: /deploy/cr.yaml
    method: POST
    data_selector: sidecars
    params: {}
- name: PerconaServerMongoDB
  endpoint:
    path: /psmdb
    method: GET
- name: PerconaServerMongoDBBackup
  endpoint:
    path: /psmdb-backup
    method: GET
- name: PerconaServerMongoDBRestore
  endpoint:
    path: /psmdb-restore
    method: GET
- name: logs
  endpoint:
    path: /kubectl/logs/my-cluster-name-rs0-0
    method: GET
    data_selector: logs
    params: {}
- name: debug_image
  endpoint:
    path: /deploy/cr.yaml
    method: SET
    data_selector: image
    params:
      image: percona/percona-server-mongodb:6.0.25-20-debug
- name: deploy_cr
  endpoint:
    path: /deploy/cr.yaml
    method: GET
    data_selector: spec
    params: {}
- name: mongodb_role
  endpoint:
    path: /admin
    method: POST
    data_selector: roles
- name: docker_registry
  endpoint:
    path: /services/docker-registry
    method: GET
    data_selector: services
    params: {}
- name: backup
  endpoint:
    path: /deploy/cr.yaml
    method: POST
    data_selector: backup
    params:
      enabled: 'true'
      version: 0.3.0
- name: custom_resource
  endpoint:
    path: /deploy/cr.yaml
    method: POST
    data_selector: status
    params:
      namespace: psmdb
- name: Victoria Metrics Kubernetes monitoring stack
  endpoint:
    path: /graph/api/auth/keys
    method: POST
    data_selector: key
    params:
      name: operator
      role: Admin
- name: percona_certified_images
  endpoint:
    path: /images
    method: GET
    data_selector: images
    params: {}
- name: images
  endpoint:
    path: /versions/v1/psmdb-operator
    method: GET
    data_selector: versions[].matrix
- name: Custom Resource
  endpoint:
    path: /kubectl/get/psmdb
    method: GET
    data_selector: resources
    params: {}
- name: Deployments
  endpoint:
    path: /kubectl/get/deploy
    method: GET
    data_selector: resources
    params: {}
- name: Custom Resource Definitions
  endpoint:
    path: /kubectl/get/crd
    method: GET
    data_selector: resources
    params: {}
- name: replsets
  endpoint:
    path: /replsets
    method: GET
    data_selector: records
- name: replsets.hidden.volumeSpec.hostPath.path
  endpoint:
    path: /data
    method: GET
    data_selector: records
    params: {}
- name: replsets.hidden.volumeSpec.hostPath.type
  endpoint:
    path: Directory
    method: GET
    data_selector: records
    params: {}
- name: replsets.hidden.volumeSpec.persistentVolumeClaim.annotations
  endpoint:
    path: 'service.beta.kubernetes.io/aws-load-balancer-backend-protocol: http'
    method: GET
    data_selector: records
    params: {}
- name: replsets.hidden.volumeSpec.persistentVolumeClaim.labels
  endpoint:
    path: 'rack: rack-22'
    method: GET
    data_selector: records
    params: {}
- name: replsets.hidden.volumeSpec.persistentVolumeClaim.storageClassName
  endpoint:
    path: standard
    method: GET
    data_selector: records
    params: {}
- name: replsets.hidden.volumeSpec.persistentVolumeClaim.accessModes
  endpoint:
    path: '[ "ReadWriteOnce" ]'
    method: GET
    data_selector: records
    params: {}
- name: replsets.hidden.volumeSpec.persistentVolumeClaim.resources.requests.storage
  endpoint:
    path: 3Gi
    method: GET
    data_selector: records
    params: {}
- name: replsets.arbiter.enabled
  endpoint:
    path: 'false'
    method: GET
    data_selector: records
    params: {}
- name: replsets.arbiter.size
  endpoint:
    path: '1'
    method: GET
    data_selector: records
    params: {}
- name: replsets.arbiter.afinity.antiAffinityTopologyKey
  endpoint:
    path: kubernetes.io/hostname
    method: GET
    data_selector: records
    params: {}
- name: replsets.arbiter.tolerations.key
  endpoint:
    path: node.alpha.kubernetes.io/unreachable
    method: GET
    data_selector: records
    params: {}
- name: replsets.arbiter.tolerations.operator
  endpoint:
    path: Exists
    method: GET
    data_selector: records
    params: {}
- name: replsets.arbiter.tolerations.effect
  endpoint:
    path: NoExecute
    method: GET
    data_selector: records
    params: {}
- name: replsets.arbiter.tolerations.tolerationSeconds
  endpoint:
    path: '6000'
    method: GET
    data_selector: records
    params: {}
- name: replsets.arbiter.priorityClassName
  endpoint:
    path: high priority
    method: GET
    data_selector: records
    params: {}
- name: replsets.arbiter.annotations
  endpoint:
    path: 'iam.amazonaws.com/role: role-arn'
    method: GET
    data_selector: records
    params: {}
- name: replsets.arbiter.labels
  endpoint:
    path: 'rack: rack-22'
    method: GET
    data_selector: records
    params: {}
- name: replsets.arbiter.nodeSelector
  endpoint:
    path: 'disktype: ssd'
    method: GET
    data_selector: records
    params: {}
- name: replsets.resources.limits.cpu
  endpoint:
    path: 300m
    method: GET
    data_selector: records
    params: {}
- name: replsets.resources.limits.memory
  endpoint:
    path: 0.5G
    method: GET
    data_selector: records
    params: {}
- name: replsets.resources.requests.cpu
  endpoint:
    path: 300m
    method: GET
    data_selector: records
    params: {}
- name: replsets.resources.requests.memory
  endpoint:
    path: 0.5G
    method: GET
    data_selector: records
    params: {}
- name: replsets.volumeSpec.emptyDir
  endpoint:
    path: '{}'
    method: GET
    data_selector: records
    params: {}
- name: replsets.volumeSpec.hostPath.path
  endpoint:
    path: /data
    method: GET
    data_selector: records
    params: {}
- name: replsets.volumeSpec.hostPath.type
  endpoint:
    path: Directory
    method: GET
    data_selector: records
    params: {}
- name: replsets.volumeSpec.persistentVolumeClaim.annotations
  endpoint:
    path: 'service.beta.kubernetes.io/aws-load-balancer-backend-protocol: http'
    method: GET
    data_selector: records
    params: {}
- name: replsets.volumeSpec.persistentVolumeClaim.labels
  endpoint:
    path: 'rack: rack-22'
    method: GET
    data_selector: records
    params: {}
- name: replsets.volumeSpec.persistentVolumeClaim.storageClassName
  endpoint:
    path: standard
    method: GET
    data_selector: records
    params: {}
- name: replsets.volumeSpec.persistentVolumeClaim.accessModes
  endpoint:
    path: '[ "ReadWriteOnce" ]'
    method: GET
    data_selector: records
    params: {}
- name: replsets.volumeSpec.persistentVolumeClaim.resources.requests.storage
  endpoint:
    path: 3Gi
    method: GET
    data_selector: records
    params: {}
- name: replsets.hostAliases.ip
  endpoint:
    path: 10.10.0.2
    method: GET
    data_selector: records
    params: {}
- name: pmm.enabled
  endpoint:
    path: 'false'
    method: GET
    data_selector: records
    params: {}
- name: pmm.image
  endpoint:
    path: percona/pmm-client:2.44.1
    method: GET
    data_selector: records
    params: {}
- name: pmm.serverHost
  endpoint:
    path: monitoring-service
    method: GET
    data_selector: records
    params: {}
- name: pmm.customClusterName
  endpoint:
    path: mongo-cluster
    method: GET
    data_selector: records
    params: {}
- name: pmm.resources.requests.cpu
  endpoint:
    path: 300m
    method: GET
    data_selector: records
    params: {}
- name: pmm.resources.requests.memory
  endpoint:
    path: 150M
    method: GET
    data_selector: records
    params: {}
- name: pmm.resources.limits.cpu
  endpoint:
    path: 400m
    method: GET
    data_selector: records
    params: {}
- name: pmm.resources.limits.memory
  endpoint:
    path: 256M
    method: GET
    data_selector: records
    params: {}
- name: sharding.enabled
  endpoint:
    path: 'true'
    method: GET
    data_selector: records
    params: {}
- name: sharding.configsvrReplSet.size
  endpoint:
    path: '3'
    method: GET
    data_selector: records
    params: {}
- name: sharding.configsvrReplSet.terminationGracePeriodSeconds
  endpoint:
    path: '300'
    method: GET
    data_selector: records
    params: {}
- name: sharding.configsvrReplSet.serviceAccountName
  endpoint:
    path: default
    method: GET
    data_selector: records
    params: {}
- name: sharding.configsvrReplSet.topologySpreadConstraints.labelSelector.matchLabels
  endpoint:
    path: 'app.kubernetes.io/name: percona-server-mongodb'
    method: GET
    data_selector: records
    params: {}
- name: sharding.configsvrReplSet.topologySpreadConstraints.maxSkew
  endpoint:
    path: '1'
    method: GET
    data_selector: records
    params: {}
- name: sharding.configsvrReplSet.topologySpreadConstraints.topologyKey
  endpoint:
    path: kubernetes.io/hostname
    method: GET
    data_selector: records
    params: {}
- name: sharding.configsvrReplSet.topologySpreadConstraints.whenUnsatisfiable
  endpoint:
    path: DoNotSchedule
    method: GET
    data_selector: records
    params: {}
- name: sharding.configsvrReplSet.externalNodes.host
  endpoint:
    path: 34.124.76.90
    method: GET
    data_selector: records
    params: {}
- name: sharding.configsvrReplSet.externalNodes.port
  endpoint:
    path: '27017'
    method: GET
    data_selector: records
    params: {}
- name: sharding.configsvrReplSet.externalNodes.votes
  endpoint:
    path: '0'
    method: GET
    data_selector: records
    params: {}
- name: config_server
  endpoint:
    path: /sharding/configsvrReplSet
    method: GET
- name: mongos
  endpoint:
    path: /sharding/mongos
    method: GET
- name: mongos
  endpoint:
    path: /sharding/mongos
    method: GET
- name: Backup
  endpoint:
    path: /deploy/backup/backup.yaml
    method: POST
    data_selector: spec
    params: {}
- name: restore
  endpoint:
    path: /deploy/backup/restore.yaml
    method: POST
    data_selector: metadata
    params: {}
- name: Percona certified images
  endpoint:
    path: /percona-certified-images
    method: GET
    data_selector: images
- name: percona-server-mongodb-operator
  endpoint:
    path: percona/percona-server-mongodb-operator:1.21.0
    method: GET
    data_selector: images
    params: {}
- name: percona-server-mongodb
  endpoint:
    path: percona/percona-server-mongodb:8.0.12-4
    method: GET
    data_selector: images
    params: {}
- name: pmm-client
  endpoint:
    path: percona/pmm-client:3.4.1
    method: GET
    data_selector: images
    params: {}
- name: percona-backup-mongodb
  endpoint:
    path: percona/percona-backup-mongodb:2.11.0
    method: GET
    data_selector: images
    params: {}
- name: MongoDB
  endpoint:
    path: /
    method: GET
    data_selector: records
    params: {}
- name: Percona Backup for MongoDB
  endpoint:
    path: /
    method: GET
    data_selector: records
    params: {}
- name: pmm
  endpoint:
    path: /spec/pmm
    method: POST
    data_selector: customClusterName
    params: {}
- name: backup_nfs
  endpoint:
    path: /backups/storage/remote-file-server
    method: POST
    data_selector: backup
    params: {}
- name: generated_passwords
  endpoint:
    path: /users/generate-passwords
    method: POST
    data_selector: users
    params: {}
- name: mysql_topologies
  endpoint:
    path: /mysql/topologies
    method: GET
    data_selector: topologies
- name: backups
  endpoint:
    path: /mysql/backups
    method: GET
    data_selector: backups
- name: monitoring
  endpoint:
    path: /mysql/monitoring
    method: GET
    data_selector: monitoring
- name: pxc-operator
  endpoint:
    path: /pxc-operator
    method: POST
- name: pxc-db
  endpoint:
    path: /pxc-db
    method: POST
- name: perconaxtradbclusters
  endpoint:
    path: /cr.yaml
    method: POST
- name: secrets
  endpoint:
    path: /kubectl/get/secrets
    method: GET
    data_selector: items
    params: {}
- name: extraordinary_gentlemen
  endpoint:
    path: /insert_data
    method: POST
    data_selector: records
    params: {}
- name: backup
  endpoint:
    path: /deploy/backup/backup.yaml
    method: POST
    data_selector: spec
    params: {}
- name: pmm_client
  endpoint:
    path: /graph/api/auth/keys
    method: POST
    data_selector: key
    params: {}
- name: supported_platforms
  endpoint:
    path: /supported/platforms
    method: GET
    data_selector: platforms
- name: resource_limits
  endpoint:
    path: /resource/limits
    method: GET
    data_selector: limits
- name: installation_guidelines
  endpoint:
    path: /installation/guidelines
    method: GET
    data_selector: guidelines
- name: cluster_deployment
  endpoint:
    path: /cr-minimal.yaml
    method: POST
    data_selector: metadata
    params: {}
- name: percona-xtradb-cluster
  endpoint:
    path: cr.yaml
    method: POST
    data_selector: cluster
    params: {}
- name: percona_xtradb_cluster
  endpoint:
    path: /deploy/cr.yaml
    method: POST
- name: cluster
  endpoint:
    path: /cr.yaml
    method: GET
    data_selector: perconaxtradbcluster.pxc.percona.com
- name: secrets
  endpoint:
    path: /secrets
    method: GET
    data_selector: cluster1-secrets
- name: PerconaXtraDBCluster
  endpoint:
    path: /deploy/cr.yaml
    method: POST
    data_selector: cluster
    params: {}
- name: pxc
  endpoint:
    path: /deploy/cr.yaml
    method: POST
    data_selector: status
    params: {}
- name: secrets
  endpoint:
    path: /deploy/secrets.yaml
    method: POST
    data_selector: data
    params: {}
- name: customresourcedefinitions
  endpoint:
    path: /apis/apiextensions.k8s.io/v1/customresourcedefinitions/perconaxtradbclusters.pxc.percona.com/status
    method: PATCH
    data_selector: status
    params:
      storedVersions:
      - v1
- name: operator_deployment
  endpoint:
    path: /kubectl/patch/deployment/percona-xtradb-cluster-operator
    method: PATCH
    data_selector: spec
    params:
      image: percona/percona-xtradb-cluster-operator:1.18.0
- name: pxc_patch
  endpoint:
    path: /kubectl/patch/pxc/cluster1
    method: PATCH
    data_selector: spec
    params:
      crVersion: 1.18.0
      pxc:
        image: percona/percona-xtradb-cluster:8.0.42-33.1
      proxysql:
        image: percona/proxysql2:2.7.3
      haproxy:
        image: percona/haproxy:2.8.15
      backup:
        image: percona/percona-xtrabackup:8.0.35-34.1
      logcollector:
        image: percona/fluentbit:4.0.1
      pmm:
        image: percona/pmm-client:2.44.1-1
- name: pxc_cluster
  endpoint:
    path: /pxc/cluster1
    method: PATCH
    data_selector: spec
    params: {}
- name: upgrade_options
  endpoint:
    path: /upgrade-options
    method: GET
    data_selector: options
- name: pxc
  endpoint:
    path: /kubectl/patch/pxc
    method: PATCH
    data_selector: spec
    params:
      crVersion: 1.18.0
      pxc:
        image: percona/percona-xtradb-cluster:8.0.42-33.1
      proxysql:
        image: percona/proxysql2:2.7.3
      haproxy:
        image: percona/haproxy:2.8.15
      backup:
        image: percona/percona-xtrabackup:8.0.35-34.1
      logcollector:
        image: percona/fluentbit:4.0.1
      pmm:
        image: percona/pmm-client:2.44.1-1
- name: pxc-5.7
  endpoint:
    path: /kubectl/patch/pxc
    method: PATCH
    data_selector: spec
    params:
      crVersion: 1.18.0
      pxc:
        image: percona/percona-xtradb-cluster:5.7.44-31.65
      proxysql:
        image: percona/proxysql2:2.7.3
      haproxy:
        image: percona/haproxy:2.8.15
      backup:
        image: percona/percona-xtrabackup:2.4.29
      logcollector:
        image: percona/fluentbit:4.0.1
      pmm:
        image: percona/pmm-client:2.44.1-1
- name: initContainer
  endpoint:
    path: /kubectl/get/deploy/percona-xtradb-cluster-operator
    method: GET
    data_selector: initContainer.image
    params: {}
- name: pxc
  endpoint:
    path: /pxc
    method: PATCH
    data_selector: spec
    params:
      crVersion: 1.18.0
      initContainer:
        image: docker.io/percona/percona-xtradb-cluster-operator:1.18.0
      pxc:
        image: docker.io/percona/percona-xtradb-cluster:8.0.42-33.1
      proxysql:
        image: docker.io/percona/proxysql2:2.7.3
      haproxy:
        image: docker.io/percona/haproxy:2.8.15
      backup:
        image: docker.io/percona/percona-xtrabackup:8.0.35-34.1
      logcollector:
        image: docker.io/percona/fluentbit:4.0.1
      pmm:
        image: docker.io/percona/pmm-client:2.44.1-1
- name: users
  endpoint:
    path: /deploy/cr.yaml
    method: POST
    data_selector: users
    params: {}
- name: haproxy
  endpoint:
    path: /haproxy
    method: GET
    data_selector: service
    params: {}
- name: proxysql
  endpoint:
    path: /proxysql
    method: GET
    data_selector: service
    params: {}
- name: pxc
  endpoint:
    path: /pxc
    method: GET
    data_selector: service
    params: {}
- name: my.cnf
  endpoint:
    path: /deploy/cr.yaml
    method: POST
    data_selector: configuration
    params: {}
- name: labels
  endpoint:
    path: /labels
    method: GET
    data_selector: records
- name: annotations
  endpoint:
    path: /annotations
    method: GET
    data_selector: records
- name: emptyDir
  endpoint:
    path: /deploy/cr.yaml
    method: GET
    data_selector: volumeSpec.emptyDir
- name: hostPath
  endpoint:
    path: /deploy/cr.yaml
    method: GET
    data_selector: volumeSpec.hostPath
    params:
      path: /data
      type: Directory
- name: OpenEBS Local Persistent Volume Hostpath
  endpoint:
    path: /local-hostpath.yaml
    method: POST
    data_selector: StorageClass
    params:
      metadata.name: localpv
      cas.openebs.io/config:
        StorageType: hostpath
        BasePath: /var/local-hostpath
      provisioner: openebs.io/local
      reclaimPolicy: Delete
      volumeBindingMode: WaitForFirstConsumer
- name: HAProxy
  endpoint:
    path: /haproxy
    method: POST
    data_selector: data
    params:
      envVarsSecret: my-env-var-secrets
- name: Alternative Memory Allocator
  endpoint:
    path: /memory_allocator
    method: POST
    data_selector: data
    params:
      envVarsSecret: my-new-env-var-secrets
- name: cluster1-haproxy
  endpoint:
    path: /haproxy
    method: GET
    data_selector: ''
    params: {}
- name: cluster1-haproxy-replicas
  endpoint:
    path: /haproxy-replicas
    method: GET
    data_selector: ''
    params: {}
- name: cluster1-proxysql
  endpoint:
    path: /services/proxysql
    method: GET
    data_selector: services
    params: {}
- name: backup
  endpoint:
    path: /pxc-backup
    method: GET
    data_selector: items
    params:
      namespace: <namespace>
- name: pxc_cluster
  endpoint:
    path: /api/v1/pxc
    method: GET
    data_selector: items
    params: {}
- name: replication_channel_primary
  endpoint:
    path: /pxc/replicationChannels
    method: PATCH
    data_selector: spec.pxc.replicationChannels
    params:
      name: pxc1_to_pxc2
      isSource: true
- name: replication_channel_replica
  endpoint:
    path: /pxc/replicationChannels
    method: PATCH
    data_selector: spec.pxc.replicationChannels
    params:
      name: pxc1_to_pxc2
      isSource: false
      sourcesList:
      - host: 34.118.227.242
        port: 3306
        weight: 100
      - host: 34.118.227.242
        port: 3306
        weight: 100
      - host: 34.118.227.242
        port: 3306
        weight: 100
- name: cluster1
  endpoint:
    path: /pxc/percona-xtradb-cluster-operator/v1.18.0/deploy/cr.yaml
    method: POST
    data_selector: status
    params: {}
- name: backup
  endpoint:
    path: /pxc-backup
    method: GET
    data_selector: backup
    params: {}
- name: restore
  endpoint:
    path: /pxc/percona-xtradb-cluster-restore
    method: POST
    data_selector: restore
    params: {}
- name: vault_configuration
  endpoint:
    path: /tmp/vault-init
    method: POST
    data_selector: root_token
- name: Backup
  endpoint:
    path: /backups
    method: POST
    data_selector: backup
    params: {}
- name: Backup Status
  endpoint:
    path: /backups/status
    method: GET
    data_selector: status
    params: {}
- name: backups
  endpoint:
    path: /backups-storage
    method: GET
- name: binary_logs
  endpoint:
    path: /backups/pitr
    method: POST
    data_selector: backup.pitr
    params:
      backup.pitr.enabled: 'true'
      backup.pitr.storageName: s3-us-west
      timeBetweenUploads: 60
- name: backup
  endpoint:
    path: /deploy/cr.yaml
    method: GET
    data_selector: backup
    params: {}
- name: backup
  endpoint:
    path: /deploy/backup/backup.yaml
    method: POST
    data_selector: metadata
    params: {}
- name: compression_configuration
  endpoint:
    path: /deploy/cr.yaml
    method: POST
    data_selector: pxc.configuration
- name: restore
  endpoint:
    path: /deploy/backup/restore.yaml
    method: POST
    data_selector: spec
    params: {}
- name: restore
  endpoint:
    path: /deploy/backup/restore.yaml
    method: POST
    data_selector: spec
    params: {}
- name: pxc
  endpoint:
    path: /operator.html
    method: GET
    data_selector: spec.pxc.resources
    params: {}
- name: pmm_client
  endpoint:
    path: /graph/api/auth/keys
    method: POST
    data_selector: key
    params: {}
- name: sidecar_container
  endpoint:
    path: /deploy/cr.yaml
    method: POST
    data_selector: sidecars
    params: {}
- name: Crash Recovery
  endpoint:
    path: /recovery
    method: GET
    data_selector: recovery_details
- name: cluster_clone
  endpoint:
    path: /deploy/cr.yaml
    method: POST
    data_selector: pxc.volumeSpec.persistentVolumeClaim.dataSource
- name: PerconaXtraDBCluster
  endpoint:
    path: /pxc
    method: GET
    data_selector: clusters
- name: PerconaXtraDBClusterBackup
  endpoint:
    path: /pxc-backup
    method: GET
    data_selector: backups
- name: PerconaXtraDBClusterRestore
  endpoint:
    path: /pxc-restore
    method: GET
    data_selector: restores
- name: logs
  endpoint:
    path: /kubectl/logs
    method: GET
    data_selector: logs
    params: {}
- name: Persistent Volume Claims
  endpoint:
    path: /pvc
    method: GET
    data_selector: items
    params: {}
- name: Persistent Volumes
  endpoint:
    path: /pv
    method: GET
    data_selector: items
    params: {}
- name: pxc
  endpoint:
    path: /pxc
    method: POST
    data_selector: pxc
    params:
      volumeSpec.resources.requests.storage: 20Gi
      backup.enabled: 'false'
- name: percona-db-1
  endpoint:
    path: /deploy/cr.yaml
    method: apply
    data_selector: status
    params: {}
- name: pxc-operator
  endpoint:
    path: /deploy/cw-bundle.yaml
    method: apply
    data_selector: status
    params: {}
- name: restore
  endpoint:
    path: /deploy/backup/restore.yaml
    method: POST
    data_selector: metadata
    params: {}
- name: asynchronous_replication
  endpoint:
    path: /deploy/cr.yaml
    method: POST
    data_selector: spec.pxc.replicationChannels
    params: {}
- name: PerconaXtraDBCluster
  endpoint:
    path: /perconaxtradbcluster
    method: GET
    data_selector: records
- name: haproxy.enabled
- name: haproxy.size
- name: haproxy.image
- name: haproxy.imagePullPolicy
- name: haproxy.imagePullSecrets.name
- name: haproxy.readinessDelaySec
- name: haproxy.livenessDelaySec
- name: haproxy.configuration
- name: haproxy.annotations
- name: haproxy.labels
- name: haproxy.readinessProbes.initialDelaySeconds
- name: haproxy.readinessProbes.timeoutSeconds
- name: haproxy.readinessProbes.periodSeconds
- name: haproxy.readinessProbes.successThreshold
- name: haproxy.readinessProbes.failureThreshold
- name: haproxy.serviceType
- name: haproxy.externalTrafficPolicy
- name: haproxy.livenessProbes.initialDelaySeconds
- name: haproxy.livenessProbes.timeoutSeconds
- name: haproxy.livenessProbes.periodSeconds
- name: haproxy.livenessProbes.successThreshold
- name: haproxy.resources.requests.memory
- name: haproxy.resources.requests.cpu
- name: haproxy.resources.limits.memory
- name: haproxy.resources.limits.cpu
- name: haproxy.envVarsSecret
- name: haproxy.priorityClassName
- name: haproxy.schedulerName
- name: haproxy.nodeSelector
- name: haproxy.topologySpreadConstraints.labelSelector.matchLabels
- name: haproxy.topologySpreadConstraints.maxSkew
- name: haproxy.topologySpreadConstraints.topologyKey
- name: haproxy.topologySpreadConstraints.whenUnsatisfiable
- name: haproxy.affinity.topologyKey
- name: haproxy.affinity.advanced
- name: haproxy.tolerations
- name: haproxy.podDisruptionBudget.maxUnavailable
- name: haproxy.podDisruptionBudget.minAvailable
- name: haproxy.gracePeriod
- name: haproxy.exposePrimary.enabled
- name: haproxy.exposePrimary.type
- name: haproxy.exposePrimary.loadBalancerClass
- name: haproxy.exposePrimary.externalTrafficPolicy
- name: haproxy.exposePrimary.internalTrafficPolicy
- name: haproxy.exposePrimary.loadBalancerSourceRanges
- name: haproxy.exposePrimary.loadBalancerIP
- name: haproxy.serviceLabels
- name: haproxy.exposePrimary.labels
- name: haproxy.serviceAnnotations
- name: haproxy.exposePrimary.annotations
- name: haproxy.replicasServiceEnabled
- name: haproxy.exposeReplicas.enabled
- name: haproxy.exposeReplicas.onlyReaders
- name: haproxy.exposeReplicas.loadBalancerSourceRanges
- name: haproxy.exposeReplicas.loadBalancerIP
- name: haproxy.exposeReplicas.type
- name: haproxy.exposeReplicas.loadBalancerClass
- name: haproxy.replicasExternalTrafficPolicy
- name: haproxy.exposeReplicas.externalTrafficPolicy
- name: haproxy.exposeReplicas.internalTrafficPolicy
- name: haproxy.exposeReplicas.labels
- name: haproxy.exposeReplicas.annotations
- name: haproxy.containerSecurityContext
- name: haproxy.podSecurityContext
- name: haproxy.serviceAccountName
- name: haproxy.runtimeClassName
- name: haproxy.sidecars.image
- name: haproxy.sidecars.command
- name: haproxy.sidecars.args
- name: haproxy.sidecars.name
- name: haproxy.sidecars.resources.requests.memory
- name: haproxy.sidecars.resources.requests.cpu
- name: haproxy.sidecars.resources.limits.memory
- name: haproxy.sidecars.resources.limits.cpu
- name: haproxy.lifecycle.preStop.exec.command
- name: haproxy.lifecycle.postStart.exec.command
- name: PerconaXtraDBCluster
  endpoint:
    path: /deploy/cr.yaml
    method: GET
- name: PerconaXtraDBClusterBackup
  endpoint:
    path: /deploy/cr.yaml
    method: GET
- name: PerconaXtraDBClusterRestore
  endpoint:
    path: /deploy/cr.yaml
    method: GET
- name: backup
  endpoint:
    path: /deploy/backup/backup.yaml
    method: GET
- name: pitr
  endpoint:
    path: /pitr
    method: POST
    data_selector: data
    params:
      type: string
      date: string
      gtid: string
      spec.backupSource: subdoc
      s3: subdoc
      azure: subdoc
- name: percona-xtradb-cluster-operator
  endpoint:
    path: /percona-xtradb-cluster-operator
    method: GET
- name: haproxy
  endpoint:
    path: /haproxy
    method: GET
- name: proxysql2
  endpoint:
    path: /proxysql2
    method: GET
- name: percona-xtrabackup
  endpoint:
    path: /percona-xtrabackup
    method: GET
- name: pmm-client
  endpoint:
    path: /pmm-client
    method: GET
- name: percona-xtradb-cluster
  endpoint:
    path: /percona-xtradb-cluster
    method: GET
- name: MySQL
  endpoint:
    path: /versions/compatibility
    method: GET
    data_selector: versions
    params: {}
- name: Percona XtraBackup
  endpoint:
    path: /versions/compatibility
    method: GET
    data_selector: versions
    params: {}
- name: HA Proxy
  endpoint:
    path: /versions/compatibility
    method: GET
    data_selector: versions
    params: {}
- name: ProxySQL
  endpoint:
    path: /versions/compatibility
    method: GET
    data_selector: versions
    params: {}
- name: Percona XtraDB Cluster
  endpoint:
    path: /create-new-percona-xtradb-cluster
    method: POST
- name: List Percona XtraDB Clusters
  endpoint:
    path: /list-percona-xtradb-clusters
    method: GET
- name: Get status of Percona XtraDB Cluster
  endpoint:
    path: /get-status-of-percona-xtradb-cluster
    method: GET
- name: Scale up/down Percona XtraDB Cluster
  endpoint:
    path: /scale-updown-percona-xtradb-cluster
    method: POST
- name: Update Percona XtraDB Cluster image
  endpoint:
    path: /update-percona-xtradb-cluster-image
    method: PUT
- name: Backup Percona XtraDB Cluster
  endpoint:
    path: /backup-percona-xtradb-cluster
    method: POST
- name: Restore Percona XtraDB Cluster
  endpoint:
    path: /restore-percona-xtradb-cluster
    method: POST
- name: perconaxtradbclusters
  endpoint:
    path: /apis/pxc.percona.com/v{{ apiversion }}/namespaces/default/perconaxtradbclusters
    method: POST
    data_selector: response
    params: {}
- name: percona_xtradb_clusters
  endpoint:
    path: /apis/pxc.percona.com/v1/namespaces/default/perconaxtradbclusters
    method: GET
    data_selector: rows
- name: percona_xtradb_cluster
  endpoint:
    path: /apis/pxc.percona.com/v1/namespaces/default/perconaxtradbclusters/cluster1
    method: GET
    data_selector: metadata
    params: {}
- name: percona_xtradb_cluster
  endpoint:
    path: /apis/pxc.percona.com/v1/namespaces/default/perconaxtradbclusters/cluster1
    method: PATCH
    data_selector: spec
    params: {}
- name: configmap
  endpoint:
    path: /api/v1/namespaces/default/configmaps
    method: POST
    data_selector: data
    params: {}
- name: perconaxtradbclusterbackups
  endpoint:
    path: /perconaxtradbclusterbackups
    method: POST
    data_selector: metadata
    params: {}
- name: perconaxtradbclusterrestores
  endpoint:
    path: /perconaxtradbclusterrestores
    method: POST
    data_selector: metadata
    params: {}
- name: MySQL 8.0
  endpoint:
    path: /percona-xtradb-cluster/8.0
    method: GET
    data_selector: records
    params: {}
- name: MySQL 5.7
  endpoint:
    path: /percona-xtradb-cluster/5.7
    method: GET
    data_selector: records
    params: {}
notes:
- Create the namespace name you will use, if not exist.
- Requires a valid Kubernetes token for authentication
- Authorization requires a Bearer token
- Request body is not required for this API.
- Authentication requires a Bearer token.
- Our documentation guides are packed with information, but they can’t cover everything
  you need to know about Percona software.
- Don’t be afraid to try things out and ask questions when you get stuck.
- Uses OAuth2 with refresh token — requires setup of connected app in api
- 'Open-source license: Apache 2.0'
- 'PostgreSQL versions: 12 - 16'
- 'Kubernetes conformance: Various versions are tested'
- 'Web-based GUI: Percona Everest'
- The Operator automates deployment and management of PostgreSQL clusters on Kubernetes.
- Custom Resource Definitions extend the Kubernetes API for PostgreSQL cluster management.
- Our documentation guides are packed with information, but they can’t cover everything
  you need to know about Percona Operator for PostgreSQL.
- Percona experts bring years of experience in tackling tough database performance
  issues and design challenges.
- The Operator extends the Kubernetes API with custom resources.
- You can deploy it locally on Minikube for testing purposes or using any cloud provider
  of your choice.
- It is a good practice to isolate workloads in Kubernetes via namespaces.
- The pgBouncer URI is stored in the Secret object, which the Operator generates during
  installation.
- The Secrets object is named as <cluster_name>-pguser-<cluster_name>.
- Uses AWS S3 as backup storage
- The Operator uses the pgBackRest tool to make backups
- Specify the right branch with -b option while cloning the code
- PMM 3 uses Grafana service accounts to control access to PMM server components and
  resources.
- If you specified both authentication methods for PMM server configuration and they
  have non-empty values, priority goes to PMM 3.
- Deepen your monitoring insights by setting up Kubernetes monitoring with PMM
- Control Pods assignment on specific Kubernetes Nodes by setting up affinity / anti-affinity
- Ready to adopt the Operator for production use and need to delete the testing deployment?
- You can also try operating the Operator and database clusters via the web interface
  with Percona Everest
- The Operator is validated for deployment on Kubernetes, GKE and EKS clusters.
- The Operator is cloud native and storage agnostic, working with a wide variety of
  storage classes, hostPath, and NFS.
- This deploys the default Percona Distribution for PostgreSQL configuration.
- You must edit the command to replace the <project ID> placeholder with your project
  ID.
- You may also be required to edit the zone location.
- Uses Kubernetes for deployment
- Namespace for the operator should be created
- Percona Operator for PostgreSQL is a Red Hat Certified Operator.
- 'Installation includes two steps: Installing the Operator and Installing Percona
  Distribution for PostgreSQL using the Operator.'
- It is crucial to specify the right branch with `-b` option while cloning the code
- Setting RBAC requires your user to have cluster-admin role privileges
- The Operator will not create users or databases automatically if spec.users is set
  during cluster creation.
- Users with non-superuser privileges do not have access to the public schema by default.
- The Operator provides entry points for accessing the database by client applications.
- The Operator passes options to Patroni without validation, so there is a theoretical
  possibility of the cluster malfunction caused by wrongly configured PostgreSQL instances.
- Pod anti-affinity is controlled by the affinity.podAntiAffinity subsection.
- Topology Spread Constraints allow you to control how Pods are distributed across
  the cluster.
- Labels are used by Kubernetes to identify and select objects.
- Annotations are used to store descriptive information.
- Starting from the Operator 2.6.0, Percona distribution for PostgreSQL comes with
  Patroni 4.x, which introduces breaking changes compared to previously used 3.x versions.
- The Operator can generate long-term certificates automatically at cluster creation
  time.
- You can customize TLS for the Operator by providing your own TLS certificates.
- Both secrets share the same ca.crt certificate but have different tls.crt certificates.
- The tls.crt in the Secret for external communications should have a Common Name
  (CN) setting that matches the primary Service name.
- The tls.crt in the Secret for internal communications should have a Common Name
  (CN) setting that matches the preset replication user.
- Telemetry is enabled by default and is sent to the Version Service server when the
  Operator connects to it at scheduled times to obtain fresh information about version
  numbers and valid image paths needed for the upgrade.
- You can disable telemetry with a special option when installing the Operator.
- Starting from the version 2.2.0, you can upgrade Percona Operator for PostgreSQL
  to newer 2.x versions.
- Upgrades from the Operator version 1.x to 2.x are completely different from the
  upgrades within 2.x versions due to substantial changes in the architecture.
- Starting from the Operator 2.4.0 you can do a minor upgrade.
- Starting with the Operator 2.6.0, PostgreSQL images are based on Red Hat Universal
  Base Image (UBI) 9 instead of UBI 8.
- Major version upgrades feature is currently a tech preview, and it is not recommended
  for production environments.
- This migration method introduces a downtime.
- You can only reverse such migration by restoring the old cluster from the backup.
- To make sure that all transactions are captured in the backup, you need to stop
  the old cluster. This brings downtime to the application.
- Before deleting the cluster, make sure that the spec.keepBackups Custom Resource
  option is set to `true`.
- This method allows you to migrate from version 1.x to version 2.x by creating a
  new version 2.x PostgreSQL cluster in a standby mode.
- 'You can make backups in two ways: On-demand and Schedule backups.'
- Backups schedule is defined on the per-repository basis in the backups.pgbackrest.repos
  subsection of the deploy/cr.yaml file.
- You can supply each repository with a schedules.<backup type> key equal to an actual
  schedule that you specify in crontab format.
- To make an on-demand backup manually, you need a backup configuration file.
- Making a backup takes time. Use the kubectl get pg-backup command to track the backup
  progress.
- There may be cases where it is needed to control what files are restored from the
  backup and apply fine-grained filtering to them.
- Backup encryption is a security best practice that helps protect your organization’s
  confidential information and prevents unauthorized access.
- You cannot change encryption settings after the backups are established. You must
  create a new repository to enable encryption or change the encryption key.
- No modifications are needed aside of setting these additional parameters.
- Manual deleting of a previously saved backup requires not more than the backup name.
- This percona.com/delete-backups finalizer is in tech preview state, and it is not
  yet recommended for production environments.
- Disabling backups should be a conscious decision based on your data’s value and
  recoverability.
- After disabling backups, the Operator deletes the repo-host PVC.
- Disaster recovery is not optional for businesses operating in the digital age.
- Operators automate routine tasks and remove toil.
- Backups should appear in the object storage. By default pgBackrest puts them into
  the pgbackrest folder.
- The Main cluster needs to expose it, so that standby can connect to the primary
  PostgreSQL instance.
- Certificates for both Main and Standby clusters must be signed by the same CA.
- standby.enabled controls if it is a standby cluster or not.
- In case of the Main site failure or in other cases, you can promote the standby
  cluster.
- Automated failover consists of multiple steps and is outside of the Operator’s scope.
- High-availability implementation is based on the Patroni template, which uses PostgreSQL
  streaming replication.
- Synchronous replication can be used to minimize data loss in case of primary server
  crash.
- Custom sidecar containers can easily access other components of your cluster. Therefore
  use them with caution, only when you are sure what you are doing.
- If you’re pausing the cluster when there is a running backup, the Operator won’t
  pause it for you. It will print a warning about running backups. In this case delete
  a running backup job and retry.
- For PMM 2, the Operator uses API keys for authentication.
- For PMM 3, it uses service account tokens.
- You can customize the configuration of Percona Distribution for PostgreSQL and install
  it with customized parameters.
- 'You can use following psql meta-command to make sure that any SQL errors would
  make psql to return the error code: \set ON_ERROR_STOP'
- \echo Any error will lead to exit code 3
- Primary instance is re-elected during the automatic failover
- Use kubectl annotate to trigger the switchover with a timestamp
- If the registry requires authentication, you can specify the imagePullSecrets option
  for all images.
- Custom extensions are downloaded by the Operator from the cloud storage.
- For now, Amazon S3 is the only supported storage type.
- This is the default configuration of our Operator.
- Cluster names may be the same in different namespaces.
- Tablespaces allow DBAs to store a database on multiple file systems within the same
  server.
- Deleting an existing tablespace involves making it empty before dropping it.
- The API key is not rotated.
- It is crucial to specify the right branch with `-b` option while cloning the code.
- Setting RBAC requires your user to have cluster-admin role privileges.
- TLS-related objects and data volumes remain by default after cluster deletion.
- Finalizers can be used to automate resource cleanup.
- Use the operator version and pg-version in the URL to retrieve images.
- Custom Resources manage options for the various components of the cluster.
- Check for the Custom Resource status using 'kubectl get pg'.
- PVC is namespace-scoped, but PV and Storage Class are cluster-scoped.
- Container must be in 'Running' state to access it.
- You may encounter errors if commands are not present in the container.
- Logs provide valuable information. It makes sense to check the logs of the database
  Pods and the Operator Pod.
- Putting a cluster in an unmanaged mode doesn’t disable any of the health check probes
  already configured for containers.
- The Operator does not validate your configuration changes.
- If you update any object controlled by the Operator, it’ll reconcile the cluster
  and your configuration changes will be reverted.
- The order of parameters matters in pg_hba.conf, so consider overriding the list
  completely.
- The Operator doesn’t run patronictl reload in old replicas even if Patroni instance
  configurations are updated.
- For configuration changes to take effect, you need to restart the Pods or manually
  run patronictl reload on all old replicas.
- delete-backups finalizer is in tech preview state, and it is not yet recommended
  for production environments.
- The pgBackRest repository name is 'repo1'.
- Scheduled time for full backup is '0 0 * * 6'.
- Scheduled time for differential backup is '0 0 * * 6'.
- Specifies the API version of the Custom Resource.
- 'Defines the type of resource being created: PerconaPGBackup.'
- A Restore resource is a Kubernetes object that tells the Operator how to restore
  your database from a specific backup.
- Versions of the cluster components and platforms tested with different Operator
  releases are shown below.
- Documentation licensing is under the Creative Commons Attribution 4.0 International
  License.
- Percona owns a number of marks, including but not limited to Percona, XtraDB, Percona
  XtraDB, XtraBackup, Percona XtraBackup, Percona Server, and Percona Live.
- Use of any Percona trademark in the name, URL, or other identifying characteristic
  of any product, service, website, or other use is not permitted without Percona’s
  written permission.
- Our documentation guides are packed with information, but they can’t cover everything
  you need to know about Percona Operator for MongoDB.
- Be a part of a space where you can tap into a wealth of knowledge from other database
  enthusiasts and experts.
- The initial configuration contains default passwords for all needed user accounts,
  which should be changed in the production environment.
- Percona Operator relies on Percona Server for MongoDB - a free, enhanced, fully
  compatible MongoDB software alternative for MongoDB Community Server with enterprise-grade
  features.
- 'Last update: 2025-10-20'
- The default Percona Server for MongoDB configuration includes three mongod, three
  mongos, and three config server instances with enabled sharding.
- The default admin user is databaseAdmin.
- MongoDB creates the collection when inserting documents.
- Uses AWS S3 as the backup storage
- You can use any S3-compatible storage like MinIO
- For PMM 2, use API keys for authentication.
- For PMM 3, use service account tokens for authentication.
- Congratulations! You have completed all the steps in the Get started guide.
- You can also try operating the Operator and database clusters via the web interface
  with Percona Everest.
- The Operator was developed and tested with Percona Server for MongoDB 6.0.25-20,
  7.0.24-13, and 8.0.12-4.
- Consider using 4 CPU and 6 GB of RAM if sharding is turned on.
- Deploys a one-shard MongoDB cluster with one replica set with one node, one mongos
  node and one config server node.
- The deploy/cr-minimal.yaml is for minimal non-production deployment.
- Percona Everest is an open source cloud-native database platform that helps developers
  deploy code faster, scale deployments rapidly, and reduce database administration
  overhead while regaining control over their data, database configuration, and DBaaS
  costs.
- Deploys default MongoDB cluster configuration, three mongod, three mongos, and three
  config server instances.
- Currently monitoring with PMM is not supported on ARM64 configurations.
- spot instances are not recommended for production environment, but may be useful
  e.g. for testing purposes.
- Please note, that currently monitoring with PMM is not supported on ARM64 configurations.
- Monitoring with PMM is not supported on ARM64 configurations.
- Admin user credentials are stored in Kubernetes Secrets.
- Base64-encoded user and password must be decoded for usage.
- Operator Lifecycle Manager (OLM) is a part of the Operator Framework that allows
  you to install, update, and manage the Operators lifecycle on the OpenShift platform.
- Credentials are stored in Kubernetes Secrets object.
- The admin user credentials are base64-encoded.
- Upgrading the Operator may cause performance degradation.
- Find the image names in the list of certified images.
- 'The way to instruct the Operator how it should run the database upgrades is to
  set the `upgradeOptions.apply` Custom Resource option to one of the following: `Never`,
  `Disabled`, `Recommended`, `Latest`, or specify a specific database version.'
- Starting with version 1.21.0, the Operator supports cluster-level logging.
- MongoDB 5.0 support has reached its end-of-life in the Operator version 1.19.0.
- MongoDB 4.4 support has reached its end-of-life in the Operator version 1.16.0.
- The update process is successfully finished when all Pods have been restarted.
- If you turned on Percona Server for MongoDB Sharding, the mongos and Config Server
  nodes must be restarted too to complete the upgrade.
- Major version upgrade is moving from the current major version to the next one.
- It is recommended to test the major version upgrade on a staging environment first.
- Before the upgrade, make a backup of your data.
- Make sure that spec.updateStrategy option in the Custom Resource is set to SmartUpdate
- The deployment rollout will be automatically triggered by the applied patch.
- Starting from Operator version 1.17.0, you can create users in Percona Server for
  MongoDB via the `users` subsection in the Custom Resource.
- Don’t use system users to run applications.
- The Operator doesn’t create application-level (unprivileged) user accounts by default.
- Starting from Operator version 1.17.0, you can create users in Percona Server for
  MongoDB via the users subsection in the Custom Resource.
- 'Default Secret name: my-cluster-name-secrets'
- 'Secret name field: spec.secrets.users'
- You can’t change options that may break the behavior of the Operator. For example,
  TLS/SSL options. If you try changing such options, your changes will be ignored.
- Adjust the node priority for backups to use a specific node.
- Configure the parallel download from the storage for a physical restore.
- Creating the Pod Disruption Budget is the Kubernetes method to limit the number
  of Pods of an application that can go down simultaneously due to voluntary disruptions.
- Distribution Budgets allow large applications to retain their high availability
  during maintenance and other administrative activities.
- Annotations store descriptive information and do not affect how Kubernetes processes
  resources.
- The Operator keeps track of all changes to its objects and can remove annotations
  that it didn’t create.
- If the Service per Pod mode is not used, the Operator won’t remove any annotations
  and labels from any Services related to this expose subsection.
- A ClusterIP Service endpoint is only reachable inside Kubernetes.
- If connecting to a cluster from outside Kubernetes, you cannot reach the Pods using
  the Kubernetes internal DNS names.
- Before v1.14, the Operator used the exposed IP addresses in the replica set configuration
  in the case of the exposed replica set.
- You should be careful with the clusterServiceDNSMode=External variant. Using IP
  addresses instead of DNS hostnames is discouraged in MongoDB.
- The emptyDir options can be used to turn the emptyDir volume on by setting the directory
  name.
- The hostPath volume mounts an existing file or directory from the host node’s filesystem
  into the Pod.
- By default, the Operator creates Percona Server for MongoDB replica set with three
  members, one primary and the remaining secondaries.
- A replica set can have up to 50 members with the maximum of 7 voting members.
- If the total number of voting members is even, the Operator converts one node to
  non-voting to maintain an odd number of voters.
- If the number of voting members is odd and not more than 7, all nodes participate
  in elections.
- If the number of voting members exceeds 7, the Operator automatically converts some
  nodes to non-voting to stay within MongoDB’s limit of 7 voting members.
- Sharding is controlled by the `sharding` section of the `deploy/cr.yaml` configuration
  file and is turned on by default.
- The cluster accepts both TLS and non-TLS incoming connections, but does not use
  TLS for internal communication.
- The cluster uses TLS for internal communication and accepts both TLS and non-TLS
  external connections.
- The cluster enforces TLS encryption for all connections and accepts only TLS connections.
- The cluster completely disables TLS for all connections.
- Self-signed issuer allows you to deploy and use the Percona Operator without creating
  a cluster issuer separately.
- If you only create the external certificate, the Operator will use it for both external
  and internal communications instead of generating a separate internal certificate.
- The commands above use rs0 as the replica set name (the default). If you set a different
  name in the replsets.name Custom Resource option, update the commands accordingly.
- Certificates generated by the Operator are long-term.
- Certificates issued by the cert-manager are short-term and valid for 3 months.
- 'Deletion command should look as follows: $ kubectl -n <namespace_name> delete psmdb
  cluster1'
- Deletion takes time. Check that all Pods disappear with $ kubectl -n <namespace_name>
  get pods command.
- You can run Percona Server for MongoDB without TLS for testing or demonstration
  purposes.
- Data at rest encryption is turned on by default.
- Use of root token is not recommended.
- By default, the Operator has one reconciliation worker.
- The general recommendation is to set the number of concurrent workers equal to the
  number of Percona Server for MongoDB clusters.
- The Operator uses Percona Backup for MongoDB (PBM) tool for backups and restores.
- Remote storage for backups has the technical preview status.
- Make sure that your storage has enough resources to store backups.
- Do not provide s3.credentialsSecret for the storage in deploy/cr.yaml
- If IRSA-related credentials are defined, they have the priority over any IAM instance
  profile.
- You must specify the main storage during the upgrade.
- To create a Backup resource, you need to modify the Custom Resource manifest and
  specify the backup configuration.
- To restore from a backup to a new Kubernetes-based environment, you must create
  a Secrets object there with the same user passwords as in the original cluster.
- Find the Secrets name object on the source cluster in the spec.secrets key in the
  deploy/cr.yaml. Use this name to recreate the Secrets on the target cluster.
- Encrypting database backups is done separately for physical and logical backups.
- Physical backups are encrypted if data-at-rest encryption is turned on.
- To restore your Percona Server for MongoDB cluster from a backup, define a PerconaServerMongoDBRestore
  custom resource.
- Selective logical backups are not yet supported.
- Selective restores have a number of limitations.
- This document focuses on the restore on a new cluster deployed in a different Kubernetes
  environment.
- Make sure that the cluster is running.
- Set spec.clusterName key to the name of the target cluster to restore the backup
  on
- Put additional restoration parameters to the pitr section
- 'Type key can be equal to one of the following options: date, latest'
- Date key is used with type=date option
- Configure the spec.backupSource subsection to point to the cloud storage where the
  backup is stored
- Deleting a backup used as a base for point-in-time recovery (PITR) is possible only
  starting from the Operator version 1.15.0. Also, deleting such a backup will delete
  the stored operations log updates based on this backup.
- The Operator deploys and manages multiple components, such as MongoDB replica set
  instances.
- You can manage CPU or memory for every component separately by editing corresponding
  sections in the Custom Resource.
- The storage size change takes some time. When it starts, the Operator automatically
  adds the pvc-resize-in-progress annotation to the PerconaServerMongoDB Custom Resource.
- The Operator will not allow you to remove existing shards unless they don’t have
  any user-created collections.
- Multi-cluster deployments span multiple Kubernetes clusters, typically within the
  same cloud provider or region.
- Multi-region deployments extend MongoDB across geographically distributed data centers
  or cloud regions.
- User credentials must be the same in both clusters.
- TLS certificates must be the same in both clusters.
- Multi-cluster Services allows service discovery and communication across clusters
  via a virtual IP address.
- GKE requires all participating Pods to be in the same project.
- Uses Workload Identity Federation for authentication.
- Ensure two EKS clusters can communicate over VPC peering
- Service account must have IAM policy for AWS Cloud Map
- If you are enabling MCS for a running cluster after upgrading from the Operator
  version 1.11.0 or below, you need rotating multi-domain (SAN) certificates.
- Multi-cluster services are enabled.
- The Main and Replica sites must have the same users credentials and TLS certificates
  to be able to communicate with each other.
- Setting unmanaged to true will prevent the Operator from controlling the Replica
  Set configuration.
- Replica will not start if the TLS secrets and the encryption key are not copied.
- Failing over services to the Replica site ensures your applications remain available
  if the Main site needs maintenance or becomes unavailable.
- Backups can be taken on primary and replica clusters.
- Backups on cross-site configurations have some specifics.
- Even though you can run backups in unmanaged clusters, you can’t run restores on
  them.
- PBM configuration is shared across all clusters.
- Setting up the Main site and Replica sites involves multiple manual operations.
- Backups are supported on the Main site only.
- If both authentication methods are specified, PMM 3 takes priority.
- API key must have the role 'Admin'.
- MongoDB operation profiling is disabled by default.
- Assigning values to common MongoDB Service Monitoring parameters is not recommended.
- Custom sidecar containers can easily access other components of your cluster.
- Sidecar containers for mongos Pods have limited Persistent volumes support.
- You can use a configMap volume to pass some configuration data to the container.
- Don’t forget you need to create a configMap Object before you can use it.
- There may be external situations when it is needed to shutdown the cluster for a
  while and then start it back up (some works related to the maintenance of the enterprise
  infrastructure, etc.).
- Setting the spec.pause key to true gracefully stops the cluster.
- To start the cluster after it was shut down just revert the spec.pause key to false.
- Custom Resources are used to manage options for the various components of the cluster.
- Exec into the container using kubectl exec command.
- To avoid the restart-on-fail loop, create /data/db/sleep-forever file.
- Cluster-level logging is enabled by default and is controlled with the logcollector.enabled
  key in the deploy/cr.yaml Custom Resource manifest.
- Logs are stored for 7 days and are rotated afterwards.
- Uses a special debug image for debugging purposes
- Images are available for Percona server for MongoDB versions 5.0 and 6.0, not for
  7.0
- You can customize the configuration of Percona Server for MongoDB and install it
  with customized parameters.
- By default, the Operator starts Percona Server for MongoDB with the default port
  27017 for all cluster components.
- Configuration requires creating Kubernetes Secret object based on your MongoDB cluster
  name.
- Transport security is set to none for LDAP connection.
- mongos is just a router between shards and underlying database instances.
- configuration ReplicaSet is responsible for keeping information about database users
  and roles.
- Use a custom registry for privacy and security.
- If the registry requires authentication, specify the imagePullSecrets option.
- The option which should be specially mentioned is credentialsSecret which is a Kubernetes
  secret for backups.
- Backups can be stored either locally, or remotely (on Amazon S3 or S3-compatible
  storage, or on Azure Blob Storage).
- 'For example, using the Amazon S3 storage can be configured with the following YAML
  file: pbm_config.yaml'
- Uses cluster-wide mode to watch multiple namespaces.
- Uses base64 encoded API key for authentication.
- Retrieve Percona certified images
- The Version Service is a centralized repository that the Percona Operator for MySQL
  connects to at scheduled times to get the latest information on compatible versions
  and valid image paths.
- Its landing page provides more details about the service itself.
- Delete Custom Resource associated with the database cluster to delete it.
- CRDs in Kubernetes are non-namespaced and should not be deleted if the Operator
  and database cluster are still present in any namespace.
- TLS-related objects and data volumes remain in Kubernetes environment after you
  delete the cluster to allow you to recreate it without losing the data.
- The Operator manages Percona Server for MongoDB using Custom Resource.
- Ensure to follow naming conventions for cluster names.
- Enable or disable exposing MongoDB Replica Set nodes with dedicated IP addresses.
- Enable or disable creation of Replica Set non-voting instances within the cluster.
- Enable or disable creation of Replica Set hidden instances within the cluster.
- Custom configuration options for Config Servers available.
- Some objects like Contact may return nulls in deeply nested fields
- A Backup resource is a Kubernetes object that tells the Operator how to create and
  manage your database backups.
- The AWS region to use is mandatory for Amazon and all S3-compatible storages.
- 'Image tags have the format: [component_name]-[component_version]'
- More detailed information about the cluster components for the current version of
  the Operator can be found in the system requirements and in the list of certified
  images.
- Percona Operator for MongoDB provides out-of-the-box functionality to automate provisioning
  and management of highly available MongoDB database clusters on Kubernetes.
- Percona Operator for MongoDB documentation is (C)2009-2023 Percona LLC and/or its
  affiliates and is distributed under the Creative Commons Attribution 4.0 International
  License.
- Percona reserves the right to revoke this authorization at any time in its sole
  discretion.
- The Operator supports both PMM2 and PMM3. The decision on what PMM version is used
  depends on the authentication method you provide in the Operator configuration.
- PBM has a known issue for using HMAC keys with GCS, which was reported in PBM-1605.
- Cluster-level logging is done with Fluent Bit, running as a sidecar container within
  each database Pods.
- Find previous version images in the documentation archive
- This release of Percona Operator for MongoDB fixes the failing backup that was caused
  by the Operator sending multiple requests to PBM.
- The issue was fixed by bypassing the cache for the backup controller and enabling
  direct communication with the API server for sending backup requests.
- Improved monitoring for clusters in multi-region or multi-namespace deployments
  in PMM
- For sharded MongoDB 8.0 deployments, Percona Operator for MongoDB versions 1.19.0
  and 1.19.1 have a known issue causing point-in-time recovery failures. Avoid upgrading
  to these Operator versions until a fix is released in Percona Backup for MongoDB
  and added into the newer versions of the Operator
- Using remote file server for backups (tech preview)
- Percona Server for MongoDB 8.0 support
- The default value of enableVolumeExpansion option is false, which means that the
  automated scaling is turned off by default.
- Declarative user management (technical preview) now supported via users subsection
  in the Custom Resource.
- Liveness check logs are stored in the /data/db/mongod-data/logs/mongodb-healthcheck.log
  file.
- The Operator was developed and tested with Percona Server for MongoDB 5.0.26-22,
  6.0.15-12, and 7.0.8-5.
- The Operator also uses Percona Backup for MongoDB 2.4.1.
- Automated volume expansion is in a technical preview stage and is not recommended
  for production environments.
- Physical Backups now support Point-in-time Recovery (in tech preview)
- Encrypted backups with Server Side Encryption (SSE)
- The Operator was developed and tested with Percona Server for MongoDB 4.4.24, 5.0.20,
  and 6.0.9.
- The Operator also uses Percona Backup for MongoDB 2.3.0.
- This list only includes the platforms that the Percona Operators are specifically
  tested on as part of the release process.
- Backups and Restores are critical for business continuity. With this release you
  can significantly reduce your Recovery Time Objective (RTO) with Physical backups
  support in the Operator. The feature is now in technical preview.
- MongoDB 6.0 comes with a variety of improvements and new features. It is now fully
  supported by the Operator.
- Physical backups cannot be restored on the clusters with arbiter, non-voting, or
  delayed members due to current Percona Backup for MongoDB limitations
- 'After switching the cluster to unsafe mode by setting allowUnsafeConfig: true,
  it is not possible to switch back into safe mode. The user can still scale the cluster
  safely, but the flag is ignored'
- Support for the cluster-wide operator mode allowing one Operator to watch for Percona
  Server for MongoDB Custom Resources in several namespaces.
- Support for the HashiCorp Vault for encryption keys.
- Support for the Azure Kubernetes Service (AKS).
- The Operator versions 1.11.0 and 1.12.0 can not be downscaled from a sharding to
  non-sharding/Replica Set configuration on Google Kubernetes Engine (GKE) 1.19-1.21
  (GKE 1.22 is not affected)
- Before the upgrade, please ensure that you have moved all custom MongoDB parameters
  to proper places!
- In addition to S3-compatible storage, you can now configure backups to use Microsoft
  Azure Blob storage.
- Custom sidecar containers allow users to customize Percona Distribution for MongoDB
  and other Operator components without changing the container images.
- Starting from this release, the Operator implements as a technical preview the possibility
  to include non-voting replica set members into the cluster, which do not participate
  in the primary election process.
- The technical preview of the cross-site replication feature allows users to add
  external replica set nodes into the cluster managed by the Operator.
- Starting from this release, the Operator changes its official name to Percona Distribution
  for MongoDB Operator.
- It is now possible to restore backups from S3-compatible storage to a new Kubernetes-based
  environment with no existing Backup Custom Resources.
- You can now customize Percona Server for MongoDB by storing custom configuration
  for Replica Set, mongos, and Config Server instances in ConfigMaps or in Secrets.
- The support for Point-in-time recovery added in this release. Users can now recover
  to a specific date and time from operations logs stored on S3
- It is now possible to perform a major version upgrade for MongoDB with no manual
  steps
- This release brings full support for the Percona Server for MongoDB Sharding.
- It is now possible to clean up Persistent Volume Claims automatically after the
  cluster deletion event.
- Monitoring with PMM v.1 configured according to the unofficial instruction will
  not work after the upgrade. Please switch to PMM v.2.
- The MMAPv1 storage engine is no longer supported for all MongoDB versions starting
  from this version of the Operator.
- Amazon Elastic Container Service for Kubernetes (EKS) was added to the list of the
  officially supported platforms
- Percona Server for MongoDB 4.2 is now supported
- OpenShift Container Platform 4.3 is now supported
- Data-at-rest encryption is now enabled by default unless EnableEncryption=false
  is explicitly specified in the deploy/cr.yaml configuration file.
- The resource constraint values were refined for all containers to eliminate the
  possibility of an out of memory error.
- Percona Kubernetes Operator simplifies the deployment and management of Percona
  Server for MongoDB in Kubernetes-based environments.
- Deployment takes about six minutes with the default configuration.
- TLS is enabled by default for replication and client traffic using Cert-Manager.
- 'Ready to get started with the Percona Operator for MySQL? In this section, you
  will learn some basic operations, such as: Install and deploy an Operator, Connect
  to MySQL instance in Percona XtraDB Cluster, Insert sample data to the database,
  Set up and make a logical backup, Monitor the database health with Percona Monitoring
  and Management (PMM).'
- The Percona Operator for MySQL is ideal for various scenarios such as providing
  Database as a Service (DBaaS), ensuring high availability for mission-critical applications,
  scaling cloud-native applications, and implementing disaster recovery strategies.
- Our documentation guides are packed with information, but they can’t cover everything
  you need to know about Percona Operator for MySQL Based on Percona XtraDB Cluster.
- We recommend visiting our Community Forum for discussions, technical insights, and
  support around Percona database software.
- Optionally the Operator allows using ProxySQL daemon instead of HAProxy, which provides
  SQL-aware database workload management and can be more more efficient in comparison
  with other load balancers.
- Open source model is Apache 2.0
- Various versions are tested for Kubernetes conformance
- Helm v3 is needed to run the following steps.
- The creation process may take some time.
- Default Percona XtraDB Cluster configuration includes three HAProxy and three XtraDB
  Cluster instances.
- Passwords are stored in the Secrets object.
- This tutorial provides SQL statements for inserting sample data to Percona Server
  for MySQL.
- PMM Server and PMM Client are installed separately.
- PMM3 uses Grafana service accounts to control access to PMM server components and
  resources.
- Access PMM via HTTPS in a web browser
- The Operator was developed and tested with Percona XtraDB Cluster versions 8.4.5-5.1
  (Tech preview), 8.0.42-33.1, and 5.7.44-31.65.
- Other options may also work but have not been tested.
- Deploys one Percona XtraDB Cluster node and one HAProxy node.
- The cr-minimal.yaml is for minimal non-production deployment.
- Percona Everest is an open source cloud-native database platform that helps developers
  deploy code faster.
- This deploys default Percona XtraDB Cluster configuration with three HAProxy and
  three XtraDB Cluster instances.
- 'You can clone the repository with all manifests and source code by executing the
  following command: $ git clone -b v1.18.0 https://github.com/percona/percona-xtradb-cluster-operator'
- The Secrets object you are interested in has the cluster1-secrets name by default.
- Deploys default Percona XtraDB Cluster configuration with three HAProxy and three
  XtraDB Cluster instances.
- If `kubectl get pxc` command doesn’t show `ready` status too long, you can check
  the creation process with the `kubectl get pods` command.
- If the command output had shown some errors, you can examine the problematic Pod
  with the `kubectl describe <pod name>` command.
- The creation process may take some time. When the process is over your cluster will
  obtain the 'ready' status.
- After deleting the cluster, all data stored in it will be lost!
- Percona Operator is portable across hybrid clouds and fully supports the Red Hat
  OpenShift lifecycle.
- The Operator generates users Secrets automatically, and no actions are required
  at this step.
- Operator generates users Secrets automatically, and no actions are required at this
  step.
- Operator generates certificates automatically, and no actions are required at this
  step.
- Replication channel demands a special system user with the same credentials on both
  Source and Replica.
- If the Replica cluster is not a clone of the original one, the appropriate user
  with necessary permissions should be created manually.
- Before upgrading the Kubernetes cluster, have a disaster recovery plan in place.
- The Operator version has three digits separated by a dot (`.`) in the format `major.minor.patch`.
- CRD supports the last 3 minor versions of the Operator.
- Find the image name for the current Operator release in the list of certified images.
- Operator queries a special Version Service server at scheduled times for upgrades.
- 'Upgrade options: Never, Disabled, Recommended, Latest, version.'
- Use Smart Update strategy to update the objects in your database cluster.
- Update PMM Server before upgrading PMM Client.
- Check custom HAProxy configuration before the upgrade.
- Check the HAProxy configuration file provided by the Operator before the upgrade.
- You can force an immediate upgrade by changing the schedule to '* * * * *'.
- The default and recommended way to upgrade the database cluster is using the Smart
  Update strategy.
- In some cases running an automatic upgrade of Percona XtraDB Cluster is not an option.
- The Pod with the newer Percona XtraDB Cluster image will start after you delete
  it.
- Delete targeted Pods manually one by one to make them restart in desired order.
- Starting with OpenShift 4.19, images with not fully qualified names may result in
  the ImagePullBackOff error.
- Manual update of initContainer.image is required after upgrading the operator.
- This command triggers the restart of your clusters. Wait till they restart and report
  the Ready status
- Declarative user management has technical preview status and is not yet recommended
  for production environments.
- The Operator tracks password changes in the Secret object, and updates the user
  password in the database, when needed.
- These users should not be used to run an application.
- Do not use the default Percona XtraDB Cluster user passwords in production!
- Load balancing with HAProxy is the default choice.
- To expose all instances, set pxc.expose.enabled to true.
- Do not forget to restart Percona XtraDB Cluster to ensure the cluster has updated
  the configuration.
- The operator does good job automatically assigning new Pods to nodes with sufficient
  to achieve balanced distribution across the cluster.
- Annotations store descriptive information that doesn’t affect how Kubernetes processes
  resources.
- If there are no annotations or labels in the Custom Resource, the Operator does
  nothing if a new label or an annotation is added to the object.
- The Operator will ignore any Service annotation or label, key of which starts with
  the mentioned above examples.
- hostPath directory is not created automatically; it must be created manually on
  the node's filesystem.
- Consider using tolerations to avoid cluster migration to different hardware.
- HA_CONNECTION_TIMEOUT sets a custom timeout for HAProxy health checks.
- OK_IF_DONOR allows application connections to XtraDB Cluster donor nodes.
- HA_SERVER_OPTIONS sets custom options for servers in the HAProxy configuration file.
- PEER_LIST_SRV_PROTOCOL defines what protocol the Operator uses for peer-list SRV
  lookups.
- Switching from ProxySQL to HAProxy will cause Percona XtraDB Cluster Pods restart.
- Switching from HAProxy to ProxySQL is not possible, and if you need ProxySQL, this
  should be configured at cluster creation time.
- 'To find the cluster name, you can use the command: $ kubectl get pxc'
- Uses a configmap and the cluster restart to reset configuration options.
- Configuration options should be put inside a specific key inside of the data section.
- ProxySQL can be enabled only when creating a cluster.
- Switching from HAProxy to ProxySQL is not possible if HAProxy is already enabled.
- Uses Kubernetes Secrets for configuration
- Configuration options should be put inside a specific key inside of the data section
- This guide explains how to set up a disaster recovery system and transfer workloads
  between sites when something goes wrong.
- Make sure to clone the correct branch. The branch name is the same as the Operator
  release version.
- The replica site must be the exact copy of the primary site and must have the same
  system user credentials.
- Use the same name for the Secret object for user credentials on both sites.
- The sites must have the same copy of data.
- Replication is defined via a replication channel.
- Modify the replication channel for cluster2 within the deploy/cr.yaml file
- Set the isSource value to true to make the replica site the source of the data
- Remove the sourcesList configuration
- The new cluster1 must be the exact copy of the current primary cluster2.
- Make sure that the passwords in the secrets file match the passwords from the cluster2-secrets.
- The Operator generates long-term certificates automatically if there are no certificate
  secrets available (default option, and requires you renew them manually)
- The Operator can use a specifically installed cert-manager, which will automatically
  generate and renew short-term TLS certificates
- Certificates can be generated manually
- For already expired certificates, follow the alternative way.
- Omitting TLS is also possible, but we recommend that you run your cluster with the
  TLS protocol enabled.
- Data at rest encryption is supported by the Operator since version 1.4.0.
- If using Percona XtraDB Cluster 8.0, the encryption is turned on by default (in
  case if Vault is configured).
- Telemetry is enabled by default and is sent to the Version Service server when the
  Operator connects to it.
- Backups can be scheduled or on-demand.
- Backups can be stored in cloud storage or on-premises with Persistent Volume.
- Point-in-time recovery is off by default and is supported by the Operator with Percona
  XtraDB Cluster versions starting from 8.0.21-12.1.
- Use either s3-compatible or Azure-compatible storage for both binlog and full backup
  for point-in-time recovery.
- Statistics data is not kept when the point-in-time recovery Pod restarts. This means
  that the counters like pxc_binlog_collector_success_total are reset.
- Before the Operator version 1.10 scheduled backups were based on Kubernetes CronJobs,
  while newer Operator versions take care about scheduled backups itself.
- Clusters upgraded from the Operator version 1.9 may need manual deletion of scheduled
  backups CronJobs, if any existed prior to the upgrade (otherwise backups will run
  twice).
- The backup.storages subsection should contain at least one configured storage.
- You can enable LZ4 compression for backups if you run Percona XtraDB Cluster 8.0
  and higher.
- When enabled, compression will be used for both backups and SST.
- Make a local copy of a previously saved backup requires not more than the backup
  name.
- Cannot restore to emptyDir and hostPath volumes
- Backup can be made from emptyDir/hostPath to S3, and later restored to a Persistent
  Volume
- Starting with version 1.18.0, the Operator no longer requires matching secrets between
  the backup and the target cluster.
- Make sure that the cluster is running before starting the restore process.
- The cluster should have a Secrets object with the same user passwords as in the
  original cluster.
- Disable the point-in-time functionality on the existing cluster before restoring
  a backup on it, regardless of whether the backup was made with point-in-time recovery
  or without it.
- The maximum amount of stored backups is controlled by the backup.schedule.keep option
  (only successful backups are counted). Older backups are automatically deleted,
  so that amount of stored backups do not exceed this number.
- Setting keep=0 or removing this option from deploy/cr.yaml disables automatic deletion
  of backups.
- Starting from the version 1.14.0, you can scale Percona XtraDB Cluster storage automatically
  by configuring the Custom Resource manifest.
- If the new storage size can’t be reached because there is a resource quota in place
  and the PVC storage limits are reached, this will be detected, there will be no
  scaling attempts, and the Operator will revert the value in the Custom Resource
  option back.
- Size of the cluster is controlled by a size key in the Custom Resource options configuration.
- To automate horizontal scaling, it is possible to use Horizontal Pod Autoscaler
  (HPA).
- PMM is compatible with both PMM versions 2 and 3.
- Ensure the PMM Server IP address is resolvable and reachable from within your cluster.
- The `deploy/secrets.yaml` file contains all values for each key/value pair in a
  convenient plain text format.
- To update the password field, you need to encode the new password into the base64
  format.
- You can specify additional parameters for pmm-admin add mysql and pmm-admin add
  proxysql commands, if needed.
- Assigning values to common Percona XtraDB Cluster Service Monitoring parameters
  is not recommended and can negatively affect functionality.
- Use sidecar containers carefully and by experienced users only.
- Pausing the cluster may take some time, and when the process is over, you will see
  only the Operator Pod running.
- Starting the cluster will take time. The process is over when all Pods have reached
  their Running status.
- Automatic crash recovery is controlled by the pxc.autoRecovery option in the deploy/cr.yaml
  configuration file.
- The default value for pxc.autoRecovery is true.
- Please make sure the Percona XtraDB Cluster version for the debug image matches
  the version currently in use in the cluster.
- To create a database cluster, apply the cluster2-cr.yaml.
- The Custom Resource should have `Ready` status.
- Avoid the restart-on-fail loop for Percona XtraDB Cluster containers
- Events are stored in the etcd for only 60 minutes.
- Kubernetes cluster administrators might also use event exporters for storing the
  events.
- Log collector is turned on by the logcollector.enabled key in the deploy/cr.yaml
  configuration file (true by default).
- Logs are stored for 7 days and then rotated.
- Ensure there is only one default Storage class.
- Check the provisioner and parameters are indicating the type of storage you intend
  to provision.
- WaitForFirstConsumer volumeBindingMode ensures volume is provisioned only after
  a Pod requesting the Volume is created.
- 'Ensure the storage class supports PVC expansion (it should have allowVolumeExpansion:
  true).'
- For the cases when Pods are failing for some reason or just show abnormal behavior,
  the Operator can be used with special debug images.
- The Pod should be restarted to get the new image.
- When the Pod is continuously restarting, you may have to delete it to apply image
  changes.
- Some Kubernetes-based environments are specifically configured to have communication
  across Namespaces is not allowed by default network policies.
- Don’t forget to set upgradeoptions.apply option to Disabled. Otherwise Smart Upgrade
  functionality will try using the image recommended by the Version Service instead
  of the custom one.
- The MySQL version for source and target environments must be 8.0.22 and higher since
  asyncronous replication is available starting with MySQL version 8.0.22.
- You must be running Percona XtraBackup as the backup tool on source environment.
- API key must have the role Admin
- The API key is not rotated
- The Prometheus node exporter is not installed by default since it requires privileged
  containers with the access to the host file system.
- By default, TLS-related objects and data volumes remain in Kubernetes environment
  after you delete the cluster to allow you to recreate it without losing the data.
- The `allowUnsafeConfigurations` option is deprecated and will be removed in future
  releases.
- The `initImage` option is deprecated and will be removed in future releases.
- Enables or disables load balancing with HAProxy
- The maximum time in seconds for a backup to remain in a suspended state is configurable.
- Create the namespace name you will use, if not exist
- Prepare API address and service account token using kubectl commands
- Requires setup of Kubernetes service account for authentication
- Authorization requires Bearer token
- Increase or decrease the size of the Percona XtraDB Cluster nodes to fit the current
  high availability needs
- Requires setup of Kubernetes with appropriate permissions
- Ensure the image version is compatible with your setup
- Supports both MySQL 8.0 and 5.7 branches
- HAProxy is turned on by default
- Custom sidecar containers can easily access other components of your cluster. Therefore
  they should be used carefully and by experienced users only.
- The technical writer oversees the integration of AI-driven tools and platforms into
  the documentation workflow, ensuring that AI-generated text meets the standards
  for clarity, coherence, and accuracy.
- While AI assists in tasks such as content generation, language enhancement, and
  formatting optimization, the technical writer is responsible for validating and
  refining the output to ensure its suitability for the intended audience.
- Throughout the documentation process, the technical writer reviews the quality and
  relevance of AI-generated content in detail and with critical judgment.
- While AI accelerates the documentation process and enhances productivity, the technical
  writer verifies the information’s accuracy and maintains consistency in terminology,
  style, and tone.
- Percona Operator for MySQL based on Percona XtraDB Cluster documentation is (C)2009-2023
  Percona LLC and/or its affiliates and is distributed under the Creative Commons
  Attribution 4.0 International License.
- Version 0.12.0 of the Percona Operator for MySQL is a tech preview release and it
  is not recommended for production environments.
- As of today, we recommend using Percona Operator for MySQL based on Percona XtraDB
  Cluster, which is production-ready and contains everything you need to quickly and
  consistently deploy and scale MySQL clusters in a Kubernetes-based environment,
  on-premises or in the cloud.
errors:
- 'REQUEST_LIMIT_EXCEEDED: Throttle API calls or reduce frequency'
- 'QUERY_TIMEOUT: Break down filters or add selectivity'
- '401 Unauthorized: Recheck OAuth scopes or token expiration'
- 'RESPONSE_TIMES_CAN_VARY: Response times can vary depending on the complexity of
  the question.'
- 'Error: PMM server cannot rotate service account tokens after they expire.'
- 'REQUEST_LIMIT_EXCEEDED: Throttle API calls or reduce frequency.'
- 'QUERY_TIMEOUT: Break down filters or add selectivity.'
- Ensure that the PMM server is up and running before deploying the client.
- If Custom Resource is not getting 'Ready' status, check individual Pods using 'kubectl
  get pods'.
- 'OCI runtime exec failed: exec failed: unable to start container process: exec:
  ''time'': executable file not found in $PATH: unknown command terminated with exit
  code 126'
- Ensure replica is rebuilt with the correct data to prevent data corruption.
- If the replica falls significantly behind the primary, reinitialize it.
- Percona reserves the right to revoke this authorization at any time in its sole
  discretion.
- If you do not immediately cease using the Percona mark upon revocation, Percona
  may take action to protect its rights and interests in the Percona mark.
- Talk to a Percona Expert
- We provide flexible support plans tailored to your specific needs.
- '404 Not Found: Check the endpoint path'
- '500 Internal Server Error: Check the server logs for more information'
- '400 Bad Request: Check the request parameters and format.'
- '404 Not Found: Verify the endpoint and resource you are trying to access.'
- 'Error with backup: Check logs for details'
- 'Invalid S3 credentials: Verify the base64 encoding'
- API key is not rotated automatically when it expires. You must manually recreate
  it and reconfigure the PMM Client.
- Use this guide to delete the testing deployment.
- Cluster Pods may restart if MONGODB_CLUSTER_MONITOR user credentials change.
- Operator will be able to remove a shard only when it contains no application (non-system)
  collections.
- If cert-manager is used, delete issuer and TLS certificates if they are expired.
- Ensure the cluster is paused before applying TLS configuration changes.
- You can set the value to any number greater than 0.
- Older backups are automatically deleted, so that amount of stored backups do not
  exceed the maximum amount controlled by the backup.tasks.keep option.
- Ensure resource requests and limits are correctly set in the Custom Resource.
- Replica will be restarting due to failed liveness checks if users are not copied.
- Backup started in primary (managed) cluster may be taken from a secondary instance
  to avoid affecting write performance.
- API key is not rotated automatically when it expires. Must manually recreate.
- 'Last update: 2025-10-20'
- Check the Pods for individual status.
- If Custom Resource is not getting 'Ready' status, check individual Pods.
- Authentication required for https://192.168.1.100:8443
- 'K8SPSMDB-925: Fix a bug where the Operator generated ''failed to start balancer''
  and ''failed to get mongos connection'' log messages.'
- 'K8SPSMDB-1105: The memory requests and limits for backups were increased.'
- 'K8SPSMDB-713: Physical backups are now supported by the Operator to recover big
  data sets faster'
- 'K8SPSMDB-737: MongoDB 6.0 is now officially supported in addition to 4.x and 5.x
  versions'
- 'K8SPSMDB-824: New ignoreAnnotations and ignoreLabels Custom Resource options allow
  to list specific annotations and labels for Kubernetes Service objects, which the
  Operator should ignore'
- 'K8SPSMDB-686: The Operator versions 1.11.0 and 1.12.0 can not be downscaled from
  a sharding to non-sharding/Replica Set configuration on Google Kubernetes Engine
  (GKE) 1.19-1.21 (GKE 1.22 is not affected)'
- 'K8SPSMDB-603: Fixed a bug where the Operator checked the presence of CPU limit
  and not memory limit when deciding whether to set the size of cache memory for WiredTiger.'
- 'K8SPSMDB-511: Fixed a bug where Operator changed NodePort port every 20 seconds
  for a Replica Set service.'
- 'K8SPSMDB-608: Fix a bug that resulted in printing the password of backup user in
  the backup agent logs.'
- 'K8SPSMDB-592: Fixed a bug where helm chart was incorrectly setting the serviceAnnotations
  and loadBalancerSourceRanges for mongos exposure.'
- 'K8SPSMDB-568: Fixed a bug where upgrading to MongoDB 5.0 failed when using the
  upgradeOptions:apply option.'
- 'K8SPSMDB-504: Fixed a race condition that could prevent the cluster with LoadBalancer-exposed
  replica set members from becoming ready'
- 'K8SPSMDB-470: Fix a bug where ServiceAnnotation and LoadBalancerSourceRanges fields
  didn’t propagate to Kubernetes service'
- 'K8SPSMDB-531: Fix compatibility issues between Percona Kubernetes Operator for
  MongoDB and Calico'
- 'K8SPSMDB-514: Fix a bug where backup cronJob created by the Operator did not include
  resources limits and requests'
- 'K8SPSMDB-512: Fix a bug where configuring getLastErrorModes in the replica set
  causes the Operator to fail to reconcile'
- 'K8SPSMDB-553: Fix a bug where wrong S3 credentials caused backup to keep running
  despite the actual failure'
- 'K8SPSMDB-496: Fix a bug where Pods did not restart if custom MongoDB config was
  updated with a secret or a configmap'
- 'K8SPSMDB-384: Fix a bug due to which mongos Pods were failing readiness probes
  for some period of time during the cluster initialization'
- 'K8SPSMDB-434: Fix a bug due to which nil pointer dereference error was occurring
  when switching the sharding.enabled option from false to true'
- 'K8SPSMDB-430: Fix a bug due to which a stale apiserver could trigger undesired
  StatefulSet and PVC deletion when recreating the cluster with the same name'
- 'request is too large: Only 20 last status changes are now stored in etcd to avoid
  this problem.'
- 'Last update: 2025-10-17'
- '24/7 Expert Support: Our dedicated team of database experts is available 24/7 to
  assist you with any database issues.'
- 'Platform not supported: Check if the Kubernetes version is compatible.'
- 'Timeout: Creation process may take some time.'
- Ensure user has cluster-admin privileges for setting Custom Resource Definition.
- Replication for channel is not running. Please, check the replication status
- Check that the current Operator version supports the new database version.
- Check version compatibility before upgrade.
- Deployment rollout may take time after patch application.
- Rollout status can be tracked using the kubectl rollout status command.
- 'ImagePullBackOff: Ensure images are fully qualified.'
- When a user sets an invalid grant or sets an administrative (global) grant with
  some value present in spec.user.dbs, the Operator logs error and creates the user
  with the default grants (GRANT USAGE).
- The Operator doesn’t delete users if they are removed from Custom Resource, to avoid
  affecting any pre-existing users.
- Backup doesn't guarantee consistent recovery with PITR. Annotate PerconaXtraDBClusterRestore
  with percona.com/unsafe-pitr to force it.
- If resize isn’t successful, the Operator will detect Kubernetes failure on scaling,
  and revert the Custom Resource option.
- '401 Unauthorized: Recheck service account token or API key expiration'
auth_info:
  mentioned_objects:
  - affinity.podAntiAffinity
  - topologySpreadConstraints
  - service account
  - token
  - API key
client:
  base_url: https://docs.percona.com/percona-operators/
  headers:
    Accept: application/json
source_metadata: null
