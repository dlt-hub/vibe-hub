resources:
- name: DataFrameSchema
  endpoint:
    path: /pandera/api/polars/model/DataFrameModel
    method: GET
    data_selector: validated DataFrame
- name: dataframe_validation
  endpoint:
    path: /pandas/validate
    method: POST
    data_selector: records
    params: {}
- name: schema_definition
  endpoint:
    path: /schemas/define
    method: POST
    data_selector: records
    params: {}
- name: dataframe_schema
  endpoint:
    path: /dataframe/schema
    method: POST
    data_selector: schema
    params: {}
- name: Schema
  endpoint:
    path: /
    method: GET
    data_selector: records
    params: {}
- name: DataFrameSchema
  endpoint:
    path: /pandera/api/dataframe_schema
    method: GET
    data_selector: schema
    params: {}
- name: Column
  endpoint:
    path: /pandera/api/column
    method: GET
    data_selector: column
    params: {}
- name: Check
  endpoint:
    path: /pandera/api/check
    method: GET
    data_selector: check
    params: {}
- name: DataFrameSchema
  endpoint:
    path: /generated/pandera.api.pandas.container.DataFrameSchema
    method: GET
    data_selector: schema
- name: SeriesSchema
  endpoint:
    path: /generated/pandera.api.pandas.array.SeriesSchema
    method: GET
    data_selector: schema
- name: columns
  endpoint:
    path: /schema/columns
    method: GET
    data_selector: columns
    params: {}
- name: index
  endpoint:
    path: /schema/index
    method: GET
    data_selector: index
    params: {}
- name: DataFrameSchema
  endpoint:
    path: /pandera/api/dataframe/schema
    method: GET
    data_selector: schema
    params: {}
- name: DataFrameModel
  endpoint:
    path: /api/dataframe/model
    method: GET
    data_selector: models
    params: {}
- name: DataFrameSchema
  endpoint:
    path: /api/dataframe/schema
    method: GET
    data_selector: schemas
    params: {}
- name: custom_check_methods
  endpoint:
    path: /reference/generated/pandera.extensions.register_check_method
    method: GET
    data_selector: methods
    params: {}
- name: InSchemaParquet
  endpoint:
    path: InSchemaParquet
    method: GET
    data_selector: records
    params: {}
- name: OutSchemaDict
  endpoint:
    path: OutSchemaDict
    method: GET
    data_selector: records
    params: {}
- name: transactions
  endpoint:
    path: /transactions/
    method: POST
    data_selector: records
- name: file_upload
  endpoint:
    path: /file/
    method: POST
    data_selector: df
- name: DataFrameSchema
  endpoint:
    path: /pandera/io/from_frictionless_schema
    method: POST
    data_selector: schema
    params: {}
- name: DataFrameModel
  endpoint:
    path: /reference/generated/pandera.api.pandas.model.DataFrameModel
    method: GET
    data_selector: records
    params: {}
- name: PydanticModel
  endpoint:
    path: /reference/generated/pandera.api.pandas.model.DataFrameModel
    method: GET
    data_selector: records
    params: {}
- name: SeriesSchema
  endpoint:
    path: pandera/api/pandas/array/SeriesSchema
    method: GET
    data_selector: records
    params: {}
- name: DataFrameSchema
  endpoint:
    path: /pandera/api/polars/container/DataFrameSchema
    method: GET
    data_selector: records
- name: DataFrameSchema
  endpoint:
    path: /pandera/api/pyspark/container/DataFrameSchema
    method: GET
    data_selector: records
- name: DataFrameSchema
  endpoint:
    path: /pandera/api/pyspark/container/DataFrameSchema
    method: GET
    data_selector: validated DataFrame
    params: {}
- name: DataFrameSchema
  endpoint:
    path: /pandera/api/dataframe/container/DataFrameSchema
    method: GET
    data_selector: records
    params: {}
- name: DataFrameSchema
  endpoint:
    path: /pandera/api/dataframe/container/DataFrameSchema
    method: GET
    data_selector: records
- name: Index
  endpoint:
    path: /pandera/api/pandas/components/Index
    method: GET
    data_selector: records
    params: {}
- name: MultiIndex
  endpoint:
    path: /api/pandas/components/MultiIndex
    method: GET
    data_selector: records
- name: ComponentSchema
  endpoint:
    path: /pandera/api/dataframe/components/ComponentSchema
    method: GET
    data_selector: parameters
    params: {}
- name: check_positive
  endpoint:
    path: /check_positive
    method: GET
    data_selector: records
    params: {}
- name: check_even
  endpoint:
    path: /check_even
    method: GET
    data_selector: records
    params: {}
- name: check_by_group
  endpoint:
    path: /check_by_group
    method: GET
    data_selector: records
    params: {}
- name: check_dataframe
  endpoint:
    path: /check_dataframe
    method: GET
    data_selector: records
    params: {}
- name: one_sample_ttest
  endpoint:
    path: /pandera/api/hypotheses/one_sample_ttest
    method: POST
    data_selector: results
    params:
      popmean: 5
      relationship: greater_than
      alpha: 0.1
- name: two_sample_ttest
  endpoint:
    path: /pandera/api/hypotheses/two_sample_ttest
    method: POST
    data_selector: results
    params:
      relationship: equal
      alpha: 0.01
      equal_var: true
      nan_policy: propagate
- name: SCHEMA
  endpoint: {}
- name: DATA
  endpoint: {}
- name: pyarrow_dtypes
  endpoint:
    path: /pyarrow_dtypes
    method: GET
    data_selector: dtypes
    params: {}
- name: geopandas_dtypes
  endpoint:
    path: /geopandas_dtypes
    method: GET
    data_selector: dtypes
    params: {}
- name: pydantic_dtypes
  endpoint:
    path: /pydantic_dtypes
    method: GET
    data_selector: dtypes
    params: {}
- name: polars_dtypes
  endpoint:
    path: /polars_dtypes
    method: GET
    data_selector: dtypes
    params: {}
- name: Float64
  endpoint:
    path: /pandera/dtypes/Float64
    method: GET
    data_selector: attributes
    params: {}
- name: Int16
  endpoint:
    path: /pandera/dtypes/Int16
    method: GET
    data_selector: attributes
    params: {}
notes:
- Validate a DataFrame based on the schema specification.
- Raises SchemaError when DataFrame violates built-in or custom checks.
- Uses OAuth2 with refresh token — requires setup of connected app in api
- Some objects like Contact may return nulls in deeply nested fields
- Pandera supports validation of various DataFrame libraries.
- Pandera v0.24.0 introduces the pandera.pandas module, which is now the recommended
  way of defining DataFrameSchemas and DataFrameModels for pandas data structures.
- The Data Synthesis Strategies functionality is not yet supported in the Ibis integration.
- Element-wise checks using DataFrameModel are not yet supported in the Ibis integration;
  use DataFrameSchema instead.
- 'The available methods for altering the schema are: add_columns(), remove_columns(),
  update_column(), update_columns(), rename_columns(), update_index(), update_indexes(),
  rename_indexes(), set_index(), reset_index().'
- Due to current limitations in the pandas library, pandera annotations are only used
  for run-time validation and has limited support for static-type checkers like mypy.
- You cannot use both typing.Annotated and dtype_kwargs.
- The Config class must be named ‘Config’.
- The alias is respected when using the class attribute to get the underlying pd.DataFrame
  column name or index level name.
- There are drawbacks to manipulating schema shape in this way.
- The hypothesis feature requires a pandera installation with hypotheses dependency
  set.
- This feature is only available in the pandas validation backend.
- This feature is currently only supported with the pandas validation backend.
- This functionality is available on DataFrameSchema, SeriesSchema, Column, as well
  as DataFrameModel schemas.
- In order to use drop_invalid_rows=True, lazy=True must be passed to the schema.validate().
- Inferred schemas are rough drafts that shouldn’t be used for validation without
  modification.
- These inferred schemas are rough drafts that shouldn’t be used for validation without
  modification.
- You can edit this json file to update the schema as needed, and then load it back
  into a pandera schema object with from_json() or from_json().
- Schema persistence feature requires a pandera installation with the io extension.
- By default, when you call the validate method on schema or schema component objects,
  a SchemaError is raised as soon as one of the assumptions specified in the schema
  is falsified.
- For more complex cases, it is useful to see all of the errors raised during the
  validate call.
- By default, error reports are generated for both schema and data level validation.
- 'SCHEMA_ONLY: perform schema validations only.'
- 'DATA_ONLY: perform data-level validations only.'
- 'SCHEMA_AND_DATA: perform both schema and data level validations (default).'
- You can override default behaviour by setting an environment variable from terminal.
- Uses hypothesis for generating synthetic data from schema.
- Example method is primarily for interactive use.
- As of pandera >= 0.21.0, only polars >= 1.0.0 is supported.
- If you’re on an Apple Silicon machine, you’ll need to install polars via pip install
  polars-lts-cpu.
- Lazy validation in pandera is different from the lazy API in polars, which is an
  unfortunate name collision.
- By default, pl.LazyFrame validation will only validate schema-level properties.
- If you want to validate data-level properties on a pl.LazyFrame, the recommended
  way would be to first call .collect().
- Uses Pandera for data validation in PySpark SQL.
- Dask is a distributed compute framework that offers a pandas-like dataframe API.
- PYARROW_IGNORE_TIMEZONE environment variable was not set. It is required to set
  this environment variable to '1' in both driver and executor sides if you use pyarrow>=2.0.0.
- Operations in a distributed setting are applied per partition.
- Don’t see a library that you want supported? Check out the github issues to see
  if that library is in the roadmap. If it isn’t, open up a new issue to add support
  for it!
- Mypy static type-linting is supported for only pandas dataframes.
- This functionality is experimental.
- Combining dtype=PydanticModel(...) and coerce=True applies the pydantic model validation
  process to each row.
- A lightweight pandas DataFrame validator.
- Library-agnostic base class for DataFrameSchema definitions.
- Lazy evaluation raises SchemaErrors only after all checks.
- Inplace applies coercion to the validated DataFrame.
- Validate types and properties of a pandas DataFrame Index.
- New in version 0.4.0
- This should pick up environment variables automatically
- Whether to apply checks at schema- or data-level, or both.
- Semantic representation of a floating data type.
- Semantic representation of a floating data type stored in 32 bits.
- Semantic representation of a floating data type stored in 64 bits.
- Semantic representation of a floating data type stored in 128 bits.
errors:
- 'SchemaError: when DataFrame violates built-in or custom checks.'
- 'SchemaError: Validation check failed'
- Column 'column1' not in dataframe.
- non-nullable series 'id' contains null values
- 'SchemaError: Issues with schema validation.'
- 'SchemaInitError: Problems initializing schema.'
- 'SchemaDefinitionError: Errors in schema definition.'
- 'COLUMN_NOT_IN_SCHEMA: column ''unknown_column'' not in DataFrameSchema'
- 'COLUMN_NOT_IN_DATAFRAME: column ''date_column'' not in dataframe.'
- 'WRONG_DATATYPE: expected series ''int_column'' to have type int64, got object'
- 'WRONG_DATATYPE: expected series ''float_column'' to have type float64, got int64'
- 'greater_than(0) failure cases: 0'
- 'equal_to(a) failure cases: b, d'
- 'Column ''color'' failed element-wise validator number 0: isin([''red'', ''green'',
  ''blue'']) failure cases: purple'
- 'Column ''length'' failed element-wise validator number 0: greater_than(10) failure
  cases: 4'
- 'Unsatisfiable: Unable to satisfy assumptions of example generation.'
- expected column 'a' to have type Int64, got String
- 'Column ''b'' failed validator number 0: <Check isin: isin([''a'', ''b'', ''c''])>
  failure case examples: [{''b'': ''d''}, {''b'': ''e''}, {''b'': ''f''}]'
- 'Column ''c'' failed validator number 0: <Check greater_than_or_equal_to: greater_than_or_equal_to(0.0)>
  failure case examples: [{''c'': -0.1}]'
- 'Column ''c'' failed validator number 1: <Check less_than_or_equal_to: less_than_or_equal_to(1.0)>
  failure case examples: [{''c'': 1.1}]'
- Python worker exited unexpectedly (crashed)
- EOFError
- 'REQUEST_LIMIT_EXCEEDED: Throttle API calls or reduce frequency'
- 'QUERY_TIMEOUT: Break down filters or add selectivity'
- '401 Unauthorized: Recheck OAuth scopes or token expiration'
- 'java.lang.UnsupportedOperationException: sun.misc.Unsafe or java.nio.DirectByteBuffer.<init>(long,
  int) not available'
auth_info:
  mentioned_objects: []
client:
  base_url: https://union.ai/pandera
  headers:
    Accept: application/json
source_metadata: null
