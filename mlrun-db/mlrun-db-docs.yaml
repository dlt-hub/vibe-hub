resources:
- name: HTTPRunDB
  endpoint:
    path: /mlrun/db/httpdb/HTTPRunDB
    method: GET
- name: HTTPRunDB
  endpoint:
    path: /mlrun/db/httpdb/HTTPRunDB
    method: GET
- name: another source
  endpoint:
    path: /local/path/to/source/2
    method: GET
- name: enable_model_monitoring
  endpoint:
    path: /enable_model_monitoring
    method: POST
    data_selector: result
    params:
      project: project
      base_period: 10
      image: mlrun/mlrun
      deploy_histogram_data_drift_app: true
      fetch_credentials_from_sys_config: false
- name: function_status
  endpoint:
    path: /function_status
    method: GET
    data_selector: status
    params:
      project: project
      name: name
      kind: dask
      selector: selector
- name: get_alert_activation
  endpoint:
    path: /get_alert_activation
    method: GET
    data_selector: activation
    params:
      project: project
      activation_id: activation_id
- name: get_alert_config
  endpoint:
    path: /get_alert_config
    method: GET
    data_selector: alert
    params:
      alert_name: alert_name
      project: ''
- name: get_alert_template
  endpoint:
    path: /get_alert_template
    method: GET
    data_selector: template
    params:
      template_name: template_name
- name: monitoring_function_summaries
  endpoint:
    path: /get_monitoring_function_summaries
    method: GET
    data_selector: FunctionSummary
    params: {}
- name: monitoring_function_summary
  endpoint:
    path: /get_monitoring_function_summary
    method: GET
    data_selector: FunctionSummary
    params: {}
- name: nuclio_deploy_status
  endpoint:
    path: /get_nuclio_deploy_status
    method: GET
    data_selector: deploy_status
    params: {}
- name: pipeline
  endpoint:
    path: /get_pipeline
    method: GET
    data_selector: pipeline_details
    params: {}
- name: project
  endpoint:
    path: /get_project
    method: GET
    data_selector: MlrunProject
    params: {}
- name: project_background_task
  endpoint:
    path: /get_project_background_task
    method: GET
    data_selector: BackgroundTask
    params: {}
- name: project_summary
  endpoint:
    path: /get_project_summary
    method: GET
    data_selector: ProjectSummary
    params: {}
- name: schedule
  endpoint:
    path: /get_schedule
    method: GET
    data_selector: ScheduleOutput
    params: {}
- name: workflow_id
  endpoint:
    path: /get_workflow_id
    method: GET
    data_selector: GetWorkflowResponse
    params: {}
- name: alert_activations
  endpoint:
    path: /list_alert_activations
    method: GET
    data_selector: AlertActivations
    params: {}
- name: alert_templates
  endpoint:
    path: /list_alert_templates
    method: GET
    data_selector: AlertTemplate
    params: {}
- name: alerts_configs
  endpoint:
    path: /list_alerts_configs
    method: GET
    data_selector: AlertConfig
    params: {}
- name: api_gateways
  endpoint:
    path: /list_api_gateways
    method: GET
    data_selector: APIGatewaysOutput
    params: {}
- name: artifact_tags
  endpoint:
    path: /list_artifact_tags
    method: GET
    data_selector: tags
    params: {}
- name: artifacts
  endpoint:
    path: /list_artifacts
    method: GET
    data_selector: ArtifactList
    params: {}
- name: monitoring_function_summaries
  endpoint:
    path: /get_monitoring_function_summaries
    method: GET
    data_selector: FunctionSummary
    params: {}
- name: monitoring_function_summary
  endpoint:
    path: /get_monitoring_function_summary
    method: GET
    data_selector: FunctionSummary
    params: {}
- name: nuclio_deploy_status
  endpoint:
    path: /get_nuclio_deploy_status
    method: GET
    data_selector: deploy_status
    params: {}
- name: pipeline
  endpoint:
    path: /get_pipeline
    method: GET
    data_selector: pipeline_details
    params: {}
- name: project
  endpoint:
    path: /get_project
    method: GET
    data_selector: MlrunProject
    params: {}
- name: project_background_task
  endpoint:
    path: /get_project_background_task
    method: GET
    data_selector: BackgroundTask
    params: {}
- name: project_summary
  endpoint:
    path: /get_project_summary
    method: GET
    data_selector: ProjectSummary
    params: {}
- name: schedule
  endpoint:
    path: /get_schedule
    method: GET
    data_selector: ScheduleOutput
    params: {}
- name: workflow_id
  endpoint:
    path: /get_workflow_id
    method: GET
    data_selector: GetWorkflowResponse
    params: {}
- name: alert_activations
  endpoint:
    path: /list_alert_activations
    method: GET
    data_selector: AlertActivations
    params: {}
- name: alert_templates
  endpoint:
    path: /list_alert_templates
    method: GET
    data_selector: AlertTemplate
    params: {}
- name: alerts_configs
  endpoint:
    path: /list_alerts_configs
    method: GET
    data_selector: AlertConfig
    params: {}
- name: api_gateways
  endpoint:
    path: /list_api_gateways
    method: GET
    data_selector: APIGatewaysOutput
    params: {}
- name: artifact_tags
  endpoint:
    path: /list_artifact_tags
    method: GET
    data_selector: tags
    params: {}
- name: artifacts
  endpoint:
    path: /list_artifacts
    method: GET
    data_selector: ArtifactList
    params: {}
- name: list_artifacts
  endpoint:
    path: /list_artifacts
    method: GET
    data_selector: artifacts
    params:
      project: iris
      tag: '*'
      labels:
      - uploaded
      - type=binary
- name: list_datastore_profiles
  endpoint:
    path: /list_datastore_profiles
    method: GET
    data_selector: profiles
    params:
      project: str
- name: list_entities_v2
  endpoint:
    path: /list_entities_v2
    method: GET
    data_selector: entities
    params:
      project: str
      name: str
      tag: str
      labels: str | dict[str, str | None] | list[str] | None
- name: list_feature_sets
  endpoint:
    path: /list_feature_sets
    method: GET
    data_selector: feature_sets
    params:
      project: str
      name: str
      tag: str
      state: str
      entities: list[str] | None
      features: list[str] | None
      labels: str | dict[str, str | None] | list[str] | None
      partition_by: FeatureStorePartitionByField | str
      rows_per_partition: 1
      partition_sort_by: SortField | str
      partition_order: OrderType | str
      format: FeatureSetFormat
- name: list_functions
  endpoint:
    path: /list_functions
    method: GET
    data_selector: functions
    params:
      name: str | None
      project: str | None
      tag: str | None
      labels: str | dict[str, str | None] | list[str] | None
      since: datetime | None
      until: datetime | None
      kind: str | None
      format: FunctionFormat
      states: list[FunctionState] | None
- name: list_hub_sources
  endpoint:
    path: /list_hub_sources
    method: GET
    data_selector: hub_sources
    params:
      item_name: str | None
      tag: str | None
      version: str | None
      item_type: HubSourceType
- name: list_model_endpoints
  endpoint:
    path: /list_model_endpoints
    method: GET
    data_selector: model_endpoints
    params:
      project: str
      names: str | list[str] | None
      function_name: str | None
      function_tag: str | None
      model_name: str | None
      model_tag: str | None
      labels: str | dict[str, str | None] | list[str] | None
      start: datetime | None
      end: datetime | None
      tsdb_metrics: bool
      metric_list: list[str] | None
      top_level: bool
      modes: EndpointMode | list[EndpointMode] | None
      uids: list[str] | None
      latest_only: bool
- name: list_pipelines
  endpoint:
    path: /list_pipelines
    method: GET
    data_selector: pipelines
    params:
      project: str
      namespace: str | None
      sort_by: str
      page_token: str
      filter_: str
      format_: PipelineFormat
      page_size: int | None
- name: list_project_background_tasks
  endpoint:
    path: /list_project_background_tasks
    method: GET
    data_selector: background_tasks
    params:
      project: str | None
      state: str | None
      created_from: datetime | None
      created_to: datetime | None
      last_update_time_from: datetime | None
      last_update_time_to: datetime | None
- name: list_project_secret_keys
  endpoint:
    path: /list_project_secret_keys
    method: GET
    data_selector: secret_keys
    params:
      project: str
      provider: str | SecretProviderName
      token: str | None
- name: list_artifacts
  endpoint:
    path: /list_artifacts
    method: GET
    data_selector: artifacts
    params:
      project: iris
      tag: '*'
      labels:
      - uploaded
      - type=binary
- name: list_datastore_profiles
  endpoint:
    path: /list_datastore_profiles
    method: GET
    data_selector: datastore_profiles
    params:
      project: str
- name: list_entities_v2
  endpoint:
    path: /list_entities_v2
    method: GET
    data_selector: entities
    params:
      project: str
- name: list_feature_sets
  endpoint:
    path: /list_feature_sets
    method: GET
    data_selector: feature_sets
    params:
      project: str
- name: list_feature_vectors
  endpoint:
    path: /list_feature_vectors
    method: GET
    data_selector: feature_vectors
    params:
      project: str
- name: list_features_v2
  endpoint:
    path: /list_features_v2
    method: GET
    data_selector: features
    params:
      project: str
- name: list_functions
  endpoint:
    path: /list_functions
    method: GET
    data_selector: functions
- name: list_hub_sources
  endpoint:
    path: /list_hub_sources
    method: GET
    data_selector: hub_sources
- name: list_model_endpoints
  endpoint:
    path: /list_model_endpoints
    method: GET
    data_selector: model_endpoints
    params:
      project: str
- name: list_pipelines
  endpoint:
    path: /list_pipelines
    method: GET
    data_selector: pipelines
    params:
      project: str
- name: list_project_background_tasks
  endpoint:
    path: /list_project_background_tasks
    method: GET
    data_selector: background_tasks
    params:
      project: str
- name: list_project_secret_keys
  endpoint:
    path: /list_project_secret_keys
    method: GET
    data_selector: secret_keys
    params:
      project: str
      provider: kubernetes
- name: list_project_secrets
  endpoint:
    path: /list_project_secrets
    method: GET
- name: list_projects
  endpoint:
    path: /list_projects
    method: GET
- name: list_runs
  endpoint:
    path: /list_runs
    method: GET
- name: project_secrets
  endpoint:
    path: /list_project_secrets
    method: GET
- name: projects
  endpoint:
    path: /list_projects
    method: GET
- name: runs
  endpoint:
    path: /list_runs
    method: GET
- name: list_runs
  endpoint:
    path: /list_runs
    method: GET
    data_selector: runs
    params: {}
- name: list_runtime_resources
  endpoint:
    path: /list_runtime_resources
    method: GET
    data_selector: runtime_resources
    params: {}
- name: list_schedules
  endpoint:
    path: /list_schedules
    method: GET
    data_selector: schedules
    params: {}
- name: list_secret_tokens
  endpoint:
    path: /list_secret_tokens
    method: GET
    data_selector: secret_tokens
    params: {}
- name: load_project
  endpoint:
    path: /load_project
    method: POST
    data_selector: project
    params: {}
- name: paginated_api_call
  endpoint:
    path: /paginated_api_call
    method: GET
    data_selector: api_call
    params: {}
- name: paginated_list_alert_activations
  endpoint:
    path: /paginated_list_alert_activations
    method: GET
    data_selector: alert_activations
    params: {}
- name: paginated_list_artifacts
  endpoint:
    path: /paginated_list_artifacts
    method: GET
    data_selector: artifacts
    params: {}
- name: paginated_list_functions
  endpoint:
    path: /paginated_list_functions
    method: GET
    data_selector: functions
    params: {}
- name: paginated_list_runs
  endpoint:
    path: /paginated_list_runs
    method: GET
    data_selector: runs
    params: {}
- name: list_runs
  endpoint:
    path: /list_runs
    method: GET
    data_selector: runs
    params: {}
- name: list_runtime_resources
  endpoint:
    path: /list_runtime_resources
    method: GET
    data_selector: resources
    params: {}
- name: list_schedules
  endpoint:
    path: /list_schedules
    method: GET
    data_selector: schedules
    params: {}
- name: list_secret_tokens
  endpoint:
    path: /list_secret_tokens
    method: GET
    data_selector: tokens
    params: {}
- name: load_project
  endpoint:
    path: /load_project
    method: POST
    data_selector: project
    params: {}
- name: paginated_api_call
  endpoint:
    path: /paginated_api_call
    method: GET
    data_selector: results
    params: {}
- name: paginated_list_alert_activations
  endpoint:
    path: /paginated_list_alert_activations
    method: GET
    data_selector: alert_activations
    params: {}
- name: paginated_list_artifacts
  endpoint:
    path: /paginated_list_artifacts
    method: GET
    data_selector: artifacts
    params: {}
- name: paginated_list_functions
  endpoint:
    path: /paginated_list_functions
    method: GET
    data_selector: functions
    params: {}
- name: paginated_list_runs
  endpoint:
    path: /paginated_list_runs
    method: GET
    data_selector: runs
    params: {}
- name: feature_set
  endpoint:
    path: /mlrun/db/httpdb/store_feature_set
    method: POST
- name: feature_vector
  endpoint:
    path: /mlrun/db/httpdb/patch_feature_vector
    method: PATCH
- name: model_endpoint
  endpoint:
    path: /mlrun/db/httpdb/patch_model_endpoint
    method: PATCH
- name: project
  endpoint:
    path: /mlrun/db/httpdb/patch_project
    method: PATCH
- name: feature_vector
  endpoint:
    path: /store_feature_vector
    method: POST
    data_selector: dict
- name: function
  endpoint:
    path: /store_function
    method: POST
    data_selector: dict
- name: hub_source
  endpoint:
    path: /store_hub_source
    method: POST
    data_selector: dict
- name: log
  endpoint:
    path: /store_log
    method: POST
    data_selector: dict
- name: project
  endpoint:
    path: /store_project
    method: POST
    data_selector: dict
- name: run
  endpoint:
    path: /store_run
    method: POST
    data_selector: dict
- name: run_notifications
  endpoint:
    path: /store_run_notifications
    method: POST
    data_selector: dict
- name: secret_token
  endpoint:
    path: /store_secret_token
    method: POST
    data_selector: dict
- name: pipeline
  endpoint:
    path: /submit_pipeline
    method: POST
    data_selector: dict
- name: workflow
  endpoint:
    path: /submit_workflow
    method: POST
    data_selector: dict
- name: artifacts
  endpoint:
    path: /tag_artifacts
    method: POST
    data_selector: dict
- name: objects
  endpoint:
    path: /tag_objects
    method: POST
    data_selector: dict
- name: pipeline_termination
  endpoint:
    path: /terminate_pipeline
    method: POST
    data_selector: dict
- name: model_monitoring_controller
  endpoint:
    path: /update_model_monitoring_controller
    method: POST
    data_selector: dict
- name: run_update
  endpoint:
    path: /update_run
    method: PATCH
    data_selector: dict
- name: schedule_update
  endpoint:
    path: /update_schedule
    method: PUT
    data_selector: dict
- name: authorization_verification
  endpoint:
    path: /verify_authorization
    method: POST
    data_selector: dict
- name: feature_vector
  endpoint:
    path: /store_feature_vector
    method: POST
    data_selector: feature_vector
    params: {}
- name: function
  endpoint:
    path: /store_function
    method: POST
    data_selector: function
    params: {}
- name: hub_source
  endpoint:
    path: /store_hub_source
    method: POST
    data_selector: source
    params: {}
- name: log
  endpoint:
    path: /store_log
    method: POST
    data_selector: log
    params: {}
- name: project
  endpoint:
    path: /store_project
    method: POST
    data_selector: project
    params: {}
- name: run
  endpoint:
    path: /store_run
    method: POST
    data_selector: run
    params: {}
- name: run_notifications
  endpoint:
    path: /store_run_notifications
    method: POST
    data_selector: notification_objects
    params: {}
- name: secret_token
  endpoint:
    path: /store_secret_token
    method: POST
    data_selector: secret_token
    params: {}
- name: secret_tokens
  endpoint:
    path: /store_secret_tokens
    method: POST
    data_selector: secret_tokens
    params: {}
- name: job
  endpoint:
    path: /submit_job
    method: POST
    data_selector: runspec
    params: {}
- name: pipeline
  endpoint:
    path: /submit_pipeline
    method: POST
    data_selector: pipeline
    params: {}
- name: workflow
  endpoint:
    path: /submit_workflow
    method: POST
    data_selector: workflow_spec
    params: {}
- name: artifacts
  endpoint:
    path: /tag_artifacts
    method: POST
    data_selector: artifacts
    params: {}
- name: objects
  endpoint:
    path: /tag_objects
    method: POST
    data_selector: objects
    params: {}
- name: pipeline_termination
  endpoint:
    path: /terminate_pipeline
    method: POST
    data_selector: run_id
    params: {}
- name: migrations
  endpoint:
    path: /trigger_migrations
    method: POST
    data_selector: migrations
    params: {}
- name: model_monitoring_controller
  endpoint:
    path: /update_model_monitoring_controller
    method: POST
    data_selector: project
    params: {}
- name: run_update
  endpoint:
    path: /update_run
    method: POST
    data_selector: updates
    params: {}
- name: schedule_update
  endpoint:
    path: /update_schedule
    method: POST
    data_selector: schedule
    params: {}
- name: authorization
  endpoint:
    path: /verify_authorization
    method: POST
    data_selector: authorization_verification_input
    params: {}
- name: background_task
  endpoint:
    path: /wait_for_background_task_to_reach_terminal_state
    method: POST
    data_selector: name
    params: {}
- name: log_watch
  endpoint:
    path: /watch_log
    method: POST
    data_selector: uid
    params: {}
- name: project_management
  endpoint:
    path: ./projects/project.html
    method: GET
    data_selector: records
    params: {}
- name: data_management
  endpoint:
    path: ./genai/data-mgmt/index.html
    method: GET
    data_selector: records
    params: {}
- name: development
  endpoint:
    path: ./genai/development/index.html
    method: GET
    data_selector: records
    params: {}
- name: deployment
  endpoint:
    path: ./genai/deployment/index.html
    method: GET
    data_selector: records
    params: {}
- name: live_ops
  endpoint:
    path: ./genai/live-ops/index.html
    method: GET
    data_selector: records
    params: {}
- name: monitoring
  endpoint:
    path: ./concepts/model-monitoring.html
    method: GET
    data_selector: records
    params: {}
- name: ingest_and_process_data
  endpoint:
    path: ./data-prep/index.html
    method: GET
    data_selector: records
    params: {}
- name: develop_and_train_models
  endpoint:
    path: ./development/index.html
    method: GET
    data_selector: records
    params: {}
- name: deploy_models_and_applications
  endpoint:
    path: ./deployment/index.html
    method: GET
    data_selector: records
    params: {}
- name: monitor_and_alert
  endpoint:
    path: ./concepts/model-monitoring.html
    method: GET
    data_selector: records
    params: {}
- name: project
  endpoint:
    path: /projects
    method: GET
    data_selector: projects
- name: project
  endpoint:
    path: /mlrun/projects
    method: POST
    data_selector: project
    params:
      name: genai-tutorial
      path: ./
      user_project: true
      allow_cross_project: true
- name: fetch-vectordb-data
  endpoint:
    path: /src/fetch-vectordb-data.py
    method: POST
    data_selector: outputs
    params:
      data_set: DATA_SET
- name: build-vectordb
  endpoint:
    path: /src/build-vector-db.py
    method: POST
    data_selector: outputs
    params:
      cache_dir: CACHE_DIR
- name: serve-llm
  endpoint:
    path: /src/serving.py
    method: POST
    data_selector: outputs
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: fetch-vectordb-data
  endpoint:
    path: src/fetch-vectordb-data.py
    method: POST
    data_selector: outputs
    params:
      data_set: mlrun.get_sample_path("data/genai-tutorial/labelled_newscatcher_dataset.csv")
- name: build-vectordb
  endpoint:
    path: src/build-vector-db.py
    method: POST
    data_selector: outputs
    params:
      cache_dir: CACHE_DIR
- name: serve-llm
  endpoint:
    path: src/serving.py
    method: POST
    data_selector: outputs
- name: project
  endpoint:
    path: /projects
    method: GET
    data_selector: projects
    params:
      incremental: updated_at
- name: project
  endpoint:
    path: /projects
    method: GET
    data_selector: projects
    params:
      incremental: created_at
- name: llm_monitoring_df
  endpoint:
    path: /v2/models/gpt2/infer
    method: POST
    data_selector: outputs
    params: {}
- name: milvus-config
  endpoint:
    path: /api/config
    method: GET
    data_selector: configuration
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: fetch-vectordb-data
  endpoint:
    path: src/fetch-vectordb-data.py
    method: POST
    data_selector: outputs
    params:
      data_set: mlrun.get_sample_path("data/genai-tutorial/labelled_newscatcher_dataset.csv")
- name: build-vectordb
  endpoint:
    path: src/build-vector-db.py
    method: POST
    data_selector: outputs
    params:
      cache_dir: CACHE_DIR
- name: serve-llm
  endpoint:
    path: src/serving.py
    method: POST
    data_selector: outputs
    params: {}
- name: llm_monitoring_df
  endpoint:
    path: /v2/models/gpt2/infer
    method: POST
    data_selector: outputs
    params: {}
- name: milvus-config
  endpoint:
    path: /milvus/config
    method: GET
    data_selector: public
    params: {}
- name: project
  endpoint:
    path: /projects
    method: GET
    data_selector: projects
    params: {}
- name: function
  endpoint:
    path: /functions
    method: GET
    data_selector: functions
    params: {}
- name: models
  endpoint:
    path: /v2/models/
    method: GET
    data_selector: models
- name: infer_cancer_classifier
  endpoint:
    path: /v2/models/cancer-classifier/infer
    method: POST
    data_selector: outputs
- name: project
  endpoint:
    path: /projects
    method: GET
    data_selector: projects
    params: {}
- name: function
  endpoint:
    path: /functions
    method: GET
    data_selector: functions
    params: {}
- name: trainer
  endpoint:
    path: /function/trainer
    method: POST
    data_selector: outputs
    params: {}
- name: models
  endpoint:
    path: /list_models
    method: GET
    data_selector: models
    params: {}
- name: models
  endpoint:
    path: /v2/models/
    method: GET
    data_selector: models
- name: infer
  endpoint:
    path: /v2/models/cancer-classifier/infer
    method: POST
    data_selector: outputs
- name: models
  endpoint:
    path: /models
    method: GET
    data_selector: models
    params: {}
- name: model_serving
  endpoint:
    path: /mlrun/serving
    method: POST
    data_selector: serving_fn
    params: {}
- name: infer
  endpoint:
    path: /v2/models/cancer-classifier/infer
    method: POST
    data_selector: outputs
- name: trainer
  endpoint:
    path: /src/trainer.py
    method: POST
    data_selector: outputs
    params: {}
- name: models
  endpoint:
    path: /list_models
    method: GET
    data_selector: models
    params: {}
- name: runs
  endpoint:
    path: /project/list_runs
    method: GET
    data_selector: results
- name: infer
  endpoint:
    path: /v2/models/cancer-classifier/infer
    method: POST
- name: models
  endpoint:
    path: /v2/models/
    method: GET
    data_selector: models
    params: {}
- name: infer
  endpoint:
    path: /v2/models/{framework}/infer
    method: POST
    data_selector: outputs
    params: {}
- name: infer_dict
  endpoint:
    path: /v2/models/{framework}/infer_dict
    method: POST
    data_selector: outputs
    params: {}
- name: model-serving
  endpoint:
    path: /v2/models/
    method: GET
    data_selector: models
- name: infer
  endpoint:
    path: /v2/models/{framework}/infer
    method: POST
    data_selector: outputs
- name: infer_dict
  endpoint:
    path: /v2/models/{framework}/infer_dict
    method: POST
    data_selector: outputs
- name: data-prep
  endpoint:
    path: /projects/tutorial/functions/data-prep
    method: POST
    data_selector: outputs
    params:
      incremental: updated_at
- name: pipeline-serving
  endpoint:
    path: /projects/tutorial/functions/pipeline-serving
    method: POST
    data_selector: outputs
    params: {}
- name: model_monitoring
  endpoint:
    path: /model-monitoring
    method: GET
    data_selector: artifacts
    params: {}
- name: model_invoke
  endpoint:
    path: /invoke
    method: POST
    data_selector: results
    params: {}
- name: project
  endpoint:
    path: /projects
    method: GET
    data_selector: projects
    params: {}
- name: function
  endpoint:
    path: /functions
    method: GET
    data_selector: functions
    params: {}
- name: model_monitoring
  endpoint:
    path: /model_monitoring
    method: GET
    data_selector: artifacts
- name: model_monitoring
  endpoint:
    path: /model_monitoring
    method: POST
    data_selector: result
    params: {}
- name: model_monitoring
  endpoint:
    path: /v2/models/{model_name}/infer
    method: POST
    data_selector: outputs
- name: model_monitoring
  endpoint:
    path: /model-monitoring
    method: POST
    data_selector: artifacts
    params: {}
- name: model_monitoring
  endpoint:
    path: /model_monitoring
    method: GET
    data_selector: results
- name: model_monitoring
  endpoint:
    path: /v2/models/{model_name}/infer
    method: POST
- name: slack_notification
  endpoint:
    path: /
    method: POST
    data_selector: notification
    params:
      webhook: https://hooks.slack.com/
- name: model_monitoring
  endpoint:
    path: /model_monitoring
    method: POST
    data_selector: results
    params: {}
- name: model_monitoring
  endpoint:
    path: /api/model_monitoring
    method: POST
    data_selector: results
    params: {}
- name: notification
  endpoint:
    path: /notification
    method: POST
    data_selector: notification
    params: {}
- name: model
  endpoint:
    path: /models/batch-predict/model-1_9_2.pkl
    method: GET
    data_selector: model_artifact
    params: {}
- name: training_set
  endpoint:
    path: /data/batch-predict/training_set.parquet
    method: GET
    data_selector: data
    params: {}
- name: prediction_set
  endpoint:
    path: /data/batch-predict/prediction_set.parquet
    method: GET
    data_selector: data
    params: {}
- name: drifted_prediction_set
  endpoint:
    path: /data/batch-predict/drifted_prediction_set.parquet
    method: GET
    data_selector: data
    params: {}
- name: predictions
  endpoint:
    path: /predictions
    method: GET
    data_selector: records
    params: {}
- name: drift_status
  endpoint:
    path: /drift_status
    method: GET
    data_selector: records
    params: {}
- name: model_monitoring
  endpoint:
    path: /model_monitoring
    method: POST
    data_selector: data
    params: {}
- name: alert_config
  endpoint:
    path: /store_alert_config
    method: POST
    data_selector: alert_data
- name: model_inference
  endpoint:
    path: /v2/models/{model_name}/infer
    method: POST
    data_selector: inputs
- name: train_set
  endpoint:
    path: /train_set
    method: GET
    data_selector: records
- name: test_set
  endpoint:
    path: /test_set
    method: GET
    data_selector: records
- name: model
  endpoint:
    path: models/batch-predict/model-1_9_2.pkl
    method: GET
    data_selector: model_artifact.uri
    params: {}
- name: predictions
  endpoint:
    path: /predictions
    method: GET
    data_selector: records
- name: drift_status
  endpoint:
    path: /drift-status
    method: GET
    data_selector: records
- name: train_set
  endpoint:
    path: ./train.csv
    method: GET
    data_selector: data
    params: {}
- name: test_set
  endpoint:
    path: ./test.csv
    method: GET
    data_selector: data
    params: {}
- name: taxi_fare_submission
  endpoint:
    path: /taxi_fare_submission
    method: POST
    data_selector: submission
    params: {}
- name: train_set
  endpoint:
    path: https://s3.us-east-1.wasabisys.com/iguazio/data/nyc-taxi/train.csv
    method: GET
    data_selector: train_set
    params: {}
- name: test_set
  endpoint:
    path: https://s3.us-east-1.wasabisys.com/iguazio/data/nyc-taxi/test.csv
    method: GET
    data_selector: test_set
    params: {}
- name: train_data
  endpoint:
    path: /get_input/train_set
    method: GET
    data_selector: data
    params: {}
- name: test_data
  endpoint:
    path: /get_input/test_set
    method: GET
    data_selector: data
    params: {}
- name: quotes
  endpoint:
    path: /api/v1/quotes
    method: GET
    data_selector: records
- name: trades
  endpoint:
    path: /api/v1/trades
    method: GET
    data_selector: records
- name: stocks
  endpoint:
    path: /api/v1/stocks
    method: GET
    data_selector: records
- name: stocks
  endpoint:
    path: /feature-sets/stocks
    method: POST
    data_selector: records
- name: quotes
  endpoint:
    path: /quotes
    method: GET
    data_selector: records
- name: train_set
  endpoint:
    path: /get_input/train_set
    method: GET
    data_selector: data
    params: {}
- name: test_set
  endpoint:
    path: /get_input/test_set
    method: GET
    data_selector: data
    params: {}
- name: taxi_fare_submission
  endpoint:
    path: /log_dataset/taxi_fare_submission
    method: POST
    data_selector: submission
    params:
      format: csv
- name: stocks
  endpoint:
    path: /feature-sets/stocks
    method: POST
    data_selector: records
    params: {}
- name: stock-quotes
  endpoint:
    path: /feature-sets/stock-quotes
    method: POST
    data_selector: records
    params: {}
- name: feature_vector
  endpoint:
    path: /fstore/FeatureVector
    method: GET
    data_selector: features
    params: {}
- name: online_feature_service
  endpoint:
    path: /service/online
    method: GET
    data_selector: service
    params: {}
- name: train_set
  endpoint:
    path: /train.csv
    method: GET
    data_selector: data
    params: {}
- name: test_set
  endpoint:
    path: /test.csv
    method: GET
    data_selector: data
    params: {}
- name: train_set
  endpoint:
    path: https://s3.us-east-1.wasabisys.com/iguazio/data/nyc-taxi/train.csv
    method: GET
    data_selector: data
    params: {}
- name: test_set
  endpoint:
    path: https://s3.us-east-1.wasabisys.com/iguazio/data/nyc-taxi/test.csv
    method: GET
    data_selector: data
    params: {}
- name: mlflow_tracking
  endpoint:
    path: /api/2.0/mlflow/runs
    method: POST
    data_selector: runs
    params: {}
- name: quotes
  endpoint:
    path: /path/to/quotes
    method: GET
    data_selector: records
- name: trades
  endpoint:
    path: /path/to/trades
    method: GET
    data_selector: records
- name: stocks
  endpoint:
    path: /path/to/stocks
    method: GET
    data_selector: records
- name: mlflow-tracking-example
  endpoint:
    path: /mlflow-tracking-example
    method: GET
    data_selector: records
    params: {}
- name: quotes
  endpoint:
    path: /path/to/quotes/endpoint
    method: GET
    data_selector: records
    params: {}
- name: trades
  endpoint:
    path: /path/to/trades/endpoint
    method: GET
    data_selector: records
    params: {}
- name: stocks
  endpoint:
    path: /path/to/stocks/endpoint
    method: GET
    data_selector: records
    params: {}
- name: train_run_outputs
  endpoint:
    path: /train_run/outputs
    method: GET
    data_selector: outputs
    params: {}
- name: train_run_status_results
  endpoint:
    path: /train_run/status/results
    method: GET
    data_selector: results
    params: {}
- name: train_run_artifact
  endpoint:
    path: /train_run/artifact
    method: GET
    data_selector: artifact
    params: {}
- name: result
  endpoint:
    path: /result
    method: GET
    data_selector: result
    params: {}
- name: quotes
  endpoint:
    path: /fstore/FeatureSet
    method: POST
    data_selector: quotes
- name: mlflow-tracking-example
  endpoint:
    path: /mlflow-tracking-example
    method: GET
    data_selector: results
    params: {}
- name: stocks
  endpoint:
    path: /path/to/stocks/endpoint
    method: GET
    data_selector: records
    params: {}
- name: quotes
  endpoint:
    path: /path/to/quotes/endpoint
    method: GET
    data_selector: records
    params: {}
- name: trades
  endpoint:
    path: /path/to/trades/endpoint
    method: GET
    data_selector: records
    params: {}
- name: stock-quotes
  endpoint:
    path: /stocks/quotes
    method: GET
    data_selector: records
    params: {}
- name: mlrun_tracking
  endpoint:
    path: /mlrun/tracking
    method: POST
    data_selector: records
- name: mlflow-tracking-example
  endpoint:
    path: /mlprojects/mlflow-tracking-example/jobs/monitor-jobs/example-xgb-run-example-xgb-run
    method: GET
    data_selector: results
    params: {}
- name: train_run_outputs
  endpoint:
    path: /train_run/outputs
    method: GET
    data_selector: outputs
    params: {}
- name: train_run_status_results
  endpoint:
    path: /train_run/status/results
    method: GET
    data_selector: results
    params: {}
- name: feature_importance_weight_png
  endpoint:
    path: /train_run/artifact/feature_importance_weight_png
    method: GET
    data_selector: artifact
    params: {}
- name: result
  endpoint:
    path: /result
    method: GET
    data_selector: result
    params: {}
- name: training_function
  endpoint:
    path: /mlrun/projects/mlflow-tracking-example/functions/example-xgb-run
    method: POST
- name: mpijob
  endpoint:
    path: /mpijob
    method: POST
- name: dask
  endpoint:
    path: /dask
    method: POST
- name: spark
  endpoint:
    path: /spark
    method: POST
- name: databricks
  endpoint:
    path: /databricks
    method: POST
- name: mlflow_xgb_model
  endpoint:
    path: /v2/models/mlflow_xgb_model/predict
    method: POST
    data_selector: outputs
- name: project
  endpoint:
    path: /projects
    method: GET
    data_selector: projects
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: project
  endpoint:
    path: /projects
    method: GET
    data_selector: projects
- name: function
  endpoint:
    path: /functions
    method: GET
    data_selector: functions
- name: trainer
  endpoint:
    path: train_code.py
    method: POST
    data_selector: function
    params: {}
- name: hp_tuning_run
  endpoint:
    path: hp
    method: POST
    data_selector: function
    params: {}
- name: mpijob
  endpoint:
    path: /functions/mpijob
    method: POST
    data_selector: spec
    params:
      replicas: 3
- name: dask
  endpoint:
    path: /functions/dask
    method: POST
    data_selector: spec
    params:
      remote: true
      replicas: 5
      service_type: NodePort
      nthreads: 5
- name: spark
  endpoint:
    path: /functions/spark
    method: POST
    data_selector: spec
    params:
      replicas: 2
- name: databricks
  endpoint:
    path: /functions/databricks
    method: POST
    data_selector: spec
    params: {}
- name: project
  endpoint:
    path: /projects
    method: GET
    data_selector: projects
    params: {}
- name: project
  endpoint:
    path: /projects
    method: GET
    data_selector: projects
    params: {}
- name: kafka_trigger
  endpoint:
    path: /kafka/trigger
    method: POST
    data_selector: spec
    params:
      brokers:
      - 192.168.1.123:39092
      topics:
      - TOPIC
      partitions: 4
      consumer_group: serving
      initial_offset: earliest
- name: get-data
  endpoint:
    path: get-data
    method: POST
    data_selector: cleaned_data
    params:
      label_column: ''
- name: train
  endpoint:
    path: train
    method: POST
    data_selector: model
    params:
      label_column: ''
- name: project
  endpoint:
    path: /mlrun/projects
    method: GET
    data_selector: projects
- name: function
  endpoint:
    path: /mlrun/functions
    method: GET
    data_selector: functions
- name: ingest
  endpoint:
    path: get-data
    method: POST
    data_selector: cleaned_data
    params:
      label_column: label_column
- name: train
  endpoint:
    path: train
    method: POST
    data_selector: model
    params:
      label_column: label_column
- name: pipeline
  endpoint:
    path: /pipeline
    method: POST
    data_selector: pipeline
    params: {}
- name: get-data
  endpoint:
    path: get_data.py
    method: job
    data_selector: outputs
    params: {}
- name: train
  endpoint:
    path: train.py
    method: job
    data_selector: outputs
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: batch_inference
  endpoint:
    path: /hub/batch_inference
    method: POST
    data_selector: batch_run
    params:
      inputs:
        dataset: prediction_set_path
      params:
        model: model_artifact.uri
- name: model_monitoring
  endpoint:
    path: /hub/v2_model_server
    method: POST
    data_selector: serving_fn
    params:
      model:
        path: store://models/project-name/model:latest
- name: alerts
  endpoint:
    path: /alerts
    method: POST
    data_selector: alert_data
    params:
      project: project_name
      name: alert_name
      summary: alert_summary
      severity: LOW
- name: notifications
  endpoint:
    path: /notifications
    method: POST
    data_selector: notification
    params:
      kind: slack
      name: slack_notification
      message: A drift was detected
      severity: warning
      when:
      - now
      condition: failed
      secret_params:
        webhook: https://hooks.slack.com/
- name: project
  endpoint:
    path: /projects
    method: GET
    data_selector: projects
    params: {}
- name: function
  endpoint:
    path: /functions
    method: GET
    data_selector: functions
    params: {}
- name: get-data
  endpoint:
    path: get_data.py
    method: POST
- name: train
  endpoint:
    path: train.py
    method: POST
- name: get-data
  endpoint:
    path: get-data
    method: POST
- name: train
  endpoint:
    path: train
    method: POST
- name: heart-disease-pandas
  endpoint:
    path: /User/test.csv
    method: write_dataframe
    data_selector: records
- name: heart-disease-spark
  endpoint:
    path: /User/test.parquet
    method: write_dataframe
    data_selector: records
- name: heart-disease-storey
  endpoint:
    path: /User/test
    method: ingest
    data_selector: records
- name: get-data
  endpoint:
    path: get_data.py
    method: GET
    data_selector: outputs
    params: {}
- name: train
  endpoint:
    path: train.py
    method: GET
    data_selector: outputs
    params: {}
- name: batch_inference
  endpoint:
    path: /hub/batch_inference
    method: POST
    data_selector: batch_run
    params:
      inputs:
        dataset: prediction_set_path
      params:
        model: model_artifact.uri
- name: batch_drift_detection
  endpoint:
    path: /hub/batch_inference_v2
    method: POST
    data_selector: batch_run
    params:
      inputs:
        dataset: prediction_set_path
        sample_set: training_set_path
      params:
        model: model_artifact.uri
        label_columns: label
        perform_drift_analysis: true
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: project
  endpoint:
    path: /projects
    method: GET
    data_selector: projects
    params: {}
- name: function
  endpoint:
    path: /functions
    method: GET
    data_selector: functions
    params: {}
- name: heart-disease-categorical
  endpoint:
    path: ./data/heart_disease_categorical.parquet
    method: GET
    data_selector: data
    params: {}
- name: heart-disease-storey
  endpoint:
    path: ./data/heart_disease_storey
    method: GET
    data_selector: data
    params: {}
- name: heart-disease-pandas
  endpoint:
    path: ./data/heart_disease_pandas
    method: GET
    data_selector: data
    params: {}
- name: heart-disease-spark
  endpoint:
    path: ./data/heart_disease_spark
    method: GET
    data_selector: data
    params: {}
- name: get-data
  endpoint:
    path: get-data
    method: POST
- name: train
  endpoint:
    path: train
    method: POST
- name: heart-disease-vector
  endpoint:
    path: /feature-store/feature-vectors
    method: GET
    data_selector: features
    params: {}
- name: heart-disease-pandas
  endpoint:
    path: /User/test.csv
    method: write_dataframe
    data_selector: df
    params:
      key_column: id
- name: heart-disease-spark
  endpoint:
    path: /User/test.parquet
    method: write_dataframe
    data_selector: df
    params:
      key_column: id
- name: heart-disease-storey
  endpoint:
    path: /User/test.csv
    method: write_dataframe
    data_selector: df
    params:
      key_column: id
- name: project
  endpoint:
    path: /projects
    method: GET
    data_selector: projects
    params: {}
- name: function
  endpoint:
    path: /functions
    method: GET
    data_selector: functions
    params: {}
- name: batch-pipeline
  endpoint:
    path: pipeline
    method: POST
    data_selector: outputs
    params: {}
- name: get-data
  endpoint:
    path: get-data
    method: POST
    data_selector: outputs
    params: {}
- name: train
  endpoint:
    path: train
    method: POST
    data_selector: outputs
    params: {}
- name: heart-disease-vector
  endpoint:
    path: /feature-store/feature-vectors/heart-disease-vector
    method: GET
    data_selector: features
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: simple-graph
  endpoint:
    path: /set_function
    method: POST
    data_selector: function
    params: {}
- name: mock-server
  endpoint:
    path: /to_mock_server
    method: GET
    data_selector: server
    params: {}
- name: get-data
  endpoint:
    path: get-data
    method: POST
    data_selector: data
    params: {}
- name: train
  endpoint:
    path: train
    method: POST
    data_selector: data
    params: {}
- name: project
  endpoint:
    path: /projects
    method: GET
    data_selector: projects
    params: {}
- name: simple-graph
  endpoint:
    path: /v2/models/model1/infer
    method: POST
    data_selector: inputs
    params: {}
- name: heart-disease-categorical
  endpoint:
    path: /data/heart_disease_categorical.parquet
    method: GET
    data_selector: records
- name: heart-disease-storey
  endpoint:
    path: /data/heart_disease_storey
    method: GET
    data_selector: records
- name: heart-disease-pandas
  endpoint:
    path: /data/heart_disease_pandas
    method: GET
    data_selector: records
- name: heart-disease-spark
  endpoint:
    path: /data/heart_disease_spark
    method: GET
    data_selector: records
- name: simple-graph
  endpoint:
    path: /v2/models/model1/infer
    method: POST
    data_selector: inputs
    params: {}
- name: advanced
  endpoint:
    path: /advanced
    method: POST
    data_selector: results
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: heart-disease-categorical
  endpoint:
    path: /data/heart_disease_categorical.parquet
    method: GET
    data_selector: records
- name: heart-disease-storey
  endpoint:
    path: /data/heart_disease_storey
    method: GET
    data_selector: records
- name: heart-disease-pandas
  endpoint:
    path: /data/heart_disease_pandas
    method: GET
    data_selector: records
- name: heart-disease-spark
  endpoint:
    path: /data/heart_disease_spark
    method: GET
    data_selector: records
- name: simple-graph
  endpoint:
    path: /v2/models/model1/infer
    method: POST
    data_selector: inputs
    params: {}
- name: advanced
  endpoint:
    path: /advanced
    method: POST
    data_selector: inputs
    params: {}
- name: simple-graph
  endpoint:
    path: /v2/models/model1/infer
    method: POST
    data_selector: inputs
    params: {}
- name: hyperparameter_tuning
  endpoint:
    path: /hyperparams/tuning
    method: POST
    data_selector: results
    params: {}
- name: hyperparameter_tuning
  endpoint:
    path: /hyperparameters/tuning
    method: POST
    data_selector: results
- name: mlrun
  endpoint:
    path: /mlrun
    method: GET
    data_selector: records
- name: mlrun
  endpoint:
    path: /mlrun
    method: GET
    data_selector: records
    params: {}
- name: mlrun
  endpoint:
    path: /mlrun
    method: GET
    data_selector: records
- name: nuclio
  endpoint:
    path: /nuclio
    method: GET
    data_selector: records
- name: jupyter
  endpoint:
    path: /jupyter
    method: GET
    data_selector: records
- name: kafka
  endpoint:
    path: /kafka
    method: GET
    data_selector: records
- name: prometheus
  endpoint:
    path: /prometheus
    method: GET
    data_selector: records
- name: tdengine
  endpoint:
    path: /tdengine
    method: GET
    data_selector: records
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: mlrun_api
  endpoint:
    path: /
    method: GET
- name: mlrun_dbpath
  endpoint:
    path: /mlrun-api
    method: GET
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: mlrun
  endpoint:
    path: /
    method: GET
    data_selector: records
    params: {}
- name: calls_analysis
  endpoint:
    path: /calls_analysis
    method: POST
    data_selector: results
    params:
      batch_size: 2
      transcribe_model: openai/whisper-large-v3
      translate_to_english: true
      pii_recognition_model: whole
      pii_recognition_entities:
      - PERSON
      - EMAIL
      - PHONE
      question_answering_model: TheBloke/Mistral-7B-OpenOrca-GPTQ
- name: milvus-config
  endpoint:
    path: /milvus/config
    method: POST
    data_selector: result
- name: call_analysis
  endpoint:
    path: /calls_analysis
    method: POST
    data_selector: results
    params: {}
- name: chroma
  endpoint:
    path: /ingest-to-chroma
    method: POST
    data_selector: results
    params: {}
- name: milvus
  endpoint:
    path: /milvus-config
    method: POST
    data_selector: profile
    params: {}
- name: Milvus configuration
  endpoint:
    path: /milvus/config
    method: GET
- name: Creating an MLRun collection from Milvus
  endpoint:
    path: /milvus/create_collection
    method: POST
- name: Creating the Milvus vector store
  endpoint:
    path: /milvus/create_vector_store
    method: POST
- name: MLRun document artifact
  endpoint:
    path: /mlrun/document_artifact
    method: GET
- name: Using MLRunLoader
  endpoint:
    path: /mlrun/loader
    method: GET
- name: Using MLRunLoader with DirectoryLoader
  endpoint:
    path: /mlrun/loader/directory
    method: GET
- name: milvus-config
  endpoint:
    path: /milvus
    method: POST
    data_selector: configuration
    params: {}
- name: MLRun document artifact
  endpoint:
    path: /api/mlrun/datastore/vectorstore
    method: POST
    data_selector: artifacts
    params: {}
- name: chroma
  endpoint:
    path: /chroma/ingest
    method: POST
    data_selector: documents
    params: {}
- name: milvus
  endpoint:
    path: /milvus/config
    method: POST
    data_selector: profile
    params: {}
- name: milvus-config
  endpoint:
    path: /api/milvus/config
    method: POST
    data_selector: config
    params: {}
- name: document_loader
  endpoint:
    path: /create_document_loader
    method: POST
    data_selector: loaded_documents
    params: {}
- name: milvus-config
  endpoint:
    path: /register_temporary_client_datastore_profile
    method: POST
    data_selector: profile
- name: vector_store_collection
  endpoint:
    path: /api/mlrun/projects/get_vector_store_collection
    method: GET
    data_selector: collection
    params: {}
- name: milvus_config
  endpoint:
    path: /config/milvus
    method: POST
    data_selector: profile
    params: {}
- name: create_collection
  endpoint:
    path: /collections
    method: POST
    data_selector: collection
    params: {}
- name: document_loader_spec
  endpoint:
    path: loader_spec
    method: POST
    data_selector: specifications
    params: {}
- name: mlrun-guardrails
  endpoint:
    path: /run/mlrun-guardrails
    method: POST
    data_selector: response
    params:
      prompt: string
- name: milvus-config
  endpoint:
    path: /api/v1/milvus/config
    method: POST
    data_selector: config
    params: {}
- name: create-collection
  endpoint:
    path: /api/v1/milvus/collection
    method: POST
    data_selector: collection
    params: {}
- name: add-documents
  endpoint:
    path: /api/v1/milvus/collection/documents
    method: POST
    data_selector: documents
    params: {}
- name: index
  endpoint:
    path: /index
    method: POST
    data_selector: documents
    params:
      url_column: url
      chunk_size: 2000
      chunk_overlap: 200
- name: rag
  endpoint:
    path: /rag
    method: POST
    data_selector: prediction
    params: {}
- name: invoke_function
  endpoint:
    path: /
    method: POST
    data_selector: prediction.outputs.content
- name: evaluate_llm
  endpoint:
    path: /evaluate
    method: POST
    data_selector: results
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: evaluation
  endpoint:
    path: /evaluate-llm-evaluate-llm
    method: POST
    data_selector: results
    params: {}
- name: index
  endpoint:
    path: index_data_new.py
    method: POST
- name: rag
  endpoint:
    path: retrieval_new.py
    method: POST
- name: invoke_function
  endpoint:
    path: /
    method: POST
    data_selector: prediction.outputs.content
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: pirate_data
  endpoint:
    path: /datasets/fine-tune/pirate-data
    method: GET
    data_selector: records
    params: {}
- name: evaluate_llm
  endpoint:
    path: /evaluate_llm
    method: POST
    data_selector: results
- name: evaluate
  endpoint:
    path: /evaluations
    method: POST
    data_selector: evaluation_results
    params: {}
- name: training_run
  endpoint:
    path: /mlrun-extended/lib/python3.9/site-packages/torch/utils/checkpoint.py
    method: POST
    data_selector: outputs
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: dataset
  endpoint:
    path: /datasets/fine-tune/pirate-data
    method: GET
    data_selector: data
    params: {}
- name: model
  endpoint:
    path: /models/NousResearch/Llama-2-7b-hf
    method: GET
    data_selector: model_info
    params: {}
- name: pirate_data
  endpoint:
    path: /datasets/fine-tune/pirate-data
    method: POST
    data_selector: dataset_artifact.uri
    params: {}
- name: fine_tune
  endpoint:
    path: /hub/functions/master/hugging_face_serving/latest/example/
    method: POST
    data_selector: outputs
    params: {}
- name: dataset
  endpoint:
    path: /datasets/databricks/databricks-dolly-15k
    method: GET
    data_selector: records
- name: hugging_face_serving
  endpoint:
    path: /hub/functions/master/hugging_face_serving
    method: POST
    data_selector: outputs
    params: {}
- name: openai_model
  endpoint:
    path: /openai-model
    method: POST
    data_selector: outputs
    params: {}
- name: Serving gen AI models
  endpoint:
    path: /genai/serving
    method: GET
- name: Gen AI realtime serving graph
  endpoint:
    path: /genai/serving/graph
    method: GET
- name: hugging_face_serving
  endpoint:
    path: /hub/functions/master/hugging_face_serving
    method: POST
    data_selector: outputs
    params: {}
- name: hugging_face_serving
  endpoint:
    path: /hub/functions/master/hugging_face_serving
    method: SET
    data_selector: function
    params: {}
- name: mymodel
  endpoint:
    path: /v2/models/mymodel
    method: POST
    data_selector: outputs
- name: local_model
  endpoint:
    path: /models/local
    method: GET
- name: remote_model
  endpoint:
    path: /models/remote
    method: GET
- name: hugging_face_serving
  endpoint:
    path: /hub/functions/master/hugging_face_serving
    method: GET
    data_selector: ''
    params: {}
- name: serve-llm
  endpoint:
    path: /predict
    method: POST
    data_selector: outputs
    params: {}
- name: model_inference
  endpoint:
    path: /v2/models/mymodel/infer
    method: POST
    data_selector: outputs
- name: model_inference
  endpoint:
    path: /v2/models/sync_invoke_model/infer
    method: POST
    data_selector: output
- name: image_artifact
  endpoint:
    path: /v2/models/sync_invoke_model/infer
    method: POST
    data_selector: result
    params: {}
- name: image_artifact
  endpoint:
    path: /v2/models/sync_invoke_model/infer
    method: POST
    data_selector: result
    params: {}
- name: Model Monitoring
  endpoint:
    path: /model/monitoring
    method: GET
- name: Alerts
  endpoint:
    path: /alerts
    method: GET
- name: Guardrails
  endpoint:
    path: /guardrails
    method: GET
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: input_data
  endpoint:
    path: /input_data.csv
    method: GET
    data_selector: data
    params: {}
- name: logging_dataset
  endpoint:
    path: /logging/dataset
    method: POST
- name: iris_dataset
  endpoint:
    path: https://s3.wasabisys.com/iguazio/data/iris/iris_dataset.csv
    method: GET
    data_selector: data
    params: {}
- name: ingest_data
  endpoint:
    path: /ingest_data
    method: POST
    data_selector: cleaned_data
    params: {}
- name: logging_dataset
  endpoint:
    path: /logging/dataset
    method: POST
    data_selector: dataset
    params: {}
- name: feature_set
  endpoint:
    path: /feature-sets
    method: GET
- name: iris_dataset
  endpoint:
    path: /iguazio/data/iris/iris_dataset.csv
    method: GET
    data_selector: data
    params: {}
- name: ingestion_engines
  endpoint:
    path: /ingestion/engines
    method: GET
- name: feature_set_verification
  endpoint:
    path: /feature_sets/verify
    method: POST
- name: local_data_ingestion
  endpoint:
    path: /ingest/local
    method: POST
- name: mlrun_job_ingestion
  endpoint:
    path: /ingest/job
    method: POST
- name: real_time_ingestion
  endpoint:
    path: /ingest/realtime
    method: POST
- name: incremental_ingestion
  endpoint:
    path: /ingest/incremental
    method: POST
- name: stocks
  endpoint:
    path: stocks
    method: GET
    data_selector: data
    params: {}
- name: feature_set
  endpoint:
    path: /feature-set
    method: POST
    data_selector: feature_set_data
- name: stocks
  endpoint:
    path: stocks
    method: GET
    data_selector: records
    params: {}
- name: basic-training
  endpoint:
    path: /jobs/basic-training
    method: POST
    data_selector: run
    params: {}
- name: local_spark_ingestion_example
  endpoint:
    path: /local_spark_ingestion
    method: GET
- name: remote_spark_ingestion_example
  endpoint:
    path: /remote_spark_ingestion
    method: GET
- name: spark_operator_ingestion_example
  endpoint:
    path: /spark_operator_ingestion
    method: GET
- name: spark_dataframe_ingestion_example
  endpoint:
    path: /spark_dataframe_ingestion
    method: GET
- name: spark_over_s3_full_flow_example
  endpoint:
    path: /spark_over_s3_full_flow
    method: GET
- name: spark_ingestion_from_snowflake_example
  endpoint:
    path: /spark_ingestion_from_snowflake
    method: GET
- name: spark_ingestion_from_azure_example
  endpoint:
    path: /spark_ingestion_from_azure
    method: GET
- name: stocks
  endpoint:
    path: /api/mlrun.feature_store/index.html#mlrun.feature_store.FeatureSet
    method: POST
    data_selector: records
- name: customer
  endpoint:
    path: /api/mlrun.feature_store/index.html#mlrun.feature_store.ingest
    method: POST
    data_selector: records
- name: train
  endpoint:
    path: /hub/auto_trainer
    method: POST
    data_selector: model
    params:
      inputs:
        dataset: ingest.outputs['dataset']
      outputs:
      - model
- name: dataset
  endpoint:
    path: /path/to/dataset
    method: GET
    data_selector: data_items
    params: {}
- name: model
  endpoint:
    path: /path/to/model
    method: POST
    data_selector: artifacts
    params: {}
- name: dataset
  endpoint:
    path: /ingest/outputs/dataset
    method: GET
    data_selector: outputs
    params: {}
- name: model
  endpoint:
    path: /train/outputs/model
    method: GET
    data_selector: outputs
    params: {}
- name: trained_model
  endpoint:
    path: /model_artifacts
    method: POST
    data_selector: model_data
    params: {}
- name: basic-training
  endpoint:
    path: /mlrun/jobs/basic-training
    method: POST
    data_selector: run.outputs
    params: {}
- name: train
  endpoint:
    path: /hub/auto_trainer
    method: POST
    data_selector: model
    params:
      dataset: ingest.outputs["dataset"]
- name: test_model
  endpoint:
    path: /test_model
    method: POST
    data_selector: model
    params:
      models_path: train_iris.outputs["model"]
      test_set: https://s3.wasabisys.com/iguazio/data/iris/iris_dataset.csv
- name: dataset
  endpoint:
    path: /path/to/dataset
    method: GET
    data_selector: data
    params: {}
- name: model
  endpoint:
    path: /path/to/model
    method: POST
    data_selector: model
    params: {}
- name: dataset
  endpoint:
    path: /store/data-items
    method: GET
    data_selector: data_items
- name: model
  endpoint:
    path: /models
    method: POST
    data_selector: models
- name: train
  endpoint:
    path: /train
    method: POST
    data_selector: results
    params:
      model_class: sklearn.ensemble.RandomForestClassifier
      model_kwargs:
        max_depth: 8
      model_name: MyModel
- name: train_model
  endpoint:
    path: /hub/auto_trainer
    method: POST
    data_selector: outputs
    params: {}
- name: model_storage
  endpoint:
    path: /store/model
    method: POST
    data_selector: result
    params: {}
- name: auto_trainer
  endpoint:
    path: /hub/auto_trainer
    method: GET
    data_selector: ''
    params: {}
- name: train_run
  endpoint:
    path: /train_run
    method: GET
    data_selector: outputs
    params: {}
- name: evaluate_run
  endpoint:
    path: /evaluate_run
    method: GET
    data_selector: outputs
    params: {}
- name: train
  endpoint:
    path: /hub/auto_trainer
    method: POST
    data_selector: outputs
    params:
      inputs:
        dataset: ingest.outputs["dataset"]
      outputs:
      - model
- name: test_model
  endpoint:
    path: /test_model
    method: POST
    data_selector: outputs
    params:
      inputs:
        models_path: train_iris.outputs["model"]
        test_set: https://s3.wasabisys.com/iguazio/data/iris/iris_dataset.csv
      params:
        label_column: label
- name: automated_experiment_tracking
  endpoint:
    path: /automated/experiment/tracking
    method: POST
    data_selector: data
    params: {}
- name: hyperparameter_tuning
  endpoint:
    path: /api/mlrun/runtimes
    method: POST
    data_selector: results
    params: {}
- name: auto_trainer
  endpoint:
    path: /hub/auto_trainer
    method: GET
    data_selector: functions
- name: function_deploy
  endpoint:
    path: /function/deploy
    method: POST
    data_selector: internal_invocation_urls
    params: {}
- name: hyperparameter_tuning
  endpoint:
    path: /hyperparameter_tuning
    method: GET
- name: hyperparameter_tuning
  endpoint:
    path: /api/mlrun/runs
    method: POST
    data_selector: results
    params: {}
- name: auto_trainer
  endpoint:
    path: /hub/auto_trainer
    method: POST
    data_selector: results
    params: {}
- name: train
  endpoint:
    params:
      train_test_split_size: 0.2
      model_name: model
- name: evaluate
  endpoint:
    params:
      model_path: train_run.outputs['model']
      label_columns: labels
- name: job_monitor
  endpoint:
    path: /mlprojects/default/jobs/monitor/{job_id}/overview
    method: GET
- name: grid_search
  endpoint:
    path: /hyperparams/grid_search
    method: GET
- name: random_search
  endpoint:
    path: /hyperparams/random_search
    method: GET
- name: list_search
  endpoint:
    path: /hyperparams/list_search
    method: GET
- name: custom_iterator
  endpoint:
    path: /hyperparams/custom_iterator
    method: GET
- name: parallel_execution
  endpoint:
    path: /hyperparams/parallel_execution
    method: GET
- name: hyperparameter_tuning
  endpoint:
    path: /api/mlrun
    method: POST
    data_selector: results
    params: {}
- name: offline_features
  endpoint:
    path: /get_offline_features
    method: GET
    data_selector: features
    params: {}
- name: training
  endpoint:
    path: /training
    method: POST
    data_selector: training_results
    params: {}
- name: hyperparameter_tuning
  endpoint:
    path: /api/mlrun.runtimes/mlrun.runtimes
    method: POST
    data_selector: results
    params: {}
- name: hyperparameter_tuning
  endpoint:
    path: /hyperparameters/tuning
    method: POST
    data_selector: results
    params: {}
- name: serving
  endpoint:
    path: /v2/models/{model_key}/infer
    method: POST
    data_selector: inputs
- name: jobs
  endpoint:
    path: /mlprojects/default/jobs
    method: GET
- name: model_inference
  endpoint:
    path: /v2/models/my_model/infer
    method: POST
    data_selector: inputs
    params: {}
- name: serving_function
  endpoint:
    path: /v2/models/{model_key}/infer
    method: POST
    data_selector: inputs
    params: {}
- name: model
  endpoint:
    path: /v2/models/{model}/infer
    method: POST
- name: get_model_health_readiness
  endpoint:
    path: /model/health
    method: GET
    data_selector: health
- name: get_model_metadata
  endpoint:
    path: /model/metadata
    method: GET
    data_selector: metadata
- name: get_server_info
  endpoint:
    path: /server/info
    method: GET
    data_selector: info
- name: infer_predict
  endpoint:
    path: /model/infer
    method: POST
    data_selector: predictions
- name: infer_dict_predict_dict
  endpoint:
    path: /model/infer_dict
    method: POST
    data_selector: predictions
- name: list_models
  endpoint:
    path: /models
    method: GET
    data_selector: models
- name: model_inference
  endpoint:
    path: /v2/models/my_model/infer
    method: POST
    data_selector: outputs
    params: {}
- name: get_model_health
  endpoint:
    path: /model/health
    method: GET
- name: get_model_metadata
  endpoint:
    path: /model/metadata
    method: GET
- name: get_server_info
  endpoint:
    path: /server/info
    method: GET
- name: infer_predict
  endpoint:
    path: /model/infer
    method: POST
- name: infer_dict_predict_dict
  endpoint:
    path: /model/infer_dict
    method: POST
- name: list_models
  endpoint:
    path: /models
    method: GET
- name: explain
  endpoint:
    path: /v2/models/[/versions/{VERSION}]/explain
    method: POST
- name: get model health / readiness
  endpoint:
    path: v2/models/${MODEL_NAME}[/versions/${VERSION}]/ready
    method: GET
- name: get model metadata
  endpoint:
    path: v2/models/${MODEL_NAME}[/versions/${VERSION}]
    method: GET
- name: get server info
  endpoint:
    path: /
    method: GET
- name: infer / predict
  endpoint:
    path: /v2/models/<model>[/versions/{VERSION}]/infer
    method: POST
- name: infer_dict / predict_dict
  endpoint:
    path: /v2/models/<model>[/versions/{VERSION}]/infer_dict
    method: POST
- name: list models
  endpoint:
    path: /v2/models/
    method: GET
- name: online_features
  endpoint:
    path: /v2/models/infer
    method: POST
    data_selector: body
    params: {}
- name: explain
  endpoint:
    path: /v2/models/[/versions/{VERSION}]/explain
    method: POST
    data_selector: outputs
    params: {}
- name: get_model_health
  endpoint:
    path: v2/models/${MODEL_NAME}[/versions/${VERSION}]/ready
    method: GET
    data_selector: ''
    params: {}
- name: get_model_metadata
  endpoint:
    path: v2/models/${MODEL_NAME}[/versions/${VERSION}]
    method: GET
    data_selector: ''
    params: {}
- name: get_server_info
  endpoint:
    path: /
    method: GET
    data_selector: ''
    params: {}
- name: infer_predict
  endpoint:
    path: /v2/models/<model>[/versions/{VERSION}]/infer
    method: POST
    data_selector: ''
    params: {}
- name: infer_dict_predict_dict
  endpoint:
    path: /v2/models/<model>[/versions/{VERSION}]/infer_dict
    method: POST
    data_selector: ''
    params: {}
- name: list_models
  endpoint:
    path: /v2/models/
    method: GET
    data_selector: models
    params: {}
- name: batch_inference
  endpoint:
    path: /batch-inference
    method: POST
    data_selector: prediction
    params: {}
- name: online_features
  endpoint:
    path: /feature-store/online-features
    method: GET
- name: serving_model
  endpoint:
    path: /feature-store/serving-model
    method: POST
- name: feature_vector
  endpoint:
    path: /feature-vectors/{project}/{feature_vector_name}
    method: GET
    data_selector: latest_feature_vector
    params: {}
- name: model_prediction
  endpoint:
    path: /v2/models/infer
    method: POST
    data_selector: predictions
    params: {}
- name: api_gateway
  endpoint:
    path: /mlrun/runtimes/nuclio/api_gateway
    method: POST
    data_selector: api_gateway
    params:
      canary:
      - 60
      - 40
- name: batch_inference
  endpoint:
    path: /hub/batch_inference_v2
    method: POST
    data_selector: results
    params: {}
- name: Create a project using a Git source
  endpoint:
    path: automate-project-git-source.html
- name: Load project YAML from Git, Zip, Tar source
  endpoint:
    path: load-project-yaml.html
- name: Run pipelines with GitHub Actions, GitLab
  endpoint:
    path: ci-integration.html
- name: project
  endpoint:
    path: /api/mlrun.projects/index.html#mlrun.projects.get_or_create_project
    method: GET
    data_selector: records
- name: canary_function
  endpoint:
    path: /api/gateway/canary
    method: POST
    data_selector: functions
    params:
      canary:
      - 60
      - 40
- name: create_project_using_git_source
  endpoint:
    path: /automate-project-git-source.html
    method: GET
- name: load_project_yaml_from_git_zip_tar_source
  endpoint:
    path: /load-project-yaml.html
    method: GET
- name: run_pipelines_with_github_actions_gitlab
  endpoint:
    path: /ci-integration.html
    method: GET
- name: data_fetch
  endpoint:
    path: ./src/data_fetch.py
    method: POST
    data_selector: ''
    params: {}
- name: project
  endpoint:
    path: /api/mlrun/projects
    method: GET
    data_selector: projects
    params: {}
- name: train
  endpoint:
    path: ./src/train.py
    method: POST
    data_selector: results
    params: {}
- name: data-fetch
  endpoint:
    path: ./src/data_fetch.py
    method: POST
    data_selector: results
    params: {}
- name: serving
  endpoint:
    path: ./function_spec/serving.yaml
    method: POST
    data_selector: results
    params: {}
- name: main
  endpoint:
    path: ./src/workflow.py
    method: POST
    data_selector: results
    params: {}
- name: project
  endpoint:
    path: /api/mlrun.projects/index.html#mlrun.projects.get_or_create_project
    method: GET
    data_selector: projects
    params: {}
- name: data-fetch
  endpoint:
    path: ./src/data_fetch.py
    method: POST
    data_selector: outputs
    params: {}
- name: train
  endpoint:
    path: ./src/train.py
    method: POST
    data_selector: outputs
    params: {}
- name: data-fetch
  endpoint:
    path: ./src/data_fetch.py
    method: POST
- name: train
  endpoint:
    path: ./src/train.py
    method: POST
- name: serving
  endpoint:
    path: ./function_spec/serving.yaml
    method: POST
- name: main
  endpoint:
    path: ./src/workflow.py
    method: POST
- name: function
  endpoint:
    path: /function_spec
    method: POST
    data_selector: function
    params: {}
- name: data-fetch
  endpoint:
    path: /src/data_fetch.py
    method: POST
    data_selector: results
    params: {}
- name: train
  endpoint:
    path: /src/train.py
    method: POST
    data_selector: results
    params: {}
- name: serving
  endpoint:
    path: /function_spec/serving.yaml
    method: POST
    data_selector: outputs
    params: {}
- name: model
  endpoint:
    path: ./artifacts
    method: GET
    data_selector: artifact
    params: {}
- name: data-fetch
  endpoint:
    path: ./src/data_fetch.py
    method: GET
- name: train
  endpoint:
    path: ./src/train.py
    method: GET
- name: serving
  endpoint:
    path: ./function_spec/serving.yaml
    method: GET
- name: main
  endpoint:
    path: ./src/workflow.py
    method: GET
- name: project
  endpoint:
    path: /projects
    method: GET
    data_selector: projects
    params: {}
- name: GitHub Actions
  endpoint:
    path: /github/actions
    method: POST
    data_selector: workflow
    params: {}
- name: GitLab CI/CD
  endpoint:
    path: /gitlab/ci
    method: POST
    data_selector: pipeline
    params: {}
- name: Jenkins Pipeline
  endpoint:
    path: /jenkins/pipeline
    method: POST
    data_selector: job
    params: {}
- name: data-fetch
  endpoint:
    path: ./src/data_fetch.py
    method: GET
- name: train
  endpoint:
    path: ./src/train.py
    method: GET
- name: serving
  endpoint:
    path: ./function_spec/serving.yaml
    method: GET
- name: main
  endpoint:
    path: ./src/workflow.py
    method: GET
- name: projects
  endpoint:
    path: /projects
    method: GET
- name: GitHub Actions
  endpoint:
    path: /github/actions
    method: POST
    data_selector: actions
    params: {}
- name: GitLab CI/CD
  endpoint:
    path: /gitlab/ci
    method: POST
    data_selector: ci
    params: {}
- name: Jenkins Pipeline
  endpoint:
    path: /jenkins/pipeline
    method: POST
    data_selector: pipeline
    params: {}
- name: project
  endpoint:
    path: /get_or_create_project
    method: GET
    data_selector: project
    params: {}
- name: project
  endpoint:
    path: /projects
    method: POST
    data_selector: project
    params: {}
- name: project
  endpoint:
    path: /api/mlrun/projects
    method: GET
    data_selector: projects
    params: {}
- name: branch
  endpoint:
    path: /utilizing-different-branches
    method: POST
    data_selector: branches
- name: mlrun_project
  endpoint:
    path: /mlrun/get_or_create_project
    method: POST
    data_selector: project
    params: {}
- name: project
  endpoint:
    path: /projects
    method: GET
    data_selector: projects
- name: project
  endpoint:
    path: /projects
    method: POST
    data_selector: project
    params:
      context: ./
- name: mlrun_project
  endpoint:
    path: /git/igz-us-sales/mlrun-git-example
    method: GET
    data_selector: source
    params:
      branch: spanish
- name: project
  endpoint:
    path: /
    method: POST
    data_selector: function
    params: {}
- name: project
  endpoint:
    path: /load_project
    method: POST
    data_selector: project
    params:
      url: git://github.com/mlrun/project-archive.git
      name: myproj
- name: training_pipeline
  endpoint:
    path: /run_function
    method: POST
    data_selector: function
    params:
      pull_at_runtime: 'True'
- name: greetings
  endpoint:
    path: /run_function
    method: POST
    data_selector: function
    params: {}
- name: run_function
  endpoint:
    path: /api/mlrun.projects/run_function
    method: POST
    data_selector: results
- name: build_function
  endpoint:
    path: /api/mlrun.projects/build_function
    method: POST
    data_selector: results
- name: deploy_function
  endpoint:
    path: /api/mlrun.projects/deploy_function
    method: POST
    data_selector: results
- name: projects
  endpoint:
    path: /api/projects
    method: GET
    data_selector: records
    params: {}
- name: get-data
  endpoint:
    path: functions/get_data.py
    method: POST
    data_selector: outputs
    params:
      label_column: label_column
- name: train-model
  endpoint:
    path: functions/train.py
    method: POST
    data_selector: outputs
    params:
      label_column: label_column
      test_size: 0.2
- name: deploy-model
  endpoint:
    path: hub://v2_model_server
    method: POST
    data_selector: outputs
    params:
      models:
      - key: model
        model_path: train.outputs['model']
- name: project
  endpoint:
    path: /load_project
    method: POST
    data_selector: project_object
- name: workflow
  endpoint:
    path: /run
    method: POST
    data_selector: workflow_object
- name: function
  endpoint:
    path: /api/mlrun/projects/functions
    method: GET
    data_selector: functions
    params: {}
- name: get-data
  endpoint:
    path: functions/get_data.py
    method: POST
- name: train-model
  endpoint:
    path: functions/train.py
    method: POST
- name: deploy-model
  endpoint:
    path: hub://v2_model_server
    method: POST
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: get-data
  endpoint:
    path: functions/data.py
    method: set_function
    data_selector: function
    params:
      kind: job
      handler: get_data
- name: train
  endpoint:
    path: functions/train.py
    method: set_function
    data_selector: function
    params:
      kind: job
      handler: train_model
- name: main_workflow
  endpoint:
    path: workflows/main_workflow.py
    method: set_workflow
    data_selector: workflow
    params: {}
- name: get-data
  endpoint:
    path: functions/data.py
    method: job
    data_selector: ''
    params: {}
- name: train
  endpoint:
    path: functions/train.py
    method: job
    data_selector: ''
    params: {}
- name: main
  endpoint:
    path: workflows/main_workflow.py
    method: ''
    data_selector: ''
    params: {}
- name: function_job
  endpoint:
    path: /functions/job
    method: GET
    data_selector: records
    params: {}
- name: data-prep
  endpoint:
    path: src/data_prep.py
    method: POST
    data_selector: function
    params: {}
- name: test-function
  endpoint:
    path: src/mynb.ipynb
    method: POST
    data_selector: function
    params: {}
- name: train
  endpoint:
    path: training.train
    method: POST
    data_selector: function
    params:
      with_repo: true
- name: functions
  endpoint:
    path: /api/functions
    method: GET
    data_selector: functions
    params: {}
- name: model_inference
  endpoint:
    path: /v2/models/scikit-learn/infer
    method: POST
    data_selector: outputs
    params: {}
- name: model_infer
  endpoint:
    path: /v2/models/scikit-learn/infer
    method: POST
    data_selector: outputs
- name: ApplicationRuntime
  endpoint:
    path: /api/mlrun/runtimes/ApplicationRuntime
    method: GET
- name: ApplicationRuntime
  endpoint:
    path: /api/mlrun.runtimes/ApplicationRuntime
    method: GET
- name: dask_cluster
  endpoint:
    path: /dask-cluster
    method: POST
    data_selector: spec
    params:
      min_replicas: 1
      max_replicas: 4
      remote: true
      service_type: NodePort
- name: Running Dask on the cluster with MLRun
  endpoint:
    path: /dask-mlrun.html
    method: GET
- name: Pipelines using Dask, Kubeflow, and MLRun
  endpoint:
    path: /dask-pipeline.html
    method: GET
- name: dask_cluster
  endpoint:
    path: /dask/clusters
    method: POST
    data_selector: clusters
    params:
      min_replicas: 1
      max_replicas: 4
      remote: true
      service_type: NodePort
      mem: 2G
      cpu: '2'
- name: dask_cluster
  endpoint:
    path: /set_function
    method: POST
    data_selector: dask_cluster
- name: dask_cluster
  endpoint:
    path: /dask-cluster
    method: POST
    data_selector: cluster_info
    params:
      replicas: 4
- name: dask_cluster
  endpoint:
    path: /mlrun/functions/dask-cluster
    method: POST
    data_selector: cluster
    params:
      replicas: 0
      min_replicas: 1
      max_replicas: 4
      remote: true
      service_type: NodePort
      mem: 2G
      cpu: '2'
- name: dask_cluster
  endpoint:
    path: /dask-cluster
    method: POST
    data_selector: cluster_info
    params:
      min_replicas: 1
      max_replicas: 4
      remote: true
      service_type: NodePort
      worker_requests:
        mem: 2G
        cpu: '2'
- name: scheduler
  endpoint:
    path: /status
    method: GET
- name: yellow_tripdata
  endpoint:
    path: /User/examples/ytrip.csv
    method: GET
    data_selector: records
    params: {}
- name: dask_cluster
  endpoint:
    path: /dask-cluster
    method: GET
    data_selector: info
    params: {}
- name: dataset
  endpoint:
    path: /User/examples/ytrip.csv
    method: GET
    data_selector: records
    params: {}
- name: dask_cluster
  endpoint:
    path: /set_function
    method: POST
    data_selector: project
    params:
      replicas: 4
      min_replicas: 1
      max_replicas: 4
      remote: true
      service_type: NodePort
      mem: 2G
      cpu: '2'
- name: test_dask
  endpoint:
    path: /set_function
    method: POST
    data_selector: function
    params: {}
- name: dask-cluster
  endpoint:
    path: /set_function
    method: POST
    data_selector: cluster
    params:
      replicas: 0
      min_replicas: 1
      max_replicas: 4
      remote: true
      service_type: NodePort
- name: test-dask
  endpoint:
    path: /set_function
    method: POST
    data_selector: function
    params: {}
- name: project
  endpoint:
    path: /projects
    method: POST
    data_selector: project
    params: {}
- name: function
  endpoint:
    path: /functions
    method: POST
    data_selector: function
    params: {}
- name: dask_function
  endpoint:
    path: /run
    method: POST
    data_selector: results
    params:
      dataset: DATA_URL
      dask_function: db://{project.name}/{dask_cluster_name}
- name: functions
  endpoint:
    path: /functions
    method: GET
    data_selector: records
- name: jobs
  endpoint:
    path: /jobs
    method: GET
    data_selector: records
- name: artifacts
  endpoint:
    path: /artifacts
    method: GET
    data_selector: records
- name: project
  endpoint:
    path: /projects
    method: POST
    data_selector: project
    params: {}
- name: function
  endpoint:
    path: /functions
    method: POST
    data_selector: function
    params: {}
- name: project
  endpoint:
    path: /projects
    method: POST
    data_selector: project
    params: {}
- name: function
  endpoint:
    path: /functions
    method: POST
    data_selector: function
    params: {}
- name: databricks_job
  endpoint:
    path: /jobs/runs/submit
    method: POST
    data_selector: run_id
    params:
      timeout_minutes: 15
- name: project
  endpoint:
    path: /projects
    method: POST
    data_selector: project
    params: {}
- name: function
  endpoint:
    path: /functions
    method: POST
    data_selector: function
    params: {}
- name: job_compute_cluster
  endpoint:
    path: /jobs/create
    method: POST
    data_selector: cluster_id
    params:
      new_cluster_spec:
        node_type_id: m5d.large
        number_of_workers: 2
        timeout_minutes: 15
- name: spark_function
  endpoint:
    path: /spark/function
    method: POST
    data_selector: result
    params: {}
- name: api_gateway
  endpoint:
    path: /api/gateway
    method: POST
    data_selector: gateway_info
    params: {}
- name: spark_function
  endpoint:
    path: /spark/function
    method: POST
    data_selector: spark_job
    params: {}
- name: function
  endpoint:
    path: /set_function
    method: POST
    data_selector: function
    params: {}
- name: nuclio_function
  endpoint:
    path: /
    method: POST
    data_selector: response
    params: {}
- name: api_gateway
  endpoint:
    path: /api/gateway
    method: POST
    data_selector: response
    params: {}
- name: my-func
  endpoint:
    path: ./src/my-code.py
    method: POST
    data_selector: function
    params: {}
- name: named_annotations
  endpoint:
    path: /named_annotations
    method: GET
    data_selector: records
- name: multi_section_function
  endpoint:
    path: /multi_section_function
    method: GET
    data_selector: records
- name: mlrun-images
  endpoint:
    path: /mlrun/images
    method: GET
    data_selector: images
- name: function_storage
  endpoint:
    path: /functions/storage
    method: POST
- name: function_image
  endpoint:
    path: /api/mlrun/projects
    method: POST
    data_selector: projects
    params: {}
- name: trainer
  endpoint:
    path: /build_function
    method: POST
    data_selector: function
    params: {}
- name: build_function
  endpoint:
    path: /api/mlrun.projects/build_function
    method: POST
    data_selector: results
    params: {}
- name: deploy_function
  endpoint:
    path: /api/mlrun.projects/deploy_function
    method: POST
    data_selector: results
    params: {}
- name: run_function
  endpoint:
    path: /api/mlrun.projects/run_function
    method: POST
    data_selector: results
    params: {}
- name: deploy_default_image
  endpoint:
    path: /api/mlrun.runtimes/deploy_default_image
    method: POST
    data_selector: results
    params: {}
- name: mlrun/mlrun
  endpoint:
    path: /mlrun/mlrun
    method: GET
- name: mlrun/mlrun-kfp
  endpoint:
    path: /mlrun/mlrun-kfp
    method: GET
- name: mlrun/mlrun-gpu
  endpoint:
    path: /mlrun/mlrun-gpu
    method: GET
- name: mlrun/ml-base
  endpoint:
    path: /mlrun/ml-base
    method: GET
- name: mlrun/jupyter
  endpoint:
    path: /mlrun/jupyter
    method: GET
- name: mlrun/mlrun-api
  endpoint:
    path: /mlrun/mlrun-api
    method: GET
- name: mlrun/log-collector
  endpoint:
    path: /mlrun/log-collector
    method: GET
- name: mlrun/mlrun-ui
  endpoint:
    path: /mlrun/mlrun-ui
    method: GET
- name: describe
  endpoint:
    path: /hub://describe
    method: GET
    data_selector: function
    params: {}
- name: function_yaml
  endpoint:
    path: /function-name/function.yaml
    method: GET
- name: function_image
  endpoint:
    path: /build_function
    method: POST
    data_selector: function_image_data
    params: {}
- name: trainer
  endpoint:
    path: /build_function
    method: POST
    data_selector: results
- name: default_spark_runtime_image
  endpoint:
    path: /deploy_default_image
    method: POST
- name: MLRun function hub
  endpoint:
    path: /mlrun/function/hub
    method: GET
- name: Custom function hub
  endpoint:
    path: /mlrun/custom/function/hub
    method: GET
- name: profile
  endpoint:
    path: /profile
    method: GET
    data_selector: profile_data
    params: {}
- name: describe
  endpoint:
    path: hub://describe
    method: GET
    data_selector: function
    params: {}
- name: DataItem
  endpoint:
    path: /api/mlrun.datastore/DataItem
    method: GET
    data_selector: data_items
    params: {}
- name: MLRun function
  endpoint:
    path: /create-and-export-function
    method: POST
- name: Import function
  endpoint:
    path: /import-function
    method: GET
- name: func-hub
  endpoint:
    path: https://raw.githubusercontent.com/user-name/repo-name/func/function.yaml
    method: GET
    data_selector: function.yaml
    params: {}
- name: data_item
  endpoint:
    path: /api/mlrun.datastore.DataItem
    method: GET
    data_selector: records
    params: {}
- name: artifacts
  endpoint:
    path: /store/artifacts
    method: GET
    data_selector: artifacts
    params: {}
- name: artifacts
  endpoint:
    path: /artifacts
    method: GET
- name: s3_bucket
  endpoint:
    path: /path/to/s3_bucket
    method: GET
    data_selector: records
- name: artifact_logging
  endpoint:
    path: /api/mlrun.execution/log_artifact
    method: POST
- name: profile_name
  endpoint:
    path: /path/to/parquet.pq
    method: GET
- name: DataItem
  endpoint:
    path: /api/mlrun.datastore.DataItem
    method: GET
- name: cleaned_data
  endpoint:
    path: /data/batch-predict/training_set.parquet
    method: GET
    data_selector: records
    params: {}
- name: artifacts
  endpoint:
    path: /artifacts
    method: GET
    data_selector: records
- name: model_endpoint
  endpoint:
    path: /model_endpoints
    method: GET
    data_selector: endpoints
- name: train_iris
  endpoint:
    path: train_iris.py
    method: job
    data_selector: results
    params: {}
- name: test_model
  endpoint:
    path: test_model.py
    method: job
    data_selector: results
    params:
      label_column: label
- name: model_endpoints
  endpoint:
    path: /model_endpoints
    method: GET
    data_selector: endpoints
- name: model_monitoring_results
  endpoint:
    path: /monitoring/model/results
    method: GET
- name: model_endpoints
  endpoint:
    path: /model_endpoints
    method: GET
    data_selector: endpoints
- name: model_endpoints
  endpoint:
    path: /model_endpoints
    method: GET
    data_selector: endpoints
- name: overview_dashboard
  endpoint:
    path: /model-monitoring/overview
    method: GET
    data_selector: endpoints
    params: {}
- name: details_dashboard
  endpoint:
    path: /model-monitoring/details
    method: GET
    data_selector: performance_data
    params: {}
- name: performance_dashboard
  endpoint:
    path: /model-monitoring/performance
    method: GET
    data_selector: performance_metrics
    params: {}
- name: applications_dashboard
  endpoint:
    path: /model-monitoring/applications
    method: GET
    data_selector: metrics
    params: {}
- name: model_monitoring_results
  endpoint:
    path: /model-monitoring/results
    method: GET
    data_selector: results
- name: model_endpoints_summary
  endpoint:
    path: /model_endpoints/summary
    method: GET
    data_selector: model_endpoints
    params: {}
- name: model_endpoints_overview
  endpoint:
    path: /model_endpoints/overview
    method: GET
    data_selector: overview
    params: {}
- name: model_endpoints_features_analysis
  endpoint:
    path: /model_endpoints/features_analysis
    method: GET
    data_selector: features_analysis
    params: {}
- name: model_endpoints_metrics
  endpoint:
    path: /model_endpoints/metrics
    method: GET
    data_selector: metrics
    params: {}
- name: enable_model_monitoring
  endpoint:
    path: /enable_model_monitoring
    method: POST
- name: create_model_monitoring_function
  endpoint:
    path: /create_model_monitoring_function
    method: POST
- name: set_model_monitoring_function
  endpoint:
    path: /set_model_monitoring_function
    method: POST
- name: list_model_monitoring_functions
  endpoint:
    path: /list_model_monitoring_functions
    method: GET
- name: set_model_monitoring_credentials
  endpoint:
    path: /set_model_monitoring_credentials
    method: POST
- name: disable_model_monitoring
  endpoint:
    path: /disable_model_monitoring
    method: POST
- name: update_model_monitoring_controller
  endpoint:
    path: /update_model_monitoring_controller
    method: POST
- name: get_model_monitoring_file_target_path
  endpoint:
    path: /get_model_monitoring_file_target_path
    method: GET
- name: create_model_monitoring_alert_configs
  endpoint:
    path: /create_model_monitoring_alert_configs
    method: POST
- name: delete_model_monitoring_function
  endpoint:
    path: /delete_model_monitoring_function
    method: DELETE
- name: model_monitoring
  endpoint:
    path: /api/mlrun/projects
    method: POST
- name: alerts
  endpoint:
    path: /api/alerts
    method: GET
    data_selector: alerts
    params: {}
- name: alert_templates
  endpoint:
    path: /api/alert_templates
    method: GET
    data_selector: templates
    params: {}
- name: alerts
  endpoint:
    path: /alerts
    method: GET
    data_selector: alerts
    params: {}
- name: alert_templates
  endpoint:
    path: /alert_templates
    method: GET
    data_selector: templates
    params: {}
- name: list_alert_activations
  endpoint:
    path: /alerts/activations
    method: GET
- name: list_alert_activations
  endpoint:
    path: /api/alerts/activations
    method: GET
    data_selector: activations
- name: alert_activations
  endpoint:
    path: /list_alert_activations
    method: GET
    data_selector: activations
    params: {}
- name: alert_activations
  endpoint:
    path: /list_alert_activations
    method: GET
    data_selector: activations
    params: {}
- name: mail_notification
  endpoint:
    path: /api/notifications/mail
    method: POST
    data_selector: notification
    params: {}
- name: run_notification
  endpoint:
    path: /api/notifications/runs
    method: POST
    data_selector: notification
    params: {}
- name: pipeline_notification
  endpoint:
    path: /api/notifications/pipelines
    method: POST
    data_selector: notification
    params: {}
- name: mail_notification
  endpoint:
    path: /api/notifications/mail
    method: POST
    data_selector: notification
    params: {}
- name: webhook_notification
  endpoint:
    path: /api/notifications/webhook
    method: POST
    data_selector: notification
    params: {}
- name: workflow
  endpoint:
    path: /api/v1/workflows
    method: POST
    data_selector: workflow
    params: {}
- name: workflow
  endpoint:
    path: /api/v1/workflows
    method: GET
    data_selector: records
- name: train_and_predict
  endpoint:
    path: /train
    method: POST
    data_selector: prediction
    params: {}
- name: run_function
  endpoint:
    path: /api/mlrun/projects/run_function
    method: POST
- name: train_and_predict
  endpoint:
    path: /train.py
    method: POST
    data_selector: outputs
    params: {}
- name: workflows
  endpoint:
    path: /workflows
    method: GET
- name: workflow
  endpoint:
    path: /api/mlrun/projects
    method: GET
    data_selector: workflows
    params: {}
- name: run_function
  endpoint:
    path: /api/mlrun/projects/run_function
    method: POST
    data_selector: run_results
    params: {}
- name: ingestion_function
  endpoint:
    path: /ingestion_function
    method: POST
    data_selector: outputs
    params: {}
- name: training_function
  endpoint:
    path: /training_function
    method: POST
    data_selector: outputs
    params: {}
- name: testing_function
  endpoint:
    path: /testing_function
    method: POST
    data_selector: outputs
    params: {}
- name: deployment_function
  endpoint:
    path: /deployment_function
    method: POST
    data_selector: outputs
    params: {}
- name: func-a
  endpoint:
    path: funcs.py
    method: GET
    data_selector: first_func_res
    params:
      input_value: '6'
- name: func-b
  endpoint:
    path: funcs.py
    method: GET
    data_selector: second_func_res
    params: {}
- name: func-c
  endpoint:
    path: funcs.py
    method: GET
    data_selector: second_func_res
    params: {}
- name: func-A
  endpoint:
    path: funcs.py
    method: POST
    data_selector: first_func_res
    params: {}
- name: func-B
  endpoint:
    path: funcs.py
    method: POST
    data_selector: second_func_res
    params: {}
- name: func-C
  endpoint:
    path: funcs.py
    method: POST
    data_selector: third_func_res
    params: {}
- name: func-D
  endpoint:
    path: funcs.py
    method: POST
    data_selector: fourth_func_res
    params: {}
- name: func-final
  endpoint:
    path: funcs.py
    method: POST
    data_selector: return
    params: {}
- name: func-a
  endpoint:
    path: funcs.py
    method: POST
    data_selector: first_func_res
    params:
      input_value: '6'
- name: func-b
  endpoint:
    path: funcs.py
    method: POST
    data_selector: second_func_res
    params: {}
- name: func-c
  endpoint:
    path: funcs.py
    method: POST
    data_selector: second_func_res
    params: {}
- name: func
  endpoint:
    method: job
    params: {}
- name: func-A
  endpoint:
    path: funcs.py
    method: POST
    data_selector: first_func_res
    params: {}
- name: func-B
  endpoint:
    path: funcs.py
    method: POST
    data_selector: second_func_res
    params: {}
- name: func-C
  endpoint:
    path: funcs.py
    method: POST
    data_selector: third_func_res
    params: {}
- name: func-D
  endpoint:
    path: funcs.py
    method: POST
    data_selector: fourth_func_res
    params: {}
- name: func-final
  endpoint:
    path: funcs.py
    method: POST
    data_selector: return
    params: {}
- name: training_function
  endpoint:
    path: /mlrun/training
    method: POST
- name: func
  endpoint:
    path: func.py
    method: POST
    data_selector: return
    params: {}
- name: training_function
  endpoint:
    path: /training.py
    method: SET
    data_selector: records
    params: {}
- name: training_function
  endpoint:
    path: /set_function/training.py
    method: POST
    data_selector: function
    params: {}
- name: training_function
  endpoint:
    path: /functions/training
    method: POST
    data_selector: function
    params: {}
- name: training_function
  endpoint:
    path: /functions/training
    method: POST
    data_selector: status
    params:
      replicas: 2
- name: training_function
  endpoint:
    path: /functions/training
    method: POST
    data_selector: function
    params: {}
- name: dask_cluster
  endpoint:
    path: /clusters/dask
    method: POST
    data_selector: cluster
    params: {}
- name: scheduled_job
  endpoint:
    path: /jobs/schedule
    method: POST
    data_selector: job
    params:
      schedule: 0 * * * *
- name: scheduled_workflow
  endpoint:
    path: /workflows/schedule
    method: POST
    data_selector: workflow
    params:
      schedule: 0 * * * *
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: simple-graph
  endpoint:
    path: /
    method: POST
    data_selector: ''
    params: {}
- name: simple-graph
  endpoint:
    path: ''
    method: POST
- name: model_inference
  endpoint:
    path: /v2/models/model1/infer
    method: POST
    data_selector: inputs
    params: {}
- name: custom_step
  endpoint:
    path: /serving/writing-custom-steps
    method: POST
    data_selector: task_parameters
    params: {}
- name: custom_step
  endpoint:
    path: /serving/writing-custom-steps
    method: GET
    data_selector: parameters
    params: {}
- name: serving_example
  endpoint:
    path: /serving_example
    method: POST
    data_selector: results
    params: {}
- name: serving_example
  endpoint:
    path: /iguazio/models/iris/model.pkl
    method: GET
    data_selector: model
    params: {}
- name: model1
  endpoint:
    path: /v2/models/model1/infer
    method: POST
    data_selector: result
    params: {}
- name: graph_serving_function
  endpoint:
    path: /deploying-graphs
    method: GET
- name: model1
  endpoint:
    path: /v2/models/model1/infer
    method: POST
    data_selector: result
- name: data_prep
  endpoint:
    path: /v3io/projects/{{run.project}}/artifacts
    method: GET
    data_selector: records
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: http
  endpoint:
    path: /http
    method: POST
- name: queue_streaming
  endpoint:
    path: /queue
    method: POST
- name: input_stream
  endpoint:
    path: /v2/models/model1/infer
    method: put
- name: output_stream
  endpoint:
    path: /v2/models/my_model/infer
    method: post
- name: in-stream
  endpoint:
    path: /in-stream
    method: GET
- name: out-stream
  endpoint:
    path: /out-stream
    method: GET
- name: err-stream
  endpoint:
    path: /err-stream
    method: GET
- name: functions
  endpoint:
    path: /functions
    method: GET
    data_selector: records
    params: {}
- name: graphs
  endpoint:
    path: /graphs
    method: GET
    data_selector: records
    params: {}
- name: input_stream
  endpoint:
    path: /v2/models/my_model/infer
    method: PUT
- name: output_stream
  endpoint:
    path: /v2/models/my_model/infer
    method: PUT
- name: err_stream
  endpoint:
    path: /v2/models/my_model/infer
    method: PUT
- name: remote_function
  endpoint:
    path: /remote/function
    method: POST
    data_selector: response
    params:
      max_in_flight: 2
      timeout: 100
      retries: 10
- name: FeatureSet
  endpoint:
    path: /api/mlrun.feature_store/index.html#mlrun.feature_store.FeatureSet
    method: GET
- name: feature_set
  endpoint:
    path: /api/mlrun.feature_store/index.html#mlrun.feature_store.FeatureSet
    method: CREATE
    data_selector: FeatureSet
    params: {}
- name: SnowflakeSource
  endpoint:
    path: /snowflake_source
    method: POST
    data_selector: result
    params: {}
- name: KafkaSource
  endpoint:
    path: /kafka_source
    method: POST
    data_selector: result
    params: {}
- name: ParquetSource
  endpoint:
    path: /parquet_source
    method: POST
    data_selector: result
    params: {}
- name: SQLSource
  endpoint:
    path: /sql_source
    method: POST
    data_selector: result
    params: {}
- name: remote_function
  endpoint:
    path: /remote_function
    method: POST
    data_selector: response
    params:
      timeout: 100
      retries: 10
      max_in_flight: 2
- name: FeatureSet
  endpoint:
    path: /api/mlrun.feature_store.FeatureSet
    method: GET
    data_selector: records
- name: feature_vector
  endpoint:
    path: /store://feature_vectors/<project>/<feature-vector-name>
    method: POST
    data_selector: feature_vector
    params: {}
- name: FeatureSet
  endpoint:
    path: /api/mlrun.feature_store/index.html#mlrun.feature_store.FeatureSet
    method: GET
- name: FeatureSet
  endpoint:
    path: /api/mlrun.feature_store/index.html#mlrun.feature_store.FeatureSet
    method: CREATE
    data_selector: FeatureSet
    params: {}
- name: online_feature_vector
  endpoint:
    path: /api/mlrun/feature_store/online_vector_service
    method: GET
    data_selector: features
    params: {}
- name: offline_feature_vector
  endpoint:
    path: /api/mlrun/feature_store/offline_vector_service
    method: GET
    data_selector: fv_response
    params: {}
- name: feature_vector
  endpoint:
    path: /feature_vectors
    method: POST
    data_selector: features
    params: {}
- name: feature_set
  endpoint:
    path: /create/feature_set
    method: POST
- name: feature_vector
  endpoint:
    path: /create/feature_vector
    method: POST
- name: snowflake_source_for_ingest
  endpoint:
    path: url
    method: GET
    data_selector: records
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: transactions
  endpoint:
    path: /transactions
    method: GET
    data_selector: records
- name: feature_vector
  endpoint:
    path: /feature_vectors
    method: POST
    data_selector: feature_vector
    params: {}
- name: offline_feature_vector
  endpoint:
    path: /get_offline_features
    method: GET
    data_selector: fv_response
    params: {}
- name: online_feature_vector
  endpoint:
    path: /get_online_feature_service
    method: GET
    data_selector: features
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
- name: feature_vector
  endpoint:
    path: /feature_vectors
    method: POST
    data_selector: feature_vector
    params: {}
- name: offline_feature_vector
  endpoint:
    path: /get_offline_features
    method: GET
    data_selector: offline_vector_response
    params: {}
- name: transactions
  endpoint:
    path: /fraud-demo-mlrun-fs-docs/data.csv
    method: GET
    data_selector: records
    params: {}
- name: user_events
  endpoint:
    path: /fraud-demo-mlrun-fs-docs/events.csv
    method: GET
    data_selector: records
    params: {}
- name: employees
  endpoint:
    path: /feature-sets/employees
    method: POST
    data_selector: employees
    params: {}
- name: departments
  endpoint:
    path: /feature-sets/departments
    method: POST
    data_selector: departments
    params: {}
- name: user_events
  endpoint:
    path: /events.csv
    method: GET
    data_selector: data
    params:
      index_col: 0
      parse_dates:
      - timestamp
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: transactions
  endpoint:
    path: /data.csv
    method: GET
    data_selector: records
- name: transactions
  endpoint:
    path: /data.csv
    method: GET
    data_selector: records
    params: {}
- name: user_events
  endpoint:
    path: /events.csv
    method: GET
    data_selector: records
    params: {}
- name: events
  endpoint:
    path: /projects/{project.name}/streams/events
    method: GET
- name: transactions
  endpoint:
    path: /iguazio/data/fraud-demo-mlrun-fs-docs/data.csv
    method: GET
    data_selector: records
    params: {}
- name: user_events
  endpoint:
    path: /iguazio/data/fraud-demo-mlrun-fs-docs/events.csv
    method: GET
    data_selector: records
    params: {}
- name: events
  endpoint:
    path: /events.csv
    method: GET
    data_selector: records
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: transactions
  endpoint:
    path: /data.csv
    method: GET
    data_selector: records
    params: {}
- name: user_events
  endpoint:
    path: /events.csv
    method: GET
    data_selector: records
    params: {}
- name: transactions
  endpoint:
    path: /data.csv
    method: GET
    data_selector: records
    params: {}
- name: user_events
  endpoint:
    path: /events.csv
    method: GET
    data_selector: records
    params: {}
- name: user_events
  endpoint:
    path: /projects/{project.name}/streams/events
    method: GET
    data_selector: events
    params: {}
- name: events
  endpoint:
    path: /projects/{project.name}/streams/events
    method: GET
    data_selector: event_details_change, event_login, event_password_change, timestamp
    params: {}
- name: labels
  endpoint:
    path: /feature_sets/labels
    method: POST
    data_selector: description, timestamp_key, entities
    params: {}
- name: dataset
  endpoint:
    path: /services/data/vXX.X/sobjects/Dataset
    method: GET
    data_selector: records
- name: transactions
  endpoint:
    path: /data.csv
    method: GET
    data_selector: records
    params: {}
- name: user_events
  endpoint:
    path: /events.csv
    method: GET
    data_selector: records
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: events
  endpoint:
    path: /projects/{project.name}/streams/events
    method: GET
    data_selector: event_details_change, event_login, event_password_change, timestamp
- name: labels
  endpoint:
    path: /fstore/FeatureSet/labels
    method: POST
    data_selector: entities, timestamp_key, description, engine
- name: transactions
  endpoint:
    path: /data.csv
    method: GET
    data_selector: records
    params: {}
- name: user_events
  endpoint:
    path: /events.csv
    method: GET
    data_selector: records
    params: {}
- name: labels
  endpoint:
    path: /target.parquet
    method: GET
    data_selector: records
    params: {}
- name: transactions
  endpoint:
    path: v3io:///projects/{project.name}/streams/transaction
    method: POST
- name: events
  endpoint:
    path: v3io:///projects/{project.name}/streams/events
    method: POST
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
- name: transactions
  endpoint:
    path: /data.csv
    method: GET
    data_selector: records
- name: user_events
  endpoint:
    path: /events.csv
    method: GET
    data_selector: records
- name: labels
  endpoint:
    path: /target.parquet
    method: GET
    data_selector: records
- name: transactions
  endpoint:
    path: v3io:///projects/{project.name}/streams/transaction
    method: GET
    data_selector: records
- name: transactions
  endpoint:
    path: /data.csv
    method: GET
    data_selector: records
    params: {}
- name: user_events
  endpoint:
    path: /events.csv
    method: GET
    data_selector: records
    params: {}
- name: labels
  endpoint:
    path: /labels
    method: POST
    data_selector: label
    params: {}
- name: user_events
  endpoint:
    path: /ingest/events
    method: POST
    data_selector: id
- name: transactions
  endpoint:
    path: /data.csv
    method: GET
    data_selector: records
    params: {}
- name: user_events
  endpoint:
    path: /events.csv
    method: GET
    data_selector: records
    params: {}
- name: labels
  endpoint:
    path: /labels
    method: POST
    data_selector: records
    params: {}
- name: user_events
  endpoint:
    path: /ingestion/endpoint
    method: POST
    data_selector: id
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: dataset
  endpoint:
    path: /api/v1/datasets
    method: POST
    data_selector: data
    params: {}
- name: transactions
  endpoint:
    path: /data.csv
    method: GET
    data_selector: records
- name: user_events
  endpoint:
    path: /events.csv
    method: GET
    data_selector: records
- name: labels
  endpoint:
    path: /target.parquet
    method: GET
    data_selector: records
- name: transactions
  endpoint:
    path: /data.csv
    method: GET
    data_selector: records
- name: user_events
  endpoint:
    path: /events.csv
    method: GET
    data_selector: records
- name: labels
  endpoint:
    path: /labels
    method: POST
    data_selector: records
- name: events
  endpoint:
    path: /projects/{project.name}/streams/events
    method: POST
- name: user_events
  endpoint:
    path: /events_set_endpoint
    method: POST
    data_selector: id
    params: {}
- name: user_events
  endpoint:
    path: /events
    method: POST
    data_selector: id
- name: feature_vector
  endpoint:
    path: /feature_vectors
    method: GET
    data_selector: records
    params: {}
- name: transactions-fraud
  endpoint:
    path: /projects/fraud-demo-dani/FeatureStore/transactions-fraud
    method: GET
    data_selector: features
    params: {}
- name: transactions-fraud-short
  endpoint:
    path: /projects/fraud-demo-dani/FeatureStore/transactions-fraud-short
    method: GET
    data_selector: features
    params: {}
- name: transactions-fraud
  endpoint:
    path: /FeatureStore/transactions-fraud
    method: GET
    data_selector: features
    params: {}
- name: transactions-fraud-short
  endpoint:
    path: /FeatureStore/transactions-fraud-short
    method: GET
    data_selector: features
    params: {}
- name: training
  endpoint:
    path: /training
    method: POST
    data_selector: results
- name: model
  endpoint:
    path: /api/v1/models
    method: GET
- name: function
  endpoint:
    path: /api/v1/functions
    method: GET
- name: transaction-fraud
  endpoint:
    path: /api/transaction-fraud
    method: POST
    data_selector: result
    params: {}
- name: training
  endpoint:
    path: /training
    method: POST
    data_selector: results
    params:
      label_columns: label
- name: transaction-fraud
  endpoint:
    path: /v2/models/infer
    method: POST
    data_selector: outputs
- name: transaction-fraud
  endpoint:
    path: /serving/transaction-fraud
    method: POST
- name: transaction-fraud
  endpoint:
    path: /v2/models/infer
    method: POST
    data_selector: outputs
- name: model_inference
  endpoint:
    path: /v2/models/infer
    method: POST
    data_selector: output
    params: {}
- name: transaction-fraud
  endpoint:
    path: /v2/models/infer
    method: POST
    data_selector: outputs
- name: model_serving
  endpoint:
    path: /api/serving/models
    method: POST
    data_selector: model
    params: {}
- name: transaction-fraud
  endpoint:
    path: /v2/models/infer
    method: POST
    data_selector: outputs
    params: {}
- name: transaction-fraud
  endpoint:
    path: /v2/models/infer
    method: POST
    data_selector: outputs
- name: model_inference
  endpoint:
    path: /v2/models/infer
    method: POST
    data_selector: output
    params: {}
- name: model_inference
  endpoint:
    path: /v2/models/infer
    method: POST
- name: transaction-fraud
  endpoint:
    path: /v2/models/infer
    method: POST
    data_selector: outputs
- name: model_inference
  endpoint:
    path: /v2/models/infer
    method: POST
- name: feature_selection
  endpoint:
    url: hub://feature_selection
- name: train
  endpoint:
    url: hub://auto_trainer
- name: serving
  endpoint:
    url: hub://v2_model_server
- name: workflow
  endpoint:
    path: /projects
    method: POST
    data_selector: results
- name: feature_selection
  endpoint:
    path: hub://feature_selection
    method: SET_FUNCTION
    data_selector: function
    params: {}
- name: train
  endpoint:
    path: hub://auto_trainer
    method: SET_FUNCTION
    data_selector: function
    params: {}
- name: serving
  endpoint:
    path: hub://v2_model_server
    method: SET_FUNCTION
    data_selector: function
    params: {}
- name: alert_config
  endpoint:
    path: /mlrun/alerts/alert
    method: GET
    data_selector: alert_configs
    params: {}
- name: feature_selection
  endpoint:
    path: hub://feature_selection
    method: POST
- name: train
  endpoint:
    path: hub://auto_trainer
    method: POST
- name: serving
  endpoint:
    path: hub://v2_model_server
    method: POST
- name: workflow
  endpoint:
    path: workflow.py
    method: POST
    data_selector: results
    params: {}
- name: DatasetArtifact
  endpoint:
    path: /api/dataset_artifact
    method: GET
    data_selector: records
- name: AlertConfig
  endpoint:
    path: /mlrun/alerts/alert
    method: GET
    data_selector: records
- name: DocumentArtifact
  endpoint:
    path: /mlrun/artifacts/document/DocumentArtifact
    method: GET
- name: DocumentLoaderSpec
  endpoint:
    path: /mlrun/artifacts/document/DocumentLoaderSpec
    method: GET
- name: MLRunLoader
  endpoint:
    path: /mlrun/artifacts/document/MLRunLoader
    method: GET
- name: DatasetArtifact
  endpoint:
    path: /mlrun/artifacts/dataset
    method: GET
    data_selector: supported_formats
    params: {}
- name: PlotArtifact
  endpoint:
    path: /mlrun/artifacts/plots/PlotArtifact
    method: GET
    data_selector: body
- name: PlotlyArtifact
  endpoint:
    path: /mlrun/artifacts/plots/PlotlyArtifact
    method: GET
    data_selector: body
- name: ModelArtifact
  endpoint:
    path: /mlrun/artifacts/model/ModelArtifact
    method: GET
- name: ModelArtifactSpec
  endpoint:
    path: /mlrun/artifacts/model/ModelArtifactSpec
    method: GET
- name: AlertActivation
  endpoint:
    path: /mlrun/common/schemas/alert/AlertActivation
    method: GET
    data_selector: activations
    params: {}
- name: AlertActivations
  endpoint:
    path: /mlrun/common/schemas/alert/AlertActivations
    method: GET
    data_selector: activations
    params: {}
- name: PlotArtifact
  endpoint:
    path: /mlrun/artifacts/plots/PlotArtifact
    method: GET
    data_selector: body
- name: PlotlyArtifact
  endpoint:
    path: /mlrun/artifacts/plots/PlotlyArtifact
    method: GET
    data_selector: body
- name: AlertActivation
  endpoint:
    path: /mlrun/common/schemas/alert/AlertActivation
    method: GET
    data_selector: records
- name: AlertActivations
  endpoint:
    path: /mlrun/common/schemas/alert/AlertActivations
    method: GET
    data_selector: records
- name: AlertConfig
  endpoint:
    path: /mlrun/common/schemas/alert/AlertConfig
    method: GET
    data_selector: records
- name: AlertCriteria
  endpoint:
    path: /mlrun/common/schemas/alert/AlertCriteria
    method: GET
    data_selector: records
- name: AlertNotification
  endpoint:
    path: /mlrun/common/schemas/alert/AlertNotification
    method: GET
    data_selector: records
- name: AlertTemplate
  endpoint:
    path: /mlrun/common/schemas/alert/AlertTemplate
    method: GET
    data_selector: records
- name: AlertTrigger
  endpoint:
    path: /mlrun/common/schemas/alert/AlertTrigger
    method: GET
    data_selector: records
- name: Event
  endpoint:
    path: /mlrun/common/schemas/alert/Event
    method: GET
    data_selector: records
- name: EventEntities
  endpoint:
    path: /mlrun/common/schemas/alert/EventEntities
    method: GET
    data_selector: records
- name: alert_activation
  endpoint:
    path: /alert_activation
    method: GET
    data_selector: activations
- name: alert_activations
  endpoint:
    path: /alert_activations
    method: GET
    data_selector: activations
- name: ImageBuilder
  endpoint:
    path: /mlrun/common/schemas/common/ImageBuilder
    method: GET
- name: LabelsModel
  endpoint:
    path: /mlrun/common/schemas/common/LabelsModel
    method: GET
- name: notification
  endpoint:
    path: /mlrun/common/schemas/notification
    method: GET
    data_selector: Notification
- name: Notification
  endpoint:
    path: /mlrun/common/schemas/notification
    method: GET
    data_selector: records
    params: {}
- name: bq1
  endpoint:
    path: /query
    method: POST
    data_selector: results
    params:
      query: SELECT * FROM `the-psf.pypi.downloads20210328` LIMIT 5000
      gcp_project: my_project
      materialization_dataset: dataviews
- name: bq2
  endpoint:
    path: /table
    method: GET
    data_selector: results
    params:
      table: the-psf.pypi.downloads20210328
      gcp_project: my_project
- name: DatastoreProfilePostgreSQL
  endpoint:
    path: DatastoreProfilePostgreSQL
    method: GET
- name: DatastoreProfileRedis
  endpoint:
    path: DatastoreProfileRedis
    method: GET
- name: DatastoreProfileS3
  endpoint:
    path: DatastoreProfileS3
    method: GET
- name: DatastoreProfileTDEngine
  endpoint:
    path: DatastoreProfileTDEngine
    method: GET
- name: DatastoreProfileV3io
  endpoint:
    path: DatastoreProfileV3io
    method: GET
- name: HuggingFaceProfile
  endpoint:
    path: HuggingFaceProfile
    method: GET
- name: OpenAIProfile
  endpoint:
    path: OpenAIProfile
    method: GET
- name: TemporaryClientDatastoreProfiles
  endpoint:
    path: TemporaryClientDatastoreProfiles
    method: GET
- name: NoSqlTarget
  endpoint:
    method: GET
- name: ParquetSource
  endpoint:
    method: GET
- name: StreamSource
  endpoint:
    method: GET
- name: StreamTarget
  endpoint:
    method: GET
- name: database
  endpoint:
    params:
      host: localhost
      port: 5432
      password: secret123
      username: admin
- name: api_version
  endpoint:
    params:
      api_version: v1
      api_key: xyz789
- name: bigquery_source
  endpoint:
    path: /bigquery
    method: GET
- name: csv_source
  endpoint:
    path: /csv
    method: GET
- name: DataItem
  endpoint:
    path: /datastore/DataItem
    method: GET
- name: DatabricksFileBugFixed
  endpoint:
    path: /datastore/DatabricksFileBugFixed
    method: GET
- name: DatabricksFileSystemDisableCache
  endpoint:
    path: /datastore/DatabricksFileSystemDisableCache
    method: GET
- name: HttpSource
  endpoint:
    path: /datastore/HttpSource
    method: GET
- name: KafkaSource
  endpoint:
    path: /datastore/KafkaSource
    method: GET
- name: ModelProvider
  endpoint:
    path: /datastore/ModelProvider
    method: GET
- name: DatastoreProfilePostgreSQL
  endpoint:
    path: /datastore/profile/postgresql
    method: GET
- name: DatastoreProfileRedis
  endpoint:
    path: /datastore/profile/redis
    method: GET
- name: DatastoreProfileS3
  endpoint:
    path: /datastore/profile/s3
    method: GET
- name: DatastoreProfileTDEngine
  endpoint:
    path: /datastore/profile/tdengine
    method: GET
- name: DatastoreProfileV3io
  endpoint:
    path: /datastore/profile/v3io
    method: GET
- name: HuggingFaceProfile
  endpoint:
    path: /datastore/profile/huggingface
    method: GET
- name: OpenAIProfile
  endpoint:
    path: /datastore/profile/openai
    method: GET
- name: NoSqlTarget
  endpoint:
    path: /datastore/nosql
    method: GET
- name: ParquetSource
  endpoint:
    path: /datastore/parquet
    method: GET
- name: StreamSource
  endpoint:
    path: /datastore/stream
    method: GET
- name: StreamTarget
  endpoint:
    path: /datastore/stream/target
    method: GET
- name: delete_artifacts
  endpoint:
    path: /mlrun/datastore/vectorstore/delete_artifacts
    method: DELETE
    data_selector: artifacts
    params: {}
- name: remove_from_artifact
  endpoint:
    path: /mlrun/datastore/vectorstore/remove_from_artifact
    method: DELETE
    data_selector: artifact
    params: {}
- name: PostgreSQL Profile
  endpoint:
    path: /datastore/datastore_profile/postgresql
    method: POST
    data_selector: profile
    params: {}
- name: TDEngine Profile
  endpoint:
    path: /datastore/datastore_profile/tdengine
    method: POST
    data_selector: profile
    params: {}
- name: DatastoreProfilePostgreSQL
  endpoint:
    path: /mlrun/datastore/datastore_profile/DatastoreProfilePostgreSQL
    method: GET
- name: DatastoreProfileRedis
  endpoint:
    path: /mlrun/datastore/datastore_profile/DatastoreProfileRedis
    method: GET
- name: DatastoreProfileS3
  endpoint:
    path: /mlrun/datastore/datastore_profile/DatastoreProfileS3
    method: GET
- name: DatastoreProfileTDEngine
  endpoint:
    path: /mlrun/datastore/datastore_profile/DatastoreProfileTDEngine
    method: GET
- name: DatastoreProfileV3io
  endpoint:
    path: /mlrun/datastore/datastore_profile/DatastoreProfileV3io
    method: GET
- name: HuggingFaceProfile
  endpoint:
    path: /mlrun/datastore/datastore_profile/HuggingFaceProfile
    method: GET
- name: OpenAIProfile
  endpoint:
    path: /mlrun/datastore/datastore_profile/OpenAIProfile
    method: GET
- name: TemporaryClientDatastoreProfiles
  endpoint:
    path: /mlrun/datastore/datastore_profile/TemporaryClientDatastoreProfiles
    method: GET
- name: MLClientCtx
  endpoint:
    path: /mlrun/execution/MLClientCtx
    method: GET
    data_selector: records
    params: {}
- name: DatastoreProfilePostgreSQL
  endpoint:
    path: /mlrun/datastore/datastore_profile/DatastoreProfilePostgreSQL
    method: GET
- name: DatastoreProfileRedis
  endpoint:
    path: /mlrun/datastore/datastore_profile/DatastoreProfileRedis
    method: GET
- name: DatastoreProfileS3
  endpoint:
    path: /mlrun/datastore/datastore_profile/DatastoreProfileS3
    method: GET
- name: DatastoreProfileTDEngine
  endpoint:
    path: /mlrun/datastore/datastore_profile/DatastoreProfileTDEngine
    method: GET
- name: DatastoreProfileV3io
  endpoint:
    path: /mlrun/datastore/datastore_profile/DatastoreProfileV3io
    method: GET
- name: HuggingFaceProfile
  endpoint:
    path: /mlrun/datastore/datastore_profile/HuggingFaceProfile
    method: GET
- name: OpenAIProfile
  endpoint:
    path: /mlrun/datastore/datastore_profile/OpenAIProfile
    method: GET
- name: TemporaryClientDatastoreProfiles
  endpoint:
    path: /mlrun/datastore/datastore_profile/TemporaryClientDatastoreProfiles
    method: GET
- name: VectorStoreCollection
  endpoint:
    path: /mlrun/datastore/vectorstore/VectorStoreCollection
    method: GET
- name: customer_support_prompt
  endpoint:
    path: /log_llm_prompt
    method: POST
    data_selector: prompt_template
    params: {}
- name: qa_prompt
  endpoint:
    path: /log_llm_prompt
    method: POST
    data_selector: prompt_path
    params: {}
- name: MLClientCtx
  endpoint:
    path: /mlrun/execution/MLClientCtx
    method: GET
    data_selector: records
- name: FeatureSet
  endpoint:
    path: /feature_sets
    method: GET
    data_selector: feature_sets
    params: {}
- name: Entity
  endpoint:
    path: /entities
    method: GET
    data_selector: entities
    params: {}
- name: Feature
  endpoint:
    path: /features
    method: GET
    data_selector: features
    params: {}
- name: measurements
  endpoint:
    path: measurements.csv
    method: GET
- name: qa_prompt
  endpoint:
    path: prompts/template.json
    method: GET
- name: FeatureSet
  endpoint:
    path: /mlrun/feature_store/feature_set
    method: POST
    data_selector: records
- name: Entity
  endpoint:
    path: /mlrun/feature_store/entity
    method: POST
    data_selector: records
- name: Feature
  endpoint:
    path: /mlrun/feature_store/feature
    method: POST
    data_selector: records
- name: mycsv
  endpoint:
    path: ./mycsv.csv
    method: GET
- name: FeaturesetValidator
  endpoint:
    path: /mlrun/feature_store/steps/FeaturesetValidator
    method: GET
    data_selector: featureset
    params: {}
- name: Imputer
  endpoint:
    path: /mlrun/feature_store/steps/Imputer
    method: GET
    data_selector: method
    params: {}
- name: MapValues
  endpoint:
    path: /mlrun/feature_store/steps/MapValues
    method: GET
    data_selector: mapping
    params: {}
- name: OneHotEncoder
  endpoint:
    path: /mlrun/feature_store/steps/OneHotEncoder
    method: GET
    data_selector: mapping
    params: {}
- name: SetEventMetadata
  endpoint:
    path: /mlrun/feature_store/steps/SetEventMetadata
    method: GET
    data_selector: id_path
    params: {}
- name: SetEventMetadata
  endpoint:
    path: /SetEventMetadata
    method: POST
    data_selector: event
    params:
      id_path: myid
      key_path: mykey
- name: get_online_feature_service
  endpoint:
    path: /get_online_feature_service
    method: GET
    data_selector: vectors
    params: {}
- name: get_offline_features
  endpoint:
    path: /get_offline_features
    method: GET
    data_selector: features
    params: {}
- name: FeaturesetValidator
  endpoint:
    path: /mlrun/feature_store/steps/FeaturesetValidator
    method: GET
- name: Imputer
  endpoint:
    path: /mlrun/feature_store/steps/Imputer
    method: GET
- name: MapValues
  endpoint:
    path: /mlrun/feature_store/steps/MapValues
    method: GET
- name: OneHotEncoder
  endpoint:
    path: /mlrun/feature_store/steps/OneHotEncoder
    method: GET
- name: SetEventMetadata
  endpoint:
    path: /mlrun/feature_store/steps/SetEventMetadata
    method: GET
- name: apply_mlrun
  endpoint:
    path: /apply_mlrun
    method: GET
    data_selector: records
    params: {}
- name: load_model
  endpoint:
    path: /load_model
    method: GET
    data_selector: records
    params: {}
- name: SetEventMetadata
  endpoint:
    path: /SetEventMetadata
    method: POST
    data_selector: event
    params:
      id_path: myid
      key_path: mykey
- name: AutoMLRun
  endpoint:
    path: /mlrun/frameworks/auto_mlrun/auto_mlrun
    method: GET
    data_selector: ''
    params: {}
- name: evaluate
  endpoint:
    path: /mlrun/frameworks/pytorch/evaluate
    method: POST
    data_selector: results
    params: {}
- name: train
  endpoint:
    path: /mlrun/frameworks/pytorch/train
    method: POST
    data_selector: model_handler
    params: {}
- name: evaluate
  endpoint:
    path: /mlrun/frameworks/pytorch/evaluate
    method: POST
    data_selector: result
    params: {}
- name: train
  endpoint:
    path: /mlrun/frameworks/pytorch/train
    method: POST
    data_selector: result
    params: {}
- name: apply_mlrun
  endpoint:
    path: /apply_mlrun
    method: POST
    data_selector: model
    params: {}
- name: apply_mlrun
  endpoint:
    path: /mlrun/frameworks/sklearn/apply_mlrun
    method: POST
    data_selector: model
    params: {}
- name: apply_mlrun
  endpoint:
    path: /mlrun/frameworks/xgboost/apply_mlrun
    method: POST
    data_selector: model
- name: DataSource
  endpoint:
    path: /mlrun/model/DataSource
    method: GET
- name: DataTarget
  endpoint:
    path: /mlrun/model/DataTarget
    method: GET
- name: DataTargetBase
  endpoint:
    path: /mlrun/model/DataTargetBase
    method: GET
- name: FeatureSetProducer
  endpoint:
    path: /mlrun/model/FeatureSetProducer
    method: GET
- name: HyperParamOptions
  endpoint:
    path: /mlrun/model/HyperParamOptions
    method: GET
- name: Notification
  endpoint:
    path: /mlrun/model/Notification
    method: GET
- name: Retry
  endpoint:
    path: /mlrun/model/Retry
    method: GET
- name: RunMetadata
  endpoint:
    path: /mlrun/model/RunMetadata
    method: GET
- name: RunObject
  endpoint:
    path: /mlrun/model/RunObject
    method: GET
- name: RunSpec
  endpoint:
    path: /mlrun/model/RunSpec
    method: GET
- name: RunStatus
  endpoint:
    path: /mlrun/model/RunStatus
    method: GET
- name: RunTemplate
  endpoint:
    path: /mlrun/model/RunTemplate
    method: GET
- name: with_param_file
  endpoint:
    path: /mlrun/model/RunTemplate/with_param_file
    method: GET
    data_selector: parameters
    params: {}
- name: with_params
  endpoint:
    path: /mlrun/model/RunTemplate/with_params
    method: GET
    data_selector: parameters
    params: {}
- name: with_secrets
  endpoint:
    path: /mlrun/model/RunTemplate/with_secrets
    method: GET
    data_selector: parameters
    params: {}
- name: with_param_file
  endpoint:
    path: /mlrun/model/RunTemplate/with_param_file
    method: GET
    data_selector: parameters
    params: {}
- name: with_params
  endpoint:
    path: /mlrun/model/RunTemplate/with_params
    method: GET
    data_selector: parameters
    params: {}
- name: with_secrets
  endpoint:
    path: /mlrun/model/RunTemplate/with_secrets
    method: GET
    data_selector: parameters
    params: {}
- name: model_endpoint
  endpoint:
    path: /model_monitoring/api/get_or_create_model_endpoint
    method: GET
    data_selector: ModelEndpoint
    params: {}
- name: sample_set_statistics
  endpoint:
    path: /model_monitoring/api/get_sample_set_statistics
    method: GET
    data_selector: dict
    params: {}
- name: dataset_as_dataframe
  endpoint:
    path: /model_monitoring/api/read_dataset_as_dataframe
    method: GET
    data_selector: tuple
    params: {}
- name: record_results
  endpoint:
    path: /model_monitoring/api/record_results
    method: GET
    data_selector: ModelEndpoint
    params: {}
- name: write_monitoring_df
  endpoint:
    path: /model_monitoring/api/write_monitoring_df
    method: GET
    data_selector: None
    params: {}
- name: get_or_create_model_endpoint
  endpoint:
    path: /mlrun/model_monitoring/api/get_or_create_model_endpoint
    method: GET
    data_selector: ModelEndpoint
    params: {}
- name: get_sample_set_statistics
  endpoint:
    path: /mlrun/model_monitoring/api/get_sample_set_statistics
    method: GET
    data_selector: dict
    params: {}
- name: read_dataset_as_dataframe
  endpoint:
    path: /mlrun/model_monitoring/api/read_dataset_as_dataframe
    method: GET
    data_selector: tuple
    params: {}
- name: record_results
  endpoint:
    path: /mlrun/model_monitoring/api/record_results
    method: GET
    data_selector: ModelEndpoint
    params: {}
- name: write_monitoring_df
  endpoint:
    path: /mlrun/model_monitoring/api/write_monitoring_df
    method: GET
    data_selector: None
    params: {}
- name: do_tracking
  endpoint:
    path: /do_tracking
    method: POST
    data_selector: results
    params: {}
- name: evaluate
  endpoint:
    path: /evaluate
    method: POST
    data_selector: results
    params: {}
- name: do_tracking
  endpoint:
    path: /do_tracking
    method: GET
    data_selector: results
    params: {}
- name: evaluate
  endpoint:
    path: /evaluate
    method: GET
    data_selector: results
    params: {}
- name: packager
  endpoint:
    path: /mlrun/package/packager
    method: GET
    data_selector: packagers
- name: default_packager
  endpoint:
    path: /mlrun/package/packagers/default_packager
    method: GET
    data_selector: packagers
- name: packagers_manager
  endpoint:
    path: /mlrun/package/packagers_manager
    method: GET
    data_selector: packagers
- name: packager
  endpoint:
    path: generated_rsts/mlrun.package.packager.Packager.html
    method: GET
    data_selector: packagers
    params: {}
- name: default_packager
  endpoint:
    path: generated_rsts/mlrun.package.packagers.default_packager.DefaultPackager.html
    method: GET
    data_selector: packagers
    params: {}
- name: packagers_manager
  endpoint:
    path: generated_rsts/mlrun.package.packagers_manager.PackagersManager.html
    method: GET
    data_selector: packagers
    params: {}
- name: python_standard_library_packagers
  endpoint:
    path: generated_rsts/mlrun.package.packagers.python_standard_library_packagers.html
    method: GET
    data_selector: packagers
    params: {}
- name: numpy_packagers
  endpoint:
    path: generated_rsts/mlrun.package.packagers.numpy_packagers.html
    method: GET
    data_selector: packagers
    params: {}
- name: pandas_packagers
  endpoint:
    path: generated_rsts/mlrun.package.packagers.pandas_packagers.html
    method: GET
    data_selector: packagers
    params: {}
- name: packager
  endpoint:
    path: /mlrun/package/packager/Packager
    method: GET
    data_selector: packager_details
- name: PackagersManagerArtifacts
  endpoint:
    path: /packagers/artifacts
    method: GET
- name: PackagersManagerResults
  endpoint:
    path: /packagers/results
    method: GET
- name: pack
  endpoint:
    path: /pack
    method: POST
    data_selector: artifact
    params: {}
- name: unpack
  endpoint:
    path: /unpack
    method: POST
    data_selector: artifact
    params: {}
- name: PackagersManager.artifacts
  endpoint:
    path: /packagers/artifacts
    method: GET
    data_selector: artifacts
- name: PackagersManager.results
  endpoint:
    path: /packagers/results
    method: GET
    data_selector: results
- name: artifacts
  endpoint:
    data_selector: artifacts
- name: results
  endpoint:
    data_selector: results
- name: artifacts
  endpoint:
    path: /artifacts
    method: GET
    data_selector: artifacts
    params: {}
- name: results
  endpoint:
    path: /results
    method: GET
    data_selector: results
    params: {}
- name: default_packing_artifact_type
  endpoint:
    path: /DEFAULT_PACKING_ARTIFACT_TYPE
    method: GET
    data_selector: result
- name: default_unpacking_artifact_type
  endpoint:
    path: /DEFAULT_UNPACKING_ARTIFACT_TYPE
    method: GET
    data_selector: object
- name: pack_subclasses
  endpoint:
    path: /PACK_SUBCLASSES
    method: GET
    data_selector: 'False'
- name: priority
  endpoint:
    path: /PRIORITY
    method: GET
    data_selector: '5'
- name: default_packing_artifact_type
  endpoint:
    path: /mlrun/package/packagers/python_standard_library_packagers/BoolPackager.DEFAULT_PACKING_ARTIFACT_TYPE
    method: GET
    data_selector: result
    params: {}
- name: default_unpacking_artifact_type
  endpoint:
    path: /mlrun/package/packagers/python_standard_library_packagers/BoolPackager.DEFAULT_UNPACKING_ARTIFACT_TYPE
    method: GET
    data_selector: object
    params: {}
- name: pack_subclasses
  endpoint:
    path: /mlrun/package/packagers/python_standard_library_packagers/BoolPackager.PACK_SUBCLASSES
    method: GET
    data_selector: 'False'
    params: {}
- name: priority
  endpoint:
    path: /mlrun/package/packagers/python_standard_library_packagers/BoolPackager.PRIORITY
    method: GET
    data_selector: '5'
    params: {}
- name: packing
  endpoint:
    path: /pack
    method: POST
    data_selector: result
    params: {}
- name: unpacking
  endpoint:
    path: /unpack
    method: POST
    data_selector: result
    params: {}
- name: packaging
  endpoint:
    path: /packaging
    method: GET
    data_selector: packaging
    params: {}
- name: unpacking
  endpoint:
    path: /unpacking
    method: GET
    data_selector: unpacking
    params: {}
- name: packing
  endpoint:
    path: /pack
    method: POST
    data_selector: result
    params: {}
- name: unpacking
  endpoint:
    path: /unpack
    method: POST
    data_selector: result
    params: {}
- name: file
  endpoint:
    data_selector: result
    params:
      file_format: json
- name: object
  endpoint:
    data_selector: result
    params:
      pickle_module_name: cloudpickle
- name: result
  endpoint:
    data_selector: result
    params: {}
- name: FloatPackager
  endpoint:
    path: /mlrun/package/packagers/python_standard_library_packagers/FloatPackager
    method: GET
    data_selector: records
- name: default_packing_artifact_type
  endpoint:
    path: /mlrun/package/packagers/python_standard_library_packagers/DictPackager/DEFAULT_PACKING_ARTIFACT_TYPE
    method: GET
    data_selector: result
    params: {}
- name: default_unpacking_artifact_type
  endpoint:
    path: /mlrun/package/packagers/python_standard_library_packagers/DictPackager/DEFAULT_UNPACKING_ARTIFACT_TYPE
    method: GET
    data_selector: result
    params: {}
- name: pack_subclasses
  endpoint:
    path: /mlrun/package/packagers/python_standard_library_packagers/DictPackager/PACK_SUBCLASSES
    method: GET
    data_selector: result
    params: {}
- name: priority
  endpoint:
    path: /mlrun/package/packagers/python_standard_library_packagers/DictPackager/PRIORITY
    method: GET
    data_selector: result
    params: {}
- name: IntPackager
  endpoint:
    path: /mlrun/package/packagers/python_standard_library_packagers/IntPackager
    method: GET
    data_selector: packager_info
    params: {}
- name: default_packing_artifact_type
  endpoint:
    path: DEFAULT_PACKING_ARTIFACT_TYPE
    method: GET
    data_selector: value
    params: {}
- name: default_unpacking_artifact_type
  endpoint:
    path: DEFAULT_UNPACKING_ARTIFACT_TYPE
    method: GET
    data_selector: value
    params: {}
- name: pack_subclasses
  endpoint:
    path: PACK_SUBCLASSES
    method: GET
    data_selector: value
    params: {}
- name: priority
  endpoint:
    path: PRIORITY
    method: GET
    data_selector: value
    params: {}
- name: frozenset_packager
  endpoint:
    path: /mlrun/package/packagers/python_standard_library_packagers/FrozensetPackager
    method: GET
    data_selector: packager
    params: {}
- name: default_packing_artifact_type
  endpoint:
    path: /mlrun/package/packagers/python_standard_library_packagers/ListPackager/DEFAULT_PACKING_ARTIFACT_TYPE
    method: GET
    data_selector: result
    params: {}
- name: default_unpacking_artifact_type
  endpoint:
    path: /mlrun/package/packagers/python_standard_library_packagers/ListPackager/DEFAULT_UNPACKING_ARTIFACT_TYPE
    method: GET
    data_selector: result
    params: {}
- name: pack_subclasses
  endpoint:
    path: /mlrun/package/packagers/python_standard_library_packagers/ListPackager/PACK_SUBCLASSES
    method: GET
    data_selector: result
    params: {}
- name: priority
  endpoint:
    path: /mlrun/package/packagers/python_standard_library_packagers/ListPackager/PRIORITY
    method: GET
    data_selector: result
    params: {}
- name: default_packing_artifact_type
  endpoint:
    path: DEFAULT_PACKING_ARTIFACT_TYPE
    method: GET
    data_selector: result
    params: {}
- name: default_unpacking_artifact_type
  endpoint:
    path: DEFAULT_UNPACKING_ARTIFACT_TYPE
    method: GET
    data_selector: object
    params: {}
- name: pack_subclasses
  endpoint:
    path: PACK_SUBCLASSES
    method: GET
    data_selector: boolean
    params: {}
- name: priority
  endpoint:
    path: PRIORITY
    method: GET
    data_selector: int
    params: {}
- name: pack_object
  endpoint:
    path: /pack_object
    method: POST
    data_selector: artifact
    params: {}
- name: pack_path
  endpoint:
    path: /pack_path
    method: POST
    data_selector: artifact
    params:
      archive_format: zip
- name: pack_result
  endpoint:
    path: /pack_result
    method: POST
    data_selector: result
    params: {}
- name: default_packing_artifact_type
  endpoint:
    path: /default/pack
    method: GET
    data_selector: result
    params: {}
- name: default_unpacking_artifact_type
  endpoint:
    path: /default/unpack
    method: GET
    data_selector: result
    params: {}
- name: supported_artifact_types
  endpoint:
    path: /supported/artifacts
    method: GET
    data_selector: result
    params: {}
- name: default_artifact_types
  endpoint:
    path: /default_artifact_types
    method: GET
    data_selector: artifact_types
    params: {}
- name: artifact_packing
  endpoint:
    path: /artifact_packing
    method: POST
    data_selector: result
    params: {}
- name: artifact_unpacking
  endpoint:
    path: /artifact_unpacking
    method: POST
    data_selector: result
    params: {}
- name: packing
  endpoint:
    path: /pack
    method: POST
    data_selector: result
    params:
      artifact_type: result
- name: unpacking
  endpoint:
    path: /unpack
    method: POST
    data_selector: result
    params:
      artifact_type: file
- name: default_packing_artifact_type
  endpoint:
    path: /mlrun/mlconf/packagers/pack_tuple
    method: GET
    data_selector: DEFAULT_PACKING_ARTIFACT_TYPE
    params: {}
- name: default_unpacking_artifact_type
  endpoint:
    path: /mlrun/mlconf/packagers/unpack_tuple
    method: GET
    data_selector: DEFAULT_UNPACKING_ARTIFACT_TYPE
    params: {}
- name: pack_subclasses
  endpoint:
    path: /mlrun/mlconf/packagers/pack_subclasses
    method: GET
    data_selector: PACK_SUBCLASSES
    params: {}
- name: priority
  endpoint:
    path: /mlrun/mlconf/packagers/priority
    method: GET
    data_selector: PRIORITY
    params: {}
- name: pack
  endpoint:
    path: /pack
    method: POST
    data_selector: artifact
    params: {}
- name: unpack
  endpoint:
    path: /unpack
    method: POST
    data_selector: artifact
    params: {}
- name: NumPyNDArrayDictPackager
  endpoint:
    path: /generated_rsts/mlrun.package.packagers.numpy_packagers.NumPyNDArrayDictPackager.html
    method: GET
    data_selector: dict[str, numpy.ndarray]
- name: NumPyNDArrayListPackager
  endpoint:
    path: /generated_rsts/mlrun.package.packagers.numpy_packagers.NumPyNDArrayListPackager.html
    method: GET
    data_selector: list[numpy.ndarray]
- name: NumPyNDArrayPackager
  endpoint:
    path: /generated_rsts/mlrun.package.packagers.numpy_packagers.NumPyNDArrayPackager.html
    method: GET
    data_selector: numpy.ndarray
- name: NumPyNumberPackager
  endpoint:
    path: /generated_rsts/mlrun.package.packagers.numpy_packagers.NumPyNumberPackager.html
    method: GET
    data_selector: numpy.number
- name: NumPySupportedFormat
  endpoint:
    path: /generated_rsts/mlrun.package.packagers.numpy_packagers.NumPySupportedFormat.html
    method: GET
    data_selector: Library of numpy formats
- name: TuplePackager
  endpoint:
    path: /mlrun/package/packagers/python_standard_library_packagers/TuplePackager
    method: GET
    data_selector: records
    params: {}
- name: DEFAULT_PACKING_ARTIFACT_TYPE
  endpoint:
    path: /pack
    method: POST
    data_selector: artifact
    params: {}
- name: DEFAULT_UNPACKING_ARTIFACT_TYPE
  endpoint:
    path: /unpack
    method: POST
    data_selector: artifact
    params: {}
- name: NumPyNDArrayDictPackager
  endpoint:
    path: /package/packagers/numpy/ndarray_dict
    method: GET
- name: NumPyNDArrayListPackager
  endpoint:
    path: /package/packagers/numpy/ndarray_list
    method: GET
- name: NumPyNDArrayPackager
  endpoint:
    path: /package/packagers/numpy/ndarray
    method: GET
- name: NumPyNumberPackager
  endpoint:
    path: /package/packagers/numpy/number
    method: GET
- name: NumPySupportedFormat
  endpoint:
    path: /package/packagers/numpy/supported_format
    method: GET
- name: NumPyNDArrayDictPackager
  endpoint:
    path: /mlrun/package/packagers/numpy_packagers/NumPyNDArrayDictPackager
    method: GET
    data_selector: packager
    params: {}
- name: NumPyNDArrayListPackager
  endpoint:
    path: /mlrun/package/packagers/numpy_packagers/NumPyNDArrayListPackager
    method: GET
    data_selector: packager
    params: {}
- name: NumPyNDArrayPackager
  endpoint:
    path: /mlrun/package/packagers/numpy_packagers/NumPyNDArrayPackager
    method: GET
    data_selector: packager
    params: {}
- name: NumPyNumberPackager
  endpoint:
    path: /mlrun/package/packagers/numpy_packagers/NumPyNumberPackager
    method: GET
    data_selector: packager
    params: {}
- name: NumPySupportedFormat
  endpoint:
    path: /mlrun/package/packagers/numpy_packagers/NumPySupportedFormat
    method: GET
    data_selector: packager
    params: {}
- name: NumPyNDArrayListPackager
  endpoint:
    path: /mlrun/package/packagers/numpy_packagers/NumPyNDArrayListPackager
    method: GET
- name: CSV
  endpoint:
    path: CSV
    method: GET
- name: GZ
  endpoint:
    path: GZ
    method: GET
- name: NPY
  endpoint:
    path: NPY
    method: GET
- name: NPZ
  endpoint:
    path: NPZ
    method: GET
- name: TXT
  endpoint:
    path: TXT
    method: GET
- name: dataset
  endpoint:
    path: /pack_dataset
    method: POST
    data_selector: artifact
    params:
      file_format: parquet
- name: file
  endpoint:
    path: /pack_file
    method: POST
    data_selector: artifact
    params:
      file_format: npy
- name: object
  endpoint:
    path: /pack_object
    method: POST
    data_selector: artifact
    params:
      pickle_module_name: cloudpickle
- name: result
  endpoint:
    path: /pack_result
    method: POST
    data_selector: result
    params: {}
- name: PandasDataFramePackager
  endpoint:
    path: /generated_rsts/mlrun.package.packagers.pandas_packagers.PandasDataFramePackager
    method: GET
    data_selector: pd.DataFrame
- name: PandasSeriesPackager
  endpoint:
    path: /generated_rsts/mlrun.package.packagers.pandas_packagers.PandasSeriesPackager
    method: GET
    data_selector: pd.Series
- name: PandasSupportedFormat
  endpoint:
    path: /generated_rsts/mlrun.package.packagers.pandas_packagers.PandasSupportedFormat
    method: GET
    data_selector: Library of Pandas formats
- name: unpack_dataset
  endpoint:
    path: /unpack/dataset
    method: GET
    data_selector: array
    params: {}
- name: unpack_file
  endpoint:
    path: /unpack/file
    method: GET
    data_selector: array
    params: {}
- name: unpack_object
  endpoint:
    path: /unpack/object
    method: GET
    data_selector: object
    params: {}
- name: default
  endpoint:
    path: ''
    method: ''
    data_selector: ''
    params: {}
- name: data_item
  endpoint:
    path: /mlrun/datastore/index.html
    method: GET
    data_selector: unpacked_data_item
- name: default_packaging
  endpoint:
    path: /mlrun/package/packagers/pandas_packagers/PandasSeriesPackager
    method: GET
    data_selector: default_packaging
    params: {}
- name: CSV
  endpoint: {}
- name: GZ
  endpoint: {}
- name: NPY
  endpoint: {}
- name: NPZ
  endpoint: {}
- name: TXT
  endpoint: {}
- name: unpack_file
  endpoint:
    path: /unpack_file
    method: GET
    data_selector: series
    params: {}
- name: unpack_object
  endpoint:
    path: /unpack_object
    method: GET
    data_selector: object
    params: {}
- name: PandasDataFramePackager
  endpoint:
    path: mlrun.package.packagers.pandas_packagers.PandasDataFramePackager
    method: GET
- name: PandasSeriesPackager
  endpoint:
    path: mlrun.package.packagers.pandas_packagers.PandasSeriesPackager
    method: GET
- name: PandasSupportedFormat
  endpoint:
    path: mlrun.package.packagers.pandas_packagers.PandasSupportedFormat
    method: GET
- name: CSV
  endpoint:
    path: /services/data/vXX.X/sobjects/CSV
    method: GET
- name: FEATHER
  endpoint:
    path: /services/data/vXX.X/sobjects/FEATHER
    method: GET
- name: H5
  endpoint:
    path: /services/data/vXX.X/sobjects/H5
    method: GET
- name: HTML
  endpoint:
    path: /services/data/vXX.X/sobjects/HTML
    method: GET
- name: JSON
  endpoint:
    path: /services/data/vXX.X/sobjects/JSON
    method: GET
- name: ORC
  endpoint:
    path: /services/data/vXX.X/sobjects/ORC
    method: GET
- name: PARQUET
  endpoint:
    path: /services/data/vXX.X/sobjects/PARQUET
    method: GET
- name: XLSX
  endpoint:
    path: /services/data/vXX.X/sobjects/XLSX
    method: GET
- name: XML
  endpoint:
    path: /services/data/vXX.X/sobjects/XML
    method: GET
- name: dataset
  endpoint:
    path: /pack_dataset
    method: POST
    data_selector: dataset
    params:
      file_format: parquet
- name: file
  endpoint:
    path: /pack_file
    method: POST
    data_selector: file
    params:
      file_format: parquet or csv
      flatten: true
- name: object
  endpoint:
    path: /pack_object
    method: POST
    data_selector: object
    params:
      pickle_module_name: cloudpickle
- name: result
  endpoint:
    path: /pack_result
    method: POST
    data_selector: result
    params: {}
- name: watch_stream
  endpoint:
    path: /watch_stream
    method: GET
    data_selector: data
    params: {}
- name: data_item
  endpoint:
    path: /unpack_dataset
    method: POST
    data_selector: unpacked_data
    params: {}
- name: data_item_file
  endpoint:
    path: /unpack_file
    method: POST
    data_selector: unpacked_series
    params: {}
- name: data_item_object
  endpoint:
    path: /unpack_object
    method: POST
    data_selector: unpacked_object
    params: {}
- name: MlrunProject
  endpoint:
    path: /mlrun/projects/MlrunProject
    method: GET
- name: ProjectMetadata
  endpoint:
    path: /mlrun/projects/ProjectMetadata
    method: GET
- name: ProjectSpec
  endpoint:
    path: /mlrun/projects/ProjectSpec
    method: GET
- name: ProjectStatus
  endpoint:
    path: /mlrun/projects/ProjectStatus
    method: GET
- name: PandasSeriesPackager
  endpoint:
    path: /mlrun/package/packagers/pandas_packagers/PandasSeriesPackager
    method: GET
    data_selector: records
    params: {}
- name: unpack_file
  endpoint:
    path: /unpack_file
    method: GET
    data_selector: series
    params: {}
- name: unpack_object
  endpoint:
    path: /unpack_object
    method: GET
    data_selector: object
    params: {}
- name: alert
  endpoint:
    path: /alert
    method: GET
    data_selector: alerts
    params: {}
- name: project
  endpoint:
    path: /projects
    method: GET
    data_selector: projects
    params: {}
- name: CSV
- name: FEATHER
- name: H5
- name: HTML
- name: JSON
- name: ORC
- name: PARQUET
- name: XLSX
- name: XML
- name: alert_templates
  endpoint:
    path: /list_alert_templates
    method: GET
    data_selector: alert_templates
- name: alerts_configs
  endpoint:
    path: /list_alerts_configs
    method: GET
    data_selector: alerts_configs
    params:
      limit: mlconf.alerts.default_list_alert_configs_limit
- name: api_gateways
  endpoint:
    path: /list_api_gateways
    method: GET
    data_selector: api_gateways
- name: artifacts
  endpoint:
    path: /list_artifacts
    method: GET
    data_selector: artifacts
- name: MlrunProject
  endpoint:
    path: /mlrun/projects/MlrunProject
    method: GET
- name: ProjectMetadata
  endpoint:
    path: /mlrun/projects/ProjectMetadata
    method: GET
- name: ProjectSpec
  endpoint:
    path: /mlrun/projects/ProjectSpec
    method: GET
- name: ProjectStatus
  endpoint:
    path: /mlrun/projects/ProjectStatus
    method: GET
- name: MlrunProject
  endpoint:
    path: /mlrun/projects
    method: GET
    data_selector: projects
    params: {}
- name: latest_artifacts
  endpoint:
    path: /list_artifacts
    method: GET
    data_selector: artifacts
    params:
      tag: latest
- name: result_versions
  endpoint:
    path: /list_artifacts
    method: GET
    data_selector: artifacts
    params:
      tag: '*'
- name: datastore_profiles
  endpoint:
    path: /list_datastore_profiles
    method: GET
    data_selector: datastore_profiles
    params: {}
- name: functions
  endpoint:
    path: /list_functions
    method: GET
    data_selector: functions
    params: {}
- name: llm_prompts
  endpoint:
    path: /list_llm_prompts
    method: GET
    data_selector: llm_prompts
    params: {}
- name: model_endpoints
  endpoint:
    path: /list_model_endpoints
    method: GET
    data_selector: model_endpoints
    params: {}
- name: model_monitoring_functions
  endpoint:
    path: /list_model_monitoring_functions
    method: GET
    data_selector: model_monitoring_functions
    params: {}
- name: models
  endpoint:
    path: /list_models
    method: GET
    data_selector: models
    params: {}
- name: runs
  endpoint:
    path: /list_runs
    method: GET
    data_selector: runs
    params: {}
- name: alert_templates
  endpoint:
    path: /list_alert_templates
    method: GET
    data_selector: list
- name: alerts_configs
  endpoint:
    path: /list_alerts_configs
    method: GET
    data_selector: list
    params:
      limit: mlconf.alerts.default_list_alert_configs_limit
      offset: null
- name: api_gateways
  endpoint:
    path: /list_api_gateways
    method: GET
    data_selector: list
- name: artifacts
  endpoint:
    path: /list_artifacts
    method: GET
    data_selector: ArtifactList
- name: list_runs
  endpoint:
    path: /list/runs
    method: GET
    data_selector: runs
    params: {}
- name: log_artifact
  endpoint:
    path: /log/artifact
    method: POST
    data_selector: artifact
    params: {}
- name: log_dataset
  endpoint:
    path: /log/dataset
    method: POST
    data_selector: dataset
    params: {}
- name: log_document
  endpoint:
    path: /log/document
    method: POST
    data_selector: document
    params: {}
- name: log_llm_prompt
  endpoint:
    path: /log/llm_prompt
    method: POST
    data_selector: llm_prompt
    params: {}
- name: log_model
  endpoint:
    path: /log/model
    method: POST
    data_selector: model
    params: {}
- name: alert_activations
  endpoint:
    params:
      page: null
      page_size: null
      page_token: null
- name: artifacts
  endpoint:
    params:
      page: null
      page_size: null
      page_token: null
- name: runs
  endpoint:
    params:
      page: null
      page_size: null
      page_token: null
- name: llm_prompts
  endpoint:
    params:
      page: null
      page_size: null
      page_token: null
- name: models
  endpoint:
    params:
      page: null
      page_size: null
      page_token: null
- name: pull
  endpoint:
    path: /pull
    method: GET
    data_selector: runs
    params:
      page: next
      page_size: mlrun.mlconf.httpdb.pagination.default_page_size
- name: push
  endpoint:
    path: /push
    method: POST
    data_selector: result
    params: {}
- name: latest_artifacts
  endpoint:
    path: /list_artifacts
    method: GET
    data_selector: artifacts
    params:
      tag: latest
- name: result_versions
  endpoint:
    path: /list_artifacts
    method: GET
    data_selector: artifacts
    params:
      tag: '*'
- name: datastore_profiles
  endpoint:
    path: /list_datastore_profiles
    method: GET
    data_selector: profiles
- name: functions
  endpoint:
    path: /list_functions
    method: GET
    data_selector: functions
- name: llm_prompts
  endpoint:
    path: /list_llm_prompts
    method: GET
    data_selector: prompts
- name: model_endpoints
  endpoint:
    path: /list_model_endpoints
    method: GET
    data_selector: endpoints
- name: model_monitoring_functions
  endpoint:
    path: /list_model_monitoring_functions
    method: GET
    data_selector: monitoring_functions
- name: models
  endpoint:
    path: /list_models
    method: GET
    data_selector: models
- name: runs
  endpoint:
    path: /list_runs
    method: GET
    data_selector: runs
- name: alert_activation
  endpoint:
    path: /alert_activations
    method: GET
    data_selector: alert_activations
    params: {}
- name: list_runs
  endpoint:
    path: /runs
    method: GET
    data_selector: runs
    params: {}
- name: model_monitoring
  endpoint:
    path: /mlrun/projects/project.html#set_model_monitoring_credentials
    method: POST
    data_selector: model_monitoring
    params:
      tsdb_profile_name: my-v3io-tsdb
      stream_profile_name: my-v3io-stream
- name: datastore_profile
  endpoint:
    path: /mlrun/datastore/index.html#mlrun.datastore.datastore_profile.DatastoreProfileV3io
    method: GET
    data_selector: datastore_profiles
    params: {}
- name: confluent_kafka
  endpoint:
    path: /mlrun/datastore/index.html#mlrun.datastore.datastore_profile.DatastoreProfileKafkaStream
    method: GET
    data_selector: kafka_streams
    params: {}
- name: paginated_list_artifacts
  endpoint:
    path: /paginated_list_artifacts
    method: GET
    data_selector: ArtifactList
    params:
      page: page
      page_size: page_size
      page_token: page_token
- name: paginated_list_runs
  endpoint:
    path: /paginated_list_runs
    method: GET
    data_selector: RunList
    params:
      page: page
      page_size: page_size
      page_token: page_token
- name: paginated_list_llm_prompts
  endpoint:
    path: /paginated_list_llm_prompts
    method: GET
    data_selector: ArtifactList
    params:
      page: page
      page_size: page_size
      page_token: page_token
- name: paginated_list_models
  endpoint:
    path: /paginated_list_models
    method: GET
    data_selector: ArtifactList
    params:
      page: page
      page_size: page_size
      page_token: page_token
- name: runs
  endpoint:
    path: /runs
    method: GET
    params:
      page: '1'
      page_size: mlrun.mlconf.httpdb.pagination.default_page_size
      page_token: None
- name: data
  endpoint:
    path: /set_artifact
    method: POST
    data_selector: artifact
    params: {}
- name: model
  endpoint:
    path: /set_artifact
    method: POST
    data_selector: artifact
    params: {}
- name: model_monitoring_credentials
  endpoint:
    path: /set_model_monitoring_credentials
    method: POST
- name: model_monitoring_function
  endpoint:
    path: /set_model_monitoring_function
    method: POST
- name: pipelines
  endpoint:
    path: /mlrun/run/pipelines
    method: GET
    data_selector: pipelines
- name: function
  endpoint:
    path: /mlrun/run/functions
    method: GET
    data_selector: functions
- name: get_or_create_project
  endpoint:
    path: /mlrun/projects/get_or_create_project
    method: GET
    data_selector: MlrunProject
    params: {}
- name: project
  endpoint:
    path: /mlrun/projects
    method: POST
    data_selector: project
    params:
      name: myproj
      context: ./
      init_git: true
      description: my new project
- name: retry_pipeline
  endpoint:
    path: /mlrun/run/retry_pipeline
    method: POST
    data_selector: run_id
    params: {}
- name: terminate_pipeline
  endpoint:
    path: /mlrun/run/terminate_pipeline
    method: POST
    data_selector: run_id
    params: {}
- name: wait_for_pipeline_completion
  endpoint:
    path: /mlrun/run/wait_for_pipeline_completion
    method: GET
    data_selector: run_id
    params: {}
- name: wait_for_runs_completion
  endpoint:
    path: /mlrun/run/wait_for_runs_completion
    method: GET
    data_selector: runs
    params: {}
- name: APIGateway
  endpoint:
    path: /mlrun/runtimes/nuclio/api_gateway
    method: GET
- name: api_gateway
  endpoint:
    path: /api_gateway
    method: GET
    data_selector: api_gateway_info
- name: pipeline_run_retry
  endpoint:
    params:
      run_id: ID of the pipeline run to retry
      project: name of the project associated with the pipeline run
- name: pipeline_run_terminate
  endpoint:
    params:
      run_id: ID of the pipeline run to terminate
      project: name of the project associated with the pipeline run
- name: wait_for_pipeline_completion
  endpoint:
    params:
      run_id: id of pipelines run
      timeout: wait timeout in sec
      expected_statuses: list of expected statuses
      namespace: k8s namespace if not default
      remote: read kfp data from mlrun service
      project: the project of the pipeline
- name: wait_for_runs_completion
  endpoint:
    params:
      runs: list of run objects
      sleep: time to sleep between checks
      timeout: maximum time to wait in seconds
      silent: set to True for silent exit on timeout
- name: DaskCluster
  endpoint:
    path: /dask/cluster
    method: POST
    data_selector: cluster
    params: {}
- name: DatabricksRuntime
  endpoint:
    path: /databricks/runtime
    method: POST
    data_selector: runtime
    params: {}
- name: HandlerRuntime
  endpoint:
    path: /handler/runtime
    method: POST
    data_selector: runtime
    params: {}
- name: application
  endpoint:
    path: /mlrun/runtimes
    method: GET
    data_selector: runtimes
    params: {}
- name: state_thresholds
  endpoint:
    path: /mlrun/runtimes/pod/set_state_thresholds
    method: POST
- name: try_auto_mount_based_on_config
  endpoint:
    path: /mlrun/runtimes/pod/try_auto_mount_based_on_config
    method: POST
- name: validate_and_enrich_service_account
  endpoint:
    path: /mlrun/runtimes/pod/validate_and_enrich_service_account
    method: POST
- name: with_annotations
  endpoint:
    path: /mlrun/runtimes/pod/with_annotations
    method: POST
- name: with_limits
  endpoint:
    path: /mlrun/runtimes/pod/with_limits
    method: POST
- name: with_node_selection
  endpoint:
    path: /mlrun/runtimes/pod/with_node_selection
    method: POST
- name: with_preemption_mode
  endpoint:
    path: /mlrun/runtimes/pod/with_preemption_mode
    method: POST
- name: with_priority_class
  endpoint:
    path: /mlrun/runtimes/pod/with_priority_class
    method: POST
- name: with_requests
  endpoint:
    path: /mlrun/runtimes/pod/with_requests
    method: POST
- name: with_security_context
  endpoint:
    path: /mlrun/runtimes/pod/with_security_context
    method: POST
- name: outputs
  endpoint:
    path: /model/outputs
    method: POST
- name: class_args
  endpoint:
    path: /model/class_args
    method: POST
- name: async_flow
  endpoint:
    path: /async/flow
    method: POST
- name: simple_model_router
  endpoint:
    path: /router/simple
    method: POST
- name: handler
  endpoint:
    path: default_function_handler
    method: GET
    data_selector: records
    params: {}
- name: KubeResource.set_state_thresholds
  endpoint:
    path: /_modules/mlrun/runtimes/pod.html#KubeResource.set_state_thresholds
    method: GET
    data_selector: state_thresholds
    params: {}
- name: KubeResource.try_auto_mount_based_on_config
  endpoint:
    path: /_modules/mlrun/runtimes/pod.html#KubeResource.try_auto_mount_based_on_config
    method: GET
    data_selector: override_params
    params: {}
- name: KubeResource.validate_and_enrich_service_account
  endpoint:
    path: /_modules/mlrun/runtimes/pod.html#KubeResource.validate_and_enrich_service_account
    method: GET
    data_selector: allowed_service_accounts
    params: {}
- name: KubeResource.with_annotations
  endpoint:
    path: /_modules/mlrun/runtimes/pod.html#KubeResource.with_annotations
    method: GET
    data_selector: annotations
    params: {}
- name: KubeResource.with_limits
  endpoint:
    path: /_modules/mlrun/runtimes/pod.html#KubeResource.with_limits
    method: GET
    data_selector: mem, cpu, gpus, gpu_type
    params: {}
- name: KubeResource.with_node_selection
  endpoint:
    path: /_modules/mlrun/runtimes/pod.html#KubeResource.with_node_selection
    method: GET
    data_selector: node_name, node_selector, affinity, tolerations
    params: {}
- name: KubeResource.with_preemption_mode
  endpoint:
    path: /_modules/mlrun/runtimes/pod.html#KubeResource.with_preemption_mode
    method: GET
    data_selector: mode
    params: {}
- name: KubeResource.with_priority_class
  endpoint:
    path: /_modules/mlrun/runtimes/pod.html#KubeResource.with_priority_class
    method: GET
    data_selector: name
    params: {}
- name: KubeResource.with_requests
  endpoint:
    path: /_modules/mlrun/runtimes/pod.html#KubeResource.with_requests
    method: GET
    data_selector: mem, cpu
    params: {}
- name: KubeResource.with_security_context
  endpoint:
    path: /_modules/mlrun/runtimes/pod.html#KubeResource.with_security_context
    method: GET
    data_selector: security_context
    params: {}
- name: KubejobRuntime.build_config
  endpoint:
    path: /_modules/mlrun/runtimes/kubejob.html#KubejobRuntime.build_config
    method: GET
    data_selector: image, base_image, commands, secret, source, extra, load_source_on_run,
      with_mlrun, auto_build, requirements, overwrite, prepare_image_for_deploy, requirements_file,
      builder_env, extra_args
    params: {}
- name: KubejobRuntime.deploy
  endpoint:
    path: /_modules/mlrun/runtimes/kubejob.html#KubejobRuntime.deploy
    method: GET
    data_selector: watch, with_mlrun, skip_deployed, is_kfp, mlrun_version_specifier,
      builder_env, show_on_failure, force_build
    params: {}
- name: KubejobRuntime.deploy_step
  endpoint:
    path: /_modules/mlrun/runtimes/kubejob.html#KubejobRuntime.deploy_step
    method: GET
    data_selector: image, base_image, commands, secret_name, with_mlrun, skip_deployed
    params: {}
- name: KubejobRuntime.is_deployed
  endpoint:
    path: /_modules/mlrun/runtimes/kubejob.html#KubejobRuntime.is_deployed
    method: GET
    data_selector: ''
    params: {}
- name: KubejobRuntime.with_source_archive
  endpoint:
    path: /_modules/mlrun/runtimes/kubejob.html#KubejobRuntime.with_source_archive
    method: GET
    data_selector: source, workdir, handler, pull_at_runtime, target_dir
    params: {}
- name: LocalRuntime.with_source_archive
  endpoint:
    path: /_modules/mlrun/runtimes/local.html#LocalRuntime.with_source_archive
    method: GET
    data_selector: source, workdir, handler, target_dir
    params: {}
- name: MpiRuntimeV1.spec
  endpoint:
    path: /_modules/mlrun/runtimes/mpijob/v1.html#MpiRuntimeV1.spec
    method: GET
    data_selector: ''
    params: {}
- name: RemoteRuntime.add_trigger
  endpoint:
    path: /_modules/mlrun/runtimes/nuclio/function.html#RemoteRuntime.add_trigger
    method: GET
    data_selector: name, spec
    params: {}
- name: RemoteRuntime.add_v3io_stream_trigger
  endpoint:
    path: /_modules/mlrun/runtimes/nuclio/function.html#RemoteRuntime.add_v3io_stream_trigger
    method: GET
    data_selector: stream_path, name, group, seek_to, shards, extra_attributes, ack_window_size
    params: {}
- name: RemoteRuntime.deploy
  endpoint:
    path: /_modules/mlrun/runtimes/nuclio/function.html#RemoteRuntime.deploy
    method: GET
    data_selector: project, tag, verbose, builder_env, force_build
    params: {}
- name: RemoteRuntime.deploy_step
  endpoint:
    path: /_modules/mlrun/runtimes/nuclio/function.html#RemoteRuntime.deploy_step
    method: GET
    data_selector: project, models, env, tag, verbose, use_function_from_db
    params: {}
- name: topology
  endpoint:
    path: /set_topology
    method: POST
    data_selector: graph
    params: {}
- name: default_handler
  endpoint:
    params:
      pull_at_runtime: false
- name: RouterStep
  endpoint:
    path: /RouterStep
    method: GET
- name: TaskStep
  endpoint:
    path: /TaskStep
    method: GET
- name: V2ModelServer
  endpoint:
    path: /V2ModelServer
    method: GET
- name: predict
  endpoint:
    path: /predict
    method: POST
    data_selector: outputs
- name: explain
  endpoint:
    path: /explain
    method: POST
    data_selector: outputs
- name: APIGateway
  endpoint:
    path: /mlrun/runtimes/nuclio/api_gateway
    method: GET
- name: APIGatewayAuthenticator
  endpoint:
    path: /mlrun/runtimes/nuclio/api_gateway/authenticator
    method: GET
- name: do_event
  endpoint:
    path: /do_event
    method: POST
- name: extract_results_from_response
  endpoint:
    path: /extract_results_from_response
    method: GET
- name: logic
  endpoint:
    path: /logic
    method: GET
- name: post_init
  endpoint:
    path: /post_init
    method: GET
- name: validate
  endpoint:
    path: /validate
    method: POST
- name: model
  endpoint:
    path: /predict
    method: POST
    data_selector: outputs
    params: {}
- name: do_event
  endpoint:
    path: VotingEnsemble.do_event
    method: POST
- name: extract_results_from_response
  endpoint:
    path: VotingEnsemble.extract_results_from_response
    method: GET
- name: logic
  endpoint:
    path: VotingEnsemble.logic
    method: POST
- name: post_init
  endpoint:
    path: VotingEnsemble.post_init
    method: POST
- name: validate
  endpoint:
    path: VotingEnsemble.validate
    method: POST
- name: do_event
  endpoint:
    path: VotingEnsemble.do_event
    method: POST
- name: extract_results_from_response
  endpoint:
    path: VotingEnsemble.extract_results_from_response
    method: GET
- name: logic
  endpoint:
    path: VotingEnsemble.logic
    method: POST
- name: post_init
  endpoint:
    path: VotingEnsemble.post_init
    method: POST
- name: validate
  endpoint:
    path: VotingEnsemble.validate
    method: POST
- name: remote_step
  endpoint:
    path: /api/projects
    method: GET
- name: VotingEnsemble
  endpoint:
    path: /v2/models/VotingEnsemble
    method: POST
- name: logic
  endpoint:
    path: logic
    method: POST
    data_selector: predictions
    params: {}
- name: do_event
  endpoint:
    path: do_event
    method: POST
    data_selector: event
    params: {}
- name: extract_results_from_response
  endpoint:
    path: extract_results_from_response
    method: POST
    data_selector: response
    params: {}
- name: AggregateByKey
  endpoint:
    path: /storey/transformations/AggregateByKey
    method: GET
- name: Assert
  endpoint:
    path: /storey/transformations/Assert
    method: GET
- name: Batch
  endpoint:
    path: /storey/transformations/Batch
    method: GET
- name: Choice
  endpoint:
    path: /storey/transformations/Choice
    method: GET
- name: Extend
  endpoint:
    path: /storey/transformations/Extend
    method: GET
- name: Filter
  endpoint:
    path: /storey/transformations/Filter
    method: GET
- name: FlatMap
  endpoint:
    path: /storey/transformations/FlatMap
    method: GET
- name: Flatten
  endpoint:
    path: /storey/transformations/Flatten
    method: GET
- name: ForEach
  endpoint:
    path: /storey/transformations/ForEach
    method: GET
- name: JoinWithTable
  endpoint:
    path: /storey/transformations/JoinWithTable
    method: GET
- name: Map
  endpoint:
    path: /storey/transformations/Map
    method: GET
- name: MapClass
  endpoint:
    path: /storey/transformations/MapClass
    method: GET
- name: MapWithState
  endpoint:
    path: /storey/transformations/MapWithState
    method: GET
- name: Partition
  endpoint:
    path: /storey/transformations/Partition
    method: GET
- name: QueryByKey
  endpoint:
    path: /storey/transformations/QueryByKey
    method: GET
- name: ReifyMetadata
  endpoint:
    path: /storey/transformations/ReifyMetadata
    method: GET
- name: SampleWindow
  endpoint:
    path: /storey/transformations/SampleWindow
    method: GET
- name: SendToHttp
  endpoint:
    path: /storey/transformations/SendToHttp
    method: GET
- name: ToDataFrame
  endpoint:
    path: /storey/transformations/ToDataFrame
    method: GET
- name: AggregateByKey
  endpoint:
    path: /storey/transformations/AggregateByKey
    method: GET
- name: Assert
  endpoint:
    path: /storey/transformations/Assert
    method: GET
- name: Batch
  endpoint:
    path: /storey/transformations/Batch
    method: GET
- name: Choice
  endpoint:
    path: /storey/transformations/Choice
    method: GET
- name: Extend
  endpoint:
    path: /storey/transformations/Extend
    method: GET
- name: Filter
  endpoint:
    path: /storey/transformations/Filter
    method: GET
- name: FlatMap
  endpoint:
    path: /storey/transformations/FlatMap
    method: GET
- name: Flatten
  endpoint:
    path: /storey/transformations/Flatten
    method: GET
- name: ForEach
  endpoint:
    path: /storey/transformations/ForEach
    method: GET
- name: JoinWithTable
  endpoint:
    path: /storey/transformations/JoinWithTable
    method: GET
- name: Map
  endpoint:
    path: /storey/transformations/Map
    method: GET
- name: MapClass
  endpoint:
    path: /storey/transformations/MapClass
    method: GET
- name: MapWithState
  endpoint:
    path: /storey/transformations/MapWithState
    method: GET
- name: Partition
  endpoint:
    path: /storey/transformations/Partition
    method: GET
- name: QueryByKey
  endpoint:
    path: /storey/transformations/QueryByKey
    method: GET
- name: ReifyMetadata
  endpoint:
    path: /storey/transformations/ReifyMetadata
    method: GET
- name: SampleWindow
  endpoint:
    path: /storey/transformations/SampleWindow
    method: GET
- name: SendToHttp
  endpoint:
    path: /storey/transformations/SendToHttp
    method: GET
- name: ToDataFrame
  endpoint:
    path: /storey/transformations/ToDataFrame
    method: GET
- name: function
  endpoint:
    path: /functions
    method: GET
    data_selector: functions
    params: {}
- name: project
  endpoint:
    path: /projects
    method: GET
    data_selector: projects
    params: {}
- name: build
  endpoint:
    path: /build
    method: POST
    data_selector: build_response
    params: {}
- name: clean
  endpoint:
    path: /clean
    method: POST
    data_selector: clean_response
    params: {}
- name: config
  endpoint:
    path: /config
    method: GET
    data_selector: config_response
    params: {}
- name: get
  endpoint:
    path: /get
    method: GET
    data_selector: get_response
    params: {}
- name: logs
  endpoint:
    path: /logs
    method: GET
    data_selector: logs_response
    params: {}
- name: project
  endpoint:
    path: /project
    method: POST
    data_selector: project_response
    params: {}
- name: run
  endpoint:
    path: /run
    method: POST
    data_selector: run_response
    params: {}
- name: version
  endpoint:
    path: /version
    method: GET
    data_selector: version_response
    params: {}
- name: watch-stream
  endpoint:
    path: /watch-stream
    method: GET
    data_selector: watch_stream_response
    params: {}
- name: dataset_artifact
  endpoint:
    path: /api/dataset/artifacts
    method: GET
    data_selector: records
    params: {}
- name: model_artifact
  endpoint:
    path: /api/model/artifacts
    method: GET
    data_selector: records
    params: {}
- name: function
  endpoint:
    path: /functions
    method: POST
    data_selector: functions
    params: {}
- name: project
  endpoint:
    path: /projects
    method: GET
    data_selector: projects
    params: {}
- name: projects
  endpoint:
    path: /api/projects
    method: GET
    data_selector: projects
    params: {}
- name: functions
  endpoint:
    path: /api/functions
    method: GET
    data_selector: functions
    params: {}
- name: project_management
  endpoint:
    path: ./projects/project.html
    method: GET
    data_selector: projects
    params: {}
- name: data_management
  endpoint:
    path: ./genai/data-mgmt/index.html
    method: GET
    data_selector: data
    params: {}
- name: development
  endpoint:
    path: ./genai/development/index.html
    method: GET
    data_selector: development
    params: {}
- name: deployment
  endpoint:
    path: ./genai/deployment/index.html
    method: GET
    data_selector: deployment
    params: {}
- name: live_ops
  endpoint:
    path: ./genai/live-ops/index.html
    method: GET
    data_selector: live_ops
    params: {}
- name: monitoring
  endpoint:
    path: ./concepts/model-monitoring.html
    method: GET
    data_selector: monitoring
    params: {}
notes:
- Some functions may require specific permissions.
- Every object in MLRun exists in the context of a project (except projects themselves).
- Many objects can be assigned labels, and listed/queried by label.
- Most objects have a create method as well as a store method.
- Most objects have a `create` method as well as a `store` method.
- Some objects have a `versioned` option.
- Many objects have both a `store` function and a `patch` function.
- This method for Vault functionality is currently in technical preview, and requires
  a HashiCorp Vault infrastructure properly set up and connected to the MLRun API
  server.
- Uses OAuth2 with refresh token  requires setup of connected app in api
- MLRun simplifies and accelerates the time to production.
- Ensure mlrun packages are installed.
- Use minimal resources  CPU and not GPU.
- Before running this notebook make sure the mlrun packages are installed (pip install
  mlrun) and that you have configured the access to MLRun service.
- The workflow may take up to 20 mins to complete.
- Some objects like Contact may return nulls in deeply nested fields
- Build the vector DB in the data layer and load the data into it.
- Uses minimal resources  CPU and not GPU, and a small amount of data.
- Uses LLM for monitoring model performance
- Set readiness timeout to 20 minutes
- This tutorial uses Milvus on a local host for simplicity.
- This tutorial illustrates deploying an LLM using MLRun.
- It uses minimal resources  CPU and not GPU, and a small amount of data.
- This notebook uses sklearn. If it is not installed in your environment, run pip
  install scikit-learn~=1.5.2.
- Credentials for the DB may be passed here assuming the code is not introduced into
  any repo, or they may be provided through project secrets.
- Functions can be executed as part of a multi-stage pipeline.
- Uses the MLRun API for project and function management.
- Make sure you reviewed the basics in MLRun Quick Start Tutorial.
- Some objects like dataset may return nulls in deeply nested fields.
- Requires Nuclio to be installed (over k8s or Docker)
- Uses user provided base image for deployment
- Training functions require logging of artifacts and models
- MLRun serving can produce managed, real-time, serverless, pipelines composed of
  various data processing and ML tasks.
- Uses MLRun for MLOps functionality
- Recommended to use an MLRun project to manage functions and assets
- Uses Nuclio real-time serverless engine for model serving
- Simulates the model server locally using the mock_server
- MLRun supports real-time serverless pipelines.
- Model serving classes must inherit from mlrun.serving.V2ModelServer.
- Uses OAuth2 with refresh token  requires setup of connected app in MLRun
- Some objects may return nulls in deeply nested fields
- Make sure to run the install command once and restart the notebook after the install.
- Uses MLRun SDK for function registration and project management.
- Restart the kernel after the install of Evidently.
- Make sure to run the installation command only once and restart the notebook after
  the install.
- Make sure to run the following once and restart the notebook after the install !!!
  After that, you can comment out `!pip install "evidently=={SUPPORTED_EVIDENTLY_VERSION}"`
- 'Backward compatibility: Support both S3_ENDPOINT_URL (deprecated) and AWS_ENDPOINT_URL_S3'
- The model-monitoring stream pod writes data to Parquet, by model endpoint.
- If this project was running with MM enabled pre-1.8.0, disable the old model monitoring
  to update configurations
- Model monitoring supports Kafka and V3IO as streaming platforms.
- Model monitoring supports TDEngine and V3IO as TSDB platforms.
- Uses OAuth2 for authentication.
- Requires setup of connected app.
- The monitoring infrastructure can trigger alerts when an event occurs
- Uses MLRun for model monitoring capabilities.
- Uses OAuth2 with refresh token  requires setup of connected app in mlrun
- You will need to create a slack webhook with a unique URL and pass that secret as
  a parameter
- Default controller frequency is 10 minutes; modifying base_period to 1 minute allows
  faster monitoring results.
- Wait two minutes for the model monitoring applications flow to finish
- Some model monitoring may require specific configurations for data sources
- Uses batch function for evaluating data against logged model.
- Uses MLRun's DataItem to pass datasets for training and testing.
- Modifying controller frequency with base_period parameter to 1 minute allows to
  see monitoring results faster, by default, its value is 10 minutes.
- The model monitoring applications flow may take time to finish.
- Uses MLRun to manage experiments and datasets
- Use the apply_mlrun function from MLRun's LightGBM framework integration
- By default, this demo works with the online feature store, which is currently not
  part of the Open Source MLRun default deployment.
- Uses custom validation for bid values  requires minimum value setup
- Original data is 5.7GB in size; demo uses sampled data.
- Server and client versions are not the same but compatible
- Integrates MLflow with MLRun for tracking and logging experiments.
- The MLFlow tracker Model serving class inherits the V2ModelServer class.
- Uses custom validation for bid values with MinMaxValidator.
- You can combine MLflow and MLRun for a comprehensive solution for managing, tracking,
  and deploying machine learning models.
- Uses feature vector for both offline and online inference
- Make sure the mlrun package is installed and that you have configured the access
  to MLRun service.
- mlrun.mlconf.external_platform_tracking.enabled must be set to True to enable tracking.
- Best practice for working with CI/CD is using MLRun Projects with a combination
  of Git and CI/CD.
- 'Project loaded successfully: mlflow-tracking-example'
- All lists must be of equal size.
- MLRun service runs over Kubernetes or local Docker for demo and test purposes.
- disable_default_http_trigger is supported from Nuclio 1.13.1.
- Requires setup of connected app in api
- Uses REST API for communication
- Setup via environment variables in mlrun.env file
- Iguazio MLOps Platform (not MLRun CE)
- MLRun can be deployed using local Docker for demo and test purposes
- Use local service with mlrun.set_environment('http://localhost:8080', artifact_path='./')
  or remote service with mlrun.set_environment('<remote-service-url>', access_key='xyz',
  username='joe')
- The real-time (nuclio) function uses default logger level `debug` (logging all)
- MLRun service runs over Kubernetes
- Can be deployed using local Docker for demo and test purposes
- Uses API key for authentication
- Environment variables must be set for access
- MLRun service runs over Kubernetes (can also be deployed using local Docker for
  demo and test purposes)
- Use local service
- Pandas is used for testing, and is not recommended for production deployments
- MLRun service runs over Kubernetes.
- Can be deployed using local Docker for demo and test purposes.
- MLRun client SDK is installed via pip.
- Uses API key for authentication.
- An MLRun project can be backed by a Git repo
- Uses MLRun framework for managing pipelines and functions.
- Local testing can be done using server.test()
- K8s deployment is handled by project.deploy_function()
- Localhost requires no username and access_key.
- This release of MLRun supports only Python 3.9 for both the server and the client.
- The MLRun Community Edition resources are configured initially with the default
  cluster/namespace resource limits.
- These configurations are only required for AWS S3 storage, due to the usage of the
  same S3 protocol in MinIO.
- The MLRun Community Edition resources are configured initially with the default
  cluster/namespace resource limits. You can modify the resources from outside if
  needed.
- 'Known issue when installing the chart on Macs using Apple silicon (ARM-based architecture):
  The current pipelines MySQL database fails to start.'
- The Grafana statistics do not work well in this release. A fix will be delivered
  in a subsequent release.
- The minimal instance size required for MLRun to operate is m5.xlarge.
- MLRUN_DBPATH saves the URL endpoint of the MLRun APIs service endpoint.
- Ensure the CIDR_RANGE is correctly formatted, including the subnet mask (e.g. 192.168.1.0/24).
- Ensure that you have remote access to your MLRun service (i.e., to the service URL
  on the remote Kubernetes cluster).
- If the MLRUN_DBPATH points to a remote iguazio cluster and the V3IO_API and/or V3IO_FRAMESD
  vars are not set, they are inferred from the DBPATH.
- Make sure that you add .env to your .gitignore file. The environment file contains
  sensitive information that you should not store in your source control.
- Ensure that you have remote access to your MLRun service.
- When installing other python packages on top of MLRun, make sure to install them
  with mlrun in the same command/requirement file.
- Transforms unstructured data into structured data for analysis.
- Uses audio recordings for call analysis.
- 'MLRun does not come with a VectorDB out-of-the-box: you need to install your choice
  of DB.'
- Register the profile temporarily for the current client session
- Credentials for the DB may be passed here assuming the code is not introduced into
  any repo, or they may be provided through project secrets
- Documents can be added using add_documents() or add_artifacts() methods.
- MLRunLoader is a wrapper that interacts with LangChain loaders.
- Uses API key for authentication  requires setup of environment variables
- MLRun does not limit the choice of vector databases you can use.
- Uses OpenAI's gpt-3.5-turbo-0125 for LLM.
- Milvus is used as the vector store.
- Some prompts may lead to forbidden responses
- Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results
  may be encountered.
- Device set to use cpu
- Some metrics may have varying thresholds depending on test cases
- USER_AGENT environment variable not set, consider setting it to identify your requests.
- Uses MLRun for orchestrating and evaluating machine learning models.
- Uses Hugging Face models and MLRun for training
- Model name is NousResearch/Llama-2-7b-hf
- This demo modifies the vocabulary and behavior of a pre-trained model to talk like
  a pirate.
- Fine-tuning is significantly faster and more efficient than training a model from
  scratch.
- Uses MLRun for dataset logging and management
- The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed
  in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config`
  argument instead.
- Uses MLRun functions for fine-tuning LLM.
- Fine tuning allows you to adapt an LLM to your specific domain or task.
- Hugging Face models might require more resources than usual.
- By default, in LLModel usage, metrics are calculated after invocation.
- In LLModel usage, metrics are calculated after invocation and may not be fully accurate.
- Quantization reduces model size and can lead to a significant reduction in accuracy,
  so validation is important.
- Dynamic batching is more optimal for LLMs compared to static batching.
- By default, in LLModel usage, metrics are calculated after invocation. These token
  metrics are estimates and may not be fully accurate.
- Each step can be a python function, a serving class, or a class that implements
  the `do` method.
- Model is loaded from the Hugging Face model hub
- Quantization can lead to a significant reduction in accuracy, so it is important
  to test the quantized model on a validation set to ensure that accuracy is not severely
  impacted.
- Static batching is not as optimal as dynamic batching for LLMs since not all inputs
  produce completion tokens at the same time.
- Unlike the example of gen AI serving class, which showed a simplistic case of deploying
  a single model with realtime serving pipelines, you can run a more realistic scenario
  of an end-to-end inference pipeline that can retrieve any data, run multiple models,
  and filter any data or results.
- Requires setup of OpenAI API key in environment variables.
- The model is ready for use with the configured execution mechanism.
- The MLRun project is a container for all your work on this gen AI application.
- Running code locally is useful for debugging and development.
- Running the function remotely may require attaching storage to the function, as
  well as passing storage credentials through project secrets.
- By default, MLRun stores a short preview of 20 lines.
- Statistics can be enabled by setting the stats parameter to True.
- Supports real-time and incremental ingestion
- Do not name columns starting with either '_' or 'aggr_'. They are reserved for internal
  use.
- Do not name columns to match the regex pattern '.*_[a-z]+_[0-9]+[smhd]$', where
  [a-z]+ is an aggregation name.
- When using the pandas engine, do not use spaces () or periods ('.') in the column
  names.
- MLRun calculates statistics on the DataFrame on all numeric fields.
- You can change the number of preview lines by changing the value of the preview
  parameter.
- Do not name columns starting with either _ or aggr_. They are reserved for internal
  use.
- Do not name columns to match the regex pattern .*_[a-z]+_[0-9]+[smhd]$, where [a-z]+
  is an aggregation name.
- When using the pandas engine, do not use spaces () or periods (.) in the column
  names.
- Uses Spark for data ingestion and transformation.
- Remote Spark execution requires MLRun function of type remote-spark.
- The default value for the overwrite parameter in the ingest function for scheduled
  ingest is False, meaning that the target from the previous ingest is not deleted.
- The dataset is from S3, but usually it is the output from a previous step in a pipeline.
- Uses Spark for ingestion and transformation
- Entity is case sensitive
- To track results use the .show() or .logs() methods.
- apply_mlrun() accepts the model object and various optional parameters.
- Hyperparameters can also be loaded directly from a JSON file.
- Hyperparameters can also be loaded directly from a CSV file.
- MLRun supports iterative tasks for automatic and distributed execution of many tasks
  with variable parameters (hyperparams).
- Parallel execution over containers is supported using Dask or Nuclio.
- The training is done with the shortcut function apply_mlrun that enables the automatic
  logging and additional features.
- replicas * workers need to match or exceed parallel_runs
- Supports parallel execution over Dask or Nuclio clusters.
- Training is done with the shortcut function apply_mlrun that enables the automatic
  logging and additional features.
- To track results use the .show() or .logs() methods or click here to open in UI
- Nuclio tasks are relatively short (preferably under 5 minutes), use it for running
  many iterations where each individual run is less than 5 min.
- Supports iterative tasks for automatic and distributed execution of many tasks with
  variable parameters.
- MLRun supports iterative tasks for automatic and distributed execution of many tasks
  with variable parameters.
- Learn how to train your model using an offline dataset created by the MLRun feature
  store.
- The offline dataset can also be used for your EDA.
- The load runs synchronously (the deploy is stalled until load completes).
- This can be an issue for large models and cause a readiness timeout.
- You can increase the function spec.readiness_timeout, or alternatively choose async
  loading.
- You can choose async loading by setting the function spec.load_mode = 'async'.
- Batch inference can sometimes take advantage of big data technologies, such as Spark,
  to generate predictions.
- Uses NoSQL for real-time performance needs
- Batch inference or offline inference addresses the need to run machine learning
  model on large datasets.
- 'The function supports the following frameworks: Scikit-learn, XGBoost, LightGBM,
  Tensorflow/Keras, PyTorch, ONNX.'
- If pull_at_runtime=True, MLRun loads the git/archive repo into the function container
  at run time and does not require a build.
- Start with a low percentage for the canary function and gradually increase it.
- If pull_at_runtime=True MLRun loads the git/archive repo into the function container
  at run time and does not require a build.
- If pull_at_runtime is not set to True, you need to deploy the functions to build
  a container.
- Uses Git source for CI/CD automation
- Pull at runtime simplifies development
- Some objects like model may require specific paths.
- Project YAML is created and updated with project metadata
- Uses Git as the source for project artifacts
- Uses GitHub as the project source
- Project metadata includes functions and artifacts
- Loading a project with a git remote source holds a reference to git processes. If
  you want to release the reference, use the project.spec.repo.close() method.
- When running using GitHub Actions you need to set the credentials/secrets and add
  a script under the .github/workflows/ directory.
- When running using GitLab CI/CD you need to set the credentials/secrets and update
  the script .gitlab-ci.yml directory.
- When using Jenkins Pipeline you need to set up the credentials/secrets in Jenkins
  and update the script Jenkinsfile in your codebase.
- Loading a project with a git remote source holds a reference to git processes.
- Use the `project.spec.repo.close()` method to release the reference.
- Projects host functions, workflows, artifacts, features, and configuration.
- Projects simplify processing data, submitting jobs, running workflows, and deploying
  pipelines.
- Use project management features for organizing tasks and functions
- MLRun supports a simple and native integration with the CI systems.
- When running using GitHub Actions you need to set the credentials/secrets.
- When running using GitLab CI/CD you need to set the credentials/secrets.
- It is assumed that your local environment has the required access to pull a private
  repo.
- Ensure that no project name is used as the prefix of another project name, since
  this would affect retrieving pipelines from Kubeflow pipelines.
- Project should be backed by a Git repo
- 'Preferred approach for production workloads: Loading the code from container'
- GIT_TOKEN must be set in MLRun project secrets for working with private repos.
- MLRun is looking for a project.yaml file in the root of the repo.
- Assumes basic familiarity with version control software such as GitHub, GitLab,
  etc.
- MLRun is looking for a project.yaml file in the root of the repo
- When working with a private Git, set the project secrets.
- If pull_at_runtime=False, re-build the Docker image.
- If pull_at_runtime=True, skip rebuilding Docker image.
- The easiest way to pass secrets to MLRun jobs is through the MLRun project secrets
  mechanism.
- MLRun jobs automatically gain access to all project secrets defined for the same
  project.
- Jobs executed locally do not have access to the project secrets.
- By default, all jobs in a project automatically get access to all the associated
  project secrets.
- It is possible to limit the keys mounted to the function
- Ensure that the script resides in the root of the project context.
- Function objects are all inclusive, containing the code and all the operational
  aspects.
- MLRun has an open public function hub that stores many pre-developed functions for
  use in your projects.
- MLRun supports numerous real-time and batch runtimes.
- You can configure automatic retries for failed job runs by passing a retry parameter.
- Uses OAuth2 with refresh token  requires setup of connected app in MLRun.
- Default authentication mode is none for open source and access-key for the Iguazio
  platform.
- The default authentication mode is none for open source and access-key for the Iguazio
  platform.
- Dask is currently in Tech Preview status.
- Set mlrun api path and artifact path for logging.
- Dask is currently in Tech Preview status
- Cluster is killed after timeout (inactivity), default is '60 minutes', should be
  at least 5 minutes to avoid transient issues.
- Use NodePort service type to access the Dask dashboard or scheduler from remote.
- Uses Dask for data processing
- Pipelines using Dask, Kubeflow, and MLRun
- Projects are used to package multiple functions, workflows, and artifacts.
- Project code and definitions are usually stored in a Git archive.
- Uses MLRun for managing pipelines with Dask and Kubeflow.
- Dask cluster requires specific configurations for memory and replicas.
- MLRun does not support decompressing large Kubeflow pipeline graphs. This issue
  occurs when Kubeflow executes a large number of steps, which results in the metadata
  for the pipeline graph being compressed. Currently, MLRun is unable to decompress
  this metadata, which may impact pipelines with extensive step counts.
- Dask cluster initialization requires setting up function specs.
- Horovod and MPI may use NCCL when applicable which may require some specific configuration
  arguments to run optimally.
- The Spark runtimes spark and remote-spark do not support dbfs, http, or memory data
  stores.
- Do not override default spec and dependencies when using with_igz_spark()
- Requires Nuclio v1.13.1 or higher
- When using with_repo, the contents of the Git repo or archive are available in the
  current working directory of your MLRun function during runtime.
- 'Do not change the configuration by using the UI: it breaks the functionality.'
- Make sure to save the notebook before running mlrun.code_to_function so that the
  lateset changes will be reflected in the function.
- 'Functions are the basic building blocks of MLRun: they are essentially Python objects
  that know how to run locally or on a Kubernetes cluster.'
- Functions should be created within a project.
- Disabling auto-mount
- Modifying the auto-mount default configuration
- In an Iguazio system, apply configurations for `v3io` access through the API.
- In an open-source deployment where NFS is configured, apply configurations for `pvc`
  access to NFS storage.
- MLRun annotations are used to identify the code that needs to be converted into
  an MLRun function.
- For production, create your own images to ensure that the image is fixed.
- When using the `mlrun` or `mlrun-gpu` image, use PyTorch versions up to and including
  than 2.0.1, but not higher.
- Modifying the auto-mount default configuration is supported.
- Disabling auto-mount can be configured.
- In cases where the default storage configuration does not fit the function needs,
  MLRun allows for function spec modifiers to be manually applied to functions.
- The auto-mount logic can also be disabled by setting func.spec.disable_auto_mount
  = True on any MLRun function.
- MLRun provides pre-built images which contain the components necessary to execute
  an MLRun runtime.
- Using the --skip-tls-verify flag poses security risks since it bypasses SSL certificate
  validation.
- When using the mlrun or mlrun-gpu image, use PyTorch versions up to and including
  than 2.0.1, but not higher.
- Functions can be easily imported into your project and therefore help you to speed
  up your development cycle by reusing built-in code.
- If you don't specify a hub name at all, the algorithm searches for the function
  in all the hubs, giving preference to newly defined hubs.
- Function YAML must be named `function.yaml`
- Use Git tags for function versioning
- For private repos, set project secret with HTTPS_AUTH_TOKEN
- One of the biggest challenge in distributed systems is handling data given the different
  access methods, APIs, and authentication mechanisms across types and providers.
- You can use Git tags for function versioning in Git.
- 'If working from a private repo, set: project.set_secret({"HTTPS_AUTH_TOKEN":<Http-Token,
  e.g. GIT-TOKEN>})'
- DataItem objects are automatically parsed to the hinted type when a type hint is
  available.
- Working with the abstractions enable you to securely access different data sources
  through a single API, many continuance methods (e.g. to/from DataFrame, get, download,
  list, ), automated data movement, and versioning.
- The UI limits the artifact query display to 1000 records.
- Remote model artifacts cannot be uploaded or downloaded.
- For models not using a datastore profile, the MLRun code attempts to retrieve credentials
  from the environment.
- Migrating from v1.7.0 to v1.8.0 and higher does not maintain backwards compatibility.
- Evidently has a memory accumulation issue as more and more snapshots are saved.
- Logging artifacts in every model monitoring window may cause scale issues.
- Any path that is supported by MLRun can be used to store artifacts.
- Evaluate method creates an MLRun job using the to_job method and runs it.
- After testing your application with external data, you can run it on the actual
  model endpoint data.
- Allows you to execute your application's monitoring logic as an MLRun job, either
  locally or remotely, with flexible input and configuration options, including writing
  the outputs to the databases.
- Each object type requires a different way to convert it for logging the object to
  a file.
- When the model endpoint does not have data in the requested time window, the application
  will not run.
- The stream profile is the datastore profile you already registered for the project.
- By default, no time window overlap is allowed - 'fail_on_overlap'.
- View model monitoring results in the platform UI
- Press Resource monitoring to get the relevant Grafana Model Monitoring Details Dashboard
  that displays detailed, real-time performance data of the selected model.
- Use the evaluate method to create and run an MLRun job.
- Customize job configuration using the to_job method.
- The start time for the batch application run is not inclusive.
- You need to train and deploy a model to see results in the dashboards.
- The dashboards immediately display data if you already have a model that is trained
  and running with production data.
- stream_profile is required when running locally with run_local=True and write_output=True.
- The Model Endpoints summary list provides a quick view of the model monitoring data.
- You must use the v1.8.0 client to utilize model monitoring on the v1.8.0 server.
- Must use the v1.8.0 client to utilize model monitoring on the v1.8.0 server.
- These variables control the basic alert behavior
- The predefined event types include data-drift-detected, data-drift-suspected, concept-drift-detected,
  etc.
- Alerts track the job runs by name, not by the unique run UID.
- Default retention period is 14 weeks, adjustable in configuration.
- The default retention period is 14 weeks.
- Notifications can be sent either locally from the SDK, or remotely from the MLRun
  API.
- Email notifications on local runs must explicitly include all SMTP settings.
- Workflows are saved/registered in the project using the set_workflow() method.
- Workflows are executed using the run() method or using the CLI command mlrun project.
- Starting from MLRun 1.9.1, the project default image no longer affects the workflow
  runner image.
- Remote workflows support both Python 3.9 and 3.11, but the workflow runner itself
  runs on Python 3.9.
- The context object is expected to be used as part of a run.
- If you are looking for a similar API to use on your local environment (outside a
  local run) you can use the MlrunProject object.
- Starting from MLRun 1.8.0, KFP client package is not pre-installed on images such
  as mlrun/mlrun.
- MLRun services (back-end) only use py3.11.
- Uses mlrun.handler to automate logging
- Type hints from the `typing` module are currently not supported but will be in the
  future.
- Workflows are asynchronous by default.
- Functions can host multiple methods (handlers). You can set the default handler
  per function.
- Multi-stage workflows define the order of execution of multiple dependent steps
  in a DAG.
- Instead of waiting for completion, you can set up a notification in Slack with a
  results summary.
- 'Use one of: project.notifiers.add_notification(notification_type="slack",params={"webhook":"<user-slack-webhook>"})
  or in a Jupyter notebook with the "%env" magic command: %env SLACK_WEBHOOK=<slack
  webhook url>'
- Workflows are written as Python functions.
- For defining the steps order you can either use steps outputs as written above,
  or use .after(step_1,step_2,..) method, that allows the user to define the order
  of the workflow steps without the need to forward the outputs from the previous
  steps.
- If you want to use workflows as part of an automated flow, save them and register
  them in the project.
- Names with underscore '_' are about to be deprecated, use dashes '-' instead.
- The ExitHandler function runs after the functions, A, B, C, D.
- It is triggered regardless of whether or not all of the preceding functions succeeded.
- The ExitHandler function runs after the functions A, B, C, D.
- The 'parallelism' parameter of dsl.ParallelFor is not supported.
- MLRun orchestrates serverless functions over Kubernetes.
- MLRun supports the concept of volume auto-mount.
- MLRun supports spot nodes for all functions.
- When an MLRun job is running on a spot node and it fails, it won't get back up again.
- MLRun orchestrates serverless functions over Kubernetes
- Node selection can be used to specify where to run workloads (e.g. specific node,
  node groups, node types, etc.).
- 'If node selection is not specified, the selection criteria defaults to the Kubernetes
  default behavior: the service/function run on a random node.'
- 'Do not configure a node selector defined in `mlconf.get_preemptible_node_selector()`
  while using the ''prevent'' preemption mode : MLRun removes the node selector to
  avoid conflicts.'
- Cloud providers use interruption handlers to warn before terminating a spot instance.
  MLRun does not currently support interruption handlers.
- MLRun jobs are more stateful by nature.
- MLRun functions run in their own pods.
- Best practice to define resource requests and limits for each MLRun function.
- Do not use node selectors for scheduling on spot/on-demand nodes.
- Node selection is often used for assigning jobs/pods to GPU nodes. But not all jobs/pods
  benefit from a GPU node.
- State thresholds are not supported for Nuclio/serving runtimes (since they have
  their own monitoring) or for the Dask runtime (which can be monitored by the client).
- Node selection is often used for assigning jobs/pods to GPU nodes.
- Scheduled jobs and workflows can be created and scheduled.
- Schedules have a minimum interval that will be allowed between two scheduled jobs.
- A job is not allowed to be scheduled twice in a 10-minute period.
- By default, a job is not allowed to be scheduled twice in a 10-minute period.
- Currently, schedules like */13 * * * * are not allowed.
- Learn how serving graphs can simplify complex workflows as illustrated in these
  examples.
- Model url is either an MLRun model store object or URL of a model directory
- If you test a Nuclio function that has a serving graph with the async engine via
  the Nuclio UI, the UI might not display the logs in the output.
- The Graph executes built-in task classes, or task classes and functions that you
  implement
- The Graph executes built-in task classes, or task classes and functions that you
  implement.
- You can use any Python function by specifying the handler name (e.g. `handler=json.dumps`).
- The function is triggered with the `event.body` as the first argument, and its result
  is passed to the next step.
- Task steps support optional input_path and result_path attributes that allow controlling
  which portion of the event is sent as input to the step, and where to update the
  returned result.
- input_path and result_path do not work together with full_event=True.
- Once the topology is set, you cannot change an existing function topology.
- The flow topology is a full graph/DAG.
- The async engine is based on Storey and asynchronous event loop.
- The url must be a valid path to the input file.
- Uses async flow topology for graph.
- Advanced graph configuration includes features like remote execution and distributed
  graphs.
- Test the live function by invoking with a valid URL path to the input file.
- Graphs can be hosted by a single function (using zero to n containers), or span
  multiple functions where each function can have its own container image and resources
  (replicas, GPUs/CPUs, volumes, etc.)
- You can specify the function attribute in task or router steps
- When the function attribute is not specified it runs on the root function
- function="*" means the step can run in any of the child functions
- Steps on different functions should be connected using a queue step (a stream)
- This API allows for the creation and deployment of serving graphs.
- Use this configuration to join the graph branches and not to join the events into
  a single large one.
- Graphs that split and rejoin can also be used for these types of scenarios.
- You can chain functions together with remote execution.
- You can define exception handling (an error-handling flow) that is triggered on
  graph or step errors.
- If you want the graph to continue after an error handler execution, specify the
  next step in the before parameter.
- If you want the graph to complete after an error handler execution, omit the before
  parameter.
- The graph errors/exceptions can be pushed into a special error stream.
- This is very convenient in the case of distributed and production graphs.
- For stateful functions, each worker has its own state.
- The buffer should be as small as possible. There is a trade-off between the buffer
  size and the latency.
- Graphs can be hosted by a single function or span multiple functions where each
  function can have its own container image and resources.
- You can specify the function attribute in task or router steps.
- Steps on different functions should be connected using a queue step.
- Avoid using timestamps or bool as entities.
- Uses passthrough=True in the feature set definition to avoid saving data to offline
  targets during ingestion.
- Maximum number of retries per event is 0
- Wait time in seconds before the first retry is 1
- If False, the process_event function is called with just one parameter (event).
  If True, the process_event function is called with two parameters (event, context).
  Defaults to False
- Whether the event processor should receive and return Event objects (when True),
  or only the payload (when False). Defaults to False
- Sql target is currently in Tech Preview status.
- Do not use SQL reserved words as entity names.
- The worker timeout must be shorter than the gateway timeout. The default is 10.
- The gateway timeout must be slightly longer than the expected function processing
  time. The default is 60.
- Aggregations must ensure feature names do not conflict with automatically generated
  names.
- Response contains only the features - the timestamp is not part of the response.
- Async nature of offline feature vector creation means response contains a status
  indicator.
- Fraud prevention requires processing raw transactions and events in real-time
- Average transaction amount needs to be calculated incrementally in real-time scenarios
- Notice that by default, Snowflake converts to uppercase name of columns ingested
  to it.
- The feature-set entity, timestamp_key and label_coumnt must have similar case to
  the source, otherwise the ingest will fail with MLRunInvalidArgumentError exception.
- This demo works with the online feature store, which is currently not part of the
  Open Source default deployment.
- This feature is currently in Tech Preview status.
- workerAllocationMode was automatically set to 'static' because explicitAckMode is
  enabled
- Setting function replicas to 1
- Create iguazio v3io stream and transactions push API endpoint
- Define the source stream trigger using v3io streams
- Uses MLRun for managing feature vectors and model training
- Predicting a fraudulent transaction
- Top features selected for model training
- 'To track results use the CLI: {''info_cmd'': ''mlrun get run 4ac3afbfb6a1409daa1e834f8f153295
  -p fraud-demo-dani'', ''logs_cmd'': ''mlrun logs 4ac3afbfb6a1409daa1e834f8f153295
  -p fraud-demo-dani''}'
- 'Or click for UI: {''ui_url'': ''https://dashboard.default-tenant.app.vmdev94.lab.iguazeng.com/mlprojects/fraud-demo-dani/jobs/monitor/4ac3afbfb6a1409daa1e834f8f153295/overview''}'
- 'To track results use the CLI: mlrun get run 4ac3afbfb6a1409daa1e834f8f153295 -p
  fraud-demo-dani'
- 'Or click for UI: https://dashboard.default-tenant.app.vmdev94.lab.iguazeng.com/mlprojects/fraud-demo-dani/jobs/monitor/4ac3afbfb6a1409daa1e834f8f153295/overview'
- Test the server locally
- Deploying the function on the Kubernetes cluster
- Uses real-time feature store for enriching requests
- Model activities can be tracked into a real-time stream and time-series DB
- Environment setup is required before serving.
- Testing the server locally is essential before deployment.
- Enrichment routers can substitute the null value with fixed or statistical value
  per feature.
- Uses MLRun for model serving and feature store
- Model activities can be tracked into a real-time stream and time-series DB.
- Monitor a deployed model to create real-time dashboards, detect drift, and analyze
  performance.
- Test the server locally before deploying
- Ensure the environment is properly set up for serving
- Enrichment routers can substitute null values with fixed or statistical value per
  feature.
- Some features can have null values (None, NaN, Inf, ).
- Uses feature enrichment and imputing for model predictions
- A pipeline can also include continuous build integration and deployment (CI/CD)
  steps, such as building container images and deploying models.
- 'Uses supported formats: csv, parquet, pq, tsdb, kv'
- Only loader classes that return single results are supported.
- SUPPORTED_FORMATS includes 'csv', 'parquet', 'pq', 'tsdb', 'kv'.
- Notification object schema with various parameters including kind, name, message,
  severity, and more.
- Notification object schema includes parameters like kind, name, severity, when,
  condition, params, and more.
- Supports asynchronous operations
- Parquet files can be read as input source
- Reads Google BigQuery query results as input source for a flow.
- For authentication, set the GCP_CREDENTIALS project secret to the credentials json
  string.
- Supports reading and writing Parquet files
- Stream sources can be created if they do not exist
- The deletion process varies depending on the type of the underlying collection implementation.
- Raises NotImplementedError if the delete operation is not supported for the collection
  implementation.
- Deletion process varies depending on the type of the underlying collection implementation.
- Provides an interface to use run params, metadata, inputs, and outputs.
- Prompt for handling customer support queries
- Q&A prompt template with user-provided question
- ML Execution Client Context is generated and injected to the function using the
  function.run() or manually using the get_or_create_ctx() call.
- Supports ingestion from various sources and real-time processing.
- Features can be specified manually or inferred automatically (during ingest/preview)
- Handles feature vector services for both online and offline use cases.
- No authentication required.
- Default auto_log is True
- Default use_horovod is None, meaning it will be read from context if available and
  if not - False.
- Auto logging will add the default artifacts and metrics to the lists of artifacts
  and metrics.
- Uses MLRun's interface providing it with mlrun's additional features.
- The `evidently` package is not installed by default in the mlrun/mlrun image. It
  must be installed separately to use this class.
- MLRun enables fully-automated experiment and pipeline tracking and reproducibility.
- 'The Packager has two main duties: Packing and Unpacking.'
- Each packager should handle a single type of object.
- The default packager implements all the required methods and has a default logic
  that should satisfy most use cases.
- Uses cloudpickle for serializing and deserializing objects.
- This method should be called at the end of the run, only after logging all artifacts,
  to ensure that files that require uploading have already been uploaded.
- Only packagers that are declared in the module are collected.
- Default packing artifact type is 'result'.
- Default unpacking artifact type is 'file'.
- Default packing artifact type is result
- Default unpacking artifact type is file
- Priority is 5
- The default artifact type to pack as is 'result'.
- The default artifact type to unpack from is 'file'.
- A flag for indicating whether to also pack all subclasses of the PACKABLE_OBJECT_TYPE
  is False.
- Default file format for packing is json.
- Default packing artifact type is result.
- Default unpacking artifact type is file.
- Default packing artifact type is 'result'
- Default unpacking artifact type is 'file'
- Pack subclasses is False
- The default artifact type to unpack from is 'object'.
- The priority of this packager is Default priority (5).
- Packing subclasses is not allowed.
- Uses builtins.int packager.
- Default unpacking artifact type is 'object'.
- Priority is set to 5.
- Pack subclasses flag is set to False.
- Priority is Default priority (5).
- Does not support packing subclasses
- Pack subclasses is set to false.
- Priority is set to default priority (5).
- Uses built-in int packager
- Default packing type is 'path'
- Default unpacking type is 'path'
- Packing subclasses is enabled
- Packing subclasses is not allowed
- Default priority is 5
- The priority of this packager in the packagers collection of the manager is 5.
- The default artifact type to unpack from is 'path'.
- The priority of this packager in the packagers collection is 5.
- Default artifact type for packing is 'result'.
- Default artifact type for unpacking is 'file'.
- A flag for indicating whether to also pack all subclasses of the PACKABLE_OBJECT_TYPE.
- The priority of this packager in the packagers collection of the manager (lower
  is better).
- Default packing type is 'result'.
- Default unpacking type is 'path'.
- Priority of this packager is 5.
- 'In order to pack tuples (not recommended), use the configuration: mlrun.mlconf.packagers.pack_tuple
  = True'
- 'Or more correctly, cast your returned tuple to a list like so: def example_func_2():
  my_tuple = (2, 4) return list(my_tuple)'
- Default packing artifact type is 'file'.
- Priority of this packager is 4.
- Packable object type is list[ndarray].
- Pack subclasses is False.
- Priority is 4.
- Warnings of mismatching python and module versions between the original pickling
  interpreter and this one may be raised.
- 'Packing Type: numpy.number'
- 'Packing Sub-Classes: True'
- 'Priority: Default priority (5)'
- 'Default Artifact Types: Packing: result, Unpacking: object'
- The default artifact type to pack as is 'file'.
- The priority of this packager is 4.
- The default artifact type to pack as is 'object'.
- Default packing type is pandas.core.frame.DataFrame
- Default artifact type to pack as is dataset
- Default artifact type to unpack from is object
- Default file format for packing is parquet
- Default packing artifact type is 'file'
- Default unpacking artifact type is 'object'
- Packing priority is 5
- Flattening is mandatory for some formats
- Default file format for packing is parquet.
- Flattening is mandatory for certain formats.
- Default artifact type to pack as is 'file'
- Default artifact type to unpack from is 'object'
- Flattening is mandatory for some formats when saving
- MLRun looks for a project.yaml file with project definition and objects in the project
  root path
- The git project should include the project yaml file.
- If the project yaml file is in a sub-directory, must specify the sub-directory.
- This API provides access to various MLRun functionalities.
- An application without an API gateway is not accessible.
- The threshold time string must conform to timelength python package standards and
  be at least 1 minute.
- With security context is not supported for spark runtime.
- If model endpoints with the same name exist, delete the latest one. Create a new
  model endpoint entry and set it as latest.
- If model endpoints with the same name exist, update the latest entry. Otherwise,
  create a new entry.
- If model endpoints with the same name exist, preserve them. Create a new model endpoint
  with the same name and set it to latest.
- Supports both 'sync' and 'async' engines, with 'async' being the default.
- 'If this flag is True the model''s responses output format is {id: <id>, model_name:
  <name>, outputs: {..., prediction: [<predictions>], ...}}'
- 'Else {id: <id>, model_name: <name>, outputs: [<predictions>]}.'
- Handles incoming events with various parameters.
- Handles incoming requests.
- Uses CLI commands for building and running functions.
- Use the mlrun CLI to build and run functions.
- Function configurations are defined in YAML files.
- Model monitoring is in TechPreview.
- You must use the v1.8.0 client to utilize model monitoring on a v1.8.0 server.
- The function logging behavior has changed in v1.4.0.
- Supports ingesting Avro-encoded Kafka records.
- Supports Confluent Kafka as a feature store data-source.
- MLRun server is based on Python 3.9.
- The event time in storey events is now taken from the `timestamp_key`.
- Users do not automatically have access rights to the project data of the projects
  they are members of. Assign the user access permission for the project folder.
- Model deployment returns ResourceNotFoundException (Nuclio error that Service is
  invalid.) Verify that all metadata.labels values are 63 characters or less. See
  the Kubernetes limitation.
- MLRun does not decompress large Kubeflow pipelines.
- When trying to identify a failed step in a workflow with mlrun.get_run_db().list_pipelines('project-name'),
  the returned error is None. To see the error, use mlrun.db.get_pipelines() instead.
- Setting AWS credentials as project secret cause a build failure on EKS configured
  with ECR. When using an ECR as the external container registry, make sure that the
  project secrets AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY have read/write access
  to ECR.
- Notifications of local runs aren't persisted.
- When using mlrun-gpu image, use PyTorch versions up to and including than 2.0.1,
  but not higher. You can build your own images with newer CUDA for a later release
  of PyTorch.
- MLRun Client does not support Win OS. Use WSL instead.
- PySpark 3.2.x cannot always read parquet files written by pyarrow 13 or above. MLRun
  ingest might fail when ingest() is called with engine="spark" and a ParquetSource
  that points to parquet files that were written by pyarrow 13 or above. Call df.to_parquet()
  with version="2.4" so that parquet files are backwards compatible.
- When using mlrun.mlrun image, use PyTorch versions up to and including than 2.0.1,
  but not higher. See MLRun runtime images.
- When using an MLRun client previous to v1.6.0, the workflow step status might show
  completed when it is actually aborted. Abort the job from the SDK instead of from
  the UI, or upgrade the client to v1.6.0 or higher.
- A loaded system takes a few minutes (5) to calculate the statistics in the Projects
  Monitoring pane.
- Default spot labels node selector is removed.
- After upgrade/restart there may be some lost notifications due to restart of the
  chief.
- Occasionally, deleting projects fails with 'Fail to delete project in MLRun'. Try
  deleting the project again.
- Deprecated and removed APIs
- Removed CLIs
- MLRun supports batch or realtime data processing at scale, data lineage and versioning,
  structured and unstructured data
errors:
- 'NON_RETRIABLE_PATHS: [''\/?user-secrets/tokens'']'
- 'RETRIABLE_POST_PATHS: [''\/?projects\/.+\/artifacts\/.+\/.+'', ''\/?run\/.+\/.+'']'
- 'REQUEST_LIMIT_EXCEEDED: Throttle API calls or reduce frequency'
- 'QUERY_TIMEOUT: Break down filters or add selectivity'
- '401 Unauthorized: Recheck OAuth scopes or token expiration'
- 'UserWarning: X does not have valid feature names, but GradientBoostingClassifier
  was fitted with feature names'
- '404 Not Found: Ensure the project or function name is correct.'
- '400 Bad Request: Check the request parameters and payload.'
- 'Run execution finished: {''status'': ''completed'', ''name'': ''tutorial-function''}'
- info! bid value is smaller than min
- 'WARNING: Saving into deprecated binary model format, please consider using `json`
  or `ubj`.'
- '401 Unauthorized: Check API key or access credentials'
- '401 Unauthorized: Check API key and permissions'
- '404 Not Found: Verify endpoint path and resource existence'
- '401 Unauthorized: Recheck API key or access permissions.'
- Ensure that you have remote access to your MLRun service.
- '401 Unauthorized: Recheck username or access key'
- '401 Unauthorized: Recheck username or access key.'
- '401 Unauthorized: Recheck your credentials or API key.'
- 'FORBIDDEN: Request contains a forbidden word'
- 'FORBIDDEN_WORD_FOUND: Request contains forbidden words'
- '401 Unauthorized: Recheck API key or permissions'
- 'FutureWarning: resume_download is deprecated and will be removed in version 1.0.0'
- Asking to truncate to max_length but no maximum length is provided and the model
  has no predefined maximum length.
- 'torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly.'
- '401 Unauthorized: Check API key or permissions.'
- '429 Too Many Requests: Rate limit exceeded.'
- 'Function deploy complete: model endpoint creation task completed with state succeeded'
- Job is running in the background, pod not found.
- WARNING!, you seem to have uncommitted git changes, use .push()
- GIT_TOKEN required for private Git repository
- Check your environment variable configurations.
- 'Permission denied: Ensure that your user has project permissions.'
- 'Error when translating nuclio names to mlrun names in api gateway: number of functions
  doesn''t match the mlrun functions in annotation'
- '401 Unauthorized: Recheck API key or token expiration'
- 'REQUEST_LIMIT_EXCEEDED: Maximum number of alerts exceeded.'
- 'INVALID_CRITERIA: Criteria parameters are invalid.'
- 'RuntimeError: Pipeline run status Failed'
- Pipeline run status Failed
- Do not configure a node selector defined in mlconf.get_preemptible_node_selector()
  while using the 'prevent' preemption mode.
- test_set or train_test_split_size are not provided, setting train_test_split_size
  to 0.2
- 'FutureWarning: The normalize argument is deprecated in v1.1 and will be removed
  in v1.3.'
- X does not have valid feature names, but RandomForestClassifier was fitted with
  feature names
- 'NotImplementedError: If the delete operation is not supported for the collection
  implementation.'
- 'INVALID_INPUT: Check input parameters for correctness.'
- 'NOT_FOUND: Ensure the specified resource exists.'
- 'SERVER_ERROR: Retry the request after a while.'
- InvalidMetricValueError
- InvalidThresholdValueError
- 'MLRunPackageCollectingError: In case the packager could not be collected.'
- 'MLRunInvalidArgumentError: If the key in the log hint instructs to log an arbitrary
  number of artifacts but the object type does not match the ''*'' or ''**'' used
  in the key.'
- 'MLRunPackagePackingError: If there was an error during the packing.'
- 'MLRunPackageCollectionError: An error that may be raised during the collection
  of packagers the manager is assigned to do.'
- 'MLRunPackageError: General error from mlrun.package.'
- 'MLRunPackagePackingError: An error that may be raised during a mlrun.Packager.pack
  method.'
- 'MLRunPackageUnpackingError: An error that may be raised during a mlrun.Packager.unpack
  method.'
- 'MLRunPackageUnpackingError: In case the packager could not unpack the data item.'
- 'MLRunInvalidArgumentError: IF the shape of the array is not 1D / 2D.'
- 'MLRunPackageUnpackingError: In case the packager could not unpack the data item'
- 'InvalidFormat: Ensure the file format is supported.'
- 'PackingError: Check the object type being packed.'
- 'RESOURCE_NOT_FOUND: Check if the resource ID is correct.'
- 'INVALID_ARGUMENT: Ensure all required arguments are provided.'
- '400 Bad Request: Check your input parameters.'
- '404 Not Found: The specified resource could not be found.'
- Users do not automatically have access rights to the project data of the projects
  they are members of. Assign the user access permission for the project folder.
- Model deployment returns ResourceNotFoundException (Nuclio error that Service is
  invalid.) Verify that all metadata.labels values are 63 characters or less. See
  the Kubernetes limitation.
- MLRun does not decompress large Kubeflow pipelines.
- When trying to identify a failed step in a workflow with mlrun.get_run_db().list_pipelines('project-name'),
  the returned error is None. To see the error, use mlrun.db.get_pipelines() instead.
- Setting AWS credentials as project secret cause a build failure on EKS configured
  with ECR. When using an ECR as the external container registry, make sure that the
  project secrets AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY have read/write access
  to ECR.
- Notifications of local runs aren't persisted.
- When using mlrun-gpu image, use PyTorch versions up to and including than 2.0.1,
  but not higher. You can build your own images with newer CUDA for a later release
  of PyTorch.
- MLRun Client does not support Win OS. Use WSL instead.
- PySpark 3.2.x cannot always read parquet files written by pyarrow 13 or above. MLRun
  ingest might fail when ingest() is called with engine="spark" and a ParquetSource
  that points to parquet files that were written by pyarrow 13 or above. Call df.to_parquet()
  with version="2.4" so that parquet files are backwards compatible.
- When using mlrun.mlrun image, use PyTorch versions up to and including than 2.0.1,
  but not higher. See MLRun runtime images.
- When using an MLRun client previous to v1.6.0, the workflow step status might show
  completed when it is actually aborted. Abort the job from the SDK instead of from
  the UI, or upgrade the client to v1.6.0 or higher.
- A loaded system takes a few minutes (5) to calculate the statistics in the Projects
  Monitoring pane.
- Default spot labels node selector is removed.
- After upgrade/restart there may be some lost notifications due to restart of the
  chief.
- Occasionally, deleting projects fails with 'Fail to delete project in MLRun'. Try
  deleting the project again.
auth_info:
  mentioned_objects:
  - OauthToken
  - AuthProvider
  - NamedCredential
  - mlrun.get_run_db
  - project.get_artifact
  - mlrun.mlconf.external_platform_tracking
  - mlrun.get_or_create_project
  - V3IO_USERNAME
  - V3IO_ACCESS_KEY
  - ConfigProfile
  - OpenAIProfile
  - GIT_TOKEN
  - GITHUB_TOKEN
  - MLRUN_DBPATH
  - SLACK_WEBHOOK
  - ApplicationRuntime
  - APIGateway
  - APIGatewayMetadata
  - APIGatewaySpec
  - AWS_ACCESS_KEY_ID
  - AWS_SECRET_ACCESS_KEY
  - AWS_ENDPOINT_URL_S3
  - MLRUN_AWS_ROLE_ARN
  - AWS_PROFILE
  - DataItem
  - ModelMonitoringApplicationBase
  - ModelMonitoringApplicationMetric
  - ModelMonitoringApplicationResult
  - MonitoringApplicationContext
  - ResultKindApp
  - ResultStatusApp
  - OPENAI_API_KEY
  - HF_TOKEN
  - EntrypointParam
  - DocumentArtifact
  - DocumentLoaderSpec
  - MLRunLoader
  - DatastoreProfilePostgreSQL
  - DatastoreProfileTDEngine
  - Entity
  - Feature
  - FeatureSet
  - APIGatewayAuthenticator
  - AccessKeyAuth
  - BasicAuth
  - NoneAuth
  - TaskStep
  - RouterStep
  - V2ModelServer
client:
  base_url: http://mlrun-api:8080
source_metadata: null
