resources:
- name: SharedTrainingMaster
  endpoint:
    path: /sharedTrainingMaster
    method: GET
    data_selector: records
    params: {}
- name: SparkComputationGraph
  endpoint:
    path: /sparkComputationGraph
    method: GET
    data_selector: records
    params: {}
- name: deeplearning4j-examples
  endpoint:
    path: /mvn-project-template
    method: GET
    data_selector: records
- name: dl4j-examples
  endpoint:
    path: /dl4j-examples
    method: GET
    data_selector: examples
    params: {}
- name: tensorflow-keras-import-examples
  endpoint:
    path: /tensorflow-keras-import-examples
    method: GET
    data_selector: examples
    params: {}
- name: dl4j-distributed-training-examples
  endpoint:
    path: /dl4j-distributed-training-examples
    method: GET
    data_selector: examples
    params: {}
- name: cuda-specific-examples
  endpoint:
    path: /cuda-specific-examples
    method: GET
    data_selector: examples
    params: {}
- name: samediff-examples
  endpoint:
    path: /samediff-examples
    method: GET
    data_selector: examples
    params: {}
- name: data-pipeline-examples
  endpoint:
    path: /data-pipeline-examples
    method: GET
    data_selector: examples
    params: {}
- name: nd4j-ndarray-examples
  endpoint:
    path: /nd4j-ndarray-examples
    method: GET
    data_selector: examples
    params: {}
- name: arbiter-examples
  endpoint:
    path: /arbiter-examples
    method: GET
    data_selector: examples
    params: {}
- name: rl4j-examples
  endpoint:
    path: /rl4j-examples
    method: GET
    data_selector: examples
    params: {}
- name: android-examples
  endpoint:
    path: /android-examples
    method: GET
    data_selector: examples
    params: {}
- name: dl4j-examples
  endpoint:
    path: /deeplearning4j/examples
    method: GET
    data_selector: examples
- name: word_vectors
  endpoint:
    path: /word2vec
    method: POST
    data_selector: vectors
    params: {}
- name: CustomLayer
  endpoint:
    path: /custom/layer
    method: POST
    data_selector: configuration
- name: CustomLayerImpl
  endpoint:
    path: /custom/layer/impl
    method: POST
    data_selector: implementation
- name: AlexNet
  endpoint:
    path: https://github.com/eclipse/deeplearning4j/blob/master/deeplearning4j/deeplearning4j-zoo/src/main/java/org/deeplearning4j/zoo/model/AlexNet.java
    method: GET
- name: Darknet19
  endpoint:
    path: https://github.com/eclipse/deeplearning4j/blob/master/deeplearning4j/deeplearning4j-zoo/src/main/java/org/deeplearning4j/zoo/model/Darknet19.java
    method: GET
- name: FaceNetNN4Small2
  endpoint:
    path: https://github.com/eclipse/deeplearning4j/blob/master/deeplearning4j/deeplearning4j-zoo/src/main/java/org/deeplearning4j/zoo/model/FaceNetNN4Small2.java
    method: GET
- name: InceptionResNetV1
  endpoint:
    path: https://github.com/eclipse/deeplearning4j/blob/master/deeplearning4j/deeplearning4j-zoo/src/main/java/org/deeplearning4j/zoo/model/InceptionResNetV1.java
    method: GET
- name: LeNet
  endpoint:
    path: https://github.com/eclipse/deeplearning4j/blob/master/deeplearning4j/deeplearning4j-zoo/src/main/java/org/deeplearning4j/zoo/model/LeNet.java
    method: GET
- name: ResNet50
  endpoint:
    path: https://github.com/eclipse/deeplearning4j/blob/master/deeplearning4j/deeplearning4j-zoo/src/main/java/org/deeplearning4j/zoo/model/ResNet50.java
    method: GET
- name: SimpleCNN
  endpoint:
    path: https://github.com/eclipse/deeplearning4j/blob/master/deeplearning4j/deeplearning4j-zoo/src/main/java/org/deeplearning4j/zoo/model/SimpleCNN.java
    method: GET
- name: TextGenerationLSTM
  endpoint:
    path: https://github.com/eclipse/deeplearning4j/blob/master/deeplearning4j/deeplearning4j-zoo/src/main/java/org/deeplearning4j/zoo/model/TextGenerationLSTM.java
    method: GET
- name: TinyYOLO
  endpoint:
    path: https://github.com/eclipse/deeplearning4j/blob/master/deeplearning4j/deeplearning4j-zoo/src/main/java/org/deeplearning4j/zoo/model/TinyYOLO.java
    method: GET
- name: VGG16
  endpoint:
    path: https://github.com/eclipse/deeplearning4j/blob/master/deeplearning4j/deeplearning4j-zoo/src/main/java/org/deeplearning4j/zoo/model/VGG16.java
    method: GET
- name: VGG19
  endpoint:
    path: https://github.com/eclipse/deeplearning4j/blob/master/deeplearning4j/deeplearning4j-zoo/src/main/java/org/deeplearning4j/zoo/model/VGG19.java
    method: GET
- name: ActivationELU
  endpoint:
    path: /activations/ActivationELU
    method: GET
    data_selector: records
- name: ActivationReLU
  endpoint:
    path: /activations/ActivationReLU
    method: GET
    data_selector: records
- name: ActivationRationalTanh
  endpoint:
    path: /activations/ActivationRationalTanh
    method: GET
    data_selector: records
- name: ActivationThresholdedReLU
  endpoint:
    path: /activations/ActivationThresholdedReLU
    method: GET
    data_selector: records
- name: ActivationReLU6
  endpoint:
    path: /activations/ActivationReLU6
    method: GET
    data_selector: records
- name: ActivationHardTanH
  endpoint:
    path: /activations/ActivationHardTanH
    method: GET
    data_selector: records
- name: ActivationSigmoid
  endpoint:
    path: /activations/ActivationSigmoid
    method: GET
    data_selector: records
- name: ActivationGELU
  endpoint:
    path: /activations/ActivationGELU
    method: GET
    data_selector: records
- name: ActivationPReLU
  endpoint:
    path: /activations/ActivationPReLU
    method: GET
    data_selector: records
- name: ActivationIdentity
  endpoint:
    path: /activations/ActivationIdentity
    method: GET
    data_selector: records
- name: ActivationSoftSign
  endpoint:
    path: /activations/ActivationSoftSign
    method: GET
    data_selector: records
- name: ActivationHardSigmoid
  endpoint:
    path: /activations/ActivationHardSigmoid
    method: GET
    data_selector: records
- name: ActivationSoftmax
  endpoint:
    path: /activations/ActivationSoftmax
    method: GET
    data_selector: records
- name: ActivationCube
  endpoint:
    path: /activations/ActivationCube
    method: GET
    data_selector: records
- name: ActivationRReLU
  endpoint:
    path: /activations/ActivationRReLU
    method: GET
    data_selector: records
- name: ActivationTanH
  endpoint:
    path: /activations/ActivationTanH
    method: GET
    data_selector: records
- name: ActivationSELU
  endpoint:
    path: /activations/ActivationSELU
    method: GET
    data_selector: records
- name: ActivationLReLU
  endpoint:
    path: /activations/ActivationLReLU
    method: GET
    data_selector: records
- name: ActivationSwish
  endpoint:
    path: /activations/ActivationSwish
    method: GET
    data_selector: records
- name: ActivationSoftPlus
  endpoint:
    path: /activations/ActivationSoftPlus
    method: GET
    data_selector: records
- name: AutoEncoder
  endpoint:
    path: /deeplearning4j/reference/auto-encoders
    method: GET
    data_selector: layers
    params: {}
- name: encoderLayerSizes
  endpoint:
    path: /encoderLayerSizes
    method: POST
    data_selector: sizes
    params: {}
- name: decoderLayerSizes
  endpoint:
    path: /decoderLayerSizes
    method: POST
    data_selector: sizes
    params: {}
- name: reconstructionDistribution
  endpoint:
    path: /reconstructionDistribution
    method: POST
    data_selector: distribution
    params: {}
- name: lossFunction
  endpoint:
    path: /lossFunction
    method: POST
    data_selector: function
    params: {}
- name: pzxActivationFn
  endpoint:
    path: /pzxActivationFn
    method: POST
    data_selector: activation
    params: {}
- name: nOut
  endpoint:
    path: /nOut
    method: POST
    data_selector: size
    params: {}
- name: numSamples
  endpoint:
    path: /numSamples
    method: POST
    data_selector: samples
    params: {}
- name: Convolution3D
  endpoint:
    path: /Convolution3D
    method: GET
    data_selector: 3D convolution layer configuration
    params: {}
- name: Deconvolution2D
  endpoint:
    path: /Deconvolution2D
    method: GET
    data_selector: 2D deconvolution layer configuration
    params: {}
- name: Cropping1D
  endpoint:
    path: /Cropping1D
    method: GET
    data_selector: Cropping layer for convolutional (1d) neural networks
    params: {}
- name: Cropping2D
  endpoint:
    path: /Cropping2D
    method: GET
    data_selector: Cropping layer for convolutional (2d) neural networks
    params: {}
- name: Cropping3D
  endpoint:
    path: /Cropping3D
    method: GET
    data_selector: Cropping layer for convolutional (3d) neural networks
    params: {}
- name: DataSet Iterators
  endpoint:
    path: /dataset/iterators
    method: GET
- name: MnistDataSetIterator
  endpoint:
    path: /MnistDataSetIterator
    method: GET
- name: UciSequenceDataSetIterator
  endpoint:
    path: /UciSequenceDataSetIterator
    method: GET
- name: Cifar10DataSetIterator
  endpoint:
    path: /Cifar10DataSetIterator
    method: GET
- name: IrisDataSetIterator
  endpoint:
    path: /IrisDataSetIterator
    method: GET
- name: LFWDataSetIterator
  endpoint:
    path: /LFWDataSetIterator
    method: GET
- name: TinyImageNetDataSetIterator
  endpoint:
    path: /TinyImageNetDataSetIterator
    method: GET
- name: EmnistDataSetIterator
  endpoint:
    path: /EmnistDataSetIterator
    method: GET
- name: RecordReaderDataSetIterator
  endpoint:
    path: /RecordReaderDataSetIterator
    method: GET
- name: RecordReaderMultiDataSetIterator
  endpoint:
    path: /RecordReaderMultiDataSetIterator
    method: GET
- name: SequenceRecordReaderDataSetIterator
  endpoint:
    path: /SequenceRecordReaderDataSetIterator
    method: GET
- name: AsyncMultiDataSetIterator
  endpoint:
    path: /AsyncMultiDataSetIterator
    method: GET
    data_selector: records
- name: IteratorDataSetIterator
  endpoint:
    path: /IteratorDataSetIterator
    method: GET
    data_selector: records
- name: AsyncDataSetIterator
  endpoint:
    path: /AsyncDataSetIterator
    method: GET
    data_selector: records
- name: DoublesDataSetIterator
  endpoint:
    path: /DoublesDataSetIterator
    method: GET
    data_selector: records
- name: MultiDataSetIteratorSplitter
  endpoint:
    path: /MultiDataSetIteratorSplitter
    method: GET
    data_selector: records
- name: RandomMultiDataSetIterator
  endpoint:
    path: /RandomMultiDataSetIterator
    method: GET
    data_selector: records
- name: EarlyTerminationMultiDataSetIterator
  endpoint:
    path: /EarlyTerminationMultiDataSetIterator
    method: GET
    data_selector: records
    params: {}
- name: ExistingDataSetIterator
  endpoint:
    path: /ExistingDataSetIterator
    method: GET
    data_selector: records
    params: {}
- name: DummyBlockMultiDataSetIterator
  endpoint:
    path: /DummyBlockMultiDataSetIterator
    method: GET
    data_selector: records
    params: {}
- name: EarlyTerminationDataSetIterator
  endpoint:
    path: /EarlyTerminationDataSetIterator
    method: GET
    data_selector: records
    params: {}
- name: ReconstructionDataSetIterator
  endpoint:
    path: /ReconstructionDataSetIterator
    method: GET
    data_selector: records
    params: {}
- name: DataSetIteratorSplitter
  endpoint:
    path: /DataSetIteratorSplitter
    method: GET
    data_selector: records
    params: {}
- name: JointMultiDataSetIterator
  endpoint:
    path: /JointMultiDataSetIterator
    method: GET
    data_selector: records
    params: {}
- name: FloatsDataSetIterator
  endpoint:
    path: /FloatsDataSetIterator
    method: GET
    data_selector: records
    params: {}
- name: FileSplitDataSetIterator
  endpoint:
    path: /FileSplitDataSetIterator
    method: GET
    data_selector: records
    params: {}
- name: MultipleEpochsIterator
  endpoint:
    path: /MultipleEpochsIterator
    method: GET
    data_selector: records
    params: {}
- name: MultiDataSetWrapperIterator
  endpoint:
    path: /MultiDataSetWrapperIterator
    method: GET
    data_selector: records
    params: {}
- name: RandomDataSetIterator
  endpoint:
    path: /RandomDataSetIterator
    method: GET
    data_selector: records
    params: {}
- name: MultiDataSetIteratorAdapter
  endpoint:
    path: /MultiDataSetIteratorAdapter
    method: GET
    data_selector: records
    params: {}
- name: ActivationLayer
  endpoint:
    path: /deeplearning4j/nn/conf/layers/ActivationLayer
    method: GET
- name: DenseLayer
  endpoint:
    path: /deeplearning4j/nn/conf/layers/DenseLayer
    method: GET
- name: DropoutLayer
  endpoint:
    path: /DropoutLayer
    method: GET
    data_selector: records
- name: EmbeddingLayer
  endpoint:
    path: /EmbeddingLayer
    method: GET
    data_selector: records
- name: EmbeddingSequenceLayer
  endpoint:
    path: /EmbeddingSequenceLayer
    method: GET
    data_selector: records
- name: GlobalPoolingLayer
  endpoint:
    path: /GlobalPoolingLayer
    method: GET
    data_selector: records
- name: LocalResponseNormalization
  endpoint:
    path: /LocalResponseNormalization
    method: GET
    data_selector: records
- name: LocallyConnected1D
  endpoint:
    path: /LocallyConnected1D
    method: GET
    data_selector: records
- name: LocallyConnected2D
  endpoint:
    path: /LocallyConnected2D
    method: GET
    data_selector: records
- name: LossLayer
  endpoint:
    path: /LossLayer
    method: GET
    data_selector: records
- name: OutputLayer
  endpoint:
    path: /OutputLayer
    method: GET
    data_selector: records
- name: Pooling1D
  endpoint:
    path: /Pooling1D
    method: GET
    data_selector: records
- name: Pooling2D
  endpoint:
    path: /Pooling2D
    method: GET
    data_selector: records
- name: Subsampling1DLayer
  endpoint:
    path: /Subsampling1DLayer
    method: GET
    data_selector: records
- name: Upsampling1D
  endpoint:
    path: /Upsampling1D
    method: GET
    data_selector: records
- name: Upsampling2D
  endpoint:
    path: /Upsampling2D
    method: GET
    data_selector: records
- name: Upsampling3D
  endpoint:
    path: /Upsampling3D
    method: GET
    data_selector: records
- name: ZeroPadding1DLayer
  endpoint:
    path: /ZeroPadding1DLayer
    method: GET
    data_selector: records
- name: ZeroPadding3DLayer
  endpoint:
    path: /ZeroPadding3DLayer
    method: GET
    data_selector: records
- name: ZeroPaddingLayer
  endpoint:
    path: /ZeroPaddingLayer
    method: GET
    data_selector: records
- name: RepeatVector
  endpoint:
    path: /RepeatVector
    method: GET
    data_selector: records
- name: Yolo2OutputLayer
  endpoint:
    path: /Yolo2OutputLayer
    method: GET
    data_selector: records
- name: MaskLayer
  endpoint:
    path: /MaskLayer
    method: GET
    data_selector: records
- name: MaskZeroLayer
  endpoint:
    path: /MaskZeroLayer
    method: GET
    data_selector: records
- name: EvaluativeListener
  endpoint:
    path: /path/to/evaluativeListener
    method: GET
    data_selector: data
    params: {}
- name: ScoreIterationListener
  endpoint:
    path: /path/to/scoreIterationListener
    method: GET
    data_selector: data
    params: {}
- name: ComposableIterationListener
  endpoint:
    path: /path/to/composableIterationListener
    method: GET
    data_selector: data
    params: {}
- name: CollectScoresIterationListener
  endpoint:
    path: /CollectScoresIterationListener
    method: GET
    data_selector: scores
    params: {}
- name: CheckpointListener
  endpoint:
    path: /CheckpointListener
    method: GET
    data_selector: checkpoints
    params: {}
- name: SleepyTrainingListener
  endpoint:
    path: /SleepyTrainingListener
    method: GET
    data_selector: sleep
    params: {}
- name: PerformanceListener
  endpoint:
    path: /PerformanceListener
    method: GET
    data_selector: performance
    params: {}
- name: TimeIterationListener
  endpoint:
    path: /TimeIterationListener
    method: GET
    data_selector: time
    params: {}
- name: MultiLayerNetwork
  endpoint:
    path: /model/multilayernetwork
    method: POST
    data_selector: models
    params: {}
- name: ComputationGraph
  endpoint:
    path: /model/computationgraph
    method: POST
    data_selector: models
    params: {}
- name: RnnOutputLayer
  endpoint:
    path: /RnnOutputLayer
    method: GET
    data_selector: records
- name: time_series_data
  endpoint:
    path: /path/to/data
    method: GET
    data_selector: records
- name: L2NormalizeVertex
  endpoint:
    path: /L2NormalizeVertex
    method: GET
- name: L2Vertex
  endpoint:
    path: /L2Vertex
    method: GET
- name: PoolHelperVertex
  endpoint:
    path: /PoolHelperVertex
    method: GET
- name: ReshapeVertex
  endpoint:
    path: /ReshapeVertex
    method: GET
- name: ScaleVertex
  endpoint:
    path: /ScaleVertex
    method: GET
- name: Word2Vec Usage
  endpoint:
    path: /s/-LsGrpMiOeoMSFYK0VJQ-714541269/deeplearning4j/reference/word2vec.md
    method: GET
    data_selector: examples
    params: {}
- name: ImageRecordReader
  endpoint:
    path: /datavec/image/recordreader
    method: GET
    data_selector: records
- name: DataSetIterator
  endpoint:
    path: /datavec/dataset/iterator
    method: GET
    data_selector: records
- name: analyze
  endpoint:
    path: /analyze
    method: GET
    data_selector: DataAnalysis
    params: {}
- name: analyzeQuality
  endpoint:
    path: /analyzeQuality
    method: GET
    data_selector: DataQualityAnalysis
    params: {}
- name: analyzeQualitySequence
  endpoint:
    path: /analyzeQualitySequence
    method: GET
    data_selector: DataQualityAnalysis
    params: {}
- name: analyzeSequence
  endpoint:
    path: /analyzeSequence
    method: GET
    data_selector: SequenceDataAnalysis
    params: {}
- name: min
  endpoint:
    path: /min
    method: GET
    data_selector: Writable
    params: {}
- name: max
  endpoint:
    path: /max
    method: GET
    data_selector: Writable
    params: {}
- name: LocalTransformExecutor
  endpoint:
    path: /datavec/local/transforms/LocalTransformExecutor
    method: GET
    data_selector: transformed
    params: {}
- name: SparkTransformExecutor
  endpoint:
    path: /datavec/spark/transform/SparkTransformExecutor
    method: GET
    data_selector: transformed
    params: {}
- name: removeExample
  endpoint:
    path: /removeExample
    method: GET
    data_selector: writables
    params: {}
- name: removeSequence
  endpoint:
    path: /removeSequence
    method: GET
    data_selector: sequence
    params: {}
- name: transform
  endpoint:
    path: /transform
    method: GET
    data_selector: inputSchema
    params: {}
- name: outputColumnName
  endpoint:
    path: /outputColumnName
    method: GET
    data_selector: outputColumnName
    params: {}
- name: columnName
  endpoint:
    path: /columnName
    method: GET
    data_selector: columnName
    params: {}
- name: NormalizerMinMaxScaler
  endpoint:
    path: /nd4j/nd4j-backends/nd4j-api-parent/nd4j-api/src/main/java/org/nd4j/linalg/dataset/api/preprocessor/NormalizerMinMaxScaler
    method: GET
    data_selector: normalizer
    params: {}
- name: Normalizer
  endpoint:
    path: /nd4j/nd4j-backends/nd4j-api-parent/nd4j-api/src/main/java/org/nd4j/linalg/dataset/api/preprocessor/Normalizer
    method: GET
    data_selector: normalizer
    params: {}
- name: ImageFlatteningDataSetPreProcessor
  endpoint:
    path: /nd4j/nd4j-backends/nd4j-api-parent/nd4j-api/src/main/java/org/nd4j/linalg/dataset/api/preprocessor/ImageFlatteningDataSetPreProcessor
    method: GET
    data_selector: imageFlattener
    params: {}
- name: MinMaxStrategy
  endpoint:
    path: /nd4j-backends/nd4j-api-parent/nd4j-api/src/main/java/org/nd4j/linalg/dataset/api/preprocessor/MinMaxStrategy.java
    method: GET
    data_selector: statistics
    params:
      minRange: the target range lower bound
      maxRange: the target range upper bound
- name: ImagePreProcessingScaler
  endpoint:
    path: /nd4j-backends/nd4j-api-parent/nd4j-api/src/main/java/org/nd4j/linalg/dataset/api/preprocessor/ImagePreProcessingScaler.java
    method: GET
    data_selector: scaling
    params:
      minRange: '0'
      maxRange: '1'
      maxBits: '8'
- name: MultiNormalizerMinMaxScaler
  endpoint:
    path: /nd4j-backends/nd4j-api-parent/nd4j-api/src/main/java/org/nd4j/linalg/dataset/api/preprocessor/MultiNormalizerMinMaxScaler.java
    method: GET
    data_selector: normalization
    params:
      minRange: the target range lower bound
      maxRange: the target range upper bound
- name: NormalizerStandardize
  endpoint:
    path: /nd4j-backends/nd4j-api-parent/nd4j-api/src/main/java/org/nd4j/linalg/dataset/api/preprocessor/NormalizerStandardize.java
    method: GET
    data_selector: normalization
    params: {}
- name: MultiNormalizerHybrid
  endpoint:
    path: /nd4j-backends/nd4j-api-parent/nd4j-api/src/main/java/org/nd4j/linalg/dataset/api/preprocessor/MultiNormalizerHybrid.java
    method: GET
    data_selector: normalization
    params: {}
- name: FloatWritableOp
  endpoint:
    path: /transform/ops/FloatWritableOp
    method: GET
    data_selector: conversion
    params: {}
- name: IntWritableOp
  endpoint:
    path: /transform/ops/IntWritableOp
    method: GET
    data_selector: conversion
    params: {}
- name: LongWritableOp
  endpoint:
    path: /transform/ops/LongWritableOp
    method: GET
    data_selector: conversion
    params: {}
- name: StringWritableOp
  endpoint:
    path: /transform/ops/StringWritableOp
    method: GET
    data_selector: conversion
    params: {}
- name: CalculateSortedRank
  endpoint:
    path: /transform/rank/CalculateSortedRank
    method: GET
    data_selector: rank
    params: {}
- name: transform_process
  endpoint:
    path: /transform/process
    method: POST
    data_selector: results
    params: {}
- name: local_transform_executor
  endpoint:
    path: /transform/local
    method: POST
    data_selector: results
    params: {}
- name: replaceStringTransform
  endpoint:
    path: /replaceStringTransform
    method: POST
    data_selector: mapping
    params: {}
- name: ndArrayScalarOpTransform
  endpoint:
    path: /ndArrayScalarOpTransform
    method: POST
    data_selector: operation
    params: {}
- name: ndArrayColumnsMathOpTransform
  endpoint:
    path: /ndArrayColumnsMathOpTransform
    method: POST
    data_selector: mathOperation
    params: {}
- name: ndArrayMathFunctionTransform
  endpoint:
    path: /ndArrayMathFunctionTransform
    method: POST
    data_selector: mathFunction
    params: {}
- name: ndArrayDistanceTransform
  endpoint:
    path: /ndArrayDistanceTransform
    method: POST
    data_selector: distanceCalculation
    params: {}
- name: firstDigitTransform
  endpoint:
    path: /firstDigitTransform
    method: POST
    data_selector: digitConversion
    params: {}
- name: FileRecordReader
  endpoint:
    path: /FileRecordReader
    method: GET
    data_selector: records
- name: LineRecordReader
  endpoint:
    path: /LineRecordReader
    method: GET
    data_selector: records
- name: CollectionRecordReader
  endpoint:
    path: /CollectionRecordReader
    method: GET
    data_selector: records
- name: CSVRecordReader
  endpoint:
    path: /CSVRecordReader
    method: GET
    data_selector: records
- name: LibSvmRecordReader
  endpoint:
    path: /LibSvmRecordReader
    method: GET
    data_selector: records
- name: MatlabRecordReader
  endpoint:
    path: /MatlabRecordReader
    method: GET
    data_selector: records
- name: SVMLightRecordReader
  endpoint:
    path: /SVMLightRecordReader
    method: GET
    data_selector: records
- name: RegexLineRecordReader
  endpoint:
    path: /RegexLineRecordReader
    method: GET
    data_selector: records
- name: ImageRecordReader
  endpoint:
    path: /ImageRecordReader
    method: GET
    data_selector: records
- name: GeographicMidpointReduction
  endpoint:
    path: /github/eclipse/deeplearning4j/tree/master/datavec/datavec-api/src/main/java/org/datavec/api/transform/reduce/impl/GeographicMidpointReduction.java
    method: GET
    data_selector: transform
    params: {}
- name: StringReducer
  endpoint:
    path: /github/eclipse/deeplearning4j/tree/master/datavec/datavec-api/src/main/java/org/datavec/api/transform/stringreduce/StringReducer.java
    method: GET
    data_selector: transform
    params: {}
- name: HtmlAnalysis
  endpoint:
    path: /datavec/api/transform/ui/HtmlAnalysis
    method: POST
    data_selector: createHtmlAnalysisString
    params: {}
- name: HtmlSequencePlotting
  endpoint:
    path: /datavec/api/transform/ui/HtmlSequencePlotting
    method: POST
    data_selector: createHtmlSequencePlots
    params: {}
- name: tensor_along_dimension
  endpoint:
    path: /nd4j/reference/tensor_along_dimension
    method: GET
    data_selector: records
- name: scalar_ops
  endpoint:
    path: /nd4j/reference/scalar_ops
    method: GET
    data_selector: records
- name: transform_ops
  endpoint:
    path: /nd4j/reference/transform_ops
    method: GET
    data_selector: records
- name: accumulation_ops
  endpoint:
    path: /nd4j/reference/accumulation_ops
    method: GET
    data_selector: records
- name: index_accumulation_ops
  endpoint:
    path: /nd4j/reference/index_accumulation_ops
    method: GET
    data_selector: records
- name: broadcast_vector_ops
  endpoint:
    path: /nd4j/reference/broadcast_vector_ops
    method: GET
    data_selector: records
- name: workspaces
  endpoint:
    path: /nd4j/reference/workspaces
    method: GET
    data_selector: records
- name: serialization
  endpoint:
    path: /nd4j/reference/serialization
    method: GET
    data_selector: records
- name: variables
  endpoint:
    path: /variables
    method: GET
    data_selector: variables
    params: {}
- name: constants
  endpoint:
    path: /constants
    method: GET
    data_selector: constants
    params: {}
- name: placeholders
  endpoint:
    path: /placeholders
    method: GET
    data_selector: placeholders
    params: {}
- name: arrays
  endpoint:
    path: /arrays
    method: GET
    data_selector: arrays
    params: {}
- name: tensorflow
  endpoint:
    path: /samediff-import-tensorflow
    method: GET
    data_selector: dependency
    params: {}
- name: onnx
  endpoint:
    path: /samediff-import-onnx
    method: GET
    data_selector: dependency
    params: {}
- name: libnd4j_build
  endpoint:
    path: /buildnativeoperations.sh
    method: POST
    data_selector: build
    params: {}
- name: cuda_backend
  endpoint:
    path: /cuda
    method: POST
    data_selector: build
    params:
      incremental: updated_at
- name: gradient_sharing
  endpoint:
    path: /gradient/sharing
    method: POST
    data_selector: gradientSharing
    params:
      batchSizePerWorker: batchSizePerWorker
      updatesThreshold: 1e-3
      workersPerNode: numWorkersPerNode
      meshBuildMode: MESH
- name: parameter_averaging
  endpoint:
    path: /parameter/averaging
    method: POST
    data_selector: parameterAveraging
    params:
      examplesPerDataSetObject: '1'
- name: DataSet
  endpoint:
    path: /path/to/dataSet
    method: GET
- name: MultiDataSet
  endpoint:
    path: /path/to/multiDataSet
    method: GET
- name: csv_loading
  endpoint:
    path: /spark/how-to-guides/data-howto.md
    method: GET
    data_selector: records
    params: {}
- name: image_classification
  endpoint:
    path: /spark/how-to-guides/data-howto.md
    method: GET
    data_selector: records
    params: {}
- name: custom_format_loading
  endpoint:
    path: /spark/how-to-guides/data-howto.md
    method: GET
    data_selector: records
    params: {}
- name: VoidConfiguration
  endpoint:
    path: /VoidConfiguration
    method: GET
    data_selector: parameters
    params:
      unicastPort: 40123
- name: TrainingMaster
  endpoint:
    path: /TrainingMaster
    method: GET
    data_selector: trainingParameters
    params:
      updatesThreshold: 1e-3
      workersPerNode: 4
- name: namespace
  endpoint:
    path: /namespace
    method: GET
    data_selector: records
    params: {}
notes:
- Fitting directly from an RDD is discouraged - it is better to export your prepared
  data once.
- Adds proper support for java 9 modules
- Flatbuffers has been upgraded to 1.12.1
- 'Removed rl4j: in continuing to cut unmaintained modules'
- Added new model zoo module called omnihub for dl4j
- Migrated the snapshots to sonatype's new repository
- Adds proper support for jetson nano
- Adds Spark 3 support
- Reduce binary size using selective compilation
- Remove scala 11 support
- 'dl4j-spark_2.11 and _2.12 dependencies incorrectly pull in datavec-spark_2.11/2.12
  version `1.0.0-SNAPSHOT`. Workaround: control version using dependency management
  as per [here](https://github.com/eclipse/deeplearning4j-examples/pull/901/files)
  or [here](https://gist.github.com/AlexDBlack/5721cb6fbd6cd98b6702cd49e733dacf)'
- Some layers (such as LSTM) may run slower on 1.0.0-beta5 than 1.0.0-beta4 on CUDA
  when not using cuDNN, due to added synchronization. This synchronization will be
  removed in the next release after 1.0.0-beta5
- 'CUDA 10.1: Rare internal cuBLAS issues may be encountered in heavily multi-threaded
  code on some systems, when running CUDA 10.1 Update 1 (and maybe 10.1). CUDA 10.1
  update 2 is recommended.'
- 'ND4J Behaviour changes of note: When creating an INDArray from a Java primitive
  array, the INDArray datatype will be determined by the primitive array type (unless
  a datatype is specified)'
- 'Some operations have datatype restrictions: for example, sum on a UTF8 array is
  not supported, nor is variance on a BOOL array.'
- Most CustomOperation operations (such as those used in SameDiff) are CPU only until
  next release. GPU support was not completed in time for 1.0.0-beta4 release.
- Some users with Intel Skylake CPUs have reported deadlocks on MKL-DNN convolution
  2d backprop operations when OMP_NUM_THREADS is set to 8 or higher.
- Android users may need to manually exclude the (now deprecated) module nd4j-base64.
- Windows users are unable to load the HDF5 files used in SvhnLabelProvider (used
  in HouseNumberDetection example). Linux/Mac users are unaffected. A workaround for
  windows users is to add the sonatype snapshot dependency `org.bytedeco.javacpp-presets:hdf5-platform:jar:1.10.2-1.4.3-SNAPSHOT`.
- Performance on some networks types may be reduced on CUDA compared to 0.9.1 (with
  workspaces configured). This will be addressed in the next release
- Some issues have been noted with FP16 support on CUDA
- Vast majority of new operations added in 1.0.0-alpha do NOT use GPU yet.
- While many of the widely used base operations and high-level layers used in practice
  are supported, op coverage is still limited.
- Goal is to achieve feature parity with TensorFlow and fully support import for TF
  graphs.
- Some of the existing ops do not have a backward pass implemented.
- 'Deeplearning4j: Use of Evaluation class no-arg constructor (i.e., new Evaluation())
  can result in accuracy/stats being reported as 0.0. Other Evaluation class constructors,
  and ComputationGraph/MultiLayerNetwork.evaluate(DataSetIterator) methods work as
  expected.'
- 'This also impacts Spark (distributed) evaluation: workaround is to replace `sparkNet.evaluate(testData);`
  with `sparkNet.doEvaluation(testData, 64, new Evaluation(10))[0];`, where 10 is
  the number of classes and 64 in the evaluation minibatch size to use.'
- 'SequenceRecordReaderDataSetIterator applies preprocessors (such as normalization)
  twice to each DataSet (possible workaround: use RecordReaderMultiDataSetIterator
  + MultiDataSetWrapperIterator)'
- 'TransferLearning: ComputationGraph may incorrectly apply l1/l2 regularization (defined
  in FinetuneConfiguration) to frozen layers. Workaround: set 0.0 l1/l2 on FineTuneConfiguration,
  and required l1/l2 on new/non-frozen layers directly. Note that MultiLayerNetwork
  with TransferLearning appears to be unaffected.'
- 'Updater configuration methods such as .momentum(double) and .epsilon(double) have
  been deprecated. Instead: use `.updater(new Nesterovs(0.9))` and `.updater(Adam.builder().beta1(0.9).beta2(0.999).build())`
  etc to configure'
- 'CsvRecordReader constructors: now uses characters for delimiters, instead of Strings
  (i.e., '','' instead of ",")'
- 'Spark versioning schemes: with the addition of Spark 2 support, the versions for
  Deeplearning4j and DataVec Spark modules has changed'
- 'UI/CUDA/Linux issue: [Link](https://github.com/eclipse/deeplearning4j/issues/3026)'
- 'Dirty shutdown on JVM exit is possible for CUDA backend sometimes: [Link](https://github.com/eclipse/deeplearning4j/issues/3028)'
- Issues with RBM implementation [Link](https://github.com/eclipse/deeplearning4j/issues/3049)
- Keras 1D convolutional and pooling layers cannot be imported yet. Will be supported
  in forthcoming release.
- Keras v2 model configurations cannot be imported yet. Will be supported in forthcoming
  release.
- 'UI overhaul: new training UI has considerably more information, supports persistence
  (saving info and loading later), Japanese/Korean/Russian support.'
- Removed Jackson as core dependency (shaded); users can now use any version of Jackson
  without issue.
- Numerous bug fixes across DL4J and ND4J.
- Performance improvements for nd4j-native & nd4j-cuda backends.
- Initial multi-GPU support viable for standalone and Spark.
- Refactored the Spark API significantly
- Added CuDNN wrapper
- Performance improvements for ND4J
- 'Introducing DataVec: Lots of new functionality for transforming, preprocessing,
  cleaning data. (This replaces Canova)'
- 'New DataSetIterators for feeding neural nets with existing data: ExistingDataSetIterator,
  Floats(Double)DataSetIterator, IteratorDataSetIterator'
- 'New learning algorithms for word2vec and paravec: CBOW and PV-DM respectively'
- 'New native ops for better performance: DropOut, DropOutInverted, CompareAndSet,
  ReplaceNaNs'
- Shadow asynchronous datasets prefetch enabled by default for both MultiLayerNetwork
  and ComputationGraph
- Better memory handling with JVM GC and CUDA backend, resulting in significantly
  lower memory footprint
- Requires Java 11 or later, only 64-Bit versions supported
- Maven is mandatory for working with DL4J
- Ensure you have cmake 3.19 or above installed
- Ensure you have GCC 4.9 or above installed
- Ensure you have Maven 3.8 or higher installed
- Ensure you have JDK 11 installed
- On macs, we use brew to manage the pre requisites.
- On windows, we use msys2 for compiling libnd4j.
- ARM based builds all link against the armcompute library by default.
- In order to compile deeplearning4j for a particular version, you must first invoke
  change-cuda-versions.sh in the root directory.
- Total training time is always ETL plus computation.
- The JVM has knobs to tune for better performance.
- Asynchronous ETL is necessary for real-world problems.
- Deeplearning4j uses DataVec as its ETL and vectorization library.
- Memory usage can vary depending on a wide variety of configurations.
- In order to avoid memory pressure, we recommend using Workspaces and minimizing
  allocations wherever possible.
- Normalizing data is important for neural networks.
- Mini-batching is essential for training models effectively.
- Neural networks can be difficult to tune. If the network hyperparameters are poorly
  chosen, the network may learn slowly, or perhaps not at all.
- 'For continuous values: you want these to be in the range of -1 to 1, 0 to 1 or
  distributed normally with mean 0 and standard deviation 1.'
- For discrete classes (and, for classification problems for the output), generally
  use a one-hot representation.
- The learning rate is one of the most important hyperparameters.
- Typical values for the learning rate are in the range of 0.1 to 1e-6.
- Common values for l2 regularization are 1e-3 to 1e-6.
- A minibatch size of 10 is frequently too small for GPUs, but can work on CPUs.
- 32 may be a sensible starting point to try for minibatch size.
- The deeplearning4j suite has different configuration requirements for your dependencies
  depending on your use case.
- All versions must be the same dependencies. We do not support mixing versions.
- Data always needs to be preprocessed.
- Normalization includes zero mean unit variance and scale zero to 1.
- Both -platform (all operating systems) and single OS (non-platform) snapshot dependencies
  are released.
- Due to the multi-platform build nature of snapshots, it is possible (though rare)
  for the -platform artifacts to temporarily get out of sync, which can cause build
  issues.
- If you are building and deploying on just one platform, it is safer to use the non-platform
  artifacts.
- DL4J targets professional Java developers who are familiar with production deployments,
  IDEs and automated build tools.
- Neural net that processes text into word vectors.
- Can be used for classification, prediction, sentiment analysis.
- DL4J Keras model import is backend agnostic.
- Keras is a popular and user-friendly deep learning library written in Python.
- MultiLayerNetwork and ComputationGraph both have save and load methods.
- Simple and sequential network configuration.
- The MultiLayerNetwork class is the simplest network configuration API available
  in Eclipse Deeplearning4j.
- Uses Truncated BPTT for training RNNs with long sequences.
- Supports variable length time series input
- One-to-many and many-to-one data loading
- Special algorithms for gradient descent.
- Uses Java for implementation and configuration.
- Requires proper setup of IntelliJ and Maven.
- Weights update after model serialization/deserialization was added.
- Option for multiple datasources for vocab construction was added.
- Epochs and Iterations can be specified separately, although they are both typically
  '1'.
- 'Word2Vec.Builder has this option: ''hugeModelExpected''. If set to ''true'', the
  vocab will be periodically truncated during the build.'
- While 'minWordFrequency' is useful for ignoring rare words in the corpus, any number
  of words can be excluded to customize.
- 'Two new WordVectorsSerialization methods have been introduced: ''writeFullModel''
  and ''loadFullModel''. These save and load a full model state.'
- A decent workstation should be able to handle a vocab with a few million words.
- Deeplearning4j's Word2vec implementation can model a few terabytes of data on a
  single machine.
- DataVec should be used for 99% of your data transformations.
- Nd4J currently allows INDArrays to be backed by either float or double-precision
  values. The default is single-precision (float).
- Broadcasting will actually take multiple copies of that row vector and put them
  together into a larger matrix.
- Samediff is a lower level and more flexible api for composing neural networks.
- It provides a declarative api for creating computation graphs.
- libnd4j and nd4j should always be rebuilt together
- Visual Studio 2017 is NOT SUPPORTED by CUDA 8.0 and below
- Cross compiles for pi/linux 32bit
- Cross compiles for pi/linux 64bit
- Cross compiles for android 32bit
- Cross compiles for android 64bit
- Cross compiles for jetson nano 64bit
- At least 1 dimension should be specified for Tear
- Tear dimensions should be non-negative values, and lower then input rank. Got %i
  instead
- Setup a toolchain. This will depend on your OS.
- Ensure this is done by keeping an eye on the bottom right of the IDE to ensure all
  tasks are complete.
- The above will configure your IDE to build a shared library for intel cpus as well
  as configure the gtest setup to run.
- Graph has single data type. I.e. Graph<float> or Graph<float16> or Graph<double>
  *This limitation will be lifted soon.
- On some platforms, like Java, single Variable/Placeholder size is limited to 2GB
  buffer size. However, on libnd4j side there's no such limitation.
- 'Variable size/dimensionality has limitations: max NDArray rank is limited to 32
  at this moment, and any single dimension is limited to MAX_INT size.'
- Recursion isn't directly supported at this moment.
- CUDA isn't supported at this moment. *This limitation will be lifted soon.*
- When used from C++, Graph only supports FeedForward mode. *This limitation will
  be lifted soon.*
- Building minified library yields libnd4j_special.so and libnd4j_special.h files
- GCC 4.9+ required
- CUDA Toolkit Versions 10 or 11 required
- CMake 3.8 required (will require 3.9 in the near future)
- Python4j is a python execution framework for the JVM based on javacpp's python distribution
  and javacpp's numpy bindings enabling seamless execution of python scripts from
  the JVM.
- This will execute a code block expicitly locking the GIL.
- It is advised to test your python script in a real environment first.
- Focus on the minimal set of inputs, outputs, and code you want to run within a python
  script.
- Supported python types can be found on the provided GitHub link.
- For more information on types, please see our types reference.
- Only dense arrays are supported at this time.
- The default python path provides bundled dependencies including numpy.
- To avoid dependency clashes, specify none for the system property org.eclipse.python4j.path.append.
- Before a python script can execute, python4j needs to initialize itself.
- DL4J supports neural network training on a cluster of CPU or GPU machines using
  Apache Spark.
- Users are directed towards the gradient sharing implementation which superseded
  the parameter averaging implementation.
- Use any free port for unicastPort
- Network mask examples include 10.0.0.0/24 or 192.168.0.0/16
- Uses CSV files for training an RNN — variable length sequences are OK
- Preprocessing images can be done locally or using Spark
- When using Deeplearning4j's SparkDl4jMultiLayer or SparkComputationGraph classes,
  a warning will be logged if the Kryo configuration is incorrect.
- Uses OAuth2 with refresh token — requires setup of connected app in api
- Some objects like Contact may return nulls in deeply nested fields
- MEMORY_ONLY and MEMORY_AND_DISK persistence can be problematic with off-heap memory,
  due to Spark not properly estimating the size of objects in the RDD.
- When persisting a RDD<DataSet> or RDD<INDArray> for re-use, use MEMORY_ONLY_SER
  or MEMORY_AND_DISK_SER
- DL4J's parameter averaging implementation has the option to collect training stats,
  by using SparkDl4jMultiLayer.setCollectTrainingStats(true).
- This functionality is optional (not required for training), and is disabled by default.
- Using Spark entails overhead.
- To determine whether Spark will help, consider using the Performance Listener.
- This configuration assumes that you have UDP port 40123 open on ALL nodes within
  your cluster.
- Uses Aeron for fast out of Spark communication.
- At the moment we still focus on nailing down an easily readable and contribution
  friendly DSL for op definition and code generation that can replace namespace definitions.
- 'Namespaces include: bitwise, neuralnetwork, random, and math.'
errors:
- 'no jnind4j in java.library.path: Ensure 64-Bit Java is installed'
- 'REQUEST_LIMIT_EXCEEDED: Throttle API calls or reduce frequency'
- 'IncompatibleKerasConfigurationException: Indicates that you are attempting to import
  a Keras model configuration that is not currently supported in Deeplearning4j.'
- 'java.lang.StackOverflowError: null'
- 'Can''t find dependent libraries: Check PATH environment variable'
- 'Can''t allocate [HOST] memory: Ensure proper GPU usage'
- 'Graph execution failure: Check for dependencies and memory allocation issues.'
- 'Unsupported operation: Ensure that the graph operations are compatible with the
  current execution environment.'
- 'NTPTimeSource: Error querying NTP server, attempt 1 of 10'
auth_info:
  mentioned_objects: []
client:
  base_url: https://deeplearning4j.konduit.ai/
  headers:
    Accept: application/json
source_metadata: null
