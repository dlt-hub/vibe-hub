resources:
- name: session
  endpoint:
    path: /session
    method: GET
    data_selector: session
- name: session
  endpoint:
    path: /session
    method: GET
    data_selector: session_data
- name: AnthropicModel
  endpoint:
    path: /evals/models/anthropic
    method: POST
    data_selector: results
- name: LiteLLMModel
  endpoint:
    method: GET
- name: GeminiModel
  endpoint:
    path: /evals/models/vertex
    method: POST
- name: GeminiModel
  endpoint:
    method: POST
- name: VertexAIModel
  endpoint:
    path: /evals/models/vertexai
    method: GET
- name: VertexAIModel
  endpoint:
    path: /evals/models/vertexai
    method: GET
    data_selector: records
- name: llm_classify
  endpoint:
    path: /evals/classify
    method: POST
    data_selector: dataframe
    params: {}
- name: run_evals
  endpoint:
    path: /evals/run
    method: POST
    data_selector: dataframe
    params: {}
- name: HallucinationEvaluator
  endpoint:
    path: /evals/evaluators/HallucinationEvaluator
    method: GET
- name: LLMEvaluator
  endpoint:
    path: /evals/evaluators/LLMEvaluator
    method: GET
- name: QAEvaluator
  endpoint:
    path: /evals/evaluators/QAEvaluator
    method: GET
- name: RelevanceEvaluator
  endpoint:
    path: /evals/evaluators/RelevanceEvaluator
    method: GET
- name: SQLEvaluator
  endpoint:
    path: /evals/evaluators/SQLEvaluator
    method: GET
- name: SummarizationEvaluator
  endpoint:
    path: /evals/evaluators/SummarizationEvaluator
    method: GET
- name: ToxicityEvaluator
  endpoint:
    path: /evals/evaluators/ToxicityEvaluator
    method: GET
- name: RAG_RELEVANCY_PROMPT_TEMPLATE
  endpoint:
    path: /evals/default_templates/RAG_RELEVANCY_PROMPT_TEMPLATE
    method: GET
- name: HALLUCINATION_PROMPT_TEMPLATE
  endpoint:
    path: /evals/default_templates/HALLUCINATION_PROMPT_TEMPLATE
    method: GET
- name: TOXICITY_PROMPT_TEMPLATE
  endpoint:
    path: /evals/default_templates/TOXICITY_PROMPT_TEMPLATE
    method: GET
- name: QA_PROMPT_TEMPLATE
  endpoint:
    path: /evals/default_templates/QA_PROMPT_TEMPLATE
    method: GET
- name: SUMMARIZATION_PROMPT_TEMPLATE
  endpoint:
    path: /evals/default_templates/SUMMARIZATION_PROMPT_TEMPLATE
    method: GET
- name: CODE_READABILITY_PROMPT_TEMPLATE
  endpoint:
    path: /evals/default_templates/CODE_READABILITY_PROMPT_TEMPLATE
    method: GET
- name: REFERENCE_LINK_CORRECTNESS_PROMPT_TEMPLATE
  endpoint:
    path: /evals/default_templates/REFERENCE_LINK_CORRECTNESS_PROMPT_TEMPLATE
    method: GET
- name: HUMAN_VS_AI_PROMPT_TEMPLATE
  endpoint:
    path: /evals/default_templates/HUMAN_VS_AI_PROMPT_TEMPLATE
    method: GET
- name: SQL_GEN_EVAL_PROMPT_TEMPLATE
  endpoint:
    path: /evals/default_templates/SQL_GEN_EVAL_PROMPT_TEMPLATE
    method: GET
- name: CODE_FUNCTIONALITY_PROMPT_TEMPLATE
  endpoint:
    path: /evals/default_templates/CODE_FUNCTIONALITY_PROMPT_TEMPLATE
    method: GET
- name: USER_FRUSTRATION_PROMPT_TEMPLATE
  endpoint:
    path: /evals/default_templates/USER_FRUSTRATION_PROMPT_TEMPLATE
    method: GET
- name: HallucinationEvaluator
  endpoint:
    path: /evals/evaluators/HallucinationEvaluator
    method: GET
    data_selector: records
- name: LLMEvaluator
  endpoint:
    path: /evals/evaluators/LLMEvaluator
    method: GET
    data_selector: records
- name: QAEvaluator
  endpoint:
    path: /evals/evaluators/QAEvaluator
    method: GET
    data_selector: records
- name: RelevanceEvaluator
  endpoint:
    path: /evals/evaluators/RelevanceEvaluator
    method: GET
    data_selector: records
- name: SQLEvaluator
  endpoint:
    path: /evals/evaluators/SQLEvaluator
    method: GET
    data_selector: records
- name: SummarizationEvaluator
  endpoint:
    path: /evals/evaluators/SummarizationEvaluator
    method: GET
    data_selector: records
- name: ToxicityEvaluator
  endpoint:
    path: /evals/evaluators/ToxicityEvaluator
    method: GET
    data_selector: records
- name: OpenAIModel
  endpoint:
    path: /evals/models/openai
    method: GET
    data_selector: records
- name: evaluate_experiment
  endpoint:
    path: /evaluate_experiment
    method: POST
    data_selector: results
    params: {}
- name: run_experiment
  endpoint:
    path: /run_experiment
    method: POST
    data_selector: results
    params: {}
- name: inferences
  endpoint:
    path: /inferences/schema
    method: GET
- name: AnthropicModel
  endpoint:
    path: /evals/models/anthropic
    method: GET
    data_selector: records
    params: {}
- name: BedrockModel
  endpoint:
    path: /evals/models/bedrock
    method: GET
    data_selector: records
- name: evaluate_experiment
  endpoint:
    path: /experiments/evaluate
    method: POST
    data_selector: results
    params: {}
- name: run_experiment
  endpoint:
    path: /experiments/run
    method: POST
    data_selector: results
    params: {}
- name: GeminiModel
  endpoint:
    path: /evals/models/vertex
    method: POST
    data_selector: response
    params: {}
- name: AnthropicModel
  endpoint:
    path: /evals/models/anthropic
    method: POST
    data_selector: model
    params: {}
- name: VertexAIModel
  endpoint:
    path: /evals/models/vertexai
    method: GET
    data_selector: records
    params: {}
- name: llm_classify
  endpoint:
    path: /evals/classify
    method: POST
    data_selector: dataframe
    params: {}
- name: run_evals
  endpoint:
    path: /evals/classify/run_evals
    method: POST
    data_selector: dataframe
    params: {}
- name: model
  endpoint:
    path: /models
    method: POST
    data_selector: model_id
- name: LiteLLMModel
  endpoint:
    path: /evals/models/litellm
    method: GET
    data_selector: model
    params: {}
- name: HallucinationEvaluator
  endpoint:
    path: /evals/evaluators/HallucinationEvaluator
    method: GET
- name: LLMEvaluator
  endpoint:
    path: /evals/evaluators/LLMEvaluator
    method: GET
- name: QAEvaluator
  endpoint:
    path: /evals/evaluators/QAEvaluator
    method: GET
- name: RelevanceEvaluator
  endpoint:
    path: /evals/evaluators/RelevanceEvaluator
    method: GET
- name: SQLEvaluator
  endpoint:
    path: /evals/evaluators/SQLEvaluator
    method: GET
- name: SummarizationEvaluator
  endpoint:
    path: /evals/evaluators/SummarizationEvaluator
    method: GET
- name: ToxicityEvaluator
  endpoint:
    path: /evals/evaluators/ToxicityEvaluator
    method: GET
- name: GeminiModel
  endpoint:
    path: /evals/models/vertex
    method: GET
    data_selector: records
- name: VertexAIModel
  endpoint:
    path: /evals/models/vertexai
    method: GET
    data_selector: models
- name: llm_classify
  endpoint:
    path: /evals/classify
    method: POST
    data_selector: data
    params: {}
- name: run_evals
  endpoint:
    path: /evals/classify/run_evals
    method: POST
    data_selector: dataframes
    params: {}
- name: experiments
  endpoint:
    path: /experiments
    method: GET
    data_selector: results
    params: {}
- name: RAG_RELEVANCY_PROMPT_TEMPLATE
  endpoint:
    path: /evals/default_templates/RAG_RELEVANCY_PROMPT_TEMPLATE
    method: GET
    data_selector: template
- name: HALLUCINATION_PROMPT_TEMPLATE
  endpoint:
    path: /evals/default_templates/HALLUCINATION_PROMPT_TEMPLATE
    method: GET
    data_selector: template
- name: TOXICITY_PROMPT_TEMPLATE
  endpoint:
    path: /evals/default_templates/TOXICITY_PROMPT_TEMPLATE
    method: GET
    data_selector: template
- name: QA_PROMPT_TEMPLATE
  endpoint:
    path: /evals/default_templates/QA_PROMPT_TEMPLATE
    method: GET
    data_selector: template
- name: SUMMARIZATION_PROMPT_TEMPLATE
  endpoint:
    path: /evals/default_templates/SUMMARIZATION_PROMPT_TEMPLATE
    method: GET
    data_selector: template
- name: CODE_READABILITY_PROMPT_TEMPLATE
  endpoint:
    path: /evals/default_templates/CODE_READABILITY_PROMPT_TEMPLATE
    method: GET
    data_selector: template
- name: REFERENCE_LINK_CORRECTNESS_PROMPT_TEMPLATE
  endpoint:
    path: /evals/default_templates/REFERENCE_LINK_CORRECTNESS_PROMPT_TEMPLATE
    method: GET
    data_selector: template
- name: HUMAN_VS_AI_PROMPT_TEMPLATE
  endpoint:
    path: /evals/default_templates/HUMAN_VS_AI_PROMPT_TEMPLATE
    method: GET
    data_selector: template
- name: SQL_GEN_EVAL_PROMPT_TEMPLATE
  endpoint:
    path: /evals/default_templates/SQL_GEN_EVAL_PROMPT_TEMPLATE
    method: GET
    data_selector: template
- name: CODE_FUNCTIONALITY_PROMPT_TEMPLATE
  endpoint:
    path: /evals/default_templates/CODE_FUNCTIONALITY_PROMPT_TEMPLATE
    method: GET
    data_selector: template
- name: USER_FRUSTRATION_PROMPT_TEMPLATE
  endpoint:
    path: /evals/default_templates/USER_FRUSTRATION_PROMPT_TEMPLATE
    method: GET
    data_selector: template
- name: AnthropicModel
  endpoint:
    path: /api/models/anthropic
    method: POST
    data_selector: model_response
    params: {}
- name: HallucinationEvaluator
  endpoint:
    path: /evals/evaluators/HallucinationEvaluator
    method: GET
- name: LLMEvaluator
  endpoint:
    path: /evals/evaluators/LLMEvaluator
    method: GET
- name: QAEvaluator
  endpoint:
    path: /evals/evaluators/QAEvaluator
    method: GET
- name: RelevanceEvaluator
  endpoint:
    path: /evals/evaluators/RelevanceEvaluator
    method: GET
- name: SQLEvaluator
  endpoint:
    path: /evals/evaluators/SQLEvaluator
    method: GET
- name: SummarizationEvaluator
  endpoint:
    path: /evals/evaluators/SummarizationEvaluator
    method: GET
- name: ToxicityEvaluator
  endpoint:
    path: /evals/evaluators/ToxicityEvaluator
    method: GET
- name: model
  endpoint:
    path: /model
    method: POST
    data_selector: model_response
    params: {}
- name: GeminiModel
  endpoint:
    path: /evals/models/vertex
    method: GET
    data_selector: model
    params: {}
- name: VertexAIModel
  endpoint:
    path: /evals/models/vertexai
    method: GET
- name: AnthropicModel
  endpoint:
    path: /evals/models/anthropic
    method: GET
    data_selector: model
    params: {}
- name: HallucinationEvaluator
  endpoint:
    path: /evals/evaluators/HallucinationEvaluator
    method: GET
- name: LLMEvaluator
  endpoint:
    path: /evals/evaluators/LLMEvaluator
    method: GET
- name: QAEvaluator
  endpoint:
    path: /evals/evaluators/QAEvaluator
    method: GET
- name: RelevanceEvaluator
  endpoint:
    path: /evals/evaluators/RelevanceEvaluator
    method: GET
- name: SQLEvaluator
  endpoint:
    path: /evals/evaluators/SQLEvaluator
    method: GET
- name: SummarizationEvaluator
  endpoint:
    path: /evals/evaluators/SummarizationEvaluator
    method: GET
- name: ToxicityEvaluator
  endpoint:
    path: /evals/evaluators/ToxicityEvaluator
    method: GET
- name: BedrockModel
  endpoint:
    path: /evals/models/bedrock
    method: GET
    data_selector: records
    params: {}
- name: LiteLLMModel
  endpoint:
    path: /evals/models/litellm
    method: GET
- name: GeminiModel
  endpoint:
    path: /evals/models/vertex
    method: GET
    data_selector: records
    params: {}
- name: VertexAIModel
  endpoint:
    path: evals/models/vertexai
    method: GET
- name: classify
  endpoint:
    path: /evals/classify
    method: POST
notes:
- Requires the openai package to be installed.
- Calls to the OpenAI API are dynamically throttled when encountering rate limit errors.
- Welcome to Arize Phoenix’s API reference.
- Launch Phoenix as a collector of LLM Traces generated by your LLM applications.
- The Phoenix server will continue running in the background until it is explicitly
  closed.
- Maximum number to retry a model if an RateLimitError, OpenAIError, or ServiceUnavailableError
  occurs.
- Maximum number of seconds to wait when retrying.
- Requires the mistralai package to be installed.
- Uses Google’s VertexAI models for Phoenix LLM evaluations.
- Calls to the VertexAI models dynamically throttled when encountering rate limit
  errors.
- Documentation on how to configure tracing can be found at https://opentelemetry.io/docs/specs/otel/trace/sdk/
- Calls to the Anthropic API are dynamically throttled when encountering rate limit
  errors.
- Requires the anthropic package to be installed.
- Cohere Command (Text) and AI21 Labs Jurassic-2 (Text) models don’t support chat
  with the Converse API and cannot support templates with multiple parts.
- Due to the number of supported models and variations in rate limit handling, we
  do not catch rate limit exceptions and throttle requests.
- 'Supports Async: ❌'
- Calls to the MistralAI API are dynamically throttled when encountering rate limit
  errors.
- This model wrapper does not support async LLM calls.
- Cohere Command (Text) and AI21 Labs Jurassic-2 (Text) models don’t support chat
  with the Converse API.
- Calls to the Gemini models dynamically throttled when encountering rate limit errors.
- Requires the vertexai package to be installed.
- An experiment is a user-defined task that runs on each example in a dataset.
- The results from each experiment can be evaluated using any number of evaluators.
- For further configuration, the phoenix.otel module provides drop-in replacements
  for OpenTelemetry TracerProvider, SimpleSpanProcessor, BatchSpanProcessor, HTTPSpanExporter,
  and GRPCSpanExporter objects with Phoenix-aware defaults.
- Uses OAuth2 with refresh token — requires setup of connected app in api
- Cohere Command and AI21 Labs Jurassic-2 models don’t support chat with the Converse
  API.
- If not provided, the endpoint will be inferred from the environment variables.
- 'Supports Async: If possible, makes LLM calls concurrently.'
- Some objects like Contact may return nulls in deeply nested fields
errors:
- 'Rate limit errors: API calls are throttled.'
- 'Rate limit errors: Calls to the AWS API are dynamically throttled when encountering
  rate limit errors.'
- 'RATE_LIMIT_EXCEEDED: Throttle API calls or reduce frequency'
- 'Rate limit errors: Adjust API call frequency.'
auth_info:
  mentioned_objects:
  - Session
  - OauthToken
  - AuthProvider
  - NamedCredential
client:
  base_url: https://arize-phoenix.readthedocs.io
  auth:
    type: oauth2
source_metadata: null
