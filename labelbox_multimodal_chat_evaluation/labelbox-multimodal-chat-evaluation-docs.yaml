resources:
- name: multimodal_chat_evaluation
  endpoint:
    path: /projects/multimodal_chat_evaluation
    method: POST
    data_selector: project
    params: {}
- name: multimodal_chat_project
  endpoint:
    path: /api/multimodal_chat_project
    method: POST
    data_selector: project
    params: {}
- name: multimodal_chat_evaluation
  endpoint:
    path: /create_model_evaluation_project
    method: POST
    data_selector: project
    params: {}
- name: projects
  endpoint:
    path: /api/projects
    method: GET
    data_selector: data
    params: {}
- name: projects
  endpoint:
    path: /api/projects
    method: GET
    data_selector: projects
    params: {}
- name: datasets
  endpoint:
    path: /api/datasets
    method: GET
    data_selector: datasets
    params: {}
- name: projects
  endpoint:
    path: /api/projects
    method: GET
    data_selector: data
    params: {}
- name: annotations
  endpoint:
    path: /api/annotations
    method: GET
    data_selector: data
    params: {}
- name: projects
  endpoint:
    path: /projects
    method: GET
    data_selector: records
- name: annotations
  endpoint:
    path: /annotations
    method: GET
    data_selector: records
- name: ExportTask
  endpoint:
    path: /services/data/vXX.X/sobjects/ExportTask
    method: GET
    data_selector: records
    params: {}
- name: Project
  endpoint:
    path: /services/data/vXX.X/sobjects/Project
    method: GET
    data_selector: records
    params: {}
- name: dataset
  endpoint:
    path: /datasets
    method: POST
    data_selector: dataset
    params: {}
- name: project
  endpoint:
    path: /projects
    method: POST
    data_selector: project
    params: {}
- name: ontology
  endpoint:
    path: /ontologies
    method: POST
    data_selector: ontology
    params: {}
- name: data_rows
  endpoint:
    path: /data-rows
    method: POST
    data_selector: data_row
    params: {}
- name: export
  endpoint:
    path: /export
    method: GET
    data_selector: export_task
    params: {}
- name: project
  endpoint:
    path: /projects
    method: GET
    data_selector: projects
- name: dataset
  endpoint:
    path: /datasets
    method: GET
    data_selector: datasets
- name: dataset
  endpoint:
    path: /datasets
    method: POST
    data_selector: data
    params: {}
- name: project
  endpoint:
    path: /projects
    method: POST
    data_selector: data
    params: {}
- name: ontology
  endpoint:
    path: /ontologies
    method: POST
    data_selector: data
    params: {}
- name: data_row
  endpoint:
    path: /data-rows
    method: POST
    data_selector: data
    params: {}
- name: export
  endpoint:
    path: /projects/{project_id}/export
    method: GET
    data_selector: data
    params: {}
- name: task
  endpoint:
    path: /tasks
    method: GET
    data_selector: tasks
- name: batch
  endpoint:
    path: /batches
    method: GET
    data_selector: batches
    params: {}
- name: batch
  endpoint:
    path: /projects/{project_id}/batches
    method: POST
    data_selector: batch
    params: {}
- name: task
  endpoint:
    path: /tasks
    method: GET
    data_selector: tasks
    params:
      incremental: created_at
- name: workflow
  endpoint:
    path: /workflows
    method: GET
- name: nodes
  endpoint:
    path: /nodes
    method: GET
- name: edges
  endpoint:
    path: /edges
    method: GET
- name: initial_review
  endpoint:
    path: /workflow/add_node
    method: POST
    data_selector: nodes
    params: {}
- name: logic_node
  endpoint:
    path: /workflow/add_node
    method: POST
    data_selector: nodes
    params: {}
- name: batch
  endpoint:
    path: /projects/{project_id}/batches
    method: POST
    data_selector: batches
- name: batch
  endpoint:
    path: /api/batches
    method: POST
    data_selector: batches
- name: initial_review_task
  endpoint:
    path: /initial_review_task
    method: POST
    data_selector: task
    params: {}
- name: logic_node
  endpoint:
    path: /logic_node
    method: POST
    data_selector: node
    params: {}
- name: done_task
  endpoint:
    path: /done_task
    method: POST
    data_selector: task
    params: {}
- name: rework_task
  endpoint:
    path: /rework_task
    method: POST
    data_selector: task
    params: {}
- name: foundry_app
  endpoint:
    path: /foundry/app
    method: POST
    data_selector: results
    params:
      incremental: updated_at
- name: initial_review
  endpoint:
    path: /workflow/add_node
    method: POST
    data_selector: initial_review
    params: {}
- name: logic
  endpoint:
    path: /workflow/add_node
    method: POST
    data_selector: logic
    params: {}
- name: done
  endpoint:
    path: /workflow/add_node
    method: POST
    data_selector: done
    params: {}
- name: foundry_app
  endpoint:
    path: /create_foundry_app
    method: POST
    data_selector: app_id
- name: foundry_app
  endpoint:
    path: /foundry/app
    method: POST
- name: initial_review_task
  endpoint:
    path: /workflow/initial_review_task
    method: POST
    data_selector: task_results
    params: {}
- name: logic_node
  endpoint:
    path: /workflow/logic_node
    method: POST
    data_selector: node_results
    params: {}
- name: done_node
  endpoint:
    path: /workflow/done_node
    method: POST
    data_selector: done_results
    params: {}
- name: dataset
  endpoint:
    path: /datasets
    method: POST
    data_selector: dataset
    params: {}
- name: data_row
  endpoint:
    path: /data-rows
    method: POST
    data_selector: dataRow
    params: {}
- name: foundry_app
  endpoint:
    path: /api/foundry/app
    method: POST
    data_selector: app
    params: {}
- name: dataset
  endpoint:
    path: /datasets
    method: POST
    data_selector: dataset
    params: {}
- name: data_rows
  endpoint:
    path: /data-rows
    method: POST
    data_selector: data_rows
    params: {}
- name: foundry_app
  endpoint:
    path: /foundry/apps
    method: POST
    data_selector: appId
- name: dataset
  endpoint:
    path: /datasets
    method: POST
    data_selector: dataset
- name: data_row
  endpoint:
    path: /data-rows
    method: POST
    data_selector: data_row
- name: foundry_app
  endpoint:
    path: /model/apps
    method: POST
    data_selector: app_id
- name: data_row
  endpoint:
    path: /data_row
    method: GET
    data_selector: data_rows
- name: dataset
  endpoint:
    path: /datasets
    method: POST
    data_selector: dataset
    params: {}
- name: data_row
  endpoint:
    path: /data-rows
    method: GET
    data_selector: data_rows
- name: dataset
  endpoint:
    path: /datasets
    method: POST
    data_selector: dataset
    params: {}
- name: data_row
  endpoint:
    path: /data-rows
    method: POST
    data_selector: data_row
    params: {}
- name: DataRow
  endpoint:
    path: /data-rows
    method: POST
    data_selector: data
- name: Attachments
  endpoint:
    path: /attachments
    method: POST
    data_selector: data
- name: attachments
  endpoint:
    path: /attachments
    method: GET
    data_selector: attachments
- name: dataset
  endpoint:
    path: /datasets
    method: POST
    data_selector: dataset
    params: {}
- name: data_rows
  endpoint:
    path: /data_rows
    method: POST
    data_selector: data_rows
    params: {}
- name: data_row
  endpoint:
    path: /data-rows
    method: GET
    data_selector: data_rows
- name: media_attributes
  endpoint:
    path: /media_attributes
    method: GET
    data_selector: mediaAttributes
- name: data_row
  endpoint:
    path: /data_row
    method: GET
    data_selector: data_rows
- name: data_row
  endpoint:
    path: /data-rows
    method: POST
    data_selector: results
- name: catalog_slice
  endpoint:
    path: /catalog/slice
    method: GET
    data_selector: data_rows
- name: attachment
  endpoint:
    path: /attachments
    method: POST
    data_selector: attachment
- name: data_row
  endpoint:
    path: /data-rows
    method: POST
    data_selector: dataRow
- name: metadata
  endpoint:
    path: /metadata
    method: GET
    data_selector: records
- name: attachments
  endpoint:
    path: /attachments
    method: POST
    data_selector: attachments
- name: data_row
  endpoint:
    path: /data-rows
    method: POST
    data_selector: data_rows
- name: iam_integration
  endpoint:
    path: /reference/cloud-storage-iam-integration
    method: GET
    data_selector: iam_integrations
    params: {}
- name: media_attributes
  endpoint:
    path: /media_attributes
    method: GET
    data_selector: dataRow.mediaAttributes
- name: webhook
  endpoint:
    path: /webhook-endpoint
    method: POST
    data_selector: payload
- name: data_row
  endpoint:
    path: /data-rows
    method: POST
    data_selector: data_rows
    params: {}
- name: project_tags
  endpoint:
    path: /api/projects/tags
    method: GET
    data_selector: tags
- name: catalog_slice
  endpoint:
    path: /api/catalog/slices
    method: GET
    data_selector: slices
- name: organization
  endpoint:
    path: /organization
    method: GET
    data_selector: data
    params: {}
- name: metadata
  endpoint:
    path: /metadata
    method: GET
    data_selector: records
- name: organization
  endpoint:
    path: /organization
    method: GET
    data_selector: organization
- name: users
  endpoint:
    path: /organization/users
    method: GET
    data_selector: users
- name: projects
  endpoint:
    path: /organization/projects
    method: GET
    data_selector: projects
- name: iam_integration
  endpoint:
    path: /iam_integration
    method: GET
    data_selector: integrations
- name: organization
  endpoint:
    path: /organization
    method: GET
- name: iam_integrations
  endpoint:
    path: /iam_integrations
    method: GET
- name: project_tags
  endpoint:
    path: /project_tags
    method: GET
- name: users
  endpoint:
    path: /users
    method: GET
- name: projects
  endpoint:
    path: /projects
    method: GET
- name: webhooks
  endpoint:
    path: /webhooks
    method: GET
- name: tasks
  endpoint:
    path: /tasks
    method: GET
- name: webhook
  endpoint:
    path: /webhook-endpoint
    method: POST
    data_selector: payload
- name: project_tags
  endpoint:
    path: /get-the-project-tags
    method: GET
    data_selector: ResourceTag
- name: dataset
  endpoint:
    path: /datasets
    method: POST
    data_selector: data_rows
- name: project
  endpoint:
    path: /projects
    method: POST
    data_selector: projects
- name: ontology
  endpoint:
    path: /ontologies
    method: POST
    data_selector: ontologies
- name: project
  endpoint:
    path: /projects
    method: GET
    data_selector: projects
- name: ontology
  endpoint:
    path: /ontologies
    method: GET
    data_selector: ontologies
- name: organization
  endpoint:
    path: /api/organization
    method: GET
    data_selector: data
    params: {}
- name: roles
  endpoint:
    path: /api/roles
    method: GET
    data_selector: data
    params: {}
- name: export
  endpoint:
    path: /projects/{project_id}/export
    method: POST
    data_selector: json
    params:
      performance_details: true
      label_details: true
- name: organization
  endpoint:
    path: /organization
    method: GET
    data_selector: organization
    params: {}
- name: users
  endpoint:
    path: /organization/users
    method: GET
    data_selector: users
    params: {}
- name: projects
  endpoint:
    path: /organization/projects
    method: GET
    data_selector: projects
    params: {}
- name: dataset
  endpoint:
    path: /api/datasets
    method: POST
    data_selector: data
    params: {}
- name: project
  endpoint:
    path: /api/projects
    method: POST
    data_selector: data
    params: {}
- name: export
  endpoint:
    path: /projects/{project_id}/export
    method: POST
    data_selector: results
    params:
      performance_details: true
      label_details: true
- name: organization
  endpoint:
    path: /get_organization
    method: GET
    data_selector: organization
- name: iam_integrations
  endpoint:
    path: /get_iam_integrations
    method: GET
    data_selector: iam_integrations
- name: roles
  endpoint:
    path: /get_roles
    method: GET
    data_selector: roles
- name: invites
  endpoint:
    path: /get_invites
    method: GET
    data_selector: invites
- name: projects
  endpoint:
    path: /get_projects
    method: GET
    data_selector: projects
- name: webhooks
  endpoint:
    path: /get_webhooks
    method: GET
    data_selector: webhooks
- name: tasks
  endpoint:
    path: /get_tasks
    method: GET
    data_selector: tasks
- name: labeling_service
  endpoint:
    path: /labeling_service
    method: GET
    data_selector: data
    params: {}
- name: dataset
  endpoint:
    path: /datasets
    method: POST
    data_selector: data
    params: {}
- name: data_rows
  endpoint:
    path: /data-rows
    method: GET
    data_selector: data
    params: {}
- name: dataset
  endpoint:
    path: /datasets
    method: POST
    data_selector: dataset
    params: {}
- name: project
  endpoint:
    path: /projects
    method: POST
    data_selector: project
    params: {}
- name: dataset
  endpoint:
    path: /datasets
    method: POST
    data_selector: dataset
    params: {}
- name: project
  endpoint:
    path: /projects
    method: POST
    data_selector: project
    params: {}
- name: ontology
  endpoint:
    path: /projects/{project_id}/ontology
    method: GET
    data_selector: ontology
- name: data_row
  endpoint:
    path: /projects/{project_id}/data_rows
    method: GET
    data_selector: data_rows
- name: export
  endpoint:
    path: /projects/{project_uid}/export
    method: POST
    params:
      performance_details: true
      label_details: true
- name: data_row
  endpoint:
    path: /data_rows
    method: GET
    data_selector: data_rows
    params: {}
- name: project
  endpoint:
    path: /projects
    method: GET
    data_selector: projects
    params: {}
- name: export_data
  endpoint:
    path: /export
    method: GET
    data_selector: json
    params:
      performance_details: 'True'
      label_details: 'True'
- name: support_tickets
  endpoint:
    path: /support/tickets
    method: GET
    data_selector: tickets
    params: {}
- name: data_rows
  endpoint:
    path: /data_rows
    method: GET
    data_selector: data_rows
    params: {}
- name: annotations
  endpoint:
    path: /annotations
    method: GET
    data_selector: annotations
    params: {}
- name: dataset
  endpoint:
    path: /datasets
    method: POST
    data_selector: dataset
    params: {}
- name: project
  endpoint:
    path: /projects
    method: POST
    data_selector: project
    params: {}
- name: model_run
  endpoint:
    path: /model/runs
    method: GET
    data_selector: data
    params: {}
- name: experimental_features
  endpoint:
    path: /docs/product-release-phases#experimental
    method: GET
    data_selector: features
    params: {}
- name: preview_features
  endpoint:
    path: /docs/product-release-phases#preview
    method: GET
    data_selector: features
    params: {}
- name: beta_features
  endpoint:
    path: /docs/product-release-phases#beta
    method: GET
    data_selector: features
    params: {}
- name: general_availability_features
  endpoint:
    path: /docs/product-release-phases#general-availability-ga
    method: GET
    data_selector: features
    params: {}
- name: slices
  endpoint:
    path: /catalog/slices
    method: GET
    data_selector: data
    params: {}
- name: ontologies
  endpoint:
    path: /api/ontologies
    method: GET
    data_selector: ontologies
- name: projects
  endpoint:
    path: /projects
    method: GET
    data_selector: records
- name: metadata
  endpoint:
    path: /metadata
    method: GET
    data_selector: data
    params: {}
- name: export_labels
  endpoint:
    path: /export/labels
    method: POST
    data_selector: data
    params: {}
- name: export_data
  endpoint:
    path: /export/data
    method: POST
    data_selector: data_rows
    params: {}
- name: export_model_run_data
  endpoint:
    path: /export/model/run/data
    method: GET
- name: cloud_storage_integration
  endpoint:
    path: /api/integration/cloud_storage
    method: GET
    data_selector: data
    params: {}
- name: fine_tune_model
  endpoint:
    path: /models/fine-tune
    method: POST
    data_selector: model
    params: {}
- name: S3 bucket data
  endpoint:
    path: /<key>
    method: GET
    data_selector: data
    params: {}
- name: bulk_classification
  endpoint:
    path: /bulk_classification
    method: POST
    data_selector: data
    params: {}
- name: gcs_bucket
  endpoint:
    path: /{bucket}
    method: GET
    data_selector: files
    params: {}
- name: batches
  endpoint:
    path: /api/batches
    method: POST
    data_selector: data
    params: {}
- name: slices
  endpoint:
    path: /api/slices
    method: GET
    data_selector: data
    params: {}
- name: ontologies
  endpoint:
    path: /api/ontologies
    method: GET
    data_selector: data
    params: {}
- name: members
  endpoint:
    path: /api/members
    method: GET
    data_selector: members
    params: {}
- name: groups
  endpoint:
    path: /api/groups
    method: GET
    data_selector: groups
    params: {}
- name: monitor_labeling_performance
  endpoint:
    path: /monitor
    method: GET
- name: notifications
  endpoint:
    path: /notifications
    method: GET
    data_selector: tasks
    params: {}
- name: export_data
  endpoint:
    path: /export/data
    method: POST
    data_selector: data
- name: model_run_data
  endpoint:
    path: /export/model/run/data
    method: GET
    data_selector: data_rows
    params: {}
- name: data_rows
  endpoint:
    path: /data-rows
    method: GET
    data_selector: dataRows
    params: {}
- name: benchmarks
  endpoint:
    path: /api/benchmarks
    method: GET
    data_selector: data
    params: {}
- name: bucket_data
  endpoint:
    path: /{bucket_name}
    method: GET
    data_selector: data
- name: azure_blob_storage
  endpoint:
    path: /microsoft-azure-blob-storage
    method: GET
    data_selector: data
    params: {}
- name: data_row
  endpoint:
    path: /api/data_rows
    method: GET
    data_selector: dataRows
    params: {}
- name: dataset
  endpoint:
    path: /api/datasets
    method: GET
    data_selector: datasets
    params: {}
- name: consensus
  endpoint:
    path: /consensus
    method: GET
    data_selector: data
    params: {}
- name: workspaces
  endpoint:
    path: /workspaces
    method: GET
- name: experiments
  endpoint:
    path: /api/v1/experiments
    method: POST
    data_selector: data
    params: {}
- name: model_run
  endpoint:
    path: /api/model_runs
    method: POST
    data_selector: data
    params: {}
- name: monitor_labeling_performance
  endpoint:
    path: /monitor
    method: GET
    data_selector: metrics
    params: {}
- name: projects
  endpoint:
    path: /projects
    method: GET
    data_selector: data
- name: labeling_queue
  endpoint:
    path: /labeling-queue
    method: GET
    data_selector: dataRows
    params: {}
- name: workflows
  endpoint:
    path: /workflows
    method: GET
    data_selector: data
- name: annotations
  endpoint:
    path: /api/annotations
    method: POST
    data_selector: data
    params: {}
- name: import_video_annotations
  endpoint:
    path: /import/video/annotations
    method: POST
    data_selector: annotations_payload
- name: data_rows
  endpoint:
    path: /data-rows
    method: GET
    data_selector: dataRows
- name: video_annotations
  endpoint:
    path: /api/video/annotations
    method: POST
    data_selector: annotations
    params: {}
- name: import_video_annotations
  endpoint:
    path: /reference/import-video-annotations
    method: POST
    data_selector: annotations
- name: data_rows
  endpoint:
    path: /data-rows
    method: GET
    data_selector: dataRows
    params: {}
- name: datasets
  endpoint:
    path: /datasets
    method: GET
    data_selector: datasets
    params: {}
- name: video_demo_dataset
  endpoint:
    path: /create_dataset
    method: POST
    data_selector: dataset
    params: {}
- name: ontology
  endpoint:
    path: /create_ontology
    method: POST
    data_selector: ontology
    params: {}
- name: project
  endpoint:
    path: /create_project
    method: POST
    data_selector: project
    params: {}
- name: batch
  endpoint:
    path: /create_batch
    method: POST
    data_selector: batch
    params: {}
- name: text_annotations
  endpoint:
    path: /annotations/text
    method: POST
    data_selector: annotations
- name: experiments
  endpoint:
    path: /experiments
    method: GET
- name: import_text_annotations
  endpoint:
    path: /annotations/import
    method: POST
    data_selector: annotations
    params: {}
- name: batch
  endpoint:
    path: /reference/batch
    method: POST
    data_selector: batch
    params: {}
- name: ontology
  endpoint:
    path: /reference/metadata
    method: POST
    data_selector: ontology
    params: {}
- name: project
  endpoint:
    path: /reference/project
    method: POST
    data_selector: project
    params: {}
- name: experiment
  endpoint:
    path: /api/experiments
    method: POST
    data_selector: data
    params: {}
- name: import_text_annotations
  endpoint:
    path: /import/text/annotations
    method: POST
    data_selector: annotations
- name: import_ground_truth
  endpoint:
    path: /import/ground/truth
    method: POST
    data_selector: labels
- name: geospatial_annotations
  endpoint:
    path: /import-geospatial-annotations
    method: POST
    data_selector: annotations
    params: {}
- name: workflows
  endpoint:
    path: /workflows
    method: GET
    data_selector: workflows
    params: {}
- name: geospatial_annotations
  endpoint:
    path: /import-geospatial-annotations
    method: POST
    data_selector: annotations
    params: {}
- name: geospatial_annotations
  endpoint:
    path: /annotations/geospatial
    method: POST
    data_selector: annotations
    params: {}
- name: import_ground_truth
  endpoint:
    path: /api/import/ground_truth
    method: POST
    data_selector: data
    params: {}
- name: annotations
  endpoint:
    path: /import-video-annotations
    method: POST
    data_selector: payload
    params: {}
- name: geospatial_annotations
  endpoint:
    path: /reference/import-geospatial-annotations
    method: POST
    data_selector: annotations
    params: {}
- name: mal_prediction_import
  endpoint:
    path: /upload/mal_prediction_import
    method: POST
    data_selector: upload_job
    params: {}
- name: label_import
  endpoint:
    path: /upload/label_import
    method: POST
    data_selector: upload_job
    params: {}
- name: import_video_annotations
  endpoint:
    path: /reference/import-video-annotations
    method: POST
- name: import_document_annotations
  endpoint:
    path: /import-document-annotations
    method: POST
    data_selector: annotations
- name: video_annotations
  endpoint:
    path: /import-video-annotations
    method: POST
    data_selector: annotations
    params: {}
- name: annotations_payload
  endpoint:
    path: /reference/import-document-annotations
    method: GET
    data_selector: annotations
    params: {}
- name: dataset
  endpoint:
    path: /datasets
    method: POST
    data_selector: dataset
    params: {}
- name: ontology
  endpoint:
    path: /ontologies
    method: POST
    data_selector: ontology
    params: {}
- name: project
  endpoint:
    path: /projects
    method: POST
    data_selector: project
    params: {}
- name: batch
  endpoint:
    path: /batches
    method: POST
    data_selector: batch
    params: {}
- name: label
  endpoint:
    path: /labels
    method: POST
    data_selector: label
    params: {}
- name: dataset
  endpoint:
    path: /datasets
    method: POST
    data_selector: data
    params: {}
- name: ontology
  endpoint:
    path: /ontologies
    method: POST
    data_selector: data
    params: {}
- name: project
  endpoint:
    path: /projects
    method: POST
    data_selector: data
    params: {}
- name: import_text_annotations
  endpoint:
    path: /reference/import-text-annotations
    method: POST
    data_selector: records
    params: {}
- name: import_document_annotations
  endpoint:
    path: /api/import/document_annotations
    method: POST
    data_selector: annotations
    params: {}
- name: text_annotations
  endpoint:
    path: /reference/import-text-annotations
    method: POST
    data_selector: annotations
    params: {}
- name: dataset
  endpoint:
    path: /datasets
    method: POST
    data_selector: data
    params: {}
- name: project
  endpoint:
    path: /projects
    method: POST
    data_selector: data
    params: {}
- name: batch
  endpoint:
    path: /reference/batch
    method: POST
    data_selector: batch
    params: {}
- name: project
  endpoint:
    path: /reference/project
    method: POST
    data_selector: project
    params: {}
- name: text_annotations
  endpoint:
    path: /import/text/annotations
    method: POST
    data_selector: labels
- name: annotations
  endpoint:
    path: /annotations/import
    method: POST
    data_selector: data
    params: {}
- name: geospatial_annotations
  endpoint:
    path: /import-geospatial-annotations
    method: POST
    data_selector: records
- name: annotations
  endpoint:
    path: /annotations
    method: POST
    data_selector: data
    params: {}
- name: projects
  endpoint:
    path: /projects
    method: GET
    data_selector: data
    params: {}
- name: annotations
  endpoint:
    path: /api/annotations
    method: POST
    data_selector: data
    params: {}
- name: audio_annotations
  endpoint:
    path: /import/audio/annotations
    method: POST
    data_selector: annotations
    params: {}
- name: geospatial_annotations
  endpoint:
    path: /import/geospatial/annotations
    method: POST
    data_selector: annotations
- name: geospatial_annotations
  endpoint:
    path: /import/geospatial/annotations
    method: POST
    data_selector: data
    params: {}
- name: audio_annotations
  endpoint:
    path: /api/audio_annotations
    method: POST
    data_selector: annotations
- name: mal_prediction_import
  endpoint:
    path: /upload/mal_prediction
    method: POST
    data_selector: upload_job
    params: {}
- name: label_import
  endpoint:
    path: /upload/label
    method: POST
    data_selector: upload_job
    params: {}
- name: audio_annotations
  endpoint:
    path: /reference/import-audio-annotations
    method: POST
    data_selector: annotations
    params: {}
- name: data_row
  endpoint:
    path: /data-rows
    method: POST
    data_selector: data_rows
    params: {}
- name: ontology
  endpoint:
    path: /ontologies
    method: POST
    data_selector: ontologies
    params: {}
- name: labeling_project
  endpoint:
    path: /labeling-projects
    method: POST
    data_selector: labeling_projects
    params: {}
- name: projects
  endpoint:
    path: /projects
    method: GET
    data_selector: data
    params: {}
- name: dataRows
  endpoint:
    path: /data-rows
    method: GET
    data_selector: data
    params: {}
- name: document_annotations
  endpoint:
    path: /import/document/annotations
    method: POST
    data_selector: annotations
    params: {}
- name: custom_model
  endpoint:
    path: /models
    method: POST
    data_selector: model
    params: {}
- name: dataset
  endpoint:
    path: /datasets
    method: POST
    data_selector: data
    params: {}
- name: ontology
  endpoint:
    path: /ontologies
    method: POST
    data_selector: data
    params: {}
- name: project
  endpoint:
    path: /projects
    method: POST
    data_selector: data
    params: {}
- name: models
  endpoint:
    path: /models
    method: GET
    data_selector: models
    params: {}
- name: import_document_annotations
  endpoint:
    path: /api/import_document_annotations
    method: POST
    data_selector: annotations
- name: model_run
  endpoint:
    path: /api/v1/model_run
    method: POST
    data_selector: data
    params: {}
- name: dataset
  endpoint:
    path: /datasets
    method: POST
    data_selector: data
    params: {}
- name: project
  endpoint:
    path: /projects
    method: POST
    data_selector: data
    params: {}
- name: MALPredictionImport
  endpoint:
    path: /upload/mal_prediction_import
    method: POST
    data_selector: upload_job
    params: {}
- name: LabelImport
  endpoint:
    path: /upload/label_import
    method: POST
    data_selector: upload_job
    params: {}
- name: model_run_progress
  endpoint:
    path: /api/model-run/progress
    method: GET
    data_selector: progress
    params: {}
- name: dataset
  endpoint:
    path: /datasets
    method: POST
    data_selector: dataset
    params: {}
- name: data_rows
  endpoint:
    path: /data-rows
    method: POST
    data_selector: data_rows
    params: {}
- name: predictions
  endpoint:
    path: /api/predictions
    method: POST
    data_selector: data
    params: {}
- name: batch
  endpoint:
    path: /api/batch
    method: POST
    data_selector: data
    params: {}
- name: ontology
  endpoint:
    path: /api/ontology
    method: POST
    data_selector: data
    params: {}
- name: project
  endpoint:
    path: /api/project
    method: POST
    data_selector: data
    params: {}
- name: audio_annotations
  endpoint:
    path: /import-audio-annotations
    method: POST
    data_selector: annotations
    params: {}
- name: model_run
  endpoint:
    path: /model/runs
    method: GET
- name: annotate_project
  endpoint:
    path: /annotate/projects
    method: GET
- name: upload_predictions
  endpoint:
    path: /api/model-runs/{model_run_id}/predictions
    method: POST
    data_selector: predictions
    params: {}
- name: audio_annotations
  endpoint:
    path: /reference/import-audio-annotations
    method: POST
    data_selector: annotations
    params: {}
- name: model_run_metrics
  endpoint:
    path: /model_run_metrics
    method: GET
    data_selector: metrics
    params: {}
- name: annotations
  endpoint:
    path: /annotations
    method: POST
    data_selector: data
    params: {}
- name: model_runs
  endpoint:
    path: /api/model_runs
    method: GET
    data_selector: data
    params: {}
- name: projects
  endpoint:
    path: /projects
    method: GET
    data_selector: data
    params: {}
- name: upload_image_predictions
  endpoint:
    path: /upload/image/predictions
    method: POST
    data_selector: predictions
- name: image_predictions
  endpoint:
    path: /upload/image/predictions
    method: POST
    data_selector: predictions
    params: {}
- name: predictions
  endpoint:
    path: /upload-image-predictions
    method: POST
    data_selector: predictions
- name: upload_image_predictions
  endpoint:
    path: /upload_image_predictions
    method: POST
    data_selector: predictions
    params: {}
- name: upload_image_predictions
  endpoint:
    path: /upload-image-predictions
    method: POST
    data_selector: predictions
- name: model_run_progress
  endpoint:
    path: /docs/foundry-track-progress
    method: GET
    data_selector: progress
- name: predictions
  endpoint:
    path: /v1/predictions
    method: POST
    data_selector: predictions
- name: video_predictions
  endpoint:
    path: /upload/video/predictions
    method: POST
    data_selector: predictions
- name: export_predictions
  endpoint:
    path: /export/predictions
    method: POST
    data_selector: results
    params: {}
- name: video_predictions
  endpoint:
    path: /upload/video/predictions
    method: POST
    data_selector: predictions
    params: {}
- name: video_predictions
  endpoint:
    path: /v1/predictions
    method: POST
    data_selector: predictions
    params: {}
- name: batch
  endpoint:
    path: /api/batch/send
    method: POST
    data_selector: data_rows
    params: {}
- name: project
  endpoint:
    path: /projects
    method: POST
    data_selector: project
    params: {}
- name: batch
  endpoint:
    path: /batches
    method: POST
    data_selector: batch
    params: {}
- name: label_import
  endpoint:
    path: /label_imports
    method: POST
    data_selector: label_import
    params: {}
- name: text_predictions
  endpoint:
    path: /upload/text/predictions
    method: POST
    data_selector: predictions
- name: model_run_metrics
  endpoint:
    path: /api/model_run_metrics
    method: GET
    data_selector: metrics
    params: {}
- name: geospatial_predictions
  endpoint:
    path: /upload/geospatial_predictions
    method: POST
    data_selector: predictions
    params: {}
- name: model_runs
  endpoint:
    path: /api/model_runs
    method: GET
    data_selector: data
    params: {}
- name: ontology
  endpoint:
    path: /create_ontology
    method: POST
    data_selector: ontology
    params: {}
- name: model
  endpoint:
    path: /create_model
    method: POST
    data_selector: model
    params: {}
- name: model_run
  endpoint:
    path: /create_model_run
    method: POST
    data_selector: model_run
    params: {}
- name: upload_predictions
  endpoint:
    path: /upload/image/predictions
    method: POST
    data_selector: predictions
- name: geospatial_predictions
  endpoint:
    path: /upload_geospatial_predictions
    method: POST
    data_selector: predictions
    params: {}
- name: image_predictions
  endpoint:
    path: /upload-image-predictions
    method: POST
    data_selector: predictions
- name: upload_predictions
  endpoint:
    path: /upload/html/predictions
    method: POST
    data_selector: predictions
- name: image_predictions
  endpoint:
    path: /upload-image-predictions
    method: POST
    data_selector: predictions
- name: image_predictions
  endpoint:
    path: /upload-image-predictions
    method: POST
    data_selector: predictions
- name: model_run
  endpoint:
    path: /model_runs
    method: POST
    data_selector: data
    params: {}
- name: predictions
  endpoint:
    path: /predictions
    method: POST
    data_selector: data
    params: {}
- name: data_rows
  endpoint:
    path: /data-rows
    method: POST
    data_selector: data
    params:
      tag: to re-label
- name: video_predictions
  endpoint:
    path: /upload_video_predictions
    method: POST
    data_selector: predictions
- name: upload_video_predictions
  endpoint:
    path: /api/upload_video_predictions
    method: POST
    data_selector: predictions
- name: upload_video_predictions
  endpoint:
    path: /upload/video/predictions
    method: POST
    data_selector: predictions
- name: project
  endpoint:
    path: /projects
    method: GET
    data_selector: projects
- name: batch
  endpoint:
    path: /batches
    method: POST
    data_selector: batches
- name: project
  endpoint:
    path: /projects
    method: POST
    data_selector: projects
    params: {}
- name: batch
  endpoint:
    path: /batches
    method: POST
    data_selector: batches
    params: {}
- name: text_predictions
  endpoint:
    path: /upload/text/predictions
    method: POST
    data_selector: predictions
- name: project
  endpoint:
    path: /projects
    method: GET
    data_selector: projects
- name: batch
  endpoint:
    path: /batches
    method: GET
    data_selector: batches
- name: project
  endpoint:
    path: /projects
    method: GET
    data_selector: projects
- name: batch
  endpoint:
    path: /batches
    method: GET
    data_selector: batches
- name: ontology
  endpoint:
    path: /ontologies
    method: POST
    data_selector: ontology
    params: {}
- name: model
  endpoint:
    path: /models
    method: POST
    data_selector: model
    params: {}
- name: model_run
  endpoint:
    path: /model_runs
    method: POST
    data_selector: model_run
    params: {}
- name: predictions
  endpoint:
    path: /predictions
    method: POST
    data_selector: predictions
    params: {}
- name: project
  endpoint:
    path: /projects
    method: GET
    data_selector: projects
- name: batch
  endpoint:
    path: /batches
    method: GET
    data_selector: batches
- name: upload_geospatial_predictions
  endpoint:
    path: /upload/geospatial/predictions
    method: POST
    data_selector: predictions
- name: project
  endpoint:
    path: /projects
    method: GET
    data_selector: projects
- name: batch
  endpoint:
    path: /batches
    method: GET
    data_selector: batches
- name: upload_predictions
  endpoint:
    path: /upload/predictions
    method: POST
    data_selector: predictions
    params: {}
- name: project
  endpoint:
    path: /projects
    method: GET
    data_selector: projects
    params: {}
- name: batch
  endpoint:
    path: /batches
    method: GET
    data_selector: batches
    params: {}
- name: send_to_annotate_params
  endpoint:
    params:
      source_project_id: project.uid
      exclude_data_rows_in_project: false
      override_existing_annotations_rule: ConflictResolutionStrategy.OverrideWithPredictions
      batch_priority: 5
- name: project
  endpoint:
    path: /projects
    method: GET
    data_selector: projects
    params: {}
- name: batch
  endpoint:
    path: /batches
    method: GET
    data_selector: batches
    params: {}
- name: export_task
  endpoint:
    params:
      attachments: true
      metadata_fields: true
      data_row_details: true
      project_details: true
      label_details: true
      performance_details: true
      interpolated_frames: true
      filters:
        last_activity_at:
        - '2000-01-01 00:00:00'
        - '2050-01-01 00:00:00'
        label_created_at:
        - '2000-01-01 00:00:00'
        - '2050-01-01 00:00:00'
        workflow_status: InReview
        batch_ids:
        - batch_id_1
        - batch_id_2
        data_row_ids:
        - data_row_id_1
        - data_row_id_2
        global_keys:
        - global_key_1
        - global_key_2
- name: project
  endpoint:
    path: /projects
    method: GET
    data_selector: projects
    params: {}
- name: batch
  endpoint:
    path: /batches
    method: GET
    data_selector: batches
    params: {}
- name: data_rows
  endpoint:
    path: /data-rows
    method: POST
    data_selector: data
    params: {}
- name: export_task
  endpoint:
    params:
      filters:
        last_activity_at:
        - '2000-01-01 00:00:00'
        - '2050-01-01 00:00:00'
        label_created_at:
        - '2000-01-01 00:00:00'
        - '2050-01-01 00:00:00'
        workflow_status: InReview
        batch_ids:
        - batch_id_1
        - batch_id_2
        data_row_ids:
        - data_row_id_1
        - data_row_id_2
        global_keys:
        - global_key_1
        - global_key_2
- name: model_training
  endpoint:
    path: /model-training
    method: POST
    data_selector: results
- name: send_to_annotate_params
  endpoint:
    params:
      source_project_id: project.uid
      exclude_data_rows_in_project: false
      override_existing_annotations_rule: ConflictResolutionStrategy.OverrideWithPredictions
      batch_priority: 5
- name: project
  endpoint:
    path: /projects
    method: POST
    data_selector: projects
    params: {}
- name: batch
  endpoint:
    path: /batches
    method: POST
    data_selector: batches
    params: {}
- name: project
  endpoint:
    path: /projects
    method: GET
    data_selector: projects
- name: batch
  endpoint:
    path: /batches
    method: GET
    data_selector: batches
- name: project
  endpoint:
    path: /projects
    method: POST
    data_selector: projects
    params: {}
- name: batch
  endpoint:
    path: /batches
    method: POST
    data_selector: batches
    params: {}
- name: export_issues
  endpoint:
    path: /export/issues
    method: GET
    data_selector: issues
- name: export_tasks
  endpoint:
    path: /export/tasks
    method: POST
    data_selector: tasks
- name: project
  endpoint:
    path: /api/projects
    method: POST
    data_selector: projects
- name: project
  endpoint:
    path: /projects
    method: POST
    data_selector: project
    params: {}
- name: batch
  endpoint:
    path: /batches
    method: POST
    data_selector: batch
    params: {}
- name: project
  endpoint:
    path: /projects
    method: GET
    data_selector: projects
    params: {}
- name: batch
  endpoint:
    path: /batches
    method: GET
    data_selector: batches
    params: {}
- name: project
  endpoint:
    path: /projects
    method: GET
    data_selector: projects
- name: batch
  endpoint:
    path: /batches
    method: GET
    data_selector: batches
- name: project
  endpoint:
    path: /projects
    method: GET
    data_selector: projects
    params: {}
- name: batch
  endpoint:
    path: /batches
    method: GET
    data_selector: batches
    params: {}
- name: export_issues
  endpoint:
    path: /export/issues
    method: GET
    data_selector: issues
- name: project
  endpoint:
    path: /projects
    method: GET
    data_selector: projects
- name: project
  endpoint:
    path: /projects
    method: GET
    data_selector: projects
- name: batch
  endpoint:
    path: /batches
    method: GET
    data_selector: batches
- name: send_to_annotate_params
  endpoint:
    params:
      source_project_id: project.uid
      exclude_data_rows_in_project: false
      override_existing_annotations_rule: ConflictResolutionStrategy.OverrideWithPredictions
      batch_priority: 5
- name: project
  endpoint:
    path: /projects
    method: GET
    data_selector: projects
- name: batch
  endpoint:
    path: /batches
    method: GET
    data_selector: batches
- name: data_row
  endpoint:
    path: /data-rows
    method: GET
    data_selector: data_rows
- name: send_to_annotate_params
  endpoint:
    params:
      source_project_id: project.uid
      exclude_data_rows_in_project: false
      override_existing_annotations_rule: ConflictResolutionStrategy.OverrideWithPredictions
      batch_priority: 5
- name: project
  endpoint:
    path: /projects
    method: POST
    data_selector: project
    params: {}
- name: batch
  endpoint:
    path: /batches
    method: POST
    data_selector: batch
    params: {}
- name: project
  endpoint:
    path: /projects
    method: GET
    data_selector: projects
- name: export_issues
  endpoint:
    path: /export/issues
    method: GET
    data_selector: issues
    params: {}
- name: project
  endpoint:
    path: /projects
    method: GET
    data_selector: projects
    params: {}
- name: export_task
  endpoint:
    path: /export_task
    method: POST
    data_selector: output
    params:
      attachments: true
      metadata_fields: true
      data_row_details: true
      project_details: true
      label_details: true
      performance_details: true
      interpolated_frames: true
      last_activity_at:
      - '2000-01-01 00:00:00'
      - '2050-01-01 00:00:00'
      label_created_at:
      - '2000-01-01 00:00:00'
      - '2050-01-01 00:00:00'
      workflow_status: InReview
      batch_ids:
      - batch_id_1
      - batch_id_2
      data_row_ids:
      - data_row_id_1
      - data_row_id_2
      global_keys:
      - global_key_1
      - global_key_2
- name: send_to_annotate
  endpoint:
    path: /send_to_annotate_from_catalog
    method: POST
- name: project
  endpoint:
    path: /projects
    method: POST
    data_selector: project
    params: {}
- name: batch
  endpoint:
    path: /batches
    method: POST
    data_selector: batch
    params: {}
- name: project
  endpoint:
    path: /projects
    method: GET
- name: export_task
  endpoint:
    params:
      filters:
        last_activity_at:
        - '2000-01-01 00:00:00'
        - '2050-01-01 00:00:00'
        label_created_at:
        - '2000-01-01 00:00:00'
        - '2050-01-01 00:00:00'
        workflow_status: InReview
        batch_ids:
        - batch_id_1
        - batch_id_2
        data_row_ids:
        - data_row_id_1
        - data_row_id_2
        global_keys:
        - global_key_1
        - global_key_2
- name: send_to_annotate_params
  endpoint:
    params:
      source_project_id: project.uid
      exclude_data_rows_in_project: false
      override_existing_annotations_rule: ConflictResolutionStrategy.OverrideWithPredictions
      batch_priority: 5
- name: ontology
  endpoint:
    path: /create_ontology
    method: POST
    data_selector: ontology
    params: {}
- name: project
  endpoint:
    path: /create_project
    method: POST
    data_selector: project
    params: {}
- name: project
  endpoint:
    path: /projects
    method: GET
    data_selector: projects
- name: batch
  endpoint:
    path: /batches
    method: GET
    data_selector: batches
- name: prompt_response_project
  endpoint:
    path: /projects
    method: POST
    data_selector: project
    params: {}
- name: response_creation_project
  endpoint:
    path: /projects
    method: POST
    data_selector: project
    params: {}
- name: project
  endpoint:
    path: /projects
    method: GET
    data_selector: projects
- name: batch
  endpoint:
    path: /batches
    method: GET
    data_selector: batches
- name: export_issues
  endpoint:
    path: /export/issues
    method: GET
    data_selector: issues
- name: export_task
  endpoint:
    path: /export/task
    method: POST
    data_selector: exported_data
- name: prompt_response_annotations
  endpoint:
    path: /annotations
    method: POST
    data_selector: data
- name: label_import
  endpoint:
    path: /import
    method: POST
    data_selector: data
- name: project
  endpoint:
    path: /projects
    method: POST
    data_selector: project
    params: {}
- name: batch
  endpoint:
    path: /batches
    method: POST
    data_selector: batch
    params: {}
- name: annotations
  endpoint:
    path: /annotations/import
    method: POST
    data_selector: annotations
- name: projects
  endpoint:
    path: /projects
    method: GET
    data_selector: projects
- name: project
  endpoint:
    path: /projects
    method: POST
    data_selector: projects
- name: llm_human_preference
  endpoint:
    path: /api/llm/human_preference
    method: POST
    data_selector: modelOutputs
- name: send_to_annotate_params
  endpoint:
    params:
      source_project_id: project.uid
      exclude_data_rows_in_project: false
      override_existing_annotations_rule: ConflictResolutionStrategy.OverrideWithPredictions
      batch_priority: 5
- name: text_data
  endpoint:
    path: /api/text-data
    method: POST
    data_selector: data
    params: {}
- name: project
  endpoint:
    path: /projects
    method: POST
    data_selector: project
    params: {}
- name: batch
  endpoint:
    path: /batches
    method: POST
    data_selector: batch
    params: {}
- name: send_to_annotate
  endpoint:
    path: /send_to_annotate_from_catalog
    method: POST
    data_selector: task
    params:
      source_project_id: project.uid
      exclude_data_rows_in_project: false
      override_existing_annotations_rule: ConflictResolutionStrategy.OverrideWithPredictions
      batch_priority: 5
- name: documents
  endpoint:
    path: /documents
    method: GET
    data_selector: records
    params: {}
- name: project
  endpoint:
    path: /projects
    method: GET
    data_selector: projects
    params: {}
- name: ontology
  endpoint:
    path: /create_ontology
    method: POST
- name: response_creation_project
  endpoint:
    path: /create_response_creation_project
    method: POST
- name: prompt_response_generation_project
  endpoint:
    path: /create_prompt_response_generation_project
    method: POST
- name: conversational_text
  endpoint:
    path: /api/conversations
    method: GET
    data_selector: data
    params: {}
- name: prompt_response_project
  endpoint:
    path: /api/v1/prompt-response-projects
    method: POST
    data_selector: data
    params: {}
- name: response_creation_project
  endpoint:
    path: /api/v1/response-creation-projects
    method: POST
    data_selector: data
    params: {}
- name: import_text_data
  endpoint:
    path: /reference/import-text-data
    method: POST
    data_selector: data
    params:
      row_data: required
      global_key: optional
      media_type: optional
      metadata_fields: optional
      attachments: optional
- name: import_prompt_response_annotations
  endpoint:
    path: /import/prompt-response
    method: POST
    data_selector: data
    params: {}
- name: multimodal_chat_evaluation
  endpoint:
    path: /projects
    method: POST
- name: offline_multimodal_chat_evaluation
  endpoint:
    path: /projects
    method: POST
    data_selector: project
    params: {}
- name: prompt_response_annotations
  endpoint:
    path: /annotations
    method: POST
    data_selector: annotations
- name: label_import
  endpoint:
    path: /labels
    method: POST
    data_selector: labels
- name: multimodal_chat_data
  endpoint:
    path: /reference/import-multimodal-chat-data
    method: POST
    data_selector: data
    params: {}
- name: conversation_data
  endpoint:
    path: /api/conversations
    method: POST
    data_selector: data
    params: {}
- name: model_outputs
  endpoint:
    path: /api/model-outputs
    method: GET
    data_selector: outputs
    params: {}
- name: annotations
  endpoint:
    path: /api/annotations
    method: POST
    data_selector: data
    params: {}
- name: data_row
  endpoint:
    path: /api/data-rows/import
    method: POST
    data_selector: data
    params: {}
- name: model_assisted_labeling
  endpoint:
    path: /api/mal-predictions/import
    method: POST
    data_selector: data
    params: {}
- name: text_data
  endpoint:
    path: /import-text-data
    method: POST
    data_selector: records
- name: geospatial_data
  endpoint:
    path: /reference/import-geospatial-data
    method: GET
    data_selector: records
    params: {}
- name: multimodal_chat_annotations
  endpoint:
    path: /import/multimodal_chat_annotations
    method: POST
    data_selector: annotations
    params: {}
- name: documents
  endpoint:
    path: /api/documents
    method: GET
    data_selector: documents
- name: annotations
  endpoint:
    path: /annotations
    method: POST
    data_selector: data
    params: {}
- name: datasets
  endpoint:
    path: /datasets
    method: POST
    data_selector: data
    params: {}
- name: audio
  endpoint:
    path: /audio
    method: GET
    data_selector: records
- name: annotations
  endpoint:
    path: /api/annotations
    method: POST
    data_selector: data
    params: {}
- name: datasets
  endpoint:
    path: /api/datasets
    method: GET
    data_selector: data
    params: {}
- name: export_multimodal_chat_annotations
  endpoint:
    path: /export/multimodal_chat_annotations
    method: POST
    data_selector: export_json
    params: {}
- name: conversational_text
  endpoint:
    path: /api/conversational_text
    method: POST
    data_selector: data
    params: {}
- name: data_row
  endpoint:
    path: /data_row
    method: GET
    data_selector: data_row
    params: {}
- name: media_attributes
  endpoint:
    path: /media_attributes
    method: GET
    data_selector: media_attributes
    params: {}
- name: projects
  endpoint:
    path: /projects
    method: GET
    data_selector: projects
    params: {}
- name: upload_llm_response_evaluation
  endpoint:
    path: /upload-llm-response-evaluation
    method: POST
    data_selector: predictions
- name: import_text_data
  endpoint:
    path: /reference/import-text-data
    method: POST
    data_selector: assets
    params:
      row_data: https://lb-test-data.s3.us-west-1.amazonaws.com/text-samples/sample-text-1.txt
      global_key: https://lb-test-data.s3.us-west-1.amazonaws.com/text-samples/sample-text-1.txt
      media_type: TEXT
- name: batch
  endpoint:
    path: /project.create_batch
    method: POST
    data_selector: batch_convo_prediction_demo
    params:
      global_keys: '[global_key]'
      priority: 5
- name: model_run
  endpoint:
    path: /model.create_model_run
    method: POST
    data_selector: Comparison_model_run_
    params: {}
- name: prediction_upload
  endpoint:
    path: /model_run.add_predictions
    method: POST
    data_selector: prediction_upload_job
    params: {}
- name: offline_multimodal_chat_evaluation
  endpoint:
    path: /projects
    method: POST
    data_selector: projects
    params: {}
- name: LLM Response Evaluation
  endpoint:
    path: /upload-llm-response-evaluation
    method: POST
    data_selector: predictions
    params: {}
- name: model_evaluation_project
  endpoint:
    path: /create_model_evaluation_project
    method: POST
    data_selector: project
    params: {}
- name: dataset
  endpoint:
    path: /create_dataset
    method: POST
    data_selector: dataset
    params: {}
- name: conversation_data
  endpoint:
    path: /import/conversation
    method: POST
    data_selector: data_rows
    params: {}
- name: conversation
  endpoint:
    path: /api/conversation/v2
    method: POST
    data_selector: row_data
    params: {}
- name: LLM Response Evaluation
  endpoint:
    path: /import/llm-response-evaluations
    method: POST
    data_selector: annotations
    params: {}
- name: annotations
  endpoint:
    path: /annotations
    method: POST
    data_selector: data
    params: {}
- name: datasets
  endpoint:
    path: /datasets
    method: GET
    data_selector: data
    params: {}
- name: annotations
  endpoint:
    path: /import/llm-response-evaluations-annotations
    method: POST
    data_selector: data
    params: {}
- name: import_llm_response_evaluations_annotations
  endpoint:
    path: /import/llm_response_evaluations
    method: POST
    data_selector: annotations
    params: {}
- name: annotations
  endpoint:
    path: /annotations
    method: POST
    data_selector: annotations
- name: data_rows
  endpoint:
    path: /data-rows
    method: POST
    data_selector: dataRows
- name: ontologies
  endpoint:
    path: /ontologies
    method: POST
    data_selector: ontologies
- name: export_llm_response_annotations
  endpoint:
    path: /export/llm_response_annotations
    method: POST
    data_selector: data_row.json
    params: {}
- name: annotations
  endpoint:
    path: /annotations/import
    method: POST
    data_selector: data
    params: {}
- name: multimodal_chat_annotations
  endpoint:
    path: /annotations/multimodal_chat
    method: POST
    data_selector: data
    params: {}
- name: export_multimodal_chat_annotations
  endpoint:
    path: /export/multimodal_chat_annotations
    method: POST
    data_selector: data_row.json
- name: data_row
  endpoint:
    path: /data_row
    method: GET
    data_selector: data_row
    params: {}
- name: media_attributes
  endpoint:
    path: /media_attributes
    method: GET
    data_selector: media_attributes
    params: {}
- name: attachments
  endpoint:
    path: /attachments
    method: GET
    data_selector: attachments
    params: {}
- name: projects
  endpoint:
    path: /projects
    method: GET
    data_selector: projects
    params: {}
- name: upload_llm_response_evaluation
  endpoint:
    path: /upload_llm_response_evaluation
    method: POST
    data_selector: predictions
- name: import_conversation_data
  endpoint:
    path: /import/conversation
    method: POST
    data_selector: data
    params: {}
- name: annotations
  endpoint:
    path: /annotations/import
    method: POST
    data_selector: data
    params: {}
- name: import_llm_response_evaluations
  endpoint:
    path: /import/llm-response-evaluations
    method: POST
    data_selector: data
- name: import_llm_response_annotations
  endpoint:
    path: /import/llm_response_annotations
    method: POST
    data_selector: data
    params: {}
- name: export_llm_response_evaluation_annotations
  endpoint:
    path: /export/llm-response-evaluation-annotations
    method: POST
    data_selector: data_row
    params: {}
notes:
- Provide a valid API key to authenticate the Labelbox client.
- Uses API key for authentication
- SDK versions earlier than 3.68 are no longer supported.
- Improved member and group management experience.
- Automatic transcription of audio and video in the Multi-modal chat editor.
- Uses OAuth2 with refresh token — requires setup of connected app in Labelbox
- Some API features may require additional permissions.
- Some endpoints may have rate limits
- Uses OAuth2 with refresh token — requires setup of connected app in api
- Some features may have limited availability based on user roles and permissions
- New fine-tuning capability (beta) to fine-tune a YoloV8 object detection model with
  custom features.
- This API requires OAuth2 for authentication.
- Labelbox supports multiple data modalities.
- Some objects may return nulls in deeply nested fields
- You need an API key to authenticate your client.
- API keys access to your Labelbox account and data. Treat API keys like passwords
  and other credentials.
- The value of an API key can only be retrieved once from the API key created prompt
  when the key is first created.
- The Labelbox SDK is primarily used to interact with Labelbox’s database.
- Requires a valid API key to connect to the Labelbox client
- Large results (over 150,000 data rows) can take up to 10 mins to process.
- Batches are chunked into groups of 100k data rows.
- The client obtains all field values for that object.
- Server-side updates made after the client-side fetch are not auto-propagated.
- You can only use either global_keys or data_rows in the batch creation method.
- Export tasks not supported
- All nodes must be connected for the workflow to be valid.
- Uses LabelingConfig and ReworkConfig for workflow initialization.
- Batches are chunked into groups of 100k data rows when creating multiple batches.
- Workflows are connected to the Project class and are generated automatically during
  project creation.
- No changes are pushed to the platform until you call update_config().
- Batches are limited to 1 million data rows and chunked into groups of 100k.
- This workflow supports the creation of various nodes like review, logic, and done.
- Filters can be applied to nodes to control their behavior.
- Foundry apps help automate data labeling and enrichment.
- You must have data rows in Catalog before you can run them through Foundry.
- Uses positional parameters
- Reset config to start a fresh workflow
- Workflows are composed of nodes and edges.
- Foundry apps can only be created using the app; you cannot use the SDK to create
  Foundry apps.
- The only required argument when creating a dataset is the name.
- 'Certain characters like #, <, > and | are not supported in URLs.'
- A Foundry app helps automate data labeling and enrichment.
- 'Certain characters like #, <, >, and | are not supported in URLs.'
- 'Certain characters like #, <, >, and | are not supported in URLs and should be
  avoided in your file names to prevent loading issues.'
- If iam_integration is not specified or set to None, it will use your default integration.
- 'Certain characters like #,<,>,| are not supported in URLs and should be avoided
  in file names.'
- Attachments can add supplementary content to any asset to help provide additional
  context for your labeling team.
- Multiple attachments can be linked to a singular data row.
- 'Certain characters like #, <, > and | are not supported in URLs and should be avoided
  in your file names.'
- Custom embeddings improve data exploration by improving similarity search.
- Labelbox automatically computes media attributes when you create new data rows in
  the platform.
- 'Special character handling: Certain characters like `#`,`<`, `>` and `|` are not
  supported in URLs.'
- Global keys are user-specified unique ID for your data rows that you can assign
  upon creation or afterward.
- Currently, we do not support creating slices through the SDK.
- Custom metadata field limits vary according to your subscription.
- Using IAM delegated access integrations is the recommended option for all cloud
  users.
- Starting from SDK version 3.69, custom embeddings are now supported.
- This can be any secret that matches your webhook config.
- Global keys are cleared after deleting data rows.
- Requires an API key for authentication.
- Requires Labelbox API Key for authentication
- You can create a v2 webhook through the Labelbox UI.
- Experimental feature requires enabling experimental features before use.
- Requires setup of connected app in Labelbox
- API key required for authentication.
- Replace the value of API_KEY with a valid API key to connect to the Labelbox client.
- OAuth2 with refresh token required for authentication.
- Ensure correct roles are assigned when inviting users.
- Recursive function is used to navigate through JSON structure for extracting annotations.
- Requires a valid API key for access.
- Experimental feature requires enabling experimental features.
- Uses API key for authentication.
- Creating a CVS file for your Labelbox data can be difficult, especially if you want
  to include information on the annotations associated with your label.
- Requires API key for authentication
- Data structure for CSV needs to be defined before export
- Labelbox supports multi-factor authentication (MFA) which adds an extra layer of
  security to prevent unauthorized access.
- Product limits broken down by subscription type.
- Exceeding these limits may cause performance issues.
- Create a valid API key to connect to the Labelbox client
- Support is available from 9:00 AM to 8:00 PM Eastern Time, Monday through Friday.
- This workflow applies only to workspaces with fully-managed labeling services enabled.
- Unused hours are non-refundable, so we encourage you to add enough data and set
  an appropriate team size to utilize the labeling time to the fullest extent.
- API key is required for authentication.
- Collaboratively annotate data with internal team or labeling service.
- Set batch size for batching data rows and annotation bulk import. 500-1000 is recommended
  size.
- Set max number of data rows to import. WikiNeural dataset has ~1.1M data rows
- Labelbox supports multi-factor authentication (MFA), which adds an extra layer of
  security to prevent unauthorized access.
- Optimize asset size to no larger than 4000x4000px for images and videos with frame
  rates no greater than 30fps.
- Use IAM delegated access to connect data to Labelbox for optimal security and performance.
- Setting up a CDN can speed up asset delivery for labelers in different locations.
- Conduct a trial run to identify and reduce latencies or issues before an ongoing
  labeling job.
- Support is available during business hours from 9:00 AM to 8:00 PM Eastern Time,
  Monday through Friday.
- The Model product is designed to help you achieve efficient collaboration with your
  team members.
- YOLOv8 for the model fine-tuning feature is currently disabled.
- You cannot use bulk classification with a consensus project.
- Benchmark data rows are excluded from bulk classification jobs.
- View the limits page to learn the custom embedding limits per workspace and the
  maximum dimensions allowed per custom embedding
- Labelbox provides expert labeling in over 30+ languages.
- A data row cannot be part of more than one batch in a project at a time.
- A batch cannot be shared between projects. However, you can create a new batch using
  the same data rows.
- Slices are dynamic, meaning any data uploaded to Labelbox will automatically populate
  in relevant slices.
- Ontologies can be reused across different projects.
- Quizzes help ensure that labelers fully understand your instructions before they
  begin labeling.
- 'Labelbox separates its annotations into two general categories: objects and classifications.'
- Code runner is a beta feature.
- Metadata is non-annotation information about an asset.
- The metadata schema lives at the organization level.
- Export labels requires at least one label in the Completed column.
- Optimize asset size. The most effective way to optimize editor performance is to
  limit asset size to the maximum resolution needed for accurate labeling and effective
  model training.
- Delegate access to your data storage. For optimal security and performance, use
  IAM delegated access to connect your data to Labelbox.
- Uses OAuth2 with refresh token — requires setup of connected app in labelbox
- IAM delegated access is required for cloud storage integrations.
- Fine-tuning improves performance with unusual data or requirements.
- CORS setup is required for accessing S3 bucket data.
- Labelbox uses the AWS role to generate temporary signed URLs every time it accesses
  data in the S3 bucket.
- Labelbox is currently not compatible with ADLS Gen2.
- RBAC changes can take up to 30 mins.
- Only one bucket is supported per integration.
- Spaces in filenames can be problematic.
- Webhook events are sent over HTTPS only.
- The Content-Type header from the Labelbox webhook events is always 'application/json'.
- A batch cannot be shared between projects.
- Only organizations on the enterprise plan can have multiple workspaces.
- Each organization can have one or multiple workspaces.
- Workspace-wide roles and project-based roles are mutually exclusive.
- Quizzes must be enabled for labelers to access the labeling interface.
- Requires setup of permissions for Tenant Admin and Admin roles.
- Only organizations on the enterprise plan can access the Monitor page.
- Notifications can be set for various task types including assignment, batch, and
  issue-related notifications.
- Labelbox adheres to strict security measures to ensure all of your data is encrypted
  at rest and in transit.
- Labelbox uses Auth0 for authentication.
- Single sign-on is an add-on available to Enterprise customers.
- If you use single sign on (SSO) to manage access to Labelbox and your SSO provider
  supports MFA, we strongly recommend using your provider’s MFA implementation.
- The Reporting page is being replaced by the new Monitor tab.
- Exporting from Catalog allows you to include the project and/or model run information.
- Excluding optional fields from your export will make the process faster and the
  export file smaller.
- You can export data from a model run via the UI.
- IAM delegated access allows you to use private cloud-hosted buckets with Labelbox,
  which helps to ensure that your assets are kept safe.
- Ensure that the project has the appropriate permissions set for accessing data rows.
- Uses IAM delegated access for S3 bucket data.
- Labelbox is currently not compatible with ADLS Gen2. To set up this integration,
  you must use Azure Blob Storage.
- Any role-based-access-control (RBAC) changes you make can take up to 30 mins to
  take into effect.
- For further security, we advise that your container be set to Private to make sure
  no unauthorized access is possible
- You can also, from the Storage account, restrict specific IP ranges to add a layer
  of control in your data access
- Consensus calculation can take up to five minutes
- Data row priority affects the position in the labeling queue
- Labelbox includes a signature in each webhook event it sends to your application
  endpoint.
- It is best to put data from a single domain or source into a single dataset.
- Experiments are designed to help you track and compare all of the iterations associated
  with your model development.
- Annotations imported as pre-labels help speed up human labeling.
- Make sure the annotations are in the proper format.
- Model runs must be connected to an experiment.
- The project is a container that houses all of your labeling operations for a specific
  set of data rows.
- Notifications page displays tasks performed in the last 30 days
- Labelbox uses Google Cloud for cloud storage, which means that your data will be
  encrypted on the server-side using GCP’s default encryption keys.
- Reservation system ensures no contention occurs and avoids duplicate labeling.
- Labelers may lose unsubmitted work if they exceed their data row reservation time
  out.
- To enable SSO, collect a few technical details including login URL, X.509 certificate,
  and email domains.
- Labelbox supports multi-factor authentication (MFA), also known as two factor authentication
  (2FA).
- Workflows are customizable and allow for multi-step review and rework pipelines.
- As of June 30, 2025, we no longer support the Census integration.
- In early September, we disabled Export v1 for all remaining customers. All users
  should use the export() method instead.
- Starting in April 2024, Export V1 will be deprecated.
- Export V2 offers more granular control over data exports.
- Use ClassificationAnnotation instead of VideoClassification for global annotations
- Flexible querying by combining any supported filters.
- Supports importing annotations in Python and JSON formats
- Global and frame-based classifications are supported on video assets
- 'Supports two formats for the annotations payload: Python annotation types and JSON.'
- Model-assisted labeling allows importing computer-generated predictions as pre-labels.
- Each batch in a project must have a unique name
- Consensus agreement scores are calculated in real-time for features and labels with
  multiple annotations by different labelers.
- Data rows must first be uploaded to Catalog to attach annotations
- You can now include other fields like attachments, media type and metadata in the
  data row creation step.
- 'When naming datasets, names can contain letters (upper and lowercase), numbers,
  spaces, and the following punctuation symbols: _-.,()/.'
- Queue mode will be deprecated once dataset mode is deprecated
- Annotations imported via MAL are pre-populated in the labeling editor
- Uses API Key for authentication.
- 'Supports two types of label imports: Model-assisted labeling and Ground truth.'
- Geospatial data annotations must be formatted correctly to be imported successfully.
- Labelbox reserves 5 data rows for each labeler, and these reservations expire after
  4 hours of idle time.
- Supports model-assisted labeling (MAL) for pre-labels.
- Ground truth annotations can be bulk imported.
- Workflows allow customization for data labeling and reviewing processes.
- Supports both Python and JSON formats for annotation payloads
- Allows bulk import of ground truth annotations
- Supports geospatial data types.
- Importing annotations as ground truth is a bulk operation meant for migrating to
  Labelbox.
- Confidence scores are not supported for frame specific bounding box annotations
  and VideoObjectAnnotation class
- Supports both Python annotation types and JSON format for annotations payload.
- 'Two types of label imports are supported: Model-assisted labeling and Ground truth.'
- 'Labelbox supports two formats for the annotations payload: Python annotation types
  and JSON.'
- Supports both Python and JSON formats for annotations payload.
- Labelbox supports both Python and JSON formats for annotations payload.
- Uses API key for authentication — ensure valid API key is provided
- Relationship annotations are not supported for ground truth import jobs.
- Supports Python annotation types and JSON format for annotations payload.
- Model-assisted labeling and ground truth imports are supported.
- Annotations are global and page based.
- Data rows must first be uploaded to Catalog to attach annotations.
- Uses API Key for authentication
- Model-assisted labeling allows you to import computer-generated predictions as pre-labels.
- The API key must be a valid key obtained from Labelbox.
- Requires valid API key to connect to the Labelbox client.
- Ensure that the name parameter in annotations matches the ontology.
- To import annotations in Labelbox, you need to create an annotations payload.
- 'Supports two formats for the annotations payload: Python and JSON.'
- Requires setup of connected app for API key.
- Supports both Python annotation types and JSON formats for annotations payload.
- 'Supports two formats for annotations payload: Python annotation types and JSON.'
- Ensure API_KEY is set to a valid API key to connect to the Labelbox client.
- Requires OAuth2 authentication.
- Ensure to manage project settings for data rows and ontology.
- Foundry is available to all subscription types except Educational.
- Free, Starter, and other self-service subscriptions need to enable Foundry as an
  add-on to their subscription.
- Annotations are global and page based
- This model integration flow doesn’t support tasks involving bounding box and mask
  annotations.
- Requires a valid API key for authentication.
- Use the Model gallery to select models hosted by Labelbox.
- Some models require ontologies while others provide advanced settings to refine
  results.
- You may only submit a model run if the settings are valid for the selected model,
  ontology, and underlying data types.
- Uses API key for authentication — requires valid API key to connect to Labelbox
  client.
- While the model run is in progress, you can use the menu to stop model runs.
- Uses API key for authentication — requires setup of API key in Labelbox
- Some models may return results that are not compatible with your project ontology.
- Requires setup of projects and ontology before importing annotations.
- Export panel lists available options that vary according to the context of the export
  requests.
- Uses API key for authentication — replace with valid API key.
- You can include confidence scores and custom metrics when uploading predictions.
- Ensure the name parameters match between annotations and ontology.
- Maximum data rows for Find similar in Catalog is 20.
- Automatic metrics are supported only for ontologies with fewer than 4,000 features.
- Automatic metrics may take a few minutes to calculate.
- Supports audio annotations.
- Requires API key for authentication.
- You will need a model with two or more model runs to use this feature.
- Deleting a project will also delete all the annotations that have been submitted
  for a project.
- Confidence scores are optional when uploading predictions.
- Uploading confidence scores is optional
- Foundry is available to all subscription types except Educational
- Free, Starter, and other self-service subscriptions need to enable Foundry as an
  add-on to their subscription
- Currently, this model integration flow doesn’t support tasks involving bounding
  box and mask annotations.
- Model run execution time depends on several factors, including the number of data
  rows processed.
- This step is optional.
- Each batch in a project must have a unique name.
- Priority is between 1(Highest) - 5(lowest).
- Predictions are stored as data row attributes.
- Some objects like VideoObjectAnnotation may not support confidence scores
- Use the Notifications Center to view prediction export progress.
- Some objects may not support confidence scores
- Free accounts have 500 free LBU credits each month.
- Uploading confidence scores is optional.
- Errors will appear for annotation uploads that failed.
- Confidence scores are optional in prediction payloads.
- Automatic metrics are computed for all data rows containing at least one prediction
  and at least one annotation.
- 'Labelbox supports two formats for the predictions payload: Python annotation types
  (recommended) and NDJSON.'
- Model runs can be compared visually and with metrics.
- Confidence scores are optional and default to 1 if not specified.
- You can include confidence scores and custom metrics when you upload your model
  predictions to a model run.
- Model run ontology should support all tools and classifications used in predictions
- Model errors can be analyzed using filters and metrics.
- Active learning is a practice where, given a trained model, you identify which data
  would be most useful to label next.
- Priority between 1(Highest) - 5(lowest).
- Tag the data rows that need re-labeling
- Model training integration is currently available for pro and enterprise customers.
- You need to establish model training settings before you can start with model training.
- Raster segmentation masks are not yet supported in the Model product.
- By default, confidence and IOU thresholds are set to 0.5
- Rasters segmentation masks are not yet supported in the Model product
- Requires setup of a Labelbox account and API key.
- 'When creating a project, specify a media_type using one of the following values:
  lb.MediaType.Audio, lb.MediaType.Conversational, lb.MediaType.Document, lb.MediaType.Geospatial_Tile,
  lb.MediaType.Html, lb.MediaType.Image, lb.MediaType.Simple_Tile, lb.MediaType.Text,
  lb.MediaType.Video.'
- Confidence scores are optional. If you do not include confidence scores in your
  prediction payloads, the prediction is treated as if it had a confidence value of
  one.
- API key must be provided to connect to the Labelbox client.
- Requires setup of API key.
- The payload for predictions can be in Python annotation types or NDJSON format.
- If the project uses consensus, you can optionally supply a dictionary with consensus
  settings.
- All predictions must be formatted as either Python annotation types or NDJSON
- API key is required to access the Labelbox API.
- Ensure to replace API_KEY with a valid API key to connect to the Labelbox client.
- Batch creation requires either global keys or data rows
- Add metadata to identify data rows that need re-labeling using a tag.
- Model training is currently available for pro and enterprise customers.
- You need to connect your training cloud account to your Labelbox organization once.
- Filters follow AND logic, so typically using one filter is sufficient.
- Deleting a project cannot be undone
- Requires an API key to access the API.
- Deleting a project cannot be undone. This method deletes the project along with
  all labels made in the project. This action cannot be reverted.
- Some projects may have specific media types that need to be specified when creating
  a project.
- Deleting a project cannot be undone and will remove all labels.
- Requires setup of API key for access
- Batches are chunked into groups of 100k data rows if necessary.
- Ensure the API key has the necessary permissions
- Requires API Key for authentication.
- Deleting a project cannot be undone.
- Send to Annotate does not currently support consensus projects.
- AI critic using the SDK is a private preview feature.
- API key is required to connect to the Labelbox client.
- Only one prompt annotation is allowed per label.
- Uses API key authentication — requires setup of API key in Labelbox
- Supports Python annotation types and NDJSON format for annotations.
- Requires setup of API key for authentication
- Use API key for authentication when creating projects.
- API key must be specified in the client.
- Deleting a project cannot be undone. This method deletes the project along with
  all labels made in the project.
- The multimodal chat evaluation editor allows evaluation of generative model responses
  across multiple data types.
- Batches are chunked into groups of 100k data rows if necessary
- Supports automatic optical character recognition (OCR) with bounding boxes for text
  extraction.
- The audio editor supports automatic speech-to-text recognition with the Whisper
  model.
- You must provide a valid API key to connect to the Labelbox client.
- Limit the character count to fewer than 6,000 characters when using the Markdown
  editor to specify a prompt or response.
- 'Labelbox supports two types of label imports: Model-assisted labeling and Ground
  truth.'
- Supports various data types, including text, images, videos, audio, and PDFs.
- Ensure API_KEY is set before making requests.
- Requires setup of multimodal chat evaluation project before importing data.
- Must create data rows and send them to projects.
- Uses application/vnd.labelbox.conversational.model-chat-evaluation as type for conversation
  data.
- Version number must be set to 2.
- Requires setup of IAM delegated access for secured URLs.
- Supports Python and JSON formats for annotations payload.
- Supports both Python and JSON formats for annotations
- Data row size limit may apply.
- Tiled imagery uses a slippy map tool for labeling map tiles of the earth at various
  zoom levels.
- Map tiles are structured like a pyramid of zoom levels.
- Labelbox supports Python and JSON formats for annotations payload.
- Supports automatic optical character recognition (OCR) with the ChatGPT o1 model.
- Supports automatic speech-to-text recognition with the Whisper model.
- 'Two formats for annotations payload: Python annotation types and JSON.'
- Supports model-assisted labeling and ground truth imports.
- Conversational UI is used for annotating text in the context of a conversation.
- Thread-based UI is used for annotating text in the context of a multi-user thread.
- Markdown editor character count limit is fewer than 6,000 characters.
- Direct upload currently does not support adding additional metadata and attachments.
- 'Markdown editor size limit: limit the character count to fewer than 6,000 characters.'
- 'LaTeX support: To add LaTeX formatting, wrap your math expressions using backticks
  and dollar signs.'
- Use client.create_model_evaluation_project to create a live multimodal chat evaluation
  project.
- Use IAM Delegated Access or Signed URLs for importing conversation data
- Ensure URLs are in virtual-hosted-style format for S3
- Requires the use of a JSON structure as defined in the documentation.
- Supports JSON format for annotations payload.
- Allows importing ground truth annotations from external systems.
- Supports uploading annotations as pre-labels or ground truth.
- Requires setup of Labelbox API Key for authentication
- Labelbox supports importing multimodal chat annotations.
- Ensure correct alignment of annotation names with ontology feature names.
- Labelbox supports both Python annotation types and JSON for importing annotations.
- Uses API Key for authentication — requires setup of API key in Labelbox
- Import methods include IAM Delegated Access and Signed URLs (https URLs only).
- Ensure URLs are in virtual-hosted-style format for IAM Delegated Access.
- Supports both Python and JSON formats for annotation payloads.
- Annotations can be either message or global based.
errors:
- '401 Unauthorized: Recheck OAuth scopes or token expiration'
- 'REQUEST_LIMIT_EXCEEDED: Throttle API calls or reduce frequency'
- '401 Unauthorized: Check your access token.'
- '404 Not Found: Verify the endpoint and resource ID.'
- 'QUERY_TIMEOUT: Break down filters or add selectivity'
- 'Unauthorized: API key is invalid or missing'
- '401 Unauthorized: Recheck API key validity'
- 'API keys of disabled accounts: If a user account is disabled, all API keys associated
  with that account are also disabled.'
- '400 Bad Request: Check the request parameters and payload.'
- '404 Not Found: Verify the resource ID.'
- '401 Unauthorized: Ensure the API key is valid.'
- 'ValueError: Validation issue during workflow update.'
- 'Validation failed: Check node types and configurations.'
- 'Validation failed: Changes must be committed using update_config()'
- '401 Unauthorized: Recheck API key or token expiration'
- '401 Unauthorized: Check API Key or permissions'
- '401 Unauthorized: Check API key or permissions.'
- '429 Too Many Requests: Rate limit exceeded.'
- 'REQUEST_LIMIT_EXCEEDED: Throttle API calls or reduce frequency.'
- 'QUERY_TIMEOUT: Break down filters or add selectivity.'
- '404 Not Found: Check the endpoint and resource being accessed.'
- '404 Not Found: Verify the resource exists.'
- '401 Unauthorized: Check API key validity.'
- 'ValueError: Job failed. Errors : Duplicate global keys found: example_global_key'
- Data Row deleted
- 'Duplicate global keys found: example_global_key'
- '401 Unauthorized: Check API key and permissions'
- '401 Unauthorized: Recheck API key.'
- '401 Unauthorized: Check if the API key is valid'
- 'Error: computed_signature does not match signature provided in the headers'
- '400 Bad Request: Check request format or parameters.'
- '401 Unauthorized: Verify access token validity.'
- '403 Forbidden: Ensure sufficient permissions.'
- '400 Bad Request: Check request parameters and data format'
- '401 Unauthorized: Recheck API key or permissions'
- '400 Bad Request: Check request parameters.'
- '403 Forbidden: Validate API key permissions.'
- Errors during dataset creation may occur.
- '401 Unauthorized: Check API key'
- '404 Not Found: Verify project ID'
- '401 Unauthorized: Check the API key provided'
- '400 Bad Request: Check the request parameters.'
- '401 Unauthorized: Verify the API key or OAuth token.'
- '404 Not Found: Ensure the endpoint exists.'
- '401 Unauthorized: Check your OAuth token and permissions.'
- '400 Bad Request: Check your input data and parameters.'
- '401 Unauthorized: Recheck OAuth scopes or token expiration.'
- 'Role cannot be assumed: Ensure that the integration’s role ARN is correct and that
  the Labelbox External ID is properly configured in your AWS account.'
- 'External ID configured insecurely: Ensure that the Labelbox External ID is properly
  configured in your AWS account.'
- Any role-based-access-control (RBAC) changes you make can take up to 30 mins to
  take into effect.
- '400 Bad Request: Check your request parameters.'
- '401 Unauthorized: Verify OAuth token and permissions.'
- '404 Not Found: Check the endpoint URL.'
- '403 Forbidden: Ensure proper permissions are set.'
- 'REQUEST_FAILED: Check the request parameters or the API status.'
- 'INVALID_TOKEN: Ensure the token is valid and not expired.'
- '401 Unauthorized: Check your API key or token.'
- '404 Not Found: Verify the endpoint and parameters.'
- If you are running into any issues, such as the dataset not loading in Labelbox,
  it is likely that the permissions are not applied correctly.
- '400 Bad Request: Check your request parameters'
- '401 Unauthorized: Verify token authenticity and scopes.'
- '404 Not Found: Ensure the endpoint and resource exist.'
- '400 Bad Request: Check the request payload for errors'
- '401 Unauthorized: API key is missing or invalid'
- '429 Too Many Requests: Rate limit exceeded'
- 'Invalid API Key: Ensure the API key is valid.'
- 'Unauthorized: Check permission settings for the API key.'
- '401 Unauthorized: Recheck API key'
- 'Errors: task.errors'
- 'Failed data rows: task.failed_data_rows'
- Delete datasets with care, this is a permanent action that cannot be undone.
- Make sure the annotations are in the proper format
- '400 BAD REQUEST: Check the request format and parameters.'
- '401 UNAUTHORIZED: Verify API key and permissions.'
- '403 Forbidden: Check permissions for the user.'
- '404 Not Found: Resource requested does not exist.'
- '500 Internal Server Error: Try again later.'
- '400 Bad Request: Check the format of your request.'
- '401 Unauthorized: Ensure your API key is valid.'
- '404 Not Found: Verify the endpoint or resource exists.'
- 'Invalid API Key: Ensure the API key is valid and has sufficient permissions.'
- 'Unsupported media type: Verify the media type specified in the request.'
- '400 Bad Request: Check the annotation payload format and data structure.'
- '401 Unauthorized: Recheck API key or authentication method.'
- '400 Bad Request: Check the annotation format and payload structure.'
- '404 Not Found: Verify the endpoint path.'
- '401 Unauthorized: Invalid API key'
- '400 Bad Request: Check the payload format and required fields'
- '401 Unauthorized: Replace API_KEY with a valid key to connect.'
- '400 Bad Request: Check the payload format and required fields.'
- '401 Unauthorized: Verify API key and permissions.'
- '401 Unauthorized: Check your API key.'
- '404 Not Found: Ensure the endpoint is correct.'
- '400 Bad Request: Validate request payload format'
- 'INVALID_API_KEY: Check if the API key is correct.'
- 'DATA_ROW_NOT_FOUND: Ensure the data row exists in the catalog.'
- 'RATE_LIMIT_EXCEEDED: Reduce the frequency of API calls.'
- '400 Bad Request: Check the format of your annotations payload.'
- '400 Bad Request: Check your request format and required fields.'
- '404 Not Found: Verify the endpoint URL.'
- '401 Unauthorized: Verify authentication credentials.'
- '404 Not Found: Endpoint does not exist.'
- '400 Bad Request: Check your request payload'
- '404 Not Found: Endpoint does not exist'
- '400 Bad Request: Check request format and required fields.'
- '401 Unauthorized: Ensure API key is valid and included in the header.'
- '404 Not Found: Verify endpoint and resource availability.'
- '401 Unauthorized: Check client credentials or token expiration.'
- '400 Bad Request: Check the format of the annotations payload.'
- '401 Unauthorized: Verify API key.'
- 'INVALID_MODEL_RUN_SETTINGS: Please check the model run parameters.'
- 'ONTOLGY_NOT_SELECTED: An ontology must be selected before submission.'
- '404 Not Found: Verify endpoint path'
- 'Incompatible feature: predictions do not correspond to features in the project
  ontology.'
- '400 Bad Request: Check the structure of the payload'
- '401 Unauthorized: Check API key validity'
- '400 Bad Request: Validate the format of the payload'
- 'Automatic metric generation fails: Notification banner appears, select Retry to
  try again.'
- '400 Bad Request: Check the structure of the request payload.'
- '404 Not Found: The specified resource was not found.'
- '400 Bad Request: Check the format of the prediction payload.'
- '401 Unauthorized: Verify your API key.'
- Model run errors may be found in the Notification Center.
- '400 Bad Request: Check the format of the predictions payload'
- '401 Unauthorized: Ensure the API Key is valid'
- 'Incompatible feature: Predictions do not correspond to features in the project
  ontology.'
- '400 Bad Request: Check the payload structure'
- '404 Not Found: Ensure the endpoint exists'
- '400 Bad Request: Check your payload format.'
- '401 Unauthorized: Recheck API key validity.'
- 'Upload failed: Check the labels and annotations format'
- Errors will appear for annotation uploads that failed.
- '400 Bad Request: Check the format of the predictions payload.'
- '401 Unauthorized: Ensure that the API key is correct.'
- '401 Unauthorized: Check your authorization token.'
- '404 Not Found: Ensure the model run exists.'
- '401 Unauthorized: Verify API key validity.'
- '400 Bad Request: Check your payload format'
- '401 Unauthorized: Invalid API Key'
- '400 Bad Request: Check the format of the uploaded data'
- '401 Unauthorized: Ensure the API key is valid'
- '403 Forbidden: Verify permissions for the requested operation'
- '401 Unauthorized: Recheck API key or its permissions'
- 'INVALID_API_KEY: Check if the API key is correct'
- 'Error: A batch with the same name already exists.'
- 'Error: Exceeds maximum batch size of 100k data rows.'
- '404 Not Found: Verify the resource ID is correct'
- '400 Bad Request: Check request parameters'
- '400 Bad Request: Invalid parameters provided'
- '404 Not Found: The specified resource does not exist'
- '400 Bad Request: Check the data format and required fields.'
- '401 Unauthorized: Ensure proper authentication is provided.'
- '404 Not Found: Verify the endpoint URL and resource existence.'
- '400 Bad Request: Ensure all required fields are provided.'
- '401 Unauthorized: Verify API key is valid.'
- '401 Unauthorized: Check API Key validity.'
- '400 Bad Request: Check the request parameters for validity.'
- '403 Forbidden: Ensure your API key has the correct permissions.'
- '404 Not Found: Verify the endpoint and resource ID are correct.'
- '401 Unauthorized: Check API key or permissions'
- '404 Not Found: Ensure the endpoint is correct'
- Error while sending to annotate
- 'INVALID_API_KEY: Ensure your API key is valid.'
- '404 Not Found: Ensure the requested resource exists'
- '404 Not Found: Ensure the resource exists.'
- '401 Unauthorized: Check your API key and permissions'
- '401 Unauthorized: Check your API key'
- '400 Bad Request: Validate your request format'
- '404 Not Found: Resource does not exist'
- '401 Unauthorized: Recheck OAuth token.'
- '404 Not Found: Validate the endpoint and resource.'
- '400 Bad Request: Check the request format and required fields.'
- '401 Unauthorized: Ensure valid API key is used.'
- '404 Not Found: Verify the endpoint and resource existence.'
- '400 Bad Request: Check the payload structure.'
- '401 Unauthorized: Verify API_KEY is correct.'
- '400 Bad Request: Check the request parameters and body.'
- '401 Unauthorized: Ensure API key is valid.'
- '404 Not Found: Verify the endpoint and resource.'
- '401 Unauthorized: Check your client_id and client_secret.'
- '401 Unauthorized: Check API key.'
- '400 Bad Request: Check input data format.'
- '400 Bad Request: Check the format of the JSON file'
- '401 Unauthorized: Verify API key and permissions'
- '401 Unauthorized: Verify the API key and permissions.'
- '401 Unauthorized: Check API key and permissions.'
- '400 Bad Request: Validate request payload structure.'
- '400 Bad Request: Check your payload for errors.'
- '400 Bad Request: Check the request payload for required fields.'
- '404 Not Found: Verify the endpoint and resource identifiers.'
- '401 Unauthorized: Ensure the API key is valid and included.'
- '400 Bad Request: Check the format of your annotation payload.'
- 'Invalid URL: Ensure the URL is properly formatted.'
- 'Duplicate global key: Ensure the global key is unique.'
- '404 Not Found: Verify the endpoint exists.'
- '400 Bad Request: Check the request payload format.'
- '400 Bad Request: Invalid payload format'
- '401 Unauthorized: Check API Key validity'
- 'INVALID_PARAMETER: Check your parameters'
- 'AUTHORIZATION_FAILED: Verify API key'
auth_info:
  mentioned_objects:
  - OauthToken
  - AuthProvider
  - OAuthToken
  - NamedCredential
  - Client
  - Tenant Admin
  - Admin
  - API_KEY
  - ApiKey
client:
  base_url: https://api.labelbox.com
  auth:
    type: apikey
    location: header
    header_name: Authorization
source_metadata: null
