resources:
- name: clone
  endpoint:
    path: /clone
    method: POST
    data_selector: clone
    params: {}
- name: snapshot
  endpoint:
    path: /snapshot
    method: POST
    data_selector: snapshot
    params: {}
- name: DBLab Engine
  endpoint:
    path: /docs/database-lab
    method: GET
- name: PostgresAI Assistant
  endpoint:
    path: /docs/reference-guides/postgres-ai-bot-reference
    method: GET
- name: clone
  endpoint:
    path: /clone
    method: POST
    data_selector: data
    params: {}
- name: instance
  endpoint:
    path: /instance
    method: GET
    data_selector: data
    params: {}
- name: clone
  endpoint:
    path: /clone
    method: POST
- name: branch
  endpoint:
    path: /branch
    method: POST
- name: instance
  endpoint:
    path: /instance
    method: GET
- name: databaseContainer
  endpoint:
    path: /databaseContainer
    method: GET
    data_selector: configs
- name: databaseConfigs
  endpoint:
    path: /databaseConfigs
    method: GET
    data_selector: configs
- name: databaseContainer
  endpoint:
    path: /databaseContainer
    method: GET
- name: databaseConfigs
  endpoint:
    path: /databaseConfigs
    method: GET
- name: logicalDump
  endpoint:
    path: /jobs/logicalDump
    method: POST
    data_selector: result
    params: {}
- name: logicalRestore
  endpoint:
    path: /jobs/logicalRestore
    method: POST
    data_selector: result
    params: {}
- name: physicalRestore
  endpoint:
    path: /jobs/physicalRestore
    method: POST
    data_selector: result
    params: {}
- name: logicalDump
  endpoint:
    path: /logicalDump
    method: POST
    data_selector: result
    params: {}
- name: logicalRestore
  endpoint:
    path: /logicalRestore
    method: POST
    data_selector: result
    params: {}
- name: physicalRestore
  endpoint:
    path: /physicalRestore
    method: POST
    data_selector: result
    params: {}
- name: webhooks
  endpoint:
    path: /webhooks
    method: POST
    data_selector: hooks
    params: {}
- name: hooks
  endpoint:
    path: ''
    method: ''
    data_selector: ''
    params: {}
- name: bgwriter
  endpoint:
    path: /bgwriter
    method: GET
    data_selector: metrics
- name: db_stats
  endpoint:
    path: /db_stats
    method: GET
    data_selector: metrics
- name: pg_stat_statements
  endpoint:
    path: /pg_stat_statements
    method: GET
    data_selector: metrics
- name: locks_mode
  endpoint:
    path: /locks_mode
    method: GET
    data_selector: metrics
- name: wait_events
  endpoint:
    path: /wait_events
    method: GET
    data_selector: metrics
- name: table_stats
  endpoint:
    path: /table_stats
    method: GET
    data_selector: metrics
- name: index_stats
  endpoint:
    path: /index_stats
    method: GET
    data_selector: metrics
- name: wal
  endpoint:
    path: /wal
    method: GET
    data_selector: metrics
- name: bloat_analysis
  endpoint:
    path: /bloat_analysis
    method: GET
    data_selector: metrics
- name: transaction_process
  endpoint:
    path: /transaction_process
    method: GET
    data_selector: metrics
- name: settings
  endpoint:
    path: /settings
    method: GET
    data_selector: settings
- name: bgwriter
  endpoint:
    path: /metrics/bgwriter
    method: GET
    data_selector: bgwriter_metrics
- name: db_stats
  endpoint:
    path: /metrics/db_stats
    method: GET
    data_selector: db_statistics
- name: pg_stat_statements
  endpoint:
    path: /metrics/pg_stat_statements
    method: GET
    data_selector: query_performance
- name: locks_mode
  endpoint:
    path: /metrics/locks_mode
    method: GET
    data_selector: lock_statistics
- name: wait_events
  endpoint:
    path: /metrics/wait_events
    method: GET
    data_selector: wait_statistics
- name: table_stats
  endpoint:
    path: /metrics/table_stats
    method: GET
    data_selector: table_statistics
- name: pg_stat_user_indexes
  endpoint:
    path: /metrics/pg_stat_user_indexes
    method: GET
    data_selector: index_statistics
- name: wal
  endpoint:
    path: /metrics/wal
    method: GET
    data_selector: wal_metrics
- name: pg_table_bloat
  endpoint:
    path: /metrics/pg_table_bloat
    method: GET
    data_selector: bloat_metrics
- name: pg_long_running_transactions
  endpoint:
    path: /metrics/pg_long_running_transactions
    method: GET
    data_selector: transaction_metrics
- name: settings
  endpoint:
    path: /settings
    method: GET
    data_selector: settings
- name: app
  endpoint:
    path: /app
    method: GET
- name: dle
  endpoint:
    path: /dle
    method: GET
- name: platform
  endpoint:
    path: /platform
    method: GET
- name: source
  endpoint:
    path: /source
    method: GET
- name: runner
  endpoint:
    path: /runner
    method: GET
- name: app
  endpoint:
    method: HTTP
    params:
      port: required
      verificationToken: required
- name: dle
  endpoint:
    method: HTTP
    params:
      url: required
      verificationToken: required
- name: platform
  endpoint:
    method: HTTP
    params:
      accessToken: required
- name: source
  endpoint:
    method: HTTP
    params:
      token: required
- name: runner
  endpoint:
    method: HTTP
    params:
      image: required
- name: joe_bot
  endpoint:
    path: /configs
    method: GET
    data_selector: configs
    params: {}
- name: help
  endpoint:
    path: /help
    method: GET
- name: explain
  endpoint:
    path: /explain
    method: GET
- name: plan
  endpoint:
    path: /plan
    method: GET
- name: exec
  endpoint:
    path: /exec
    method: POST
- name: activity
  endpoint:
    path: /activity
    method: GET
- name: terminate
  endpoint:
    path: /terminate
    method: POST
- name: reset
  endpoint:
    path: /reset
    method: POST
- name: hypo
  endpoint:
    path: /hypo
    method: POST
- name: help
  endpoint:
    path: /help
    method: GET
- name: explain
  endpoint:
    path: /explain
    method: GET
- name: plan
  endpoint:
    path: /plan
    method: GET
- name: exec
  endpoint:
    path: /exec
    method: POST
- name: activity
  endpoint:
    path: /activity
    method: GET
- name: terminate
  endpoint:
    path: /terminate
    method: POST
- name: reset
  endpoint:
    path: /reset
    method: POST
- name: hypo
  endpoint:
    path: /hypo
    method: POST
- name: DB migration tools
  endpoint:
    path: /docs/reference-guides/db-migration-checker-configuration-reference
    method: GET
    data_selector: tools
    params: {}
- name: DB Migration Tools
  endpoint:
    path: /migration-tools
    method: GET
    data_selector: tools
    params: {}
- name: engine_started
  endpoint:
    path: /engine/started
    method: POST
    data_selector: event_data
- name: engine_stopped
  endpoint:
    path: /engine/stopped
    method: POST
    data_selector: event_data
- name: snapshot_created
  endpoint:
    path: /snapshot/created
    method: POST
    data_selector: event_data
- name: clone_created
  endpoint:
    path: /clone/created
    method: POST
    data_selector: event_data
- name: clone_reset
  endpoint:
    path: /clone/reset
    method: POST
    data_selector: event_data
- name: clone_destroyed
  endpoint:
    path: /clone/destroyed
    method: POST
    data_selector: event_data
- name: alert
  endpoint:
    path: /alert
    method: POST
    data_selector: event_data
notes:
- 'DBLab API reference documentation is available at the following locations: DLE
  3.5.x API Reference, DBLab 4.0.x API Reference.'
- DBLab SE can be installed on any cloud or on-premises environment.
- DBLab SE billing is calculated on an hourly basis.
- You will not be billed for hours when your DBLab SE instance is off.
- Uses API key for authentication.
- Initial data provisioning takes time depending on the source database size.
- Database clones are instant and do not affect storage and instance bill.
- Currently, the AWS Marketplace version of DLE focuses on the 'logical' data provisioning
  mode (dump/restore).
- The use of DLE clones doesn't affect the bill anyhow – both 'compute' and 'storage'
  costs remain constant regardless of the number clones provisioned at any time.
- Uses OAuth2 with refresh token — requires setup of connected app in api
- Some objects may return nulls in deeply nested fields
- Public conversations are completely free.
- We love startups. And we're extremely passionate about Postgres, an awesome DBMS.
- Our engagement is typically structured for immediate impact and systematic analysis.
- Uses token-based authentication
- Insecure option available for self-signed certificates
- DBLab Engine supports YAML 1.2 including anchors, aliases, tags, map merging.
- Make sure that the file name is server.yml and its directory is mounted to /home/dblab/configs
  inside the DBLab Engine container.
- The recommended location of configuration files for DBLab Engine is `~/.dblab/engine/configs`.
- The recommended location of metadata files is `~/.dblab/engine/meta`.
- DBLab Engine requires a verification token for API access
- Ensure the DBLab Engine is running on the specified host and port
- Requires setup of connected app in API
- Webhooks provide a way to notify external systems about clone lifecycle events.
- PostgresAI may not be used to store, maintain, process or transmit protected health
  information (PHI).
- This Policy applies to our customers and users who have visited our website and
  inquired about or bought our services.
- This Policy was last updated on May 26, 2021.
- Environment variables have a higher priority.
- Configuration file must be named 'joe.yml' and directory should be writable.
- 'There are two ways to define Joe Bot options: configuration file and environment
  variables. Use both of them to get the best experience.'
- From version 3.0 onwards, DLE can be run with an empty verification token, although
  this is not recommended. In such cases, the UI application will not require any
  credentials.
- 'Very secure: PII is stored only on production and does not reach the DBLab Engine'
- Data structure is not identical to production, making SQL troubleshooting and optimization
  less reliable
- From version 3.0 onwards, DLE can be run with an empty verification token, although
  this is not recommended.
- 'DB Migration Checker runs all tests in a secure environment: data cannot be copied
  outside the secure container.'
- Automated DB migration testing in CI/CD pipelines.
- Telemetry is optional for DLE Community Edition and cannot be disabled for DLE Standard
  and Enterprise Editions.
- Uses Docker to run the DB Migration Checker
- DB Migration Checker runs all tests in a secure environment
errors:
- 'REQUEST_LIMIT_EXCEEDED: Throttle API calls or reduce frequency'
- 'Connection failed: Check your database credentials or network settings.'
- 'Provisioning timeout: Ensure the source database is accessible.'
- If data provisioning fails, check out the 'Logs' tab to see what's wrong.
- Use SSH to connect to the EC2 instance.
- 'QUERY_TIMEOUT: Break down filters or add selectivity'
- '401 Unauthorized: Recheck OAuth scopes or token expiration'
- The data refresh/snapshot is currently in progress. Skip a new data refresh iteration
- Data retrieving suspended because Retrieval state is pending
- Pool to perform full refresh not found. Skip refreshing
- '401 Unauthorized: Recheck verification token'
- '403 Forbidden: Check user permissions'
- '404 Not Found: Verify resource existence'
- '400 Bad Request: Check the request payload for required fields'
- '401 Unauthorized: Ensure the verification token is valid'
- '404 Not Found: Verify the endpoint path is correct'
- '401 Unauthorized: Check platform token.'
- Limit request rates. Works in pair with 'interval' value.
- Enable command logging.
auth_info:
  mentioned_objects:
  - verificationToken
  - host
  - port
  - Postgres.ai Platform
client:
  base_url: https://console.postgres.ai
  auth:
    type: apikey
    location: header
    header_name: Authorization
source_metadata: null
