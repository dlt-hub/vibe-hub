resources:
- name: warehouses
  endpoint:
    path: /api/warehouses
    method: GET
    data_selector: warehouses
- name: account
  endpoint:
    path: /api/account
    method: GET
    data_selector: account
- name: 無料トライアルのタイムライン
  endpoint:
    path: /BYOC/ja/docs/get_started/free_trial/
    method: GET
    data_selector: timeline
    params: {}
- name: 無料トライアル前
  endpoint:
    path: /BYOC/ja/docs/get_started/free_trial/#無料トライアル前
    method: GET
    data_selector: before_trial
    params: {}
- name: 無料トライアル中
  endpoint:
    path: /BYOC/ja/docs/get_started/free_trial/#無料トライアル中
    method: GET
    data_selector: during_trial
    params: {}
- name: 無料トライアルの終了
  endpoint:
    path: /BYOC/ja/docs/get_started/free_trial/#無料トライアルの終了
    method: GET
    data_selector: end_of_trial
    params: {}
- name: 無料トライアル終了後
  endpoint:
    path: /BYOC/ja/docs/get_started/free_trial/#無料トライアル終了後
    method: GET
    data_selector: after_trial
    params: {}
- name: 無料トライアル延長の申請
  endpoint:
    path: /BYOC/ja/docs/get_started/free_trial/#無料トライアル延長の申請
    method: GET
    data_selector: extend_trial
    params: {}
- name: example
  endpoint:
    path: /
    method: CREATE
    data_selector: records
    params: {}
- name: AWS_regions
  endpoint:
    path: /supported/aws/regions
    method: GET
- name: Azure_regions
  endpoint:
    path: /supported/azure/regions
    method: GET
- name: GCP_regions
  endpoint:
    path: /supported/gcp/regions
    method: GET
- name: scripts
  endpoint:
    params:
      cluster_id: STRING
      run_scripts_parallel: BOOLEAN
      scripts: ARRAY
- name: security_group_creation
  endpoint:
    path: /BYOC/ja/docs/sql-reference/aws/create_security_group_for_nlb/
    method: GET
    data_selector: instructions
- name: Private Preview
  endpoint:
    path: /api/private_preview
    method: GET
    data_selector: features
    params: {}
- name: Public Preview
  endpoint:
    path: /api/public_preview
    method: GET
    data_selector: features
    params: {}
- name: GA
  endpoint:
    path: /api/ga
    method: GET
    data_selector: features
    params: {}
- name: Deprecated
  endpoint:
    path: /api/deprecated
    method: GET
    data_selector: features
    params: {}
- name: data_credential
  endpoint:
    params:
      Managed identity resource ID: required
      Storage account name: required
      Container name: required
- name: deployment_credential
  endpoint:
    params:
      Directory (tenant) ID: required
      Application (client) ID: required
      Client secret value: required
      SSH Key resource ID: required
- name: network_configuration
  endpoint:
    params:
      Virtual network resource ID: required
      Subnet name: required
- name: Transparent Data Encryption
  endpoint:
    path: /BYOC/ja/docs/security/tde/
    method: GET
    data_selector: overview
- name: multi_az_deployment
  endpoint:
    path: /BYOC/ja/docs/get_started/create_cluster/aws_cluster/multi-az/
    method: GET
    data_selector: content
    params: {}
- name: IP Access Rules
  endpoint:
    path: /BYOC/ja/docs/security/cloud_access_control/open_cluster_access_control/
    method: GET
    data_selector: rules
    params: {}
- name: warehouse_suspend
  endpoint:
    path: /api/1.0/warehouses/:warehouse_id/suspend
    method: PATCH
    data_selector: ''
    params:
      warehouse_id: ff09d6ac-b821-447d-b4c1-59167d022c8b
- name: warehouses
  endpoint:
    path: /clusters/:cluster_id/warehouses
    method: GET
- name: account_list
  endpoint:
    path: /api/1.0/accounts
    method: GET
    data_selector: data
- name: cluster_usage
  endpoint:
    path: /api/1.0/usages/:cluster_id
    method: GET
    params:
      start_date: '20230701'
      end_date: '20230731'
      show_detail: true
- name: resource_group
  endpoint:
    path: <resource_group_name>
    method: CREATE
    data_selector: resource
    params:
      location: <Azure_region_name>
- name: managed_identity
  endpoint:
    path: <managed_identity_name>
    method: CREATE
    data_selector: identity
    params: {}
- name: storage_account
  endpoint:
    path: <storage_account_name>
    method: CREATE
    data_selector: account
    params:
      account_tier: Standard
      account_replication_type: GRS
- name: storage_container
  endpoint:
    path: <storage_container_name>
    method: CREATE
    data_selector: container
    params:
      container_access_type: private
- name: app_registration
  endpoint:
    path: <app_registration_name>
    method: CREATE
    data_selector: app
    params:
      description: My example application
      sign_in_audience: AzureADMyOrg
- name: ssh_key
  endpoint:
    path: <ssh_key_name>
    method: CREATE
    data_selector: ssh_key
    params:
      public_key: file('~/.ssh/id_rsa.pub')
- name: virtual_network
  endpoint:
    path: <network_name>
    method: CREATE
    data_selector: network
    params:
      address_space:
      - 10.0.0.0/16
- name: subnet
  endpoint:
    path: <subnet_name>
    method: CREATE
    data_selector: subnet
    params:
      address_prefixes:
      - 10.0.1.0/24
- name: network_security_group
  endpoint:
    path: <security_group_name>
    method: CREATE
    data_selector: nsg
    params: {}
- name: azure_data_credential
  endpoint:
    path: /BYOC/ja/docs/get_started/create_cluster/terraform_provider/resources/azure_data_credential/
    method: POST
    data_selector: resource
    params: {}
- name: azure_deployment_credential
  endpoint:
    path: /BYOC/ja/docs/get_started/create_cluster/terraform_provider/resources/azure_deployment_credential/
    method: POST
    data_selector: resource
    params: {}
- name: azure_network
  endpoint:
    path: /BYOC/ja/docs/get_started/create_cluster/terraform_provider/resources/azure_network/
    method: POST
    data_selector: resource
    params: {}
- name: classic_cluster
  endpoint:
    path: /BYOC/ja/docs/get_started/create_cluster/terraform_provider/resources/classic_cluster/
    method: POST
    data_selector: resource
    params: {}
- name: Alarm Policy
  endpoint:
    path: /BYOC/ja/docs/administration/management/monitoring/alarm/
    method: GET
- name: example
  endpoint:
    path: /example
    method: INSERT
    data_selector: rows
    params: {}
- name: classic_cluster
  endpoint:
    path: /BYOC/docs/get_started/create_cluster/gcp_cluster/create_cluster_gcp/
    method: GET
- name: elastic_cluster
  endpoint:
    path: /BYOC/docs/get_started/create_cluster/gcp_cluster/create_cluster_gcp/
    method: GET
- name: network_configuration
  endpoint:
    path: /BYOC/docs/sql-reference/azure/create_virtual_network_subnet_security_group/
    method: GET
    data_selector: network_configuration
    params: {}
- name: cluster_credential
  endpoint:
    path: /BYOC/docs/cluster_management/manage_cluster/
    method: GET
    data_selector: cluster_credential
    params: {}
- name: connectivity_test
  endpoint:
    path: /BYOC/docs/cluster_management/test_connectivity/
    method: POST
    data_selector: connectivity_test
    params: {}
- name: data_credential
  endpoint:
    path: /BYOC/docs/cloud_settings/gcp_cloud_settings/manage_gcp_data_credentials/
    method: POST
    data_selector: data_credentials
    params: {}
- name: deployment_credential
  endpoint:
    path: /BYOC/docs/cloud_settings/gcp_cloud_settings/manage_gcp_deployment_credentials/
    method: GET
    data_selector: deployment_credentials
    params: {}
- name: network_configuration
  endpoint:
    path: /BYOC/docs/cloud_settings/gcp_cloud_settings/manage_gcp_network_configurations/
    method: GET
    data_selector: network_configurations
    params: {}
- name: Classic clusters
  endpoint:
    path: /supported_instance_types/gcp/classic_clusters
    method: GET
    data_selector: instance_types
    params: {}
- name: Elastic clusters
  endpoint:
    path: /supported_instance_types/gcp/elastic_clusters
    method: GET
    data_selector: instance_types
    params: {}
- name: IAM roles and permissions
  endpoint:
    path: /sql-reference/gcp/grant_resource_permission
    method: GET
    data_selector: roles
    params: {}
- name: vpc_network
  endpoint:
    path: /vpc/networks
    method: CREATE
    data_selector: network
    params: {}
- name: subnet
  endpoint:
    path: /vpc/subnets
    method: CREATE
    data_selector: subnet
    params: {}
- name: firewall_rule
  endpoint:
    path: /vpc/firewallRules
    method: CREATE
    data_selector: firewallRule
    params: {}
- name: psc_endpoint
  endpoint:
    path: /sql-reference/gcp/create_psc_endpoint
    method: GET
    data_selector: endpoint
    params: {}
- name: service_directory
  endpoint:
    path: /sql-reference/gcp/check_service_directory
    method: GET
    data_selector: service
    params: {}
- name: cloud_dns
  endpoint:
    path: /sql-reference/gcp/check_cloud_dns
    method: GET
    data_selector: dns
    params: {}
- name: clusters
  endpoint:
    path: /clusters
    method: GET
    data_selector: clusters
- name: classic_cluster_scaling
  endpoint:
    path: /BYOC/docs/cluster_management/scale_cluster/
    method: GET
    data_selector: details
    params: {}
- name: elastic_cluster_scaling
  endpoint:
    path: /BYOC/docs/cluster_management/scale_cluster/
    method: GET
    data_selector: details
    params: {}
- name: Batch load data from AWS S3
  endpoint:
    path: /BYOC/docs/sql-reference/aws/aws_iam_policies/
    method: GET
    data_selector: Statement
    params: {}
- name: Read/write AWS S3
  endpoint:
    path: /BYOC/docs/sql-reference/aws/aws_iam_policies/
    method: GET
    data_selector: Statement
    params: {}
- name: Integrate with AWS Glue
  endpoint:
    path: /BYOC/docs/sql-reference/aws/aws_iam_policies/
    method: GET
    data_selector: Statement
    params: {}
- name: Create a data credential
  endpoint:
    path: /BYOC/docs/sql-reference/aws/aws_iam_policies/
    method: GET
    data_selector: Statement
    params: {}
- name: deployment_credential_policy
  endpoint:
    path: /create_deployment_credential
    method: POST
    data_selector: policy
    params: {}
- name: data credential role
  endpoint:
    path: /BYOC/docs/cloud_settings/aws_cloud_settings/manage_aws_data_credentials/#create-a-data-credential
    method: GET
- name: cross-account IAM role
  endpoint:
    path: /BYOC/docs/sql-reference/aws/create_iam_role/
    method: GET
- name: KMS key
  endpoint:
    path: /BYOC/docs/sql-reference/aws/create_kms_key/
    method: GET
- name: VPC
  endpoint:
    path: /sql-reference/aws/create_vpc/
    method: CREATE
    data_selector: VPC creation details
    params: {}
- name: VPC_endpoint_S3
  endpoint:
    path: /BYOC/docs/sql-reference/aws/create_vpc_endpoint_for_s3/
    method: GET
    data_selector: records
    params: {}
- name: EC2_instances
  endpoint:
    path: /view/associated/aws/cloud/resources
    method: GET
    data_selector: instances
    params: {}
- name: placement_groups
  endpoint:
    path: /view/associated/aws/cloud/resources
    method: GET
    data_selector: placement_groups
    params: {}
- name: user_account_management
  endpoint:
    path: /BYOC/docs/category/user-account-management/
    method: GET
- name: cluster_management
  endpoint:
    path: /BYOC/docs/category/cluster-management/
    method: GET
- name: loading_and_unloading
  endpoint:
    path: /BYOC/docs/category/loading-and-unloading/
    method: GET
- name: catalog
  endpoint:
    path: /BYOC/docs/category/catalog/
    method: GET
- name: database
  endpoint:
    path: /BYOC/docs/category/database/
    method: GET
- name: resource
  endpoint:
    path: /BYOC/docs/category/resource/
    method: GET
- name: table_bucket_partition_and_index
  endpoint:
    path: /BYOC/docs/category/table-bucket-partition-and-index/
    method: GET
- name: view
  endpoint:
    path: /BYOC/docs/category/view/
    method: GET
- name: materialized_view
  endpoint:
    path: /BYOC/docs/category/materialized-view/
    method: GET
- name: function
  endpoint:
    path: /BYOC/docs/category/function/
    method: GET
- name: cbo_statistics
  endpoint:
    path: /BYOC/docs/category/cbo-statistics/
    method: GET
- name: backup_and_restore
  endpoint:
    path: /BYOC/docs/category/backup-and-restore/
    method: GET
- name: translate_trino_sql
  endpoint:
    path: /BYOC/docs/sql-reference/sql-statements/TRANSLATE_TRINO/
    method: GET
- name: dictionary
  endpoint:
    path: /BYOC/docs/sql-reference/sql-statements/dictionary/CANCEL_REFRESH_DICTIONARY/
    method: GET
- name: generated_columns
  endpoint:
    path: /BYOC/docs/sql-reference/sql-statements/generated_columns/
    method: GET
- name: keywords
  endpoint:
    path: /BYOC/docs/sql-reference/sql-statements/keywords/
    method: GET
- name: prepared_statements
  endpoint:
    path: /BYOC/docs/sql-reference/sql-statements/prepared_statement/
    method: GET
- name: system_variables
  endpoint:
    path: /BYOC/docs/sql-reference/System_variable/
    method: GET
    data_selector: variables
    params: {}
- name: be_bvars
  endpoint:
    path: /BYOC/docs/sql-reference/information_schema/be_bvars/
    method: GET
    data_selector: records
- name: be_cloud_native_compactions
  endpoint:
    path: /BYOC/docs/sql-reference/information_schema/be_cloud_native_compactions/
    method: GET
    data_selector: records
- name: be_compactions
  endpoint:
    path: /BYOC/docs/sql-reference/information_schema/be_compactions/
    method: GET
    data_selector: records
- name: character_sets
  endpoint:
    path: /BYOC/docs/sql-reference/information_schema/character_sets/
    method: GET
    data_selector: records
- name: collations
  endpoint:
    path: /BYOC/docs/sql-reference/information_schema/collations/
    method: GET
    data_selector: records
- name: column_privileges
  endpoint:
    path: /BYOC/docs/sql-reference/information_schema/column_privileges/
    method: GET
    data_selector: records
- name: columns
  endpoint:
    path: /BYOC/docs/sql-reference/information_schema/columns/
    method: GET
    data_selector: records
- name: engines
  endpoint:
    path: /BYOC/docs/sql-reference/information_schema/engines/
    method: GET
    data_selector: records
- name: events
  endpoint:
    path: /BYOC/docs/sql-reference/information_schema/events/
    method: GET
    data_selector: records
- name: global_variables
  endpoint:
    path: /BYOC/docs/sql-reference/information_schema/global_variables/
    method: GET
    data_selector: records
- name: key_column_usage
  endpoint:
    path: /BYOC/docs/sql-reference/information_schema/key_column_usage/
    method: GET
    data_selector: records
- name: load_tracking_logs
  endpoint:
    path: /BYOC/docs/sql-reference/information_schema/load_tracking_logs/
    method: GET
    data_selector: records
- name: loads
  endpoint:
    path: /BYOC/docs/sql-reference/information_schema/loads/
    method: GET
    data_selector: records
- name: materialized_views
  endpoint:
    path: /BYOC/docs/sql-reference/information_schema/materialized_views/
    method: GET
    data_selector: records
- name: partitions
  endpoint:
    path: /BYOC/docs/sql-reference/information_schema/partitions/
    method: GET
    data_selector: records
- name: pipe_files
  endpoint:
    path: /BYOC/docs/sql-reference/information_schema/pipe_files/
    method: GET
    data_selector: records
- name: pipes
  endpoint:
    path: /BYOC/docs/sql-reference/information_schema/pipes/
    method: GET
    data_selector: records
- name: referential_constraints
  endpoint:
    path: /BYOC/docs/sql-reference/information_schema/referential_constraints/
    method: GET
    data_selector: records
- name: routines
  endpoint:
    path: /BYOC/docs/sql-reference/information_schema/routines/
    method: GET
    data_selector: records
- name: schema_privileges
  endpoint:
    path: /BYOC/docs/sql-reference/information_schema/schema_privileges/
    method: GET
    data_selector: records
- name: schemata
  endpoint:
    path: /BYOC/docs/sql-reference/information_schema/schemata/
    method: GET
    data_selector: records
- name: session_variables
  endpoint:
    path: /BYOC/docs/sql-reference/information_schema/session_variables/
    method: GET
    data_selector: records
- name: statistics
  endpoint:
    path: /BYOC/docs/sql-reference/information_schema/statistics/
    method: GET
    data_selector: records
- name: table_constraints
  endpoint:
    path: /BYOC/docs/sql-reference/information_schema/table_constraints/
    method: GET
    data_selector: records
- name: table_privileges
  endpoint:
    path: /BYOC/docs/sql-reference/information_schema/table_privileges/
    method: GET
    data_selector: records
- name: tables
  endpoint:
    path: /BYOC/docs/sql-reference/information_schema/tables/
    method: GET
    data_selector: records
- name: tables_config
  endpoint:
    path: /BYOC/docs/sql-reference/information_schema/tables_config/
    method: GET
    data_selector: records
- name: task_runs
  endpoint:
    path: /BYOC/docs/sql-reference/information_schema/task_runs/
    method: GET
    data_selector: records
- name: tasks
  endpoint:
    path: /BYOC/docs/sql-reference/information_schema/tasks/
    method: GET
    data_selector: records
- name: triggers
  endpoint:
    path: /BYOC/docs/sql-reference/information_schema/triggers/
    method: GET
    data_selector: records
- name: user_privileges
  endpoint:
    path: /BYOC/docs/sql-reference/information_schema/user_privileges/
    method: GET
    data_selector: records
- name: views
  endpoint:
    path: /BYOC/docs/sql-reference/information_schema/views/
    method: GET
    data_selector: records
- name: grants_to_roles
  endpoint:
    path: /BYOC/docs/sql-reference/sys/grants_to_roles/
    method: GET
    data_selector: records
- name: grants_to_users
  endpoint:
    path: /BYOC/docs/sql-reference/sys/grants_to_users/
    method: GET
    data_selector: records
- name: role_edges
  endpoint:
    path: /BYOC/docs/sql-reference/sys/role_edges/
    method: GET
    data_selector: records
- name: object_dependencies
  endpoint:
    path: /BYOC/docs/sql-reference/sys/object_dependencies/
    method: GET
    data_selector: records
- name: policy_references
  endpoint:
    path: /BYOC/docs/sql-reference/sys/policy_references/
    method: GET
    data_selector: records
- name: users
  endpoint:
    path: /BYOC/docs/sql-reference/sql-statements/account-management/CREATE_USER/
    method: POST
    data_selector: user
    params: {}
- name: roles
  endpoint:
    path: /BYOC/docs/sql-reference/sql-statements/account-management/CREATE_ROLE/
    method: POST
    data_selector: role
    params: {}
- name: privileges
  endpoint:
    path: /BYOC/docs/sql-reference/sql-statements/account-management/GRANT/
    method: POST
    data_selector: privilege
    params: {}
- name: network_configuration
  endpoint:
    path: /BYOC/docs/cloud_settings/aws_cloud_settings/manage_aws_network_configurations/
    method: GET
    data_selector: network_configurations
    params: {}
- name: suspend_warehouse
  endpoint:
    path: /api/1.0/warehouses/:warehouse_id/suspend
    method: PATCH
- name: clusters
  endpoint:
    path: /api/clusters
    method: GET
- name: warehouses
  endpoint:
    path: /api/warehouses
    method: GET
- name: identity_and_access_management
  endpoint:
    path: /api/iam
    method: GET
- name: organization_and_account
  endpoint:
    path: /api/organization_account
    method: GET
- name: usage_and_billing
  endpoint:
    path: /api/usage_billing
    method: GET
- name: release_warehouse
  endpoint:
    path: /api/1.0/warehouses/:warehouse_id
    method: DELETE
    data_selector: data
    params: {}
- name: resume_warehouse
  endpoint:
    path: /api/1.0/warehouses/:warehouse_id/resume
    method: PATCH
    data_selector: data
    params: {}
- name: scale_warehouse
  endpoint:
    path: /api/1.0/warehouses/:warehouse_id/scale-num
    method: POST
- name: scale_warehouse
  endpoint:
    path: /api/1.0/warehouses/:warehouse_id/scale-size
    method: POST
- name: list_warehouses
  endpoint:
    path: /API/actions/warehouses/query_warehouses/list_warehouses/
    method: GET
- name: query_warehouse
  endpoint:
    path: /API/actions/warehouses/query_warehouses/query_warehouse/
    method: GET
- name: query_warehouse_operation_status
  endpoint:
    path: /API/actions/warehouses/query_warehouses/query_warehouse_operation_status/
    method: GET
- name: account_list
  endpoint:
    path: /BYOC/docs/API/actions/organization_and_account/account_list/
    method: GET
- name: Query CCU usage of the logged-in account
  endpoint:
    path: /API/actions/usage_and_billing/query_account_CCU_usage/
    method: GET
- name: Query billing information of the logged-in account
  endpoint:
    path: /API/actions/usage_and_billing/query_account_billing_info/
    method: GET
- name: Query CCU usage of a cluster
  endpoint:
    path: /API/actions/usage_and_billing/query_cluster_CCU_usage/
    method: GET
- name: Query CCU usage of the organization
  endpoint:
    path: /API/actions/usage_and_billing/query_organization_CCU_usage/
    method: GET
- name: warehouse
  endpoint:
    path: /warehouses/:warehouse_id
    method: GET
- name: warehouses
  endpoint:
    path: /api/1.0/clusters/:cluster_id/warehouses
    method: GET
- name: warehouse_operation_status
  endpoint:
    path: /api/1.0/clusters/:cluster_id/infra-action/state
    method: GET
    params:
      order_id: required
- name: account
  endpoint:
    path: /api/1.0/accounts
    method: GET
    data_selector: data
    params: {}
- name: CCU_usage
  endpoint:
    path: /api/1.0/usages/:cluster_id
    method: GET
    params:
      start_date: yyyyMMdd
      end_date: yyyyMMdd
      show_detail: 'true'
- name: CCU_usage
  endpoint:
    path: /api/1.0/usages
    method: GET
    params:
      start_date: '20230701'
      end_date: '20230731'
      show_detail: 'true'
- name: billing_info
  endpoint:
    path: /api/1.0/bills
    method: GET
    data_selector: data
    params:
      start_month: '202304'
      end_month: '202307'
- name: CCU_usage
  endpoint:
    path: /api/1.0/org/cluster/usage
    method: POST
    params:
      start_date: '20230701'
      end_date: '20230731'
- name: azure_data_credential
  endpoint:
    path: /celerdatabyoc_azure_data_credential
    method: POST
    data_selector: data
    params:
      managed_identity_resource_id: azurerm_user_assigned_identity.example.id
      storage_account_name: azurerm_storage_account.example.name
      container_name: azurerm_storage_container.example.name
- name: azure_deployment_credential
  endpoint:
    path: /celerdatabyoc_azure_deployment_credential
    method: POST
    data_selector: data
    params:
      application_id: azuread_application_registration.example.client_id
      directory_id: azuread_service_principal.app_service_principal.application_tenant_id
      client_secret_value: azuread_application_password.example.value
      ssh_key_resource_id: azurerm_ssh_public_key.example.id
- name: azure_network
  endpoint:
    path: /celerdatabyoc_azure_network
    method: POST
    data_selector: data
    params:
      deployment_credential_id: celerdatabyoc_azure_deployment_credential.example.id
      virtual_network_resource_id: azurerm_virtual_network.example.id
      subnet_name: azurerm_subnet.example.name
      region: local.cluster_region
      public_accessible: true
- name: celerdatabyoc_classic_cluster
  endpoint:
    path: /celerdatabyoc_classic_cluster
    method: POST
- name: data_credential
  endpoint:
    path: /celerdatabyoc/aws_data_credential
    method: POST
    data_selector: data_credential
    params: {}
- name: deployment_credential
  endpoint:
    path: /celerdatabyoc/aws_deployment_credential
    method: POST
    data_selector: deployment_credential
    params: {}
- name: celerdatabyoc_aws_network
  endpoint:
    path: /BYOC/docs/get_started/create_cluster/terraform_provider/resources/aws_network/
    method: resource
    data_selector: network
    params:
      name: <VPC_name>
      subnet_id: <subnet_id>
      security_group_id: <security_group_id>
      region: <AWS_VPC_region>
      deployment_credential_id: celerdatabyoc_aws_deployment_role_credential.deployment_role_credential.id
      vpc_endpoint_id: <vpc_endpoint_id>
- name: celerdatabyoc_classic_cluster
  endpoint:
    path: /BYOC/docs/get_started/create_cluster/terraform_provider/resources/aws_network/
    method: resource
    data_selector: demo_cluster
    params:
      deployment_credential_id: celerdatabyoc_aws_deployment_role_credential.deployment_role_credential.id
      data_credential_id: celerdatabyoc_aws_data_credential.data_credential.id
      network_id: celerdatabyoc_aws_network.network.id
      cluster_name: <cluster_name>
      fe_instance_type: <fe_node_instance_type>
      fe_node_count: 1
      be_instance_type: <be_node_instance_type>
      be_node_count: 1
      default_admin_password: <SQL_user_initial_password>
      expected_cluster_state: Running
      resource_tags:
        celerdata: <tag_name>
      csp: aws
      region: <AWS_VPC_region>
- name: gcp_data_credential
  endpoint:
    path: /BYOC/docs/get_started/create_cluster/terraform_provider/resources/gcp_data_credential/
    method: POST
    data_selector: data
    params:
      name: tf-test-0604
      bucket_name: google_storage_bucket.storage-bucket.name
      service_account: google_service_account.storage-sa.email
- name: gcp_deployment_credential
  endpoint:
    path: /BYOC/docs/get_started/create_cluster/terraform_provider/resources/gcp_deployment_credential/
    method: POST
    data_selector: data
    params:
      name: tf-test-0604
      project_id: <gcp_project_id>
- name: gcp_network
  endpoint:
    path: /BYOC/docs/get_started/create_cluster/terraform_provider/resources/gcp_network/
    method: POST
    data_selector: data
    params:
      name: tf-test-0604
      region: us-central1
      subnet: google_compute_subnetwork.subnetwork.name
      network_tag: <gcp_network_tag>
      deployment_credential_id: celerdatabyoc_gcp_deployment_credential.deployment_credential.id
- name: celerdatabyoc_classic_cluster
  endpoint:
    path: /BYOC/docs/get_started/create_cluster/terraform_provider/resources/classic_cluster/
    method: POST
    data_selector: cluster
    params: {}
- name: AWS Policy in Data Credential
  endpoint:
    path: /BYOC/docs/get_started/create_cluster/terraform_provider/guides/policy_template_data_credential_role/
    method: GET
    data_selector: PolicyTemplate
    params: {}
- name: classic_cluster
  endpoint:
    path: /BYOC/docs/get_started/create_cluster/terraform_provider/resources/classic_cluster/
    method: POST
    data_selector: expected_cluster_state
    params: {}
- name: elastic_cluster_v2
  endpoint:
    path: /BYOC/docs/get_started/create_cluster/terraform_provider/resources/elastic_cluster_v2/
    method: POST
    data_selector: expected_cluster_state
    params: {}
- name: celerdatabyoc_azure_data_credential
  endpoint:
    path: /BYOC/docs/get_started/create_cluster/terraform_provider/resources/azure_data_credential/
    method: resource
    data_selector: attributes
    params:
      name: <data_credential_name>
      managed_identity_resource_id: <managed_identity_id>
      storage_account_name: <storage_account_name>
      container_name: <container_name>
- name: celerdatabyoc_azure_deployment_credential
  endpoint:
    path: /BYOC/docs/get_started/create_cluster/terraform_provider/resources/azure_deployment_credential/
    method: POST
    data_selector: id
    params: {}
- name: celerdatabyoc_azure_network
  endpoint:
    path: /BYOC/docs/get_started/create_cluster/terraform_provider/resources/azure_network/
    method: POST
    data_selector: id
    params:
      name: <network_credential_name>
      deployment_credential_id: <deployment_credential_id>
      virtual_network_resource_id: <virtual_network_id>
      subnet_name: <subnet_name>
      region: <region_id>
      public_accessible: true
- name: alarm_policy
  endpoint:
    path: /BYOC/docs/administration/management/monitoring/alarm/
    method: GET
    data_selector: alarm policies
    params: {}
- name: warehouse_query_queue
  endpoint:
    path: /monitoring/metrics/warehouse_query_queue
    method: GET
    data_selector: metrics
    params: {}
- name: warehouse_cngroup
  endpoint:
    path: /admin/management/monitoring/metrics-warehouse_cngroup
    method: GET
    data_selector: metrics
- name: blacklist
  endpoint:
    path: /BYOC/docs/sql-reference/sql-statements/cluster-management/nodes_processes/ADD_BACKEND_BLACKLIST/
    method: POST
    data_selector: records
    params: {}
- name: access_token
  endpoint:
    path: /api/1.0/token
    method: POST
- name: member_list
  endpoint:
    path: /API/actions/identity_and_access_management/member_and_role/member_list/
    method: GET
- name: invite_member
  endpoint:
    path: /API/actions/identity_and_access_management/member_and_role/invite_member/
    method: POST
- name: delete_member
  endpoint:
    path: /API/actions/identity_and_access_management/member_and_role/delete_member/
    method: DELETE
- name: modify_roles
  endpoint:
    path: /API/actions/identity_and_access_management/member_and_role/modify_roles/
    method: POST
- name: role_list
  endpoint:
    path: /API/actions/identity_and_access_management/member_and_role/role_list/
    method: GET
- name: clear_roles
  endpoint:
    path: /API/actions/identity_and_access_management/member_and_role/clear_roles/
    method: POST
- name: account_list
  endpoint:
    path: /BYOC/ja/docs/API/actions/organization_and_account/account_list/
    method: GET
- name: account_CCU_usage
  endpoint:
    path: /BYOC/ja/docs/API/actions/usage_and_billing/query_account_CCU_usage/
    method: GET
- name: billing_info
  endpoint:
    path: /BYOC/ja/docs/API/actions/usage_and_billing/query_account_billing_info/
    method: GET
- name: cluster_CCU_usage
  endpoint:
    path: /BYOC/ja/docs/API/actions/usage_and_billing/query_cluster_CCU_usage/
    method: GET
- name: organization_CCU_usage
  endpoint:
    path: /BYOC/ja/docs/API/actions/usage_and_billing/query_organization_CCU_usage/
    method: GET
- name: clear_member_roles
  endpoint:
    path: /BYOC/docs/API/actions/identity_and_access_management/member_and_role/clear_roles/
    method: GET
- name: delete_member
  endpoint:
    path: /BYOC/docs/API/actions/identity_and_access_management/member_and_role/delete_member/
    method: GET
- name: invite_members
  endpoint:
    path: /BYOC/docs/API/actions/identity_and_access_management/member_and_role/invite_member/
    method: GET
- name: get_member_list
  endpoint:
    path: /BYOC/docs/API/actions/identity_and_access_management/member_and_role/member_list/
    method: GET
- name: set_member_roles
  endpoint:
    path: /BYOC/docs/API/actions/identity_and_access_management/member_and_role/modify_roles/
    method: GET
- name: get_role_list
  endpoint:
    path: /BYOC/docs/API/actions/identity_and_access_management/member_and_role/role_list/
    method: GET
notes:
- Client Credentials-based authentication in compliance with OAuth 2.0.
- You must generate an application key or create a service account.
- Supports SSO login using SAML SSO.
- Some improvements and optimizations made in the SQL Editor.
- Supports querying CCU usage and billing information using OpenAPI.
- Users can create clusters using Terraform.
- このサービスは、専用環境と高性能で安全なネットワーキングにより、データ処理と配信を大幅に高速化します。
- アップグレードはすべて CelerData チームによって処理および管理されます。すべてのパッチ（マイナーおよびメジャー）は自動的に処理されます。
- Free Developer Tier パッケージは、クラシック クラスターでのみサポートされています。
- Free Developer Tier クラスターは請求プロセスに含まれず、その CCU 消費は常に 0 です。そのため、Free Developer Tier
  クラスターを使用している間は、料金が発生することはありません。
- CelerData クラスターが作成されると、ADMIN 権限を持つデフォルトのデータベースユーザー `admin` が作成されます。
- デフォルトでは、CelerData クラスター内のテーブルには 3 つのデータレプリカが作成されます。
- Data Cache is enabled by default starting from version 3.3.0.
- CelerData は、正確なデータ分布統計を収集するためにヒストグラムを導入しています。
- この機能は v3.1 以降でサポートされています。
- Uses OAuth2 with refresh token — requires setup of connected app in CelerData
- CelerData Cloud BYOC API は、ユーザーインターフェースを通じて行われるプロセスを自動化するのに役立ちます。
- CelerData は、Transparent Data Encryption (TDE) を使用して、弾力性のあるクラスター内のデータを保護します。
- CelerData の請求は、CelerData Cloud アカウント内のすべてのクラスターによって消費された CelerData Cloud Units (CCUs)
  の合計である総 CCU 使用量に基づいており、CelerData は CCU 使用量に対して 1 CCU あたり USD 0.65 を請求します（2025 年
  7 月 1 日より有効）。
- CelerData クラウドアカウント内の使用状況は、CelerData Cloud Units (CCUs) で測定されます。CCUs は、CelerData
  クラスターが稼働しているときにのみ消費されます。
- すべてのスクリプトはデフォルトユーザーによって実行されます。 **root** ユーザーの権限を適用したい場合は、Sudo を使用してください。
- 指定されたすべてのスクリプトの実行に許可される最大時間は 5 分です。
- 一度に最大 20 個のスクリプトを実行できます。
- 異常に実行されるスクリプトはクラスターのデプロイに失敗を引き起こします。したがって、指定されたスクリプトが正常に実行できることを確認してください。
- CelerData クラスターがデプロイされるすべての EC2 インスタンスに関連付けられたインスタンスプロファイルが、スクリプトおよびログファイルで指定されたバケットおよびキーに対して必要な読み取りまたは書き込み権限を持っていることを確認してください。
- リクエストパラメータ `scripts` で指定されたスクリプトのリストは異なるパスに配置でき、スクリプト実行時に生成されるログファイルはスクリプトのパスに類似したパスに保存されます。
- CelerData は [Free Developer Tier](/BYOC/ja/docs/get_started/free_developer_tier/)
  を提供しています。これを使用するには、4 CPU コアと 16-GB RAM を提供する FE および BE インスタンスタイプを選択する必要があります。
- 4 CPU コアと 16-GB RAM は、FEs および BEs の最小構成パッケージでもあります。
- クラスタを作成する際、クラスタと同じリージョンにあるバケットを参照するデータクレデンシャルのみを使用できます。
- Shared VPC を有効にしている場合、サービスプロジェクト（つまり、クラスタがデプロイされるプロジェクト）からバケットの名前を入力する必要があります。
- Shared VPC を有効にしている場合、サービスプロジェクト（つまり、クラスタがデプロイされるプロジェクト）からインスタンスサービスアカウントを入力する必要があります。
- Project ID は、GCP に CelerData クラスタをデプロイするために作成した Google Cloud プロジェクトの ID を入力します。
- クラスタが作成された後、クラスタの詳細ページに移動し、ページの右上隅で Manage > Reset password を選択して、admin アカウントのパスワードをリセットできます。クラスタが
  Running 状態にあるときのみ、admin アカウントのパスワードをリセットできます。
- NLB は、SQL クエリを送信したり、データを取り込むために Stream Load リクエストを送信したりするためのエンドポイントです。
- このステップでは、インバウンドまたはアウトバウンドルールを作成しないでください。セキュリティグループが作成された後に、インバウンドおよびアウトバウンドルールを作成します。
- Private Preview features are off by default and need to be enabled through SQL or
  configuration files.
- Public Preview features are off by default and need to be enabled through SQL or
  configuration files.
- GA features are on by default and can be used in production.
- SSO を設定できるのはアカウント管理者のみです。
- 現在、CelerData クラスターは SSO との統合をサポートしていません。
- CelerData は手動デプロイメントのみをサポートしています。
- データ資格情報、デプロイメント資格情報、およびネットワーク構成を提供する必要があります。
- デフォルトストレージボリュームはクラスタを作成した後、データベースやテーブルを作成する前に手動で作成する必要があります。
- 現在、Storage Volume は Azure Blob Storage の Managed Identity 認証方法をサポートしていないため、認証と授権には
  Shared Key または Shared Access Signatures (SAS) トークンを使用する必要があります。
- Transparent Data Encryption は弾力性のあるクラスターでのみサポートされています。
- 既存のクラスターに対して Transparent Data Encryption を有効にしたり、マスターキーの設定を変更したりすることはサポートされていません。セットアップ後にマスターキーを変更することはできません。
- Transparent Data Encryption を有効にすると、10% 未満のパフォーマンス低下が発生する可能性があります。
- マルチ AZ デプロイメントは、弾力的な CelerData クラスターにのみサポートされています。
- この機能は、手動デプロイメントを介してクラスターをデプロイする場合にのみ有効にできます。
- 現在、CloudFormation を介してマルチ AZ デプロイメントを有効にすることはサポートされていません。
- デプロイメントを作成する際、選択した既存のデータクレデンシャルを編集することはできません。既存のデータクレデンシャルがデプロイメント要件を満たさない場合は、新しいデータクレデンシャルを作成することをお勧めします。
- CelerData はデプロイメントクレデンシャルとして RAM ロールのみをサポートしています。
- デプロイメントクレデンシャルは作成後に編集することはできません。
- CelerData allows users to connect to the Open Cluster page from any IP address by
  default.
- Multiple IP access lists can be set for each CelerData cluster.
- この操作には、Suspend & resume cluster 権限が必要です。
- デフォルトのウェアハウスは一時停止または再開できません。
- この操作には、クラスターの表示権限が必要です。
- この操作には組織管理権限が必要です。
- この操作には、請求の表示および管理の権限が必要です。
- 'クエリする期間の開始日と終了日は、形式: yyyyMMddで指定する必要があります。'
- メンバー管理特権を持つCelerDataメンバーのみがサービスアカウントを作成し、特権を付与できます。
- サービスアカウントはCelerData Cloud BYOC APIおよびCelerData Cloud BYOC provider on Terraformのみで使用できます。
- Uses OAuth 2.0 client credentials for authentication — requires generation of application
  key or service account.
- CelerData allows clusters to be paused to avoid unnecessary costs during idle times.
- When a cluster is paused, all warehouses are also paused.
- CelerData creates a root account for you and launches an organization with which
  this account is bound.
- CelerData offers a 30-day free trial for each account following your initial sign-up
  date.
- The Free Developer Tier package is supported only for classic clusters.
- A Free Developer Tier cluster is not included in the billing process, and its CCU
  consumption will always be 0.
- A default database user `admin` with the ADMIN privilege is created after a CelerData
  cluster is created.
- To create a table in a CelerData cluster, you MUST strategize the data distribution
  plan of the table by specifying the DISTRIBUTED BY HASH clause.
- Loading data via INSERT INTO VALUES merely applies to the situation when you need
  to verify a DEMO with a small dataset. It is not recommended for a massive testing
  or production environment.
- CelerData is compatible with SQL-92.
- CelerData now supports deployments on Amazon Web Services (AWS) and Microsoft Azure.
- Uses OAuth2 with refresh token — requires setup of connected app in api
- Data Cache is enabled by default from v3.3.0.
- Some objects may return nulls in deeply nested fields
- All scripts are run by the default user. If you want to apply the privileges of
  the root user, use Sudo.
- The maximum amount of time allowed for execution of all specified scripts each time
  is 5 minutes.
- Up to 20 scripts can be run at a time.
- Scripts running abnormally will cause cluster deployment failures. Therefore, make
  sure the specified scripts can be successfully run.
- Make sure that the instance profiles associated with all EC2 instances to which
  the CelerData cluster will be deployed have the required read or write permissions
  on the bucket and key specified in the scripts and log files.
- CelerData provides a Free Developer Tier.
- 4 CPU cores and 16-GB RAM are the minimum configuration package for FEs and BEs.
- When you create a cluster, you can only use a data credential that references a
  bucket located in the same region as the cluster.
- If you have enabled Shared VPC, you must enter the name of the bucket from the service
  project (that is, the project where the cluster is deployed).
- If you have enabled Shared VPC, you must enter the instance service account from
  the service project (that is, the project where the cluster is deployed).
- If you have enabled Shared VPC, you must enter the ID of the service project (that
  is, the project where the cluster is deployed).
- If you have enabled Shared VPC, you must specify the name of the subnet in the host
  project (that is, the project where the Shared VPC is deployed).
- If you have enabled Shared VPC, you must specify the target tag from the host project
  (that is, the project where the Shared VPC is deployed).
- If PSC connection ID is not set, then the Private Service Connect connection will
  not be built, CelerData's VPC communicates with your own VPC over the Internet.
- If you have enabled Shared VPC, you should enter the ID of the PSC Connection from
  the service project (that is, the project where the cluster is deployed).
- Quick Deployments using CloudFormation are not suitable for production use, and
  are recommended for non-production use only.
- To use the Free Developer Tier package, you must select FE and BE instance types
  that provide up to 4 CPU cores and up to 16-GB RAM.
- CelerData supports only manual deployments on Azure.
- CelerData allows you to reuse the same network configuration among multiple clusters.
- The admin account has all privileges enabled within your CelerData cloud account.
- Quick Deployments are not suitable for production use, and are recommended for non-production
  use only.
- CelerData provides a Free Developer Tier. To use it, you must select FE and BE instance
  types that provide 4 CPU cores and 16-GB RAM.
- Cluster deployments require the cloud settings management privilege.
- Each elastic CelerData cluster is provided with a built-in warehouse named `default_warehouse`,
  which is automatically created when you create the cluster.
- The default warehouse cannot be deleted or suspended separately from the coordinator
  node.
- You must enable billing for your new Google Cloud project to allow the necessary
  cloud resources to be launched.
- Data credentials cannot be edited after they are created.
- A data credential cannot be deleted if there are still CelerData clusters created
  based on it.
- CelerData supports only RAM roles as deployment credentials. Therefore, you can
  select only IAM Role.
- A deployment credential cannot be deleted if there are still CelerData clusters
  created based on it.
- A network configuration cannot be deleted if there are still CelerData clusters
  created based on it.
- When you are creating a deployment, you cannot edit an existing network configuration
  that you select.
- The Cloud Storage bucket must reside in the same Google Cloud region as the CelerData
  cluster you want to deploy.
- CelerData requires the role Compute Admin and permissions iam.serviceAccounts.actAs,
  storage.buckets.get.
- If you want to enable Shared VPC, grant the role Compute Network User and permission
  compute.addresses.use.
- The subnet you use for cluster deployment must reside in the same region where the
  cluster is deployed.
- You must specify exactly the same target tag for all firewall rules.
- Ensure your cluster is not publicly accessible.
- Create a PSC endpoint for secure connectivity.
- You can enable the End-to-End Private Link solution for a cluster only when deploying
  the cluster.
- Public Internet access to the Cluster Console and direct MySQL protocol access is
  disabled when Private Link is enabled.
- 'Valid values for cluster status: Failed, Running, Stopped, Updating, Deploying.'
- CelerData supports deploying classic clusters on AWS and Azure, and GCP.
- CelerData supports deploying elastic clusters only on AWS and GCP.
- A minimum of six hours is mandatory as the interval between two scaling operations
  (including manual scaling and autoscaling).
- Currently, Azure-based clusters does not support storage autoscaling.
- The maximum size of each storage is 16 TB.
- Autoscaling policies take effect only when the warehouse is running.
- For Node Scaling, the lower bound of the Scaling range is 1, and the upper bound
  is 100.
- For Group Scaling, the lower bound of the Scaling range is 1, and the upper bound
  is 10 in Single-AZ Deployment, and 2 and 20 in Multi-AZ Deployment.
- Scale out policy takes effect only when the current Compute Node or Compute Node
  Group count is less than the upper limit of the Scaling range you have defined.
- Scale in policy takes effect only when the current Compute Node or Compute Node
  Group count is greater than the lower limit of the Scaling range you have defined.
- The CPU utilization upper limit of Scale out policy must be greater than the lower
  limit of Scale in policy.
- To avoid significant fluctuations in cluster performance, only a maximum of two
  Compute Nodes or Compute Node Groups can be scaled in per step.
- Releasing a cluster means terminating all workloads and removing all data in the
  cluster.
- CelerData allows suspending a cluster to avoid unnecessary costs during idle time.
- Once your cluster is suspended, CelerData does not charge you with CCUs for your
  suspended cluster any more.
- To open a cluster, you must have the View Cluster privilege and the username and
  password to connect to the cluster.
- CelerData supports setting IP Access List for a cluster to allow or deny access
  from a specific set of IP addresses.
- Do not create inbound or outbound rules in this step. Create inbound and outbound
  rules after the security group is created.
- Replace <Storage Role ARN> with the ARN of the data credential role and <s3-bucket-name>
  with the name of the data credential bucket.
- The IAM role and bucket referenced in the data credential are referred to as the
  data credential role and the data credential bucket in this topic.
- 'A name can be up to 255 characters in length. Allowed characters are lowercase
  letters (a-z), uppercase letters (A-Z), digits (0-9), spaces, and the following
  special characters: ._-:/()#,@[]+=;{}!$*.'
- 'A description can be up to 255 characters in length. Allowed characters are lowercase
  letters (a-z), uppercase letters (A-Z), digits (0-9), spaces, and the following
  special characters: ._-:/()#,@[]+=;{}!$*.'
- You can use public network or Private Link with S3 Gateway.
- If you want to use Private Link with S3 Gateway, you do not need to configure public
  subnets and NAT gateways.
- Select AWS services for Endpoint settings > Type.
- Search and select com.amazonaws.<region>.s3 with type as Interface or Gateway.
- Enable DNS name and disable private DNS only for inbound endpoint in Additional
  settings.
- Setting a dedicated security group for NLB can avoid direct connection to your cluster
  from clients.
- It is also acceptable if you decide not to use a VPC endpoint for a secure connection.
  In this case, you must add an outbound rule to the cluster's security group that
  allows traffic to destination 0.0.0.0/0 over port 443.
- CelerData launches AWS Cloud resources, namely, EC2 instances and placement groups,
  that you must pay for, during deployment.
- If you no longer need a CelerData cluster, we recommend that you release the cluster
  to save costs.
- CelerData uses the MySQL protocol for communication.
- We recommend that you use a MySQL client whose version is 5.1 or later.
- Any user has the privilege to run SHOW VARIABLES and make a variable take effect
  at session level.
- Only users with the SYSTEM-level OPERATE privilege can make a variable take effect
  globally.
- The default value for force_streaming_aggregate is false.
- The default value for forward_to_master is false.
- The default value for group_concat_max_len is 1024.
- The default value for hash_join_push_down_right_table is true.
- The default value for io_tasks_per_scan_operator is 4.
- The default value for load_mem_limit is 0.
- The default value for log_rejected_record_num is 0.
- The default value for materialized_view_rewrite_mode is default.
- The default value for max_allowed_packet is 32 MB.
- The default value for max_scan_key_num is -1.
- The default value for max_pushdown_conditions_per_column is -1.
- The default value for nested_mv_rewrite_max_level is 3.
- The default value for new_planner_optimize_timeout is 3000.
- The default value for parallel_fragment_exec_instance_num is 1.
- The default value for pipeline_dop is 0.
- The default value for pipeline_profile_level is 1.
- The default value for query_cache_entry_max_rows is 409600.
- The default value for query_cache_agg_cardinality_limit is 5000000.
- The default value for query_mem_limit is 0.
- The default value for query_queue_pending_timeout_second is 300.
- The default value for query_timeout is 300.
- The default value for range_pruner_max_predicate is 100.
- The default value for runtime_join_filter_push_down_limit is 1024000.
- The default value for runtime_profile_report_interval is 10.
- The default value for spill_mode is auto.
- The default value for sql_dialect is not specified but can be set using 'set sql_dialect
  = 'trino';'
- The types of storage engines supported by CelerData include olap, mysql, broker,
  elasticsearch, hive, iceberg, hudi, jdbc.
- The default value for streaming_preaggregation_mode is auto.
- The default value for wait_timeout is 8 hours, in seconds.
- To set a warehouse for the current session, users must be granted the USAGE privilege
  on the warehouse.
- Views in sys are only accessible to some admin roles by default.
- User-defined variables expire when the session is closed.
- CelerData does not support using the SHOW statement to display existing user-defined
  variables.
- User-defined variables of the JSON type are converted to the STRING type for storage.
- Only account administrators can configure SSO.
- Currently, CelerData clusters does not support integration with SSO.
- Only CelerData members with the Member Management privilege can manage the members
  within their account.
- Only members with the Edit Cluster role have the privilege to perform the following
  operations.
- Currently, only IPv4 is supported.
- CelerData only allows access from IP addresses in all allowed-type rules.
- CelerData clusters support secure connections encrypted by SSL.
- Connections to CelerData clusters via API are encrypted by HTTPS.
- The MySQL client uses SSL by default when connecting to a CelerData cluster.
- Currently, Transparent Data Encryption is only supported in elastic clusters.
- Enabling Transparent Data Encryption for an existing cluster or modifying the Master
  Key configurations is not supported. The Master Key cannot be changed after setup.
- Enabling Transparent Data Encryption can cause a performance loss of less than 10%.
- CelerData employs both role-based access control (RBAC) and identity-based access
  control (IBAC) to manage privileges.
- Multi-AZ deployment is supported only for elastic CelerData clusters.
- Currently, enabling Multi-AZ deployment via CloudFormation is not supported.
- CelerData automatically generates a network configuration upon each successful cluster
  deployment on AWS.
- If you create a deployment without selecting an existing network configuration,
  CelerData automatically creates a network configuration based on your input during
  deployment and saves it for future use.
- CelerData clusters must be deployed in private subnets. Do not select a public subnet
  in this step.
- This operation requires the Suspend & resume cluster privilege.
- You cannot suspend or resume the default warehouse.
- This operation requires the Delete cluster privilege.
- You cannot release the default warehouse.
- This operation requires the Modify cluster privilege.
- This operation requires the View cluster privilege.
- This operation requires the Organization Management privilege.
- This operation requires the View and manage billing privilege.
- 'Frequency: 600/minute'
- 'Frequency limit: 600 requests per minute'
- This operation requires the application key of the organization root account member
  and the View and manage billing privilege.
- After you change the provider versions in the Terraform configuration, you must
  run `terraform init -upgrade` to initialize the providers and then run `terraform
  apply` again to apply the Terraform configuration.
- Ensure your IAM user has the necessary permissions.
- Local values should be set for S3 bucket names.
- To resume a cluster, set the argument to 'Running'.
- To suspend a cluster, set the argument to 'Suspended'.
- The resource's API may change in subsequent versions to simplify user experience.
- This resource depends on the implementation of other resources before implementing
  this one.
- This resource depends on the implementation of other resources.
- Classic CelerData clusters do not support Multi-AZ Deployment.
- Only members that are bound to a role with the Configure alarm privilege can configure
  alarm policies.
- Alarms can be sent at a 15-minute interval at most.
- CelerData employs a role-based access control (RBAC) framework, which allows cluster
  administrators to precisely manage and regulate access to objects or data in their
  CelerData clusters.
- Creating a backup strategy, testing that strategy, and performing backups is each
  customers' responsibility.
- CelerData supports creating repositories in AWS S3 only according to the S3A protocol.
- Replace <YOUR_DD_KEY> with your DataDog API key.
- Replace <YOUR_DD_SITE> with your DataDog site URL.
- Repleace <fe_metric_namespace> with the namespace you want to use for FE/Coordinator
  Node metrics.
- Repleace <be_metric_namespace> with the namespace you want to use for BE/Compute
  Node metrics.
- The user must have the OPERATE Privilege on the SYSTEM Level.
- Provides various metrics for managing warehouses and monitoring the warehouse query
  queue.
- The CN Group resource usage metrics are cached for 1 second to avoid excessive computation
- CPU usage metrics return -1.0 when the value is invalid, null, or NaN
- Maximum running queries count returns -1 when the value is invalid or unavailable
- Only users with the SYSTEM-level BLACKLIST privilege can use this feature.
- Each FE node keeps its own BE Blacklist, and will not share it with other FE nodes.
- Dynamic parameters can be configured and adjusted by running SQL commands, which
  is very convenient.
- Static parameters can only be configured and adjusted in the ClerData Cloud BYOC
  console.
- 'The ID of the StarRocks cluster to which the FE belongs. Valid values: any positive
  integer.'
- The directory that stores metadata.
- The type of edit log that can be generated. Set the value to `BDB`.
- The port that is used for communication among the Leader, Follower, and Observer
  FEs in the cluster.
- The maximum number of metadata log entries that can be written before a log file
  is created for these log entries.
- Whether to ignore an unknown log ID.
- The maximum duration by which the metadata on the follower and observer FEs can
  lag behind that on the leader FE.
- The policy based on which the leader FE flushes logs to disk.
- The policy based on which the follower FE flushes logs to disk.
- The policy based on which a log entry is considered valid.
- The amount of time after which the heartbeats among the leader, follower, and observer
  FEs in the StarRocks cluster time out.
- The maximum amount of time for which the leader FE can wait for ACK messages from
  a specified number of follower FEs.
- The amount of time after which a lock in the BDB JE-based FE times out.
- Whether to reset the BDBJE replication group.
- The maximum clock offset that is allowed between the leader FE and the follower
  or observer FEs in the StarRocks cluster.
- The maximum number of transactions that can be rolled back.
- The number of threads that can be run by the Heartbeat Manager to run heartbeat
  tasks.
- The size of the blocking queue that stores heartbeat tasks run by the Heartbeat
  Manager.
- The timeout duration to obtain the global lock.
- Whether FE ignores the metadata exception caused by materialized view errors.
- Whether non-Leader FEs ignore the metadata gap from the Leader FE.
- Whether to delete a BE after the BE is decommissioned.
- Whether to collect the profile of a query.
- The format of the Profile output by the system.
- Whether to enable the periodic Hive metadata cache refresh.
- The interval between two consecutive Hive metadata cache refreshes.
- The expiration time of a Hive metadata cache refresh task.
- Whether to generate profiles for statistics queries.
- Whether to enable the metadata recovery mode.
- The time duration for retaining historical connection failures of BE nodes in the
  BE Blacklist.
- The threshold of connection failures allowed for a blacklisted BE node.
- Whether to enable the lock manager.
- Whether to refine the granularity of metadata locks from the database level to the
  table level.
- Whether to enable the Legacy Compatibility for Replication.
- The interval at which the Automated Cluster Snapshot tasks are triggered.
- The interval at which FE runs the periodical metadata synchronization with StarMgr
  in a shared-data cluster.
- Before you load data into StarRocks, modify the global time zone of your StarRocks
  cluster to the same value of the system_time_zone parameter.
- Time zone abbreviations are not supported except for CST.
- Frequency limit of 600 calls per minute
- アクセストークンを作成するためには、アプリケーションキーまたはサービスアカウントのシークレットキーとクライアントIDを使用して生成されたbase64エンコード文字列をAuthorizationヘッダーに含める必要があります。
- 最大600回のリクエストが1分間に許可されています。
errors:
- '20000: The request succeeded.'
- 'Any other error code: The request failed.'
- Currently, only IPv4 is supported.
- '20000: リクエストは成功しました。'
- その他のエラーコードが返された場合、リクエストは失敗しました。
- param start_date is invalid
- '20000: Request was successful.'
- Other error codes indicate failure.
- 'PUBLIC_ACCESS_ENABLED: Check your VPC routes to ensure no public access to the
  cluster.'
- 'SERVICE_DIRECTORY_NOT_FOUND: Verify the service name in the Service Directory.'
- '1005: Table creation failed. Returns a specific reason.'
- '1007: Cannot create a database with the same name.'
- '1008: Cannot delete non-existent database.'
- '1044: Cannot access unauthorized database.'
- '1045: Username and password do not match and therefore cannot access the system.'
- '1046: The target database is not specified.'
- '1047: An invalid command is specified.'
- '1049: An invalid database is specified.'
- '1050: A table with the same name already exists.'
- '1051: An invalid table is specified.'
- '1052: The specified column name is ambiguous and therefore the corresponding column
  cannot be uniquely identified.'
- '1053: An illegal data column was specified for the Semi-Join/Anti-Join query.'
- '1054: The specified column does not exist in the table.'
- '1058: The number of columns selected in the query statement does not match the
  number of columns in the query result.'
- '1060: There are duplicate column names.'
- '1064: There is no surviving BE node.'
- '1066: Duplicate table alias appears in the query statement.'
- '1094: Thread ID is invalid.'
- '1095: The non-owner of a thread cannot terminate the thread.'
- '1096: The query statement does not specify the table to be queried.'
- '1102: The database name is incorrect.'
- '1104: The table name is incorrect.'
- '1105: Other errors.'
- '1110: Duplicate columns were specified in the subquery.'
- '1111: Illegal use of aggregation function in `WHERE` clause.'
- '1113: The set of columns in the new table cannot be empty.'
- '1115: Unsupported character sets are used.'
- '1130: An unauthorized IP address is used by the client.'
- '1132: No permission to change user password.'
- '1141: Specified entries don’t have privileges to revoke.'
- '1142: An unauthorized action was performed.'
- '1166: The data column name is incorrect.'
- '1193: System variable has invalid name.'
- '1203: The number of active connections used exceeded the limit.'
- '1211: Not allowed to create new users.'
- '1227: The user has performed an out-of-authority operation.'
- '1228: Session variables cannot be modified by the `SET GLOBAL` command.'
- '1229: Global variables should be modified by the `SET GLOBAL` command.'
- '1230: Related system variables do not have default values.'
- '1231: An invalid value was set for a system variable.'
- '1232: A value of the wrong data type was set for a system variable.'
- '1248: No alias was set for an inline view.'
- '1251: The client does not support the user authentication protocol required by
  the server.'
- '1286: The storage engine is incorrectly configured.'
- '1298: The time zone is incorrectly configured.'
- '1347: The object does not match the expected type.'
- '1353: The specified column number in the `Select` clause of the view is not equal
  to the defined column number.'
- '1364: No default value is set for columns that do not allow NULL values.'
- '1372: The password is not long enough.'
- '1396: The performed operation failed.'
- '1471: The specified table is not allowed to insert data.'
- '1507: Delete nonexistent partition, and no condition is specified to only delete
  existing partitions.'
- '1508: All partitions should be deleted by a delete table operation.'
- '1517: There are duplicate partition names.'
- '1524: The specified plugin has not been loaded.'
- '1567: The name of the partition is incorrect.'
- '1621: The specified system variable is read-only.'
- '1735: The specified partition name does not exist in the table.'
- '1748: Data cannot be inserted into a table that does not have a partition.'
- '1749: The specified partition does not exist.'
- '5000: The specified table is not an OLAP table.'
- '5001: The specified storage path is invalid.'
- '5002: The name of the specified column should be displayed.'
- '5003: The dimension column should be preceded by the index column.'
- '5004: The table should contain at least 1 dimension column.'
- '5005: The cluster ID is invalid.'
- '5006: Invalid query plan.'
- '5007: Conflicting query plans.'
- '5008: The data insert is only available for data tables with partitions.'
- '5009: The `PARTITION` clause cannot be used to insert data into tables without
  partitions.'
- '5010: The number of columns in the table to be created is not equal to the number
  of columns in the `SELECT` clause.'
- '5011: Table reference could not be accessed.'
- '5012: The specified value is not a valid number.'
- '5013: The time unit is not supported.'
- '5014: The table status is not normal.'
- '5015: The partition status is not normal.'
- '5016: A data import job exists in the partition.'
- '5017: The specified column is not a dimension column.'
- '5018: The format of the value is invalid.'
- '5019: The data replica does not match the version.'
- '5021: The BE node is offline.'
- '5022: The number of partitions in a non-partitioned table is not 1.'
- '5023: No action was specified in the statement used to modify the table or data.'
- '5024: Job execution timed out.'
- '5025: Data insertion failed.'
- '5026: An unsupported data type was used when creating a table via the `SELECT`
  statement.'
- '5027: The specified parameter was not set.'
- '5028: The specified cluster was not found.'
- '5030: The user does not have permission to access the cluster.'
- '5031: No parameter specified or invalid parameter.'
- '5032: The number of cluster instances was not specified.'
- '5034: A cluster with the same name already exists.'
- '5035: The number of cluster instances is incorrectly configured.'
- '5036: Insufficient BE nodes in the cluster.'
- '5037: All databases should be deleted before deleting the cluster.'
- '5038: The BE node with the specified ID does not exist in the cluster.'
- '5040: No cluster with the same name exists.'
- '5042: No permissions.'
- '5043: The number of instances should be greater than 0.'
- '5046: Source cluster does not exist.'
- '5047: Destination cluster does not exist.'
- '5048: Source database does not exist.'
- '5049: Destination database does not exist.'
- '5050: No cluster selected.'
- '5051: The source database should be associated with the destination database first.'
- '5052: Intra-cluster error: BE node information is incorrect.'
- '5053: There is no migration task from the source database to the destination database.'
- '5054: The specified database has been associated with the destination database,
  or data is being migrated.'
- '5055: Database associations or data migrations cannot be performed within the same
  cluster.'
- '5056: Database cannot be deleted: it is associated with another database or data
  is being migrated.'
- '5056: Database cannot be renamed: it is associated with another database or data
  is being migrated.'
- '5056: Insufficient BE nodes in the cluster.'
- '5056: The specified number of BE nodes already exists in the cluster.'
- '5059: There are BE nodes in the cluster that are in the offline state.'
- '5063: The type name is incorrect.'
- '5064: Generic error message.'
- '5063: The Colocate feature has been disabled by the administrator.'
- '5063: A colocate data table with the same name does not exist.'
- '5063: The Colocate table must be an OLAP table.'
- '5063: Colocate tables should have the same number of replicas.'
- '5063: Colocate tables should have the same number of split buckets.'
- '5063: Colocate tables should have the same number of partition columns.'
- '5063: Colocate tables should have the same data type of partitioned columns.'
- '5064: The specified table is not a colocate table.'
- '5065: The specified operation is invalid.'
- '5065: The specified time unit is illegal. The correct units are `DAY`, `WEEK`,
  and `MONTH`.'
- '5066: The start value of the dynamic partition should be less than 0.'
- '5066: The start value of the dynamic partition is not a valid number.'
- '5066: The end value of the dynamic partition should be greater than 0.'
- '5066: The end value of the dynamic partition is not a valid number.'
- '5066: The end value of the dynamic partition is null.'
- '5067: The bucket number of the dynamic partition should be greater than 0.'
- '5067: The bucket number of the dynamic partition is not a valid number.'
- '5066: The bucket number of the dynamic partition is empty.'
- '5068: Whether to allow dynamic partition where the value is not a valid boolean:
  true or false.'
- '5069: The name of the specified dynamic partition has an illegal prefix.'
- '5070: The specified operation is disabled.'
- '5071: The number of replicas of the dynamic partition should be greater than 0.'
- '5072: The number of replicas of the dynamic partition is not a valid number.'
- Other error codes indicate the request failed.
- Other error codes indicate a failure.
- 'Message: The time range is out of limits.max:31 days'
- param end_month should less than current month.
- 'REQUEST_LIMIT_EXCEEDED: Throttle API calls or reduce frequency'
- '401 Unauthorized: Recheck OAuth scopes or token expiration'
- Invalid time zone setting may lead to incorrect data loading.
- '401 Unauthorized: Check the Authorization header'
auth_info:
  mentioned_objects: []
client:
  base_url: https://celerdata.com
  auth:
    type: oauth2
    location: header
    header_name: Authorization
source_metadata: null
