resources:
- name: models
  endpoint:
    path: /models
    method: GET
    data_selector: data
- name: batches
  endpoint:
    path: /batches
    method: GET
    data_selector: data
- name: files
  endpoint:
    path: /files
    method: GET
    data_selector: data
- name: fine_tunings
  endpoint:
    path: /fine_tunings
    method: GET
    data_selector: data
- name: chat_completion
  endpoint:
    path: /openai/v1/chat/completions
    method: POST
    data_selector: choices
    params: {}
- name: responses
  endpoint:
    path: /openai/v1/responses
    method: POST
    data_selector: output
    params: {}
- name: audio_transcriptions
  endpoint:
    path: /openai/v1/audio/transcriptions
    method: POST
    data_selector: text
    params: {}
- name: audio_translations
  endpoint:
    path: /openai/v1/audio/translations
    method: POST
    data_selector: text
    params: {}
- name: audio_speech
  endpoint:
    path: /openai/v1/audio/speech
    method: POST
    data_selector: audio
    params: {}
- name: models
  endpoint:
    path: /openai/v1/models
    method: GET
    data_selector: models
    params: {}
- name: chat_completions
  endpoint:
    path: /openai/v1/chat/completions
    method: POST
    data_selector: data
    params: {}
- name: chat_completions
  endpoint:
    path: /openai/v1/chat/completions
    method: POST
    data_selector: response
    params: {}
- name: responses
  endpoint:
    path: /responses
    method: POST
    data_selector: output_text
- name: transcriptions
  endpoint:
    path: /audio/transcriptions
    method: POST
    data_selector: transcription
    params: {}
- name: translations
  endpoint:
    path: /audio/translations
    method: POST
    data_selector: translation
    params: {}
- name: transcriptions
  endpoint:
    path: /audio/transcriptions
    method: POST
    data_selector: transcription
    params:
      file: Required unless using url instead
      url: Required unless using file instead
      model: Required
      response_format: json
      language: Optional
      temperature: '0'
- name: translations
  endpoint:
    path: /audio/translations
    method: POST
    data_selector: translation
    params:
      file: Required unless using url instead
      url: Required unless using file instead
      model: Required
      language: en
      response_format: json
      temperature: '0'
- name: speech
  endpoint:
    path: /openai/v1/audio/speech
    method: POST
    data_selector: response
    params: {}
- name: chat.completions
  endpoint:
    path: /openai/v1/chat/completions
    method: POST
    data_selector: choices
- name: product_review
  endpoint:
    path: /docs/structured-outputs
    method: GET
    data_selector: product_review
    params: {}
- name: sql_query_generation
  endpoint:
    path: /docs/structured-outputs
    method: GET
    data_selector: sql_query_generation
    params: {}
- name: support_ticket_classification
  endpoint:
    path: /docs/structured-outputs
    method: GET
    data_selector: support_ticket_classification
    params: {}
- name: math_response
  endpoint:
    path: /docs/structured-outputs
    method: GET
    data_selector: math_response
    params: {}
- name: web_search
  endpoint:
    path: /web-search
    method: GET
    data_selector: results
- name: browser_search
  endpoint:
    path: /api/browser_search
    method: POST
    data_selector: results
- name: code_execution
  endpoint:
    path: /api/code-execution
    method: POST
    data_selector: message
    params: {}
- name: chat_completions
  endpoint:
    path: /openai/v1/chat/completions
    method: POST
    data_selector: choices
    params: {}
- name: compound_beta
  endpoint:
    path: /docs/compound/systems/compound-beta
    method: GET
- name: compound_beta_mini
  endpoint:
    path: /docs/compound/systems/compound-beta-mini
    method: GET
- name: chat_completion
  endpoint:
    path: /openai/v1/chat/completions
    method: POST
    data_selector: choices
    params: {}
- name: chat_completions
  endpoint:
    path: /v1/chat/completions
    method: POST
    data_selector: responses
- name: audio_transcriptions
  endpoint:
    path: /v1/audio/transcriptions
    method: POST
    data_selector: responses
- name: audio_translations
  endpoint:
    path: /v1/audio/translations
    method: POST
    data_selector: responses
- name: batches
  endpoint:
    path: /v1/batches
    method: POST
    data_selector: results
    params: {}
- name: files
  endpoint:
    path: /v1/files
    method: POST
    data_selector: results
    params: {}
- name: chat_completions
  endpoint:
    path: /v1/chat/completions
    method: POST
    data_selector: results
    params: {}
- name: audio_transcriptions
  endpoint:
    path: /v1/audio/transcriptions
    method: POST
    data_selector: results
    params: {}
- name: audio_translations
  endpoint:
    path: /v1/audio/translations
    method: POST
    data_selector: results
    params: {}
- name: chat_completions
  endpoint:
    path: /openai/v1/chat/completions
    method: POST
    data_selector: response
    params:
      service_tier: flex
- name: Llama Guard 4
  endpoint:
    path: /models/meta-llama/Llama-Guard-4-12B
    method: POST
    data_selector: choices
- name: get_weather_info
  endpoint:
    path: /get_weather_info
    method: GET
    data_selector: parameters
    params:
      location: San Francisco
- name: get_current_weather
  endpoint:
    path: /get_current_weather
    method: GET
    data_selector: parameters
    params:
      location: San Francisco, CA
- name: chat_completions
  endpoint:
    path: /openai/v1/chat/completions
    method: POST
    data_selector: choices
    params: {}
- name: files
  endpoint:
    path: /openai/v1/files
    method: POST
    data_selector: file
    params:
      purpose: fine_tuning
- name: fine_tunings
  endpoint:
    path: /v1/fine_tunings
    method: POST
    data_selector: fine_tuning
    params: {}
- name: chat_completions
  endpoint:
    path: /openai/v1/chat/completions
    method: POST
    data_selector: completion
    params: {}
- name: support_ticket
  endpoint:
    path: /api/support_ticket
    method: POST
    data_selector: ticket
    params: {}
- name: support_ticket
  endpoint:
    path: /support/tickets
    method: POST
    data_selector: records
- name: chat_completions
  endpoint:
    path: /openai/v1/chat/completions
    method: POST
    data_selector: messages
- name: responses
  endpoint:
    path: /openai/v1/responses
    method: POST
    data_selector: responses
    params: {}
- name: chat_completions
  endpoint:
    path: /openai/v1/chat/completions
    method: POST
    data_selector: choices
    params: {}
- name: chat_completions
  endpoint:
    path: /openai/v1/chat/completions
    method: POST
    data_selector: choices
    params: {}
- name: text_to_speech
  endpoint:
    path: /text-to-speech
    method: POST
    data_selector: audio_output
- name: chat_completions
  endpoint:
    path: /chat/completions
    method: POST
    data_selector: choices
    params: {}
notes:
- Customer accepts the Service and Hosted Model as-is, with no representation or warranty
  or condition of any kind.
- Uses OAuth2 with refresh token — requires setup of connected app in api
- Preview models are intended for evaluation purposes only and should not be used
  in production environments as they may be discontinued at short notice.
- Fast LLM inference, OpenAI-compatible.
- Configure your API key as an environment variable to enhance security by minimizing
  the risk of inadvertently including your API key in your codebase.
- The Responses API is currently in beta.
- Rate limits act as control measures to regulate how frequently users and applications
  can access our API within specified timeframes.
- Rate limits apply at the organization level, not individual users.
- Jumpstart your AI-powered applications with Groq's lightning-fast inference templates
  and community-driven solutions.
- 'JSON Schema enforcement: Responses match your schema exactly'
- 'Type-safe outputs: No validation or retry logic needed'
- 'Max File Size: 25 MB (free tier), 100MB (dev tier)'
- 'Minimum Billed Length: 10 seconds'
- Groq API is the fastest speech-to-text solution available, offering OpenAI-compatible
  endpoints.
- The response format defaults to 'wav'.
- User input text to be converted to speech has a maximum length of 10K characters.
- Maximum allowed size for a request containing an image URL as input is 20MB.
- Maximum allowed resolution for a request containing images is 33 megapixels.
- Maximum allowed size for a request containing a base64 encoded image is 4MB.
- You can process a maximum of 5 images.
- Avoid system prompts - include all instructions in the user message!
- 'Recommended temperature range: 0.5-0.7'
- Web search is priced at $5 / 1K queries.
- Web search functionality is powered by Tavily, a search API optimized for AI applications.
- Some models and systems on Groq have native support for access to real-time web
  content.
- Browser search is currently in beta.
- Citations are currently not returned from browser search.
- Only Python is currently supported for code execution.
- Code execution runs in a secure sandboxed environment with no access to external
  networks or sensitive data.
- Code execution is performed on the server side in a secure sandboxed environment.
- Groq's compound AI system should not be used by customers for processing protected
  health information as it is not a HIPAA Covered Cloud Service.
- Batch processing allows handling of large-scale workloads asynchronously.
- The completion window for batch jobs can be set from 24 hours to 7 days.
- You can only request up to 200 batch IDs in a single request.
- Consider splitting very large workloads into multiple smaller batches (e.g. 1000
  requests per batch) for a better chance at completion rather than expiration for
  when we are under heavy load.
- Flex Processing is optimized for high-throughput workloads.
- Llama Guard 4 generates text output that indicates whether a given prompt or response
  is safe or unsafe.
- For some models, adding a newline after the prefill `assistant` message leads to
  better results.
- Use the stop sequence (`stop`) parameter in combination with prefilling for even
  more concise results.
- We recommend tool use with the Instructor library for structured outputs.
- Groq API supports tool use to deliver structured JSON output.
- LoRA is available exclusively to enterprise-tier customers.
- This service is not available currently for use with regional / sovereign endpoints.
- Uses OAuth2 with refresh token — requires setup of connected app in Groq
- Each ticket analysis requires an accurate JSON output for processing.
- Uses OAuth2 with refresh token—requires setup of connected app in api
- Prompt caching works automatically on all your API requests with no code changes
  required and no additional fees.
- Streaming implementation improves perceived latency
- Batch processing enables cost-effective asynchronous processing
- 'Uses various service tiers for processing: On-Demand, Flex, Auto'
- This checklist should be customized based on your specific application requirements
  and updated based on production learnings.
- Spending limits automatically protect your budget by blocking API access when you
  reach your monthly cap.
- There's a 10-15 minute delay in spend tracking.
- Create separate projects for development, staging, and production environments,
  and use descriptive, consistent naming conventions (e.g. "myapp-dev", "myapp-staging",
  "myapp-prod") to avoid conflicts and maintain clear project boundaries.
- Start with conservative limits for new projects, increase limits based on actual
  usage patterns and needs, and monitor usage regularly to adjust as needed.
- Supports domain-based search filtering through parameters like include_domains and
  exclude_domains.
- Prompt caching automatically reuses computation from recent requests.
- Responses API is in beta.
- Regularly check our deprecation page for updates
- Plan migration efforts according to the announced timeline
- 'Leverage the context window: Use the large context window to maintain context for
  large-scale processing'
- 'Simplify complex queries: Break down multi-part questions into clear, small steps
  for more reliable reasoning'
- 'Enable JSON mode: For generating structured data or when you need outputs in a
  specific format'
- 'Include examples: Add sample outputs or specific formats to guide the model into
  specific output structures'
- Uses Groq's TruePoint Numerics for speedup while preserving accuracy.
- Whisper Large v3 is OpenAI's most advanced and capable speech recognition model.
- Optimized for real-time transcription
- Supports 99+ languages
- The model reflects biases present in training data regarding pronunciations and
  accents.
- For best results, keep input text under 10K characters and experiment with different
  voices to find the best fit for your application.
- Compound-beta should not be used by customers for processing protected health information.
  It is not a HIPAA Covered Cloud Service under Groq's Business Associate Addendum
  for customers at this time.
- Compound-beta-mini should not be used by customers for processing protected health
  information.
- Groq's compound AI system should not be used by customers for processing protected
  health information as it is not a HIPAA Covered Cloud Service under Groq's Business
  Associate Addendum at this time.
errors:
- '401 Unauthorized: Check API key or token'
- 'REQUEST_LIMIT_EXCEEDED: Throttle API calls or reduce frequency'
- 'QUERY_TIMEOUT: Break down filters or add selectivity'
- '401 Unauthorized: Recheck OAuth scopes or token expiration'
- '429 Too Many Requests: Exceeding rate limits.'
- '400: Requests larger than the size limit.'
- '413: Requests larger than the base64 size limit.'
- '400: Bad Request - Check the request format and parameters'
- '401: Unauthorized - Verify API key and permissions'
- '429: Too Many Requests - Throttle your requests'
- '403 Forbidden: Check API key or permissions'
- '500 Internal Server Error: Retry the request'
- '401 Unauthorized: Recheck API key or token expiration'
- '401 Unauthorized: Recheck API key'
- 'invalid_method: Invalid value: ''GET''. Supported values are: ''POST'''
- 'unsafe: Indicates content is harmful or inappropriate.'
- '400: Invalid tool call object generated'
- '400: blocked_api_access'
- '400 Bad Request: The server could not understand the request due to invalid syntax.
  Review the request format and ensure it is correct.'
- '401 Unauthorized: The request was not successful because it lacks valid authentication
  credentials for the requested resource. Ensure the request includes the necessary
  authentication credentials and the api key is valid.'
- '404 Not Found: The requested resource could not be found. Check the request URL
  and the existence of the resource.'
- '413 Request Entity Too Large: The request body is too large. Please reduce the
  size of the request body.'
- '422 Unprocessable Entity: The request was well-formed but could not be followed
  due to semantic errors. Verify the data provided for correctness and completeness.'
- '429 Too Many Requests: Too many requests were sent in a given timeframe. Implement
  request throttling and respect rate limits.'
- '498 Custom: Flex Tier Capacity Exceeded: This is a custom status code we use and
  will return in the event that the flex tier is at capacity and the request won''t
  be processed. You can try again later.'
- '499 Custom: Request Cancelled: This is a custom status code we use in our logs
  page to signify when the request is cancelled by the caller.'
- '500 Internal Server Error: A generic error occurred on the server. Try the request
  again later or contact support if the issue persists.'
- '502 Bad Gateway: The server received an invalid response from an upstream server.
  This may be a temporary issue; retrying the request might resolve it.'
- '503 Service Unavailable: The server is not ready to handle the request, often due
  to maintenance or overload. Wait before retrying the request.'
- '206 Partial Content: Only part of the resource is being delivered, usually in response
  to range headers sent by the client. Ensure this is expected for the request being
  made.'
- '401 Unauthorized: Recheck API key or token'
- '400 Bad Request: Check input parameters and request format.'
- '429 Too Many Requests: Throttle your requests and try again.'
auth_info:
  mentioned_objects: []
client:
  base_url: https://api.groq.com
  auth:
    type: apikey
    location: header
    header_name: Authorization
source_metadata: null
