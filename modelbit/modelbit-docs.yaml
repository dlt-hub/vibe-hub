resources:
- name: predict_double
  endpoint:
    path: /deployments/predict_double
    method: POST
    data_selector: result
    params: {}
- name: predict_double
  endpoint:
    path: /v1/predict_double/latest
    method: POST
    data_selector: data
    params: {}
- name: logs
  endpoint:
    path: /deployments/receiving-logs
    method: GET
    data_selector: logs
- name: add_tags
  endpoint:
    path: /api-reference/add_tags/
    method: POST
- name: delete_tags
  endpoint:
    path: /api-reference/delete_tags/
    method: DELETE
- name: get_tags
  endpoint:
    path: /api-reference/get_tags/
    method: GET
- name: GitLab Integration
  endpoint:
    path: /gitlab/integration
    method: POST
    data_selector: integration_status
- name: Azure DevOps Repo
  endpoint:
    path: /api/v1/azure-devops/repo
    method: POST
- name: train_my_predictor
  endpoint:
    path: /api/reference/files/training-metadata-yaml/
    method: GET
    data_selector: records
    params: {}
- name: cpu_jobs
  endpoint:
    path: /jobs/sizes/cpu
    method: GET
    data_selector: training_job_sizes
    params: {}
- name: gpu_jobs
  endpoint:
    path: /jobs/sizes/gpu
    method: GET
    data_selector: training_job_sizes
    params: {}
- name: other_machine_types
  endpoint:
    path: /jobs/sizes/other
    method: GET
    data_selector: machine_types
    params: {}
- name: dataset
  endpoint:
    path: /api/v1/datasets
    method: GET
    data_selector: datasets
- name: historical_fraud_rates
  endpoint:
    path: /api-reference/get_dataset/
    method: GET
    data_selector: rows
    params:
      filters:
        USER_ID: 42
- name: customer_features
  endpoint:
    path: /api-reference/get_dataset/
    method: GET
    data_selector: rows
    params:
      filters:
        CUSTOMER_ID: customerId
- name: refresh_dataset
  endpoint:
    path: /api/c/<WORKSPACE_NAME>/main/datasets/<DATASET_NAME>/refresh
    method: POST
- name: add_model
  endpoint:
    path: /api-reference/add_model/
    method: POST
- name: get_model
  endpoint:
    path: /api-reference/get_model/
    method: GET
- name: model
  endpoint:
    path: /api-reference/add_model/
    method: POST
    data_selector: model
    params: {}
- name: model_metrics
  endpoint:
    path: /api-reference/add_model
    method: POST
- name: add_models
  endpoint:
    path: /api-reference/add_models/
    method: POST
- name: get_model
  endpoint:
    path: /api-reference/get_model/
    method: GET
- name: Snowflake warehouse
  endpoint:
    path: /warehouses/snowflake/
    method: GET
- name: Redshift warehouse
  endpoint:
    path: /warehouses/redshift/
    method: GET
- name: Athena warehouse
  endpoint:
    path: /warehouses/athena/
    method: GET
- name: BigQuery warehouse
  endpoint:
    path: /warehouses/bigquery/
    method: GET
- name: Databricks warehouse
  endpoint:
    path: /warehouses/databricks/
    method: GET
- name: modelbit_role
  endpoint:
    path: /create-role
    method: POST
    data_selector: role_creation_response
- name: modelbit_user
  endpoint:
    path: /create-user
    method: POST
    data_selector: user_creation_response
- name: warehouse_usage
  endpoint:
    path: /grant-usage-warehouse
    method: POST
    data_selector: usage_grant_response
- name: database_usage
  endpoint:
    path: /grant-usage-database
    method: POST
    data_selector: usage_grant_response
- name: schema_usage
  endpoint:
    path: /grant-usage-schema
    method: POST
    data_selector: usage_grant_response
- name: table_select
  endpoint:
    path: /grant-select-table
    method: POST
    data_selector: select_grant_response
- name: modelbit_user
  endpoint:
    path: /create_user
    method: POST
    data_selector: user
    params:
      password: <choose a password>
- name: Athena Warehouse
  endpoint:
    path: /settings/athena
    method: POST
    data_selector: warehouse
    params: {}
- name: databricks_compute
  endpoint:
    path: /api/2.0/clusters/list
    method: GET
- name: fraud_detection_feature_service
  endpoint:
    path: /api/v1/feature-service/get-features
    method: POST
    data_selector: result.features
- name: logs
  endpoint:
    path: /deployments/receiving-logs
    method: POST
    data_selector: data
- name: logs
  endpoint:
    path: /deployment/logs
    method: POST
    headers:
      x-mb-webhook-secret: your_secret_value
- name: add_common_files
  endpoint:
    path: /api-reference/add_common_files/
    method: POST
    data_selector: files
    params: {}
- name: add_files
  endpoint:
    path: /api-reference/add_files/
    method: POST
    data_selector: parameters
    params: {}
- name: add_job
  endpoint:
    path: /api-reference/add_job/
    method: POST
    data_selector: job
    params: {}
- name: metrics
  endpoint:
    path: /add_metrics
    method: POST
    data_selector: metrics
    params: {}
- name: add_models
  endpoint:
    path: /api-reference/add_models/
    method: POST
    data_selector: models
    params: {}
- name: add_package
  endpoint:
    path: /api-reference/add_package/
    method: POST
    data_selector: parameters
    params:
      path: str
      force: Optional[bool]
      branch: Optional[str]
- name: add_tags
  endpoint:
    path: /api-reference/add_tags/
    method: POST
    data_selector: tags
    params:
      deployment: str
      tags: List[str]
      overwrite: Optional[bool]
      branch: Optional[str]
- name: common_files
  endpoint:
    path: /api-reference/common_files/
    method: GET
    data_selector: List[str]
    params:
      prefix: Optional[str]
- name: create_branch
  endpoint:
    path: /api-reference/create_branch/
    method: POST
    data_selector: parameters
    params: {}
- name: datasets
  endpoint:
    path: /datasets/
    method: GET
    data_selector: datasets
- name: delete_common_files
  endpoint:
    path: /api-reference/delete_common_files/
    method: DELETE
    data_selector: status
    params:
      names: Union[str, List[str]]
- name: delete_models
  endpoint:
    path: /api-reference/delete_models/
    method: POST
    data_selector: models
    params:
      names: Union[str, List[str]]
- name: delete_package
  endpoint:
    path: /api_reference/delete_package
    method: POST
    data_selector: parameters
    params:
      name: string
      version: string
      branch: Optional[string]
- name: delete_tags
  endpoint:
    path: /delete_tags
    method: POST
    data_selector: ''
    params:
      deployment: str
      branch: Optional[str]
- name: deploy
  endpoint:
    path: /api-reference/deploy/
    method: POST
    data_selector: deployment
    params: {}
- name: disable_keep_warm
  endpoint:
    path: /api-reference/disable_keep_warm/
    method: POST
    data_selector: message
    params:
      deployment: str
      version: int
      branch: Optional[str]
- name: enable_keep_warm
  endpoint:
    path: /api/enable_keep_warm
    method: POST
    data_selector: response
    params:
      deployment: my_deployment
      version: 12
- name: get_branch
  endpoint:
    path: /api-reference/get_branch/
    method: GET
- name: dataset
  endpoint:
    path: /get_dataset
    method: GET
    data_selector: DataFrame
    params: {}
- name: deployment_info
  endpoint:
    path: /get_deployment_info
    method: GET
    data_selector: branch, name, version
- name: get_inference
  endpoint:
    path: /api-reference/get_inference/
    method: POST
- name: metrics
  endpoint:
    path: /get_metrics
    method: GET
    data_selector: Dict[str, Any]
    params:
      name_or_names: Union[str, List[str]]
- name: get_model
  endpoint:
    path: /api-reference/get_model/
    method: GET
    data_selector: Any
    params:
      name: str
      file: Optional[str]
      branch: Optional[str]
- name: get_models
  endpoint:
    path: /get_models
    method: GET
    data_selector: models
    params: {}
- name: get_secret
  endpoint:
    path: /api-reference/get_secret/
    method: GET
    data_selector: str
    params:
      name: str
      ignore_missing: Optional[bool]
- name: get_snowflake_mock_return_value
  endpoint:
    path: /api-reference/get_snowflake_mock_return_value/
    method: GET
    data_selector: Any
    params:
      deployment_name: str
      branch: Optional[str]
      version: Optional[int]
- name: tags
  endpoint:
    path: /get_tags
    method: GET
    data_selector: List[str]
    params:
      deployment: str
- name: keep_warms
  endpoint:
    path: /api-reference/keep_warms/
    method: GET
    data_selector: deployments
    params:
      branch: Optional[str]
- name: log_image
  endpoint:
    path: /api-reference/log_image/
    method: POST
    data_selector: image
    params: {}
- name: login
  endpoint:
    path: /api-reference/login/
    method: POST
- name: merge_deployment
  endpoint:
    path: /merge_deployment
    method: POST
    data_selector: status
    params:
      deployment_name: example_deployment
      to_branch: prod
      from_branch: staging
- name: models
  endpoint:
    path: /api-reference/models/
    method: GET
    data_selector: List[str]
    params: {}
- name: restart_deployment
  endpoint:
    path: /restart_deployment
    method: POST
    data_selector: ''
    params:
      deployment_name: str
      version: Optional[str,'latest']
      branch: Optional[str]
- name: run_job
  endpoint:
    path: /api-reference/run_job/
    method: POST
    data_selector: instance of ModelbitJob
    params: {}
- name: set_snowflake_mock_return_value
  endpoint:
    path: /api-reference/set_snowflake_mock_return_value/
    method: POST
    data_selector: None
    params: {}
- name: setup
  endpoint:
    path: /api-reference/setup/
    method: GET
    data_selector: parameters
    params: {}
- name: switch_branch
  endpoint:
    path: /api-reference/switch_branch/
    method: POST
    data_selector: branch
    params: {}
- name: trace
  endpoint:
    path: /api-reference/trace/
    method: GET
    data_selector: performance traces
    params: {}
- name: add_common_files
  endpoint:
    path: /api-reference/add_common_files/
    method: GET
    data_selector: parameters
    params: {}
- name: deployment
  endpoint:
    path: /api-reference/deployment/
    method: GET
    data_selector: deployments
    params: {}
- name: add_model
  endpoint:
    path: /api-reference/add_model/
    method: POST
    data_selector: records
    params: {}
- name: get_model
  endpoint:
    path: /api-reference/get_model/
    method: GET
    data_selector: records
    params: {}
- name: list_private_packages
  endpoint:
    path: /api-reference/package/list
    method: GET
- name: add_private_package
  endpoint:
    path: /api-reference/package/add
    method: POST
- name: delete_private_package
  endpoint:
    path: /api-reference/package/delete
    method: DELETE
- name: validate_workspace
  endpoint:
    path: /validate
    method: GET
    data_selector: validations
    params: {}
notes:
- Uses API key for authentication
- 'Make sure to update owner: ... to your email address.'
- Modelbit allows specifying Python packages and system packages for deployments.
- You can create API keys in the Settings area of Modelbit, and send them to deployments
  in the Authorization header.
- Modelbit can send your model an entire batch as a DataFrame, and accept any iterable
  as a return value.
- Modelbit's Slack Alerting integration is recommended for quick and easy alerting
  on model errors.
- For more robust alerting, Modelbit's DataDog integration or with logging webhooks
  can be paired with pager systems like PagerDuty or OpsGenie.
- Logs the inputs, responses, runtimes, and other metadata related to deployments.
- Different compute environments have different costs.
- Modelbit runs your inferences rapidly across autoscaling hardware to minimize latency
  and maximize throughput.
- The Modelbit platform enforces rate limits to manage the aggregate load of inferences
  across all the deployments running on the platform.
- Requests that have been sent to Modelbit but have not yet completed are in-flight
  and count against this limit.
- Modelbit is backed by Git instead of a traditional database. This allows you to
  version control all of your deployments, models and datasets.
- Create a new, empty Git repository for use with Modelbit.
- Must check the `Allow write access` box for the Deploy Key.
- You must check the 'Grant write permissions to this key' box in order for Modelbit
  to push changes to this repository.
- This workflow requires you to have admin permissions within your Azure DevOps project.
- Make sure to leave the `Add a README` box checked. Below it you'll see the message
  'Your repository will be initialized with a `main` branch'. This is necessary for
  Modelbit to connect.
- Branches allow you to work separately from your teammates.
- Pushing a newly created branch will create a fork of your workspace.
- Modelbit works with your branch protection rules in GitHub and GitLab by preventing
  changes that don't come from approved merge requests.
- Deployments, datasets, endpoints, and other assets on protected branches will no
  longer be editable in Modelbit's web app or using the modelbit Python package.
- Make sure your notebook is logged into Modelbit
- Make sure to update owner in metadata.yaml to your email address.
- Review the entire schema definition and examples of metadata.yaml in the API Reference.
- You can store metadata about the models you train in Modelbit's model registry as
  metrics.
- Datasets are DataFrames for use as feature stores in deployments and training data.
- Webhooks can be called from any REST-friendly environment.
- API Keys can be created and managed in Settings.
- Request aliasing allows you to change the Modelbit deployment behind the URL without
  changing the URL.
- Request splitting allows you to run A/B tests among different versions of a deployment
  without the calling application needing to implement A/B testing logic.
- To avoid errors, the deployments configured in each split should expect the same
  input format.
- Using alternatives to pickle can come with their own drawbacks.
- For large file-based models, download them once by calling mb.get_model after your
  import statements.
- Models are cached in the deployment so subsequent calls to get_model are instant.
- Modelbit's name for all of this metadata is 'metrics'.
- We recommend creating a separate user for Modelbit.
- To add an Athena warehouse, click `Add a Warehouse` within `Settings`, choose `Athena`
  and name the connection.
- 'Include roles: BigQuery Job User, BigQuery Data Viewer'
- Download the associated credentials file in JSON format
- Locate your Space Key and API Key in Arize on the Space Settings page.
- Use mb.get_secret to load your Arize API keys.
- You can access AWS resources in Modelbit by storing your AWS Access Key ID and AWS
  Secret Access Key as Modelbit Secrets.
- Log files will be written to the data source that is connected as a Warehouse.
- Ensure that your Personal Access Token has permissions to write files to the datastore.
- The NEPTUNE_API_TOKEN is available as an environment variable for training jobs.
- You can integrate Modelbit with Slack to receive alerts when deployments return
  errors.
- Logs will be posted to this URL frequently in batches, typically within seconds
  of when the inferences took place.
- Make sure your webhook supports 6MB bodies.
- Modelbit is built from the ground up with best-in-class security practices, and
  with the privacy of your data in mind.
- Best practices are to have one API key per data scientist who may do testing, plus
  one API key per production environment that will call REST APIs
- Make sure to enable 'Deployments Require API Keys.'
- Customers on the Enterprise plan may use Okta instead of Google as the SSO provider
  for their workspace.
- Workspace users can have multiple roles.
- Changes to IP filters take about 1 minute to roll out to all of your deployments.
- By default, deployments accept REST API traffic from all IP addresses.
- REST API traffic that doesn't match an IP filter will be rejected with the error
  Request Forbidden.
- Customers on enterprise plans can connect to Modelbit's inference APIs without traversing
  the public internet.
- Get notified when your usage exceeds daily, weekly or monthly thresholds by setting
  up billing alerts.
- Handles serialization, network session reuse, retries, and large batch chunking.
- Tracing is most helpful on deployments that take at least 100ms to complete.
- Individual traces shorter than 10ms are not recorded.
- Don't use `git clone` with Modelbit workspaces. Using `modelbit clone` ensures your
  local repo is configured to work with Modelbit.
errors:
- 'RateLimitExceeded: Concurrency request count limit reached'
- 'RateLimitExceeded: Concurrency request size limit reached'
- '401 Unauthorized: Recheck API key or workspace setup'
auth_info:
  mentioned_objects:
  - OPENAI_API_KEY
  - Service Account
  - Tecton API key
client:
  base_url: https://us-east-2.aws.modelbit.com
  auth:
    type: oauth2
source_metadata: null
