resources:
- name: document_elements
  endpoint:
    path: /api/partition/document/elements
    method: GET
    data_selector: elements
- name: Element
  endpoint:
    path: /api-reference/partition/document-elements
    method: GET
    data_selector: elements
- name: document_elements
  endpoint:
    path: /api-reference/partition/document-elements
    method: GET
    data_selector: elements
- name: document_processing
  endpoint:
    path: /api/v1/documents
    method: POST
    data_selector: data
    params: {}
- name: create_destination_connection_check
  endpoint:
    path: /api/v1/destinations/{destination_id}/connection-check
    method: POST
- name: create_destination_connector
  endpoint:
    path: /api/v1/destinations/
    method: POST
- name: delete_destination_connector
  endpoint:
    path: /api/v1/destinations/{destination_id}
    method: DELETE
- name: get_destination_connector
  endpoint:
    path: /api/v1/destinations/{destination_id}
    method: GET
- name: get_latest_destination_connector_connection_check
  endpoint:
    path: /api/v1/destinations/{destination_id}/connection-check
    method: GET
- name: create_destination_connection_check
  endpoint:
    path: /api/v1/destinations/{destination_id}/connection-check
    method: POST
- name: create_destination_connector
  endpoint:
    path: /api/v1/destinations/
    method: POST
- name: delete_destination_connector
  endpoint:
    path: /api/v1/destinations/{destination_id}
    method: DELETE
- name: get_destination_connector
  endpoint:
    path: /api/v1/destinations/{destination_id}
    method: GET
- name: get_latest_destination_connector_connection_check
  endpoint:
    path: /api/v1/destinations/{destination_id}/connection-check
    method: GET
- name: list_destination_connectors
  endpoint:
    path: /api/v1/destinations/
    method: GET
- name: update_destination_connector
  endpoint:
    path: /api/v1/destinations/{destination_id}
    method: PUT
- name: cancel_job
  endpoint:
    path: /api/v1/jobs/{job_id}/cancel
    method: POST
- name: download_job_output
  endpoint:
    path: /api/v1/jobs/{job_id}/download
    method: GET
- name: get_job
  endpoint:
    path: /api/v1/jobs/{job_id}
    method: GET
- name: get_job_failed_files
  endpoint:
    path: /api/v1/jobs/{job_id}/failed-files
    method: GET
- name: get_job_processing_details
  endpoint:
    path: /api/v1/jobs/{job_id}/details
    method: GET
- name: list_jobs
  endpoint:
    path: /api/v1/jobs/
    method: GET
- name: create_destination_connection_check
  endpoint:
    path: /api/v1/destinations/{destination_id}/connection-check
    method: POST
- name: create_destination_connector
  endpoint:
    path: /api/v1/destinations/
    method: POST
- name: delete_destination_connector
  endpoint:
    path: /api/v1/destinations/{destination_id}
    method: DELETE
- name: get_destination_connector
  endpoint:
    path: /api/v1/destinations/{destination_id}
    method: GET
- name: get_latest_destination_connector_connection_check
  endpoint:
    path: /api/v1/destinations/{destination_id}/connection-check
    method: GET
- name: partition
  endpoint:
    path: /api-reference/partition
    method: POST
    data_selector: elements
    params: {}
- name: create_destination_connection_check
  endpoint:
    path: /api/v1/destinations/{destination_id}/connection-check
    method: POST
- name: create_destination_connector
  endpoint:
    path: /api/v1/destinations/
    method: POST
- name: delete_destination_connector
  endpoint:
    path: /api/v1/destinations/{destination_id}
    method: DELETE
- name: get_destination_connector
  endpoint:
    path: /api/v1/destinations/{destination_id}
    method: GET
- name: get_latest_destination_connector_connection_check
  endpoint:
    path: /api/v1/destinations/{destination_id}/connection-check
    method: GET
- name: list_destination_connectors
  endpoint:
    path: /api/v1/destinations/
    method: GET
- name: update_destination_connector
  endpoint:
    path: /api/v1/destinations/{destination_id}
    method: PUT
- name: cancel_job
  endpoint:
    path: /api/v1/jobs/{job_id}/cancel
    method: POST
- name: download_job_output
  endpoint:
    path: /api/v1/jobs/{job_id}/download
    method: GET
- name: get_job
  endpoint:
    path: /api/v1/jobs/{job_id}
    method: GET
- name: get_job_failed_files
  endpoint:
    path: /api/v1/jobs/{job_id}/failed-files
    method: GET
- name: get_job_processing_details
  endpoint:
    path: /api/v1/jobs/{job_id}/details
    method: GET
- name: list_jobs
  endpoint:
    path: /api/v1/jobs/
    method: GET
- name: partition
  endpoint:
    path: /partition
    method: POST
    data_selector: elements
    params: {}
- name: partition
  endpoint:
    path: ''
    method: POST
    data_selector: elements
- name: partition
  endpoint:
    path: /general/partition
    method: POST
    data_selector: elements
    params: {}
- name: partition
  endpoint:
    path: /partition
    method: POST
    data_selector: elements
- name: index
  endpoint:
    path: /indexes
    method: GET
    data_selector: '@odata.context'
    params: {}
- name: extract_image_block_types
  endpoint:
    path: /api/v1/partition/extract-image-block-types
    method: POST
    data_selector: elements
- name: generate_schema
  endpoint:
    path: /api/v1/partition/generate-schema
    method: POST
    data_selector: schema
- name: get_chunked_elements
  endpoint:
    path: /api/v1/partition/get-chunked-elements
    method: GET
    data_selector: elements
- name: get_elements
  endpoint:
    path: /api/v1/partition/get-elements
    method: GET
    data_selector: elements
- name: subject
  endpoint:
    path: /services/data/vXX.X/sobjects/Subject
    method: GET
    data_selector: records
- name: section
  endpoint:
    path: /services/data/vXX.X/sobjects/Section
    method: GET
    data_selector: records
- name: header_footer_type
  endpoint:
    path: /services/data/vXX.X/sobjects/HeaderFooterType
    method: GET
    data_selector: records
- name: emphasized_text_contents
  endpoint:
    path: /services/data/vXX.X/sobjects/EmphasizedTextContents
    method: GET
    data_selector: records
- name: emphasized_text_tags
  endpoint:
    path: /services/data/vXX.X/sobjects/EmphasizedTextTags
    method: GET
    data_selector: records
- name: text_as_html
  endpoint:
    path: /services/data/vXX.X/sobjects/TextAsHtml
    method: GET
    data_selector: records
- name: regex_metadata
  endpoint:
    path: /services/data/vXX.X/sobjects/RegexMetadata
    method: GET
    data_selector: records
- name: detection_class_prob
  endpoint:
    path: /services/data/vXX.X/sobjects/DetectionClassProb
    method: GET
    data_selector: records
- name: partitioner_type
  endpoint:
    path: /services/data/vXX.X/sobjects/PartitionerType
    method: GET
    data_selector: records
- name: partition
  endpoint:
    path: /general
    method: POST
    data_selector: elements
- name: destination
  endpoint:
    path: /destinations
    method: POST
    data_selector: destination_connector_information
- name: partition
  endpoint:
    path: /api/partition
    method: POST
    data_selector: elements
- name: delta_table
  endpoint:
    path: /api/delta/tables
    method: POST
- name: kafka-cloud
  endpoint:
    path: /destinations
    method: POST
    data_selector: destination_connector_information
    params: {}
- name: ibm_watsonx_s3
  endpoint:
    path: /destinations
    method: POST
    data_selector: destination_connector_information
    params: {}
- name: my-index-name
  endpoint:
    path: /indexes/my-index-name
    method: GET
    data_selector: '@odata.context'
    params: {}
- name: milvus
  endpoint:
    path: /destinations
    method: POST
    data_selector: destination_connector_information
- name: mongodb
  endpoint:
    path: /destinations
    method: POST
    data_selector: destination_connector_information
- name: motherduck
  endpoint:
    path: /destinations
    method: POST
    data_selector: destination_connector_information
- name: onedrive
  endpoint:
    path: /destinations
    method: POST
- name: destination_connector
  endpoint:
    path: /destinations
    method: POST
- name: subject
  endpoint:
    path: /services/data/vXX.X/sobjects/Subject
    method: GET
    data_selector: records
- name: section
  endpoint:
    path: /services/data/vXX.X/sobjects/Section
    method: GET
    data_selector: records
- name: header_footer_type
  endpoint:
    path: /services/data/vXX.X/sobjects/HeaderFooterType
    method: GET
    data_selector: records
- name: emphasized_text_contents
  endpoint:
    path: /services/data/vXX.X/sobjects/EmphasizedTextContents
    method: GET
    data_selector: records
- name: emphasized_text_tags
  endpoint:
    path: /services/data/vXX.X/sobjects/EmphasizedTextTags
    method: GET
    data_selector: records
- name: text_as_html
  endpoint:
    path: /services/data/vXX.X/sobjects/TextAsHtml
    method: GET
    data_selector: records
- name: regex_metadata
  endpoint:
    path: /services/data/vXX.X/sobjects/RegexMetadata
    method: GET
    data_selector: records
- name: detection_class_prob
  endpoint:
    path: /services/data/vXX.X/sobjects/DetectionClassProb
    method: GET
    data_selector: records
- name: partitioner_type
  endpoint:
    path: /services/data/vXX.X/sobjects/PartitionerType
    method: GET
    data_selector: records
- name: destination_connector
  endpoint:
    path: /destinations
    method: POST
    data_selector: destination_connector_information
- name: destination
  endpoint:
    path: /destinations
    method: POST
    data_selector: destination_connector_information
- name: elements
  endpoint:
    path: /elements
    method: POST
    data_selector: elements
- name: destination_connector
  endpoint:
    path: /destinations
    method: POST
    data_selector: destination_connector_information
- name: sources
  endpoint:
    path: /sources
    method: GET
    data_selector: response_list_sources
- name: destination
  endpoint:
    path: /destinations
    method: POST
    data_selector: destination_connector_information
- name: destination_connector
  endpoint:
    path: /destinations
    method: POST
    data_selector: destination_connector_information
    params: {}
- name: update_destination_connector
  endpoint:
    path: /api/v1/destinations/{destination_id}
    method: PUT
- name: cancel_job
  endpoint:
    path: /api/v1/jobs/{job_id}/cancel
    method: POST
- name: download_job_output
  endpoint:
    path: /api/v1/jobs/{job_id}/download
    method: GET
- name: get_job
  endpoint:
    path: /api/v1/jobs/{job_id}
    method: GET
- name: get_job_failed_files
  endpoint:
    path: /api/v1/jobs/{job_id}/failed-files
    method: GET
- name: get_job_processing_details
  endpoint:
    path: /api/v1/jobs/{job_id}/details
    method: GET
- name: list_jobs
  endpoint:
    path: /api/v1/jobs/
    method: GET
- name: databricks_volumes
  endpoint:
    path: /sources
    method: POST
    data_selector: destination_connector_information
- name: destination_connector
  endpoint:
    path: /destinations
    method: POST
    data_selector: destination_connector_information
- name: CloudFormation Stack
  endpoint:
    path: /cloudformation/stack
    method: POST
    data_selector: stackDetails
- name: kafka-cloud
  endpoint:
    path: /destinations
    method: POST
    data_selector: destination_connector_information
- name: milvus
  endpoint:
    path: /destinations
    method: POST
    data_selector: destination_connector_information
- name: my_collection
  endpoint:
    path: /create_collection
    method: POST
    data_selector: response
    params: {}
- name: destination
  endpoint:
    path: /destinations
    method: POST
    data_selector: destination_connector_information
- name: create-destination-connection-check
  endpoint:
    path: /api/v1/destinations/{destination_id}/connection-check
    method: POST
- name: create-destination-connector
  endpoint:
    path: /api/v1/destinations/
    method: POST
- name: delete-destination-connector
  endpoint:
    path: /api/v1/destinations/{destination_id}
    method: DELETE
- name: get-destination-connector
  endpoint:
    path: /api/v1/destinations/{destination_id}
    method: GET
- name: get-the-latest-destination-connector-connection-check
  endpoint:
    path: /api/v1/destinations/{destination_id}/connection-check
    method: GET
- name: list-destination-connectors
  endpoint:
    path: /api/v1/destinations/
    method: GET
- name: update-destination-connector
  endpoint:
    path: /api/v1/destinations/{destination_id}
    method: PUT
- name: cancel-job
  endpoint:
    path: /api/v1/jobs/{job_id}/cancel
    method: POST
- name: download-job-output
  endpoint:
    path: /api/v1/jobs/{job_id}/download
    method: GET
- name: get-job
  endpoint:
    path: /api/v1/jobs/{job_id}
    method: GET
- name: get-job-failed-files
  endpoint:
    path: /api/v1/jobs/{job_id}/failed-files
    method: GET
- name: get-job-processing-details
  endpoint:
    path: /api/v1/jobs/{job_id}/details
    method: GET
- name: list-jobs
  endpoint:
    path: /api/v1/jobs/
    method: GET
- name: redis
  endpoint:
    path: /destinations
    method: POST
    data_selector: destination_connector_information
- name: s3
  endpoint:
    path: /destinations
    method: POST
    data_selector: destination_connector_information
- name: partition
  endpoint:
    path: /api/partition
    method: POST
    data_selector: elements
- name: destinations
  endpoint:
    path: /destinations
    method: POST
    data_selector: config
- name: update_destinations
  endpoint:
    path: /destinations/<connector-id>
    method: PUT
    data_selector: config
- name: partition
  endpoint:
    path: /partition
    method: POST
    data_selector: elements
- name: partition
  endpoint:
    path: /general/v0/general
    method: POST
    data_selector: elements
- name: cancel_job
  endpoint:
    path: /api/v1/jobs/{job_id}/cancel
    method: POST
- name: download_job_output
  endpoint:
    path: /api/v1/jobs/{job_id}/download
    method: GET
- name: get_job
  endpoint:
    path: /api/v1/jobs/{job_id}
    method: GET
- name: get_job_failed_files
  endpoint:
    path: /api/v1/jobs/{job_id}/failed-files
    method: GET
- name: get_job_processing_details
  endpoint:
    path: /api/v1/jobs/{job_id}/details
    method: GET
- name: list_jobs
  endpoint:
    path: /api/v1/jobs/
    method: GET
- name: CloudFormation
  endpoint:
    path: /stacks
    method: GET
    data_selector: Stacks
- name: create_destination_connection_check
  endpoint:
    path: /api/v1/destinations/{destination_id}/connection-check
    method: POST
- name: create_destination_connector
  endpoint:
    path: /api/v1/destinations/
    method: POST
- name: delete_destination_connector
  endpoint:
    path: /api/v1/destinations/{destination_id}
    method: DELETE
- name: get_destination_connector
  endpoint:
    path: /api/v1/destinations/{destination_id}
    method: GET
- name: get_the_latest_destination_connector_connection_check
  endpoint:
    path: /api/v1/destinations/{destination_id}/connection-check
    method: GET
- name: list_destination_connectors
  endpoint:
    path: /api/v1/destinations/
    method: GET
- name: update_destination_connector
  endpoint:
    path: /api/v1/destinations/{destination_id}
    method: PUT
- name: cancel_job
  endpoint:
    path: /api/v1/jobs/{job_id}/cancel
    method: POST
- name: download_job_output
  endpoint:
    path: /api/v1/jobs/{job_id}/download
    method: GET
- name: get_job
  endpoint:
    path: /api/v1/jobs/{job_id}
    method: GET
- name: get_job_failed_files
  endpoint:
    path: /api/v1/jobs/{job_id}/failed-files
    method: GET
- name: get_job_processing_details
  endpoint:
    path: /api/v1/jobs/{job_id}/details
    method: GET
- name: list_jobs
  endpoint:
    path: /api/v1/jobs/
    method: GET
- name: Unstructured Workflow
  endpoint:
    path: /api/v1/workflow
    method: POST
    data_selector: results
- name: Unstructured Partition
  endpoint:
    path: /api/v1/partition
    method: POST
    data_selector: results
- name: create_destination_connection_check
  endpoint:
    path: /api/v1/destinations/{destination_id}/connection-check
    method: POST
- name: create_destination_connector
  endpoint:
    path: /api/v1/destinations/
    method: POST
- name: delete_destination_connector
  endpoint:
    path: /api/v1/destinations/{destination_id}
    method: DELETE
- name: get_destination_connector
  endpoint:
    path: /api/v1/destinations/{destination_id}
    method: GET
- name: get_latest_destination_connector_connection_check
  endpoint:
    path: /api/v1/destinations/{destination_id}/connection-check
    method: GET
- name: list_destination_connectors
  endpoint:
    path: /api/v1/destinations/
    method: GET
- name: update_destination_connector
  endpoint:
    path: /api/v1/destinations/{destination_id}
    method: PUT
- name: cancel_job
  endpoint:
    path: /api/v1/jobs/{job_id}/cancel
    method: POST
- name: download_job_output
  endpoint:
    path: /api/v1/jobs/{job_id}/download
    method: GET
- name: get_job
  endpoint:
    path: /api/v1/jobs/{job_id}
    method: GET
- name: get_job_failed_files
  endpoint:
    path: /api/v1/jobs/{job_id}/failed-files
    method: GET
- name: get_job_processing_details
  endpoint:
    path: /api/v1/jobs/{job_id}/details
    method: GET
- name: list_jobs
  endpoint:
    path: /api/v1/jobs/
    method: GET
- name: partition
  endpoint:
    path: /partition
    method: POST
    data_selector: elements
    params: {}
- name: Unstructured Workflow Endpoint
  endpoint:
    path: /api-reference/workflow/overview
    method: POST
    data_selector: results
- name: Unstructured Partition Endpoint
  endpoint:
    path: /api-reference/partition/overview
    method: POST
    data_selector: results
- name: chroma_data
  endpoint:
    path: /chroma/data
    method: POST
    data_selector: data
    params: {}
- name: partition
  endpoint:
    path: /partition
    method: POST
    data_selector: elements
- name: partition
  endpoint:
    path: ''
    method: POST
    data_selector: elements
- name: create_destination_connection_check
  endpoint:
    path: /api/v1/destinations/{destination_id}/connection-check
    method: POST
- name: create_destination_connector
  endpoint:
    path: /api/v1/destinations/
    method: POST
- name: delete_destination_connector
  endpoint:
    path: /api/v1/destinations/{destination_id}
    method: DELETE
- name: get_destination_connector
  endpoint:
    path: /api/v1/destinations/{destination_id}
    method: GET
- name: get_latest_destination_connector_connection_check
  endpoint:
    path: /api/v1/destinations/{destination_id}/connection-check
    method: GET
- name: list_destination_connectors
  endpoint:
    path: /api/v1/destinations/
    method: GET
- name: update_destination_connector
  endpoint:
    path: /api/v1/destinations/{destination_id}
    method: PUT
- name: cancel_job
  endpoint:
    path: /api/v1/jobs/{job_id}/cancel
    method: POST
- name: download_job_output
  endpoint:
    path: /api/v1/jobs/{job_id}/download
    method: GET
- name: get_job
  endpoint:
    path: /api/v1/jobs/{job_id}
    method: GET
- name: get_job_failed_files
  endpoint:
    path: /api/v1/jobs/{job_id}/failed-files
    method: GET
- name: get_job_processing_details
  endpoint:
    path: /api/v1/jobs/{job_id}/details
    method: GET
- name: list_jobs
  endpoint:
    path: /api/v1/jobs/
    method: GET
- name: partition
  endpoint:
    path: /api/partition
    method: POST
    data_selector: elements
- name: create_destination_connection_check
  endpoint:
    path: /api/v1/destinations/{destination_id}/connection-check
    method: POST
- name: create_destination_connector
  endpoint:
    path: /api/v1/destinations/
    method: POST
- name: delete_destination_connector
  endpoint:
    path: /api/v1/destinations/{destination_id}
    method: DELETE
- name: get_destination_connector
  endpoint:
    path: /api/v1/destinations/{destination_id}
    method: GET
- name: get_latest_destination_connector_connection_check
  endpoint:
    path: /api/v1/destinations/{destination_id}/connection-check
    method: GET
- name: list_destination_connectors
  endpoint:
    path: /api/v1/destinations/
    method: GET
- name: update_destination_connector
  endpoint:
    path: /api/v1/destinations/{destination_id}
    method: PUT
- name: cancel_job
  endpoint:
    path: /api/v1/jobs/{job_id}/cancel
    method: POST
- name: download_job_output
  endpoint:
    path: /api/v1/jobs/{job_id}/download
    method: GET
- name: get_job
  endpoint:
    path: /api/v1/jobs/{job_id}
    method: GET
- name: get_job_failed_files
  endpoint:
    path: /api/v1/jobs/{job_id}/failed-files
    method: GET
- name: get_job_processing_details
  endpoint:
    path: /api/v1/jobs/{job_id}/details
    method: GET
- name: list_jobs
  endpoint:
    path: /api/v1/jobs/
    method: GET
- name: partition
  endpoint:
    path: /
    method: POST
    data_selector: elements
    params: {}
- name: partition
  endpoint:
    path: ''
    method: POST
    data_selector: elements
- name: partition
  endpoint:
    path: /general/partition
    method: POST
    data_selector: elements
- name: CompositeElement
  endpoint:
    path: /composite/elements
    method: GET
    data_selector: elements
    params: {}
- name: Table
  endpoint:
    path: /table/elements
    method: GET
    data_selector: elements
    params: {}
- name: chroma
  endpoint:
    path: /api/chroma
    method: POST
    data_selector: elements
    params: {}
- name: chroma
  endpoint:
    path: /chroma
    method: POST
    data_selector: records
- name: Chroma Cloud
  endpoint:
    path: /
    method: POST
    data_selector: data
    params: {}
- name: chroma_collection
  endpoint:
    path: /chroma/collection
    method: POST
- name: astradb_destination
  endpoint:
    path: /destinations
    method: POST
    data_selector: destination_connector_information
- name: fields
  endpoint:
    path: /$metadata#indexes/$entity
    method: GET
    data_selector: '@odata.context'
    params: {}
- name: chroma_collection
  endpoint:
    path: /chroma/collections
    method: POST
    data_selector: collection
    params:
      tenant: CHROMA_TENANT
      database: CHROMA_DATABASE
      collection_name: CHROMA_COLLECTION
- name: subject
  endpoint:
    path: /services/data/vXX.X/sobjects/Subject
    method: GET
    data_selector: records
    params: {}
- name: section
  endpoint:
    path: /services/data/vXX.X/sobjects/Section
    method: GET
    data_selector: records
    params: {}
- name: header_footer_type
  endpoint:
    path: /services/data/vXX.X/sobjects/HeaderFooterType
    method: GET
    data_selector: records
    params: {}
- name: emphasized_text_contents
  endpoint:
    path: /services/data/vXX.X/sobjects/EmphasizedTextContents
    method: GET
    data_selector: records
    params: {}
- name: emphasized_text_tags
  endpoint:
    path: /services/data/vXX.X/sobjects/EmphasizedTextTags
    method: GET
    data_selector: records
    params: {}
- name: text_as_html
  endpoint:
    path: /services/data/vXX.X/sobjects/TextAsHtml
    method: GET
    data_selector: records
    params: {}
- name: regex_metadata
  endpoint:
    path: /services/data/vXX.X/sobjects/RegexMetadata
    method: GET
    data_selector: records
    params: {}
- name: detection_class_prob
  endpoint:
    path: /services/data/vXX.X/sobjects/DetectionClassProb
    method: GET
    data_selector: records
    params: {}
- name: partitioner_type
  endpoint:
    path: /services/data/vXX.X/sobjects/PartitionerType
    method: GET
    data_selector: records
    params: {}
- name: destination
  endpoint:
    path: /destinations
    method: POST
    data_selector: destination_connector_information
- name: databricks_volume_delta_tables
  endpoint:
    path: /destinations
    method: POST
    data_selector: destination_connector_information
- name: Partition Endpoint
  endpoint:
    path: /partition
    method: POST
    data_selector: files
    params: {}
- name: databricks_volumes
  endpoint:
    path: /api/v1/destinations/databricks-volumes
    method: POST
    data_selector: data
    params: {}
- name: Salesforce categories
  endpoint:
    params: {}
- name: elements
  endpoint:
    path: /services/data/vXX.X/sobjects/ELEMENTS
    method: GET
    data_selector: records
    params: {}
- name: partition
  endpoint:
    path: /partition
    method: POST
    data_selector: elements
- name: tickets
  endpoint:
    path: /api/v2/tickets.json
    method: GET
    data_selector: tickets
- name: articles
  endpoint:
    path: /api/v2/help_center/articles.json
    method: GET
    data_selector: articles
- name: partition
  endpoint:
    path: ''
    method: POST
    data_selector: ''
    params: {}
- name: kafka_topic
  endpoint:
    path: /topics
    method: GET
    data_selector: records
- name: collection
  endpoint:
    params: {}
- name: chroma
  endpoint:
    path: /chroma
    method: POST
    data_selector: records
- name: couchbase
  endpoint:
    path: /api-reference/partition/overview
    method: POST
    data_selector: records
- name: target_folder
  endpoint:
    path: /my-folder/my-subfolder
    method: POST
- name: destination_connector
  endpoint:
    path: /ui/destinations/pinecone
    method: POST
    data_selector: connector
    params: {}
- name: pinecone-destination-connector
  endpoint:
    path: /connectors
    method: POST
    data_selector: connector
    params:
      type: Destination
      provider: Pinecone
      namespace: default
      batch_size: 50
- name: chroma_collection
  endpoint:
    path: /chroma/tenant/database/collection
    method: POST
    data_selector: records
- name: astradb
  endpoint:
    path: /destinations
    method: POST
    data_selector: destination_connector_information
- name: titles
  endpoint:
    path: /indexes/<my-index-name>
    method: GET
    data_selector: '@odata.context'
    params: {}
- name: destination
  endpoint:
    path: /destinations
    method: POST
    data_selector: destination_connector_information
- name: messages
  endpoint:
    params:
      channels: channel_id_list
      start_date: YYYY-MM-DDTHH:MM:SSZ
      end_date: YYYY-MM-DDTHH:MM:SSZ
      bot_token: access_token
- name: elements
  endpoint:
    params:
      columns: '*'
      id_column: RECORD_ID
      batch_size: 50
- name: tickets
  endpoint:
    path: /api/v2/tickets
    method: GET
    data_selector: tickets
- name: articles
  endpoint:
    path: /api/v2/help_center/articles
    method: GET
    data_selector: articles
- name: databricks_volume_delta_tables
  endpoint:
    path: /destinations
    method: POST
- name: elements
  endpoint:
    path: /services/data/vXX.X/sobjects/ELEMENTS
    method: GET
    data_selector: records
    params: {}
- name: tickets
  endpoint:
    path: /api/v2/tickets.json
    method: GET
    data_selector: tickets
- name: articles
  endpoint:
    path: /api/v2/help_center/articles.json
    method: GET
    data_selector: articles
- name: Kafka Topic
  endpoint:
    path: /api/topics
    method: POST
    data_selector: topic
    params: {}
- name: create_destination_connection_check
  endpoint:
    path: /api/v1/destinations/{destination_id}/connection-check
    method: POST
- name: create_destination_connector
  endpoint:
    path: /api/v1/destinations/
    method: POST
- name: delete_destination_connector
  endpoint:
    path: /api/v1/destinations/{destination_id}
    method: DELETE
- name: get_destination_connector
  endpoint:
    path: /api/v1/destinations/{destination_id}
    method: GET
- name: get_latest_destination_connector_connection_check
  endpoint:
    path: /api/v1/destinations/{destination_id}/connection-check
    method: GET
- name: list_destination_connectors
  endpoint:
    path: /api/v1/destinations/
    method: GET
- name: update_destination_connector
  endpoint:
    path: /api/v1/destinations/{destination_id}
    method: PUT
- name: cancel_job
  endpoint:
    path: /api/v1/jobs/{job_id}/cancel
    method: POST
- name: download_job_output
  endpoint:
    path: /api/v1/jobs/{job_id}/download
    method: GET
- name: get_job
  endpoint:
    path: /api/v1/jobs/{job_id}
    method: GET
- name: get_job_failed_files
  endpoint:
    path: /api/v1/jobs/{job_id}/failed-files
    method: GET
- name: get_job_processing_details
  endpoint:
    path: /api/v1/jobs/{job_id}/details
    method: GET
- name: list_jobs
  endpoint:
    path: /api/v1/jobs/
    method: GET
- name: elements
  endpoint:
    path: /create-table
    method: POST
- name: target_folder
  endpoint:
    path: onedrive://my-folder/my-subfolder
- name: Pinecone
  endpoint:
    path: /api/v1/indexes
    method: POST
- name: pinecone-destination-connector
  endpoint:
    path: /connectors
    method: POST
    data_selector: connector
    params:
      type: Destination
      provider: Pinecone
      index_name: ''
      namespace: default
      batch_size: 50
      api_key: your_api_key
- name: partition
  endpoint:
    path: /
    method: POST
    data_selector: elements
    params:
      strategy: vlm
      vlm_model: gpt-4o
      vlm_model_provider: openai
      unique_element_ids: true
      chunking_strategy: by_title
      max_characters: 1024
- name: partition
  endpoint:
    path: /
    method: POST
    data_selector: results
    params: {}
- name: partition
  endpoint:
    path: /general/partition
    method: POST
    data_selector: elements
- name: messages
  endpoint:
    path: /api/conversations.history
    method: GET
    params: {}
- name: elements
  endpoint:
    path: /services/data/snowflake/elements
    method: GET
    data_selector: records
    params: {}
- name: tickets
  endpoint:
    path: /api/v2/tickets.json
    method: GET
- name: articles
  endpoint:
    path: /api/v2/help_center/articles.json
    method: GET
- name: workflow
  endpoint:
    path: /destinations
    method: POST
    data_selector: destination_connector_information
- name: subject
  endpoint:
    path: /services/data/vXX.X/sobjects/Subject
    method: GET
    data_selector: records
- name: section
  endpoint:
    path: /services/data/vXX.X/sobjects/Section
    method: GET
    data_selector: records
- name: header_footer_type
  endpoint:
    path: /services/data/vXX.X/sobjects/HeaderFooterType
    method: GET
    data_selector: records
- name: emphasized_text_contents
  endpoint:
    path: /services/data/vXX.X/sobjects/EmphasizedTextContents
    method: GET
    data_selector: records
- name: emphasized_text_tags
  endpoint:
    path: /services/data/vXX.X/sobjects/EmphasizedTextTags
    method: GET
    data_selector: records
- name: text_as_html
  endpoint:
    path: /services/data/vXX.X/sobjects/TextAsHtml
    method: GET
    data_selector: records
- name: regex_metadata
  endpoint:
    path: /services/data/vXX.X/sobjects/RegexMetadata
    method: GET
    data_selector: records
- name: detection_class_prob
  endpoint:
    path: /services/data/vXX.X/sobjects/DetectionClassProb
    method: GET
    data_selector: records
- name: partitioner_type
  endpoint:
    path: /services/data/vXX.X/sobjects/PartitionerType
    method: GET
    data_selector: records
- name: destination
  endpoint:
    path: /destinations
    method: POST
    data_selector: destination_connector_information
- name: create_destination_connection_check
  endpoint:
    path: /api/v1/destinations/{destination_id}/connection-check
    method: POST
- name: create_destination_connector
  endpoint:
    path: /api/v1/destinations/
    method: POST
- name: delete_destination_connector
  endpoint:
    path: /api/v1/destinations/{destination_id}
    method: DELETE
- name: get_destination_connector
  endpoint:
    path: /api/v1/destinations/{destination_id}
    method: GET
- name: get_latest_destination_connector_connection_check
  endpoint:
    path: /api/v1/destinations/{destination_id}/connection-check
    method: GET
- name: list_destination_connectors
  endpoint:
    path: /api/v1/destinations/
    method: GET
- name: update_destination_connector
  endpoint:
    path: /api/v1/destinations/{destination_id}
    method: PUT
- name: cancel_job
  endpoint:
    path: /api/v1/jobs/{job_id}/cancel
    method: POST
- name: download_job_output
  endpoint:
    path: /api/v1/jobs/{job_id}/download
    method: GET
- name: get_job
  endpoint:
    path: /api/v1/jobs/{job_id}
    method: GET
- name: get_job_failed_files
  endpoint:
    path: /api/v1/jobs/{job_id}/failed-files
    method: GET
- name: get_job_processing_details
  endpoint:
    path: /api/v1/jobs/{job_id}/details
    method: GET
- name: list_jobs
  endpoint:
    path: /api/v1/jobs/
    method: GET
- name: summary
  endpoint:
    path: /general/v0/general
    method: POST
- name: destination_connector
  endpoint:
    path: /destinations
    method: POST
    data_selector: destination_connector_information
- name: kafka-cloud
  endpoint:
    path: /destinations
    method: POST
    data_selector: destination_connector_information
    params: {}
- name: milvus
  endpoint:
    path: /destinations
    method: POST
    data_selector: destination_connector_information
    params: {}
- name: my_collection
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: POST
- name: partition
  endpoint:
    path: /api/partition
    method: POST
    data_selector: elements
- name: destination
  endpoint:
    path: /destinations
    method: POST
    data_selector: destination_connector_information
    params: {}
- name: partition
  endpoint:
    path: /partition
    method: POST
    data_selector: elements
- name: destination
  endpoint:
    path: /destinations
    method: POST
    data_selector: destination_connector_information
- name: partition
  endpoint:
    path: ''
    method: POST
    data_selector: elements
    params: {}
- name: user
  endpoint:
    path: /admin/users
    method: GET
- name: database
  endpoint:
    path: /data/databases
    method: GET
- name: schema
  endpoint:
    path: /data/schemas
    method: GET
- name: table
  endpoint:
    path: /data/tables
    method: GET
- name: sources
  endpoint:
    path: /sources
    method: POST
    data_selector: source_connector_information
- name: get_source
  endpoint:
    path: /sources/<connector-id>
    method: GET
    data_selector: source_connector_information
- name: index
  endpoint:
    path: /indexes
    method: GET
    data_selector: value
- name: destinations
  endpoint:
    path: /destinations/<connector-id>
    method: PUT
- name: destination
  endpoint:
    path: /destinations
    method: POST
    data_selector: destination_connector_information
- name: databricks_volume
  endpoint:
    path: /destinations
    method: POST
    data_selector: destination_connector_information
- name: databricks_volumes
  endpoint:
    path: /sources
    method: POST
    data_selector: destination_connector_information
    params: {}
- name: destination_connector
  endpoint:
    path: /destinations
    method: POST
    data_selector: destination_connector_information
- name: create_destination_connection_check
  endpoint:
    path: /api/v1/destinations/{destination_id}/connection-check
    method: POST
- name: create_destination_connector
  endpoint:
    path: /api/v1/destinations/
    method: POST
- name: delete_destination_connector
  endpoint:
    path: /api/v1/destinations/{destination_id}
    method: DELETE
- name: get_destination_connector
  endpoint:
    path: /api/v1/destinations/{destination_id}
    method: GET
- name: get_latest_destination_connector_connection_check
  endpoint:
    path: /api/v1/destinations/{destination_id}/connection-check
    method: GET
- name: list_destination_connectors
  endpoint:
    path: /api/v1/destinations/
    method: GET
- name: update_destination_connector
  endpoint:
    path: /api/v1/destinations/{destination_id}
    method: PUT
- name: cancel_job
  endpoint:
    path: /api/v1/jobs/{job_id}/cancel
    method: POST
- name: download_job_output
  endpoint:
    path: /api/v1/jobs/{job_id}/download
    method: GET
- name: get_job
  endpoint:
    path: /api/v1/jobs/{job_id}
    method: GET
- name: get_job_failed_files
  endpoint:
    path: /api/v1/jobs/{job_id}/failed-files
    method: GET
- name: get_job_processing_details
  endpoint:
    path: /api/v1/jobs/{job_id}/details
    method: GET
- name: list_jobs
  endpoint:
    path: /api/v1/jobs/
    method: GET
- name: kafka
  endpoint:
    path: /destinations
    method: POST
    data_selector: destination_connector_information
- name: milvus
  endpoint:
    path: /destinations
    method: POST
    data_selector: destination_connector_information
- name: my_collection
  endpoint:
    path: /collections/my_collection
    method: POST
- name: onedrive
  endpoint:
    path: /destinations
    method: POST
    data_selector: destination_connector_information
- name: partition
  endpoint:
    path: ''
    method: POST
    data_selector: elements
    params: {}
- name: collection
  endpoint:
    path: /collections/<collection_name>
    method: POST
    data_selector: collection_information
- name: redis
  endpoint:
    path: /destinations
    method: POST
    data_selector: destination_connector_information
- name: s3
  endpoint:
    path: /destinations
    method: POST
    data_selector: destination_connector_information
- name: partition
  endpoint:
    path: /general
    method: POST
    data_selector: elements
- name: s3_destination
  endpoint:
    path: /api-reference/workflow/destinations/s3
    method: POST
    data_selector: destination_connector_information
- name: snowflake_destination
  endpoint:
    path: /api-reference/workflow/destinations/snowflake
    method: POST
    data_selector: destination_connector_information
- name: data_source
  endpoint:
    path: /$metadata#indexes/$entity
    method: GET
    data_selector: '@odata.context'
    params: {}
- name: sources
  endpoint:
    path: /sources
    method: GET
    data_selector: response_list_sources
    params: {}
- name: sources
  endpoint:
    path: /sources
    method: POST
    data_selector: null
    params: {}
- name: source
  endpoint:
    path: /sources/<connector-id>
    method: GET
    data_selector: source_connector_information
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: destinations
  endpoint:
    path: /destinations/<connector-id>
    method: PUT
    data_selector: destination_connector_information
- name: destination
  endpoint:
    path: /destinations
    method: POST
    data_selector: destination_connector_information
- name: destination_connector
  endpoint:
    path: /destinations
    method: POST
    data_selector: destination_connector_information
- name: delta_table
  endpoint:
    path: /api/v1/delta_table
    method: POST
    data_selector: data
    params: {}
- name: data_asset
  endpoint:
    path: /v1/data/assets
    method: GET
    data_selector: assets
    params: {}
- name: kafka-cloud
  endpoint:
    path: /destinations
    method: POST
    data_selector: destination_connector_information
    params: {}
- name: milvus
  endpoint:
    path: /destinations
    method: POST
    data_selector: destination_connector_information
    params: {}
- name: my_collection
  endpoint:
    path: /api/collections/my_collection
    method: POST
    data_selector: records
- name: onedrive
  endpoint:
    path: /destinations
    method: POST
    data_selector: destination_connector_information
- name: partition
  endpoint:
    path: /partition
    method: POST
    data_selector: elements
- name: collection
  endpoint:
    path: /api/collections
    method: POST
    data_selector: data
- name: destination
  endpoint:
    path: /destinations
    method: POST
    data_selector: destination_connector_information
- name: partition
  endpoint:
    path: ''
    method: POST
    data_selector: elements
- name: partition
  endpoint:
    path: /general/partition
    method: POST
    data_selector: elements
- name: connection_check
  endpoint:
    path: /destinations/<connector-id>/connection-check
    method: POST
    data_selector: response
- name: recent_connector_check
  endpoint:
    path: /destinations/<connector-id>/connection-check
    method: GET
    data_selector: response
- name: list_workflows
  endpoint:
    path: /workflows
    method: GET
    data_selector: response
- name: update_workflow
  endpoint:
    path: /workflows/<workflow-id>
    method: PUT
    data_selector: response
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: couchbase
  endpoint:
    path: /destinations
    method: POST
    data_selector: destination_connector_information
- name: databricks_delta_table
  endpoint:
    path: /destinations
    method: POST
    data_selector: destination_connector_information
- name: create_destination_connection_check
  endpoint:
    path: /api/v1/destinations/{destination_id}/connection-check
    method: POST
- name: create_destination_connector
  endpoint:
    path: /api/v1/destinations/
    method: POST
- name: delete_destination_connector
  endpoint:
    path: /api/v1/destinations/{destination_id}
    method: DELETE
- name: get_destination_connector
  endpoint:
    path: /api/v1/destinations/{destination_id}
    method: GET
- name: get_latest_destination_connector_connection_check
  endpoint:
    path: /api/v1/destinations/{destination_id}/connection-check
    method: GET
- name: list_destination_connectors
  endpoint:
    path: /api/v1/destinations/
    method: GET
- name: update_destination_connector
  endpoint:
    path: /api/v1/destinations/{destination_id}
    method: PUT
- name: cancel_job
  endpoint:
    path: /api/v1/jobs/{job_id}/cancel
    method: POST
- name: download_job_output
  endpoint:
    path: /api/v1/jobs/{job_id}/download
    method: GET
- name: get_job
  endpoint:
    path: /api/v1/jobs/{job_id}
    method: GET
- name: get_job_failed_files
  endpoint:
    path: /api/v1/jobs/{job_id}/failed-files
    method: GET
- name: get_job_processing_details
  endpoint:
    path: /api/v1/jobs/{job_id}/details
    method: GET
- name: list_jobs
  endpoint:
    path: /api/v1/jobs/
    method: GET
- name: summary
  endpoint:
    path: /general/v0/general
    method: POST
- name: destination_connector
  endpoint:
    path: /destinations
    method: POST
- name: kafka
  endpoint:
    path: /destinations/kafka
    method: POST
    data_selector: destination_connector_information
- name: milvus
  endpoint:
    path: /destinations/milvus
    method: POST
    data_selector: destination_connector_information
- name: my_collection
  endpoint:
    path: /create-collection
    method: POST
    data_selector: collection_info
    params:
      name: my_collection
      schema:
        fields:
        - name: element_id
          dtype: VARCHAR
          is_primary: true
          max_length: 200
        - name: embeddings
          dtype: FLOAT_VECTOR
          dim: 3072
        - name: record_id
          dtype: VARCHAR
          max_length: 200
        - name: text
          dtype: VARCHAR
          max_length: 65536
        enable_dynamic_field: true
- name: partition
  endpoint:
    path: /
    method: POST
    data_selector: elements
    params: {}
- name: collection
  endpoint:
    path: /collections/<collection-name>
    method: POST
    data_selector: collection_info
- name: partition
  endpoint:
    path: ''
    method: POST
    data_selector: elements
- name: destination
  endpoint:
    path: /destinations
    method: POST
- name: elements
  endpoint:
    path: /destinations
    method: POST
    data_selector: destination_connector_information
- name: destination_connector
  endpoint:
    path: /destinations
    method: POST
    data_selector: destination_connector_information
- name: sources
  endpoint:
    path: /sources
    method: GET
    data_selector: response_list_sources
    params: {}
- name: destination
  endpoint:
    path: /destinations
    method: POST
    data_selector: destination_connector_information
- name: databricks_volume_delta_tables
  endpoint:
    path: /destinations
    method: POST
    data_selector: destination_connector_information
- name: databricks_volumes
  endpoint:
    path: /sources
    method: POST
    data_selector: destination_connector_information
- name: connection_check
  endpoint:
    path: /destinations/<connector-id>/connection-check
    method: POST
    data_selector: response
    params: {}
- name: recent_connector_check
  endpoint:
    path: /destinations/<connector-id>/connection-check
    method: GET
    data_selector: response
    params: {}
- name: list_workflows
  endpoint:
    path: /workflows
    method: GET
    data_selector: response
    params: {}
- name: update_workflow
  endpoint:
    path: /workflows/<workflow-id>
    method: PUT
    data_selector: response
    params: {}
- name: kafka
  endpoint:
    path: /destinations
    method: POST
    data_selector: destination_connector_information
- name: milvus
  endpoint:
    path: /destinations
    method: POST
    data_selector: destination_connector_information
- name: my_collection
  endpoint:
    path: /services/data/vXX.X/sobjects/my_collection
    method: POST
- name: neo4j
  endpoint:
    path: /destinations
    method: POST
    data_selector: destination_connector_information
- name: create_destination_connection_check
  endpoint:
    path: /api/v1/destinations/{destination_id}/connection-check
    method: POST
- name: create_destination_connector
  endpoint:
    path: /api/v1/destinations/
    method: POST
- name: delete_destination_connector
  endpoint:
    path: /api/v1/destinations/{destination_id}
    method: DELETE
- name: get_destination_connector
  endpoint:
    path: /api/v1/destinations/{destination_id}
    method: GET
- name: get_latest_destination_connector_connection_check
  endpoint:
    path: /api/v1/destinations/{destination_id}/connection-check
    method: GET
- name: list_destination_connectors
  endpoint:
    path: /api/v1/destinations/
    method: GET
- name: update_destination_connector
  endpoint:
    path: /api/v1/destinations/{destination_id}
    method: PUT
- name: cancel_job
  endpoint:
    path: /api/v1/jobs/{job_id}/cancel
    method: POST
- name: download_job_output
  endpoint:
    path: /api/v1/jobs/{job_id}/download
    method: GET
- name: get_job
  endpoint:
    path: /api/v1/jobs/{job_id}
    method: GET
- name: get_job_failed_files
  endpoint:
    path: /api/v1/jobs/{job_id}/failed-files
    method: GET
- name: get_job_processing_details
  endpoint:
    path: /api/v1/jobs/{job_id}/details
    method: GET
- name: list_jobs
  endpoint:
    path: /api/v1/jobs/
    method: GET
- name: qdrant
  endpoint:
    path: /destinations
    method: POST
    data_selector: destination_connector_information
- name: destination
  endpoint:
    path: /destinations
    method: POST
    data_selector: destination_connector_information
- name: elements
  endpoint:
    path: /elements
    method: POST
- name: destination_connector
  endpoint:
    path: /destinations
    method: POST
- name: partition
  endpoint:
    path: /partition
    method: POST
    data_selector: elements
- name: partition
  endpoint:
    path: /general
    method: POST
    data_selector: elements
- name: workflows
  endpoint:
    path: /workflows
    method: POST
    data_selector: ''
    params: {}
- name: run_workflow
  endpoint:
    path: /workflows/<workflow-id>/run
    method: POST
    data_selector: ''
    params: {}
- name: update_workflow
  endpoint:
    path: /workflows/<workflow-id>
    method: PUT
    data_selector: ''
    params: {}
- name: OneDrive Files
  endpoint:
    path: /path/to/target/folder
    method: GET
    data_selector: files
    params: {}
- name: source_connector
  endpoint:
    path: /sources
    method: POST
    data_selector: source_connector_information
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: destination
  endpoint:
    path: /destinations
    method: POST
    data_selector: destination_connector_information
- name: messages
  endpoint:
    params:
      channels: comma-separated list of channel IDs
      start_date: YYYY-MM-DDTHH:MM:SSZ
      end_date: YYYY-MM-DDTHH:MM:SSZ
      bot_token: access token for the Slack app
- name: databricks_volume
  endpoint:
    path: /destinations
    method: POST
    data_selector: destination_connector_information
    params: {}
- name: elements
  endpoint:
    path: /services/data/vXX.X/sobjects/ELEMENTS
    method: GET
    data_selector: records
    params: {}
- name: databricks_volumes
  endpoint:
    path: /sources
    method: POST
    data_selector: destination_connector_information
- name: kafka
  endpoint:
    path: /destinations/kafka
    method: POST
    data_selector: destination_connector_information
- name: milvus
  endpoint:
    path: /destinations/milvus
    method: POST
    data_selector: destination_connector_information
- name: local
  endpoint:
    path: /destinations/local
    method: POST
    data_selector: destination_connector_information
- name: resource_group
  endpoint:
    path: /subscriptions/{subscription_id}/resourceGroups/{resource_group_name}
    method: PUT
    data_selector: properties
    params: {}
- name: aks_cluster
  endpoint:
    path: /subscriptions/{subscription_id}/resourceGroups/{resource_group_name}/providers/Microsoft.ContainerService/managedClusters/{cluster_name}
    method: PUT
    data_selector: properties
    params: {}
- name: managed_identities
  endpoint:
    path: /subscriptions/{subscription_id}/resourceGroups/{resource_group_name}/providers/Microsoft.ManagedIdentity/userAssignedIdentities/{identity_name}
    method: PUT
    data_selector: properties
    params: {}
- name: storage_account
  endpoint:
    path: /subscriptions/{subscription_id}/resourceGroups/{resource_group_name}/providers/Microsoft.Storage/storageAccounts/{account_name}
    method: PUT
    data_selector: properties
    params: {}
- name: my_collection
  endpoint:
    path: /services/data/vXX.X/sobjects/my_collection
    method: POST
    data_selector: records
- name: OneDrive
  endpoint:
    path: /destinations
    method: POST
    data_selector: destination_connector_information
- name: upload_document
  endpoint:
    path: /2/files/upload
    method: POST
    data_selector: result
    params: {}
- name: create_folder
  endpoint:
    path: /2/files/create_folder_v2
    method: POST
    data_selector: result
    params: {}
- name: postgres_destination
  endpoint:
    path: /destinations
    method: POST
    data_selector: destination_connector_information
    params: {}
- name: qdrant_destination
  endpoint:
    path: /destinations
    method: POST
    data_selector: destination_connector_information
    params: {}
- name: partition_pdf
  endpoint:
    path: /partition_pdf
    method: POST
    data_selector: tables
    params:
      skip_infer_table_types: 'False'
      strategy: hi_res
- name: auto_partition
  endpoint:
    path: /auto_partition
    method: POST
    data_selector: tables
    params:
      strategy: hi_res
- name: destination
  endpoint:
    path: /destinations
    method: POST
    data_selector: destination_connector_information
- name: documents
  endpoint:
    path: /v1/documents
    method: POST
    data_selector: data
    params: {}
- name: workflows
  endpoint:
    path: /workflows
    method: POST
    data_selector: null
    params: {}
- name: run_workflow
  endpoint:
    path: /workflows/<workflow-id>/run
    method: POST
    data_selector: null
    params: {}
- name: update_workflow
  endpoint:
    path: /workflows/<workflow-id>
    method: PUT
    data_selector: null
    params: {}
- name: crawled_pages
  endpoint:
    path: /crawls/<timestamp>/pages/
    method: GET
    data_selector: pages
    params:
      limit: '5'
- name: onedrive_files
  endpoint:
    path: /path/to/target/folder
    method: GET
- name: kafka_source
  endpoint:
    path: /sources
    method: POST
    data_selector: source_connector_information
    params:
      name: <name>
      type: kafka-cloud
      config:
        bootstrap_servers: <bootstrap-server>
        port: <port>
        group_id: <group-id>
        kafka_api_key: <kafka-api-key>
        secret: <secret>
        topic: <topic>
        num_messages_to_consume: <num-messages-to-consume>
- name: messages
  endpoint:
    path: /api/conversations.history
    method: GET
- name: elements
  endpoint:
    path: /services/data/vXX.X/sobjects/ELEMENTS
    method: GET
    data_selector: records
    params: {}
- name: create_destination_connection_check
  endpoint:
    path: /api/v1/destinations/{destination_id}/connection-check
    method: POST
- name: create_destination_connector
  endpoint:
    path: /api/v1/destinations/
    method: POST
- name: delete_destination_connector
  endpoint:
    path: /api/v1/destinations/{destination_id}
    method: DELETE
- name: get_destination_connector
  endpoint:
    path: /api/v1/destinations/{destination_id}
    method: GET
- name: get_latest_destination_connector_connection_check
  endpoint:
    path: /api/v1/destinations/{destination_id}/connection-check
    method: GET
- name: list_destination_connectors
  endpoint:
    path: /api/v1/destinations/
    method: GET
- name: update_destination_connector
  endpoint:
    path: /api/v1/destinations/{destination_id}
    method: PUT
- name: cancel_job
  endpoint:
    path: /api/v1/jobs/{job_id}/cancel
    method: POST
- name: download_job_output
  endpoint:
    path: /api/v1/jobs/{job_id}/download
    method: GET
- name: get_job
  endpoint:
    path: /api/v1/jobs/{job_id}
    method: GET
- name: get_job_failed_files
  endpoint:
    path: /api/v1/jobs/{job_id}/failed-files
    method: GET
- name: get_job_processing_details
  endpoint:
    path: /api/v1/jobs/{job_id}/details
    method: GET
- name: list_jobs
  endpoint:
    path: /api/v1/jobs/
    method: GET
- name: tickets
  endpoint:
    path: /api/v2/tickets.json
    method: GET
    data_selector: tickets
- name: articles
  endpoint:
    path: /api/v2/help_center/articles.json
    method: GET
    data_selector: articles
- name: workflows
  endpoint:
    path: /api/v1/workflows/
    method: GET
- name: partition
  endpoint:
    path: /partition
    method: POST
    data_selector: elements
- name: partition
  endpoint:
    path: ''
    method: POST
    data_selector: elements
- name: partition
  endpoint:
    path: /general/partition
    method: POST
    data_selector: elements
- name: documents
  endpoint:
    path: /documents
    method: POST
    data_selector: data
- name: Azure Blob Storage event triggers
  endpoint:
    path: /api-reference/workflow/overview
    method: POST
    data_selector: workflow
- name: index
  endpoint:
    path: /$metadata/indexes/$entity
    method: GET
    data_selector: '@odata.context'
    params: {}
- name: destination
  endpoint:
    path: /destinations
    method: POST
    data_selector: destination_connector_information
- name: databricks_volumes
  endpoint:
    path: /sources
    method: POST
    data_selector: destination_connector_information
- name: crawled_pages
  endpoint:
    path: /crawls
    method: POST
    data_selector: pages
    params:
      limit: 5
- name: kafka
  endpoint:
    path: /destinations
    method: POST
    data_selector: destination_connector_information
- name: milvus
  endpoint:
    path: /destinations
    method: POST
    data_selector: destination_connector_information
- name: local
  endpoint:
    path: /destinations
    method: POST
    data_selector: destination_connector_information
- name: Unstructured Workflow Endpoint
  endpoint:
    path: /api-reference/workflow/overview
    method: POST
- name: my_collection
  endpoint:
    path: /create_collection
    method: POST
    data_selector: records
- name: vector_bucket
  endpoint:
    path: /vector_bucket
    method: POST
    data_selector: bucket_name
    params:
      encryption: default
- name: vector_index
  endpoint:
    path: /vector_index
    method: POST
    data_selector: index_name
    params:
      dimension: 1024
      distance_metric: Cosine
- name: destination
  endpoint:
    path: /destinations
    method: POST
    data_selector: destination_connector_information
    params: {}
- name: destination
  endpoint:
    path: /destinations
    method: POST
    data_selector: destination_connector_information
- name: destination_connector
  endpoint:
    path: /destinations
    method: POST
    data_selector: destination_connector_information
- name: create_destination_connection_check
  endpoint:
    path: /api/v1/destinations/{destination_id}/connection-check
    method: POST
- name: create_destination_connector
  endpoint:
    path: /api/v1/destinations/
    method: POST
- name: delete_destination_connector
  endpoint:
    path: /api/v1/destinations/{destination_id}
    method: DELETE
- name: get_destination_connector
  endpoint:
    path: /api/v1/destinations/{destination_id}
    method: GET
- name: get_latest_destination_connector_connection_check
  endpoint:
    path: /api/v1/destinations/{destination_id}/connection-check
    method: GET
- name: list_destination_connectors
  endpoint:
    path: /api/v1/destinations/
    method: GET
- name: update_destination_connector
  endpoint:
    path: /api/v1/destinations/{destination_id}
    method: PUT
- name: cancel_job
  endpoint:
    path: /api/v1/jobs/{job_id}/cancel
    method: POST
- name: download_job_output
  endpoint:
    path: /api/v1/jobs/{job_id}/download
    method: GET
- name: get_job
  endpoint:
    path: /api/v1/jobs/{job_id}
    method: GET
- name: get_job_failed_files
  endpoint:
    path: /api/v1/jobs/{job_id}/failed-files
    method: GET
- name: get_job_processing_details
  endpoint:
    path: /api/v1/jobs/{job_id}/details
    method: GET
- name: list_jobs
  endpoint:
    path: /api/v1/jobs/
    method: GET
- name: sources
  endpoint:
    path: /sources
    method: GET
    data_selector: response_list_sources
    params: {}
- name: source
  endpoint:
    path: /sources/<connector-id>
    method: GET
- name: create_source
  endpoint:
    path: /sources
    method: POST
- name: update_source
  endpoint:
    path: /sources/<connector-id>
    method: PUT
- name: delete_source
  endpoint:
    path: /sources/<connector-id>
    method: DELETE
- name: connection_check
  endpoint:
    path: /sources/<connector-id>/connection-check
    method: POST
- name: get_connection_check
  endpoint:
    path: /sources/<connector-id>/connection-check
    method: GET
- name: workflows
  endpoint:
    path: /workflows
    method: POST
    data_selector: null
    params: {}
- name: run_workflow
  endpoint:
    path: /workflows/<workflow-id>/run
    method: POST
    data_selector: null
    params: {}
- name: update_workflow
  endpoint:
    path: /workflows/<workflow-id>
    method: PUT
    data_selector: null
    params: {}
- name: delete_workflow
  endpoint:
    path: /workflows/<workflow-id>
    method: DELETE
    data_selector: null
    params: {}
- name: list_jobs
  endpoint:
    path: /jobs
    method: GET
    data_selector: null
    params: {}
- name: get_job
  endpoint:
    path: /jobs/<job-id>
    method: GET
    data_selector: null
    params: {}
- name: partition
  endpoint:
    path: /partition
    method: POST
    data_selector: elements
- name: partition
  endpoint:
    path: /general/v0/general
    method: POST
    data_selector: elements
- name: job
  endpoint:
    path: /jobs/<job-id>
    method: GET
    data_selector: job_information
- name: job_details
  endpoint:
    path: /jobs/<job-id>/details
    method: GET
    data_selector: job_details
- name: failed_files
  endpoint:
    path: /jobs/<job-id>/failed-files
    method: GET
    data_selector: job_failed_files
- name: cancel_job
  endpoint:
    path: /jobs/<job-id>/cancel
    method: POST
- name: download_job_output
  endpoint:
    path: /jobs/<job-id>/download
    method: GET
- name: box_source
  endpoint:
    path: box://<path/to/folder/in/account>
    method: POST
    data_selector: files
    params:
      recursive: true
- name: confluence_source
  endpoint:
    path: /wiki/rest/api
    method: GET
    data_selector: pages
    params: {}
- name: index
  endpoint:
    path: /search/indexes/my-index-name
    method: GET
    data_selector: '@odata.context'
    params: {}
- name: couchbase
  endpoint:
    path: /sources
    method: POST
    data_selector: source_connector_information
- name: databricks_volumes
  endpoint:
    path: /sources
    method: POST
    data_selector: source_connector_information
- name: <name>
  endpoint:
    path: <host>
    method: POST
    data_selector: source_connector_information
- name: subject
  endpoint:
    path: /services/data/vXX.X/sobjects/Subject
    method: GET
    data_selector: records
- name: section
  endpoint:
    path: /services/data/vXX.X/sobjects/Section
    method: GET
    data_selector: records
- name: header_footer_type
  endpoint:
    path: /services/data/vXX.X/sobjects/HeaderFooterType
    method: GET
    data_selector: records
- name: emphasized_text_contents
  endpoint:
    path: /services/data/vXX.X/sobjects/EmphasizedTextContents
    method: GET
    data_selector: records
- name: emphasized_text_tags
  endpoint:
    path: /services/data/vXX.X/sobjects/EmphasizedTextTags
    method: GET
    data_selector: records
- name: text_as_html
  endpoint:
    path: /services/data/vXX.X/sobjects/TextAsHtml
    method: GET
    data_selector: records
- name: regex_metadata
  endpoint:
    path: /services/data/vXX.X/sobjects/RegexMetadata
    method: GET
    data_selector: records
- name: detection_class_prob
  endpoint:
    path: /services/data/vXX.X/sobjects/DetectionClassProb
    method: GET
    data_selector: records
- name: partitioner_type
  endpoint:
    path: /services/data/vXX.X/sobjects/PartitionerType
    method: GET
    data_selector: records
- name: couchbase
  endpoint:
    path: /destinations
    method: POST
    data_selector: destination_connector_information
- name: databricks_delta_table
  endpoint:
    path: /destinations
    method: POST
    data_selector: destination_connector_information
- name: databricks_destination
  endpoint:
    path: /destinations
    method: POST
    data_selector: destination_connector_information
- name: projects
  endpoint:
    path: /rest/api/latest/project
    method: GET
    data_selector: projects
    params: {}
- name: boards
  endpoint:
    path: /rest/agile/1.0/board
    method: GET
    data_selector: boards
    params: {}
- name: issues
  endpoint:
    path: /rest/api/latest/issue
    method: GET
    data_selector: issues
    params: {}
- name: databricks_volumes
  endpoint:
    path: /sources
    method: POST
    data_selector: destination_connector_information
    params: {}
- name: onedrive
  endpoint:
    path: /sources
    method: POST
    data_selector: null
    params: {}
- name: watsonxdata_destination
  endpoint:
    path: /destinations
    method: POST
    data_selector: destination_connector_information
- name: snowflake_account
  endpoint:
    path: /services/data/vXX.X/accounts
    method: GET
    data_selector: records
- name: kafka-cloud
  endpoint:
    path: /destinations
    method: POST
    data_selector: destination_connector_information
    params: {}
- name: milvus
  endpoint:
    path: /destinations
    method: POST
    data_selector: destination_connector_information
    params: {}
- name: zendesk_items
  endpoint:
    path: /api/v2/items
    method: GET
    data_selector: items
- name: my_collection
  endpoint:
    path: /create_collection
    method: POST
    data_selector: collection
    params: {}
- name: <name>
  endpoint:
    path: /sources
    method: POST
- name: neo4j
  endpoint:
    path: /destinations
    method: POST
- name: workflow
  endpoint:
    path: /workflows
    method: POST
    data_selector: ''
    params: {}
- name: destination
  endpoint:
    path: /destinations
    method: POST
    data_selector: destination_connector_information
- name: destination
  endpoint:
    path: /destinations
    method: POST
    data_selector: response.destination_connector_information
- name: create_workflow
  endpoint:
    path: /api/v1/workflows/
    method: POST
- name: delete_workflow
  endpoint:
    path: /api/v1/workflows/{workflow_id}
    method: DELETE
- name: get_workflow
  endpoint:
    path: /api/v1/workflows/{workflow_id}
    method: GET
- name: list_workflows
  endpoint:
    path: /api/v1/workflows/
    method: GET
- name: run_workflow
  endpoint:
    path: /api/v1/workflows/{workflow_id}/run
    method: POST
- name: update_workflow
  endpoint:
    path: /api/v1/workflows/{workflow_id}
    method: PUT
- name: blob_storage_credentials
  endpoint:
    path: /blob_storage_credentials
    method: GET
    data_selector: records
    params: {}
- name: database_credentials
  endpoint:
    path: /database_credentials
    method: GET
    data_selector: records
    params: {}
- name: authentication
  endpoint:
    path: /authentication
    method: GET
    data_selector: records
    params: {}
- name: blob_storage_settings
  endpoint:
    path: /blob_storage_settings
    method: GET
    data_selector: records
    params: {}
- name: environment
  endpoint:
    path: /environment
    method: GET
    data_selector: records
    params: {}
- name: observability_and_opentelementry
  endpoint:
    path: /observability_and_opentelementry
    method: GET
    data_selector: records
    params: {}
- name: unstructured_api_and_authentication
  endpoint:
    path: /unstructured_api_and_authentication
    method: GET
    data_selector: records
    params: {}
- name: BlobTrigger1
  endpoint:
    path: samples-workitems/{name}
    method: POST
- name: workflows
  endpoint:
    path: /workflows
    method: POST
    data_selector: null
    params: {}
- name: run_workflow
  endpoint:
    path: /workflows/<workflow-id>/run
    method: POST
    data_selector: null
    params: {}
- name: list_jobs
  endpoint:
    path: /jobs
    method: GET
    data_selector: null
    params: {}
- name: get_job
  endpoint:
    path: /jobs/<job-id>
    method: GET
    data_selector: null
    params: {}
- name: job_details
  endpoint:
    path: /jobs/<job-id>/details
    method: GET
    data_selector: job_details
- name: failed_files
  endpoint:
    path: /jobs/<job-id>/failed-files
    method: GET
    data_selector: job_failed_files
- name: download_file
  endpoint:
    path: /jobs/<job-id>/download
    method: GET
    data_selector: output
- name: cancel_job
  endpoint:
    path: /jobs/<job-id>/cancel
    method: POST
- name: azure_blob
  endpoint:
    path: az://<container-name>/<path/to/file/or/folder>
    method: POST
    data_selector: files
    params:
      recursive: true
- name: firecrawl_data
  endpoint:
    path: /crawls
    method: GET
    data_selector: data
- name: pinecone_index
  endpoint:
    path: /indexes
    method: POST
    data_selector: index
    params: {}
- name: couchbase
  endpoint:
    path: /sources
    method: POST
    data_selector: source_connector_information
- name: databricks_volumes
  endpoint:
    path: /sources
    method: POST
    data_selector: source_connector_information
- name: Astra DB Ingest
  endpoint:
    path: /astra/db/ingest
    method: POST
- name: Astra DB RAG
  endpoint:
    path: /astra/db/rag
    method: POST
- name: OpenAIResponse
  endpoint:
    path: /v1/chat/completions
    method: POST
    data_selector: choices
    params: {}
- name: dropbox_files
  endpoint:
    path: /files/list_folder
    method: POST
    data_selector: entries
- name: issues
  endpoint:
    path: /rest/api/latest/issue
    method: GET
    data_selector: issues
- name: sources
  endpoint:
    path: /api/v1/sources
    method: GET
    data_selector: response_list_sources
- name: source_details
  endpoint:
    path: /api/v1/sources/{source_id}
    method: GET
    data_selector: source_connector_information
- name: document_processing
  endpoint:
    path: /api/process
    method: POST
    data_selector: results
- name: onedrive_files
  endpoint:
    path: /api/v1/onedrive/files
    method: GET
    data_selector: files
- name: vector_index
  endpoint:
    path: /s3vectors
    method: DELETE
- name: vector_bucket
  endpoint:
    path: /s3vectors
    method: DELETE
- name: sharepoint_event
  endpoint:
    path: /workflows
    method: POST
- name: sharepoint_library
  endpoint:
    path: /sites/<site>/libraries/<library>
    method: GET
    data_selector: records
- name: <item-type>
  endpoint:
    path: /api/v2/<item-type>.json
    method: GET
    data_selector: records
- name: Pinecone
  endpoint:
    path: /api/v1/pinecone
    method: POST
- name: OpenAI LLM
  endpoint:
    path: /api/v1/openai
    method: POST
- name: element
  endpoint:
    path: /open-source/concepts/document-elements
    method: GET
- name: workflow
  endpoint:
    path: /workflows
    method: POST
    data_selector: workflow_nodes
- name: Create Workflow
  endpoint:
    path: /api/v1/workflows/
    method: POST
- name: Delete Workflow
  endpoint:
    path: /api/v1/workflows/{workflow_id}
    method: DELETE
- name: Get Workflow
  endpoint:
    path: /api/v1/workflows/{workflow_id}
    method: GET
- name: List Workflows
  endpoint:
    path: /api/v1/workflows/
    method: GET
- name: Run Workflow
  endpoint:
    path: /api/v1/workflows/{workflow_id}/run
    method: POST
- name: Update Workflow
  endpoint:
    path: /api/v1/workflows/{workflow_id}
    method: PUT
- name: create_destination_connection_check
  endpoint:
    path: /api/v1/destinations/{destination_id}/connection-check
    method: POST
- name: create_destination_connector
  endpoint:
    path: /api/v1/destinations/
    method: POST
- name: delete_destination_connector
  endpoint:
    path: /api/v1/destinations/{destination_id}
    method: DELETE
- name: get_destination_connector
  endpoint:
    path: /api/v1/destinations/{destination_id}
    method: GET
- name: get_latest_destination_connector_connection_check
  endpoint:
    path: /api/v1/destinations/{destination_id}/connection-check
    method: GET
- name: list_destination_connectors
  endpoint:
    path: /api/v1/destinations/
    method: GET
- name: update_destination_connector
  endpoint:
    path: /api/v1/destinations/{destination_id}
    method: PUT
- name: cancel_job
  endpoint:
    path: /api/v1/jobs/{job_id}/cancel
    method: POST
- name: download_job_output
  endpoint:
    path: /api/v1/jobs/{job_id}/download
    method: GET
- name: get_job
  endpoint:
    path: /api/v1/jobs/{job_id}
    method: GET
- name: get_job_failed_files
  endpoint:
    path: /api/v1/jobs/{job_id}/failed-files
    method: GET
- name: get_job_processing_details
  endpoint:
    path: /api/v1/jobs/{job_id}/details
    method: GET
- name: list_jobs
  endpoint:
    path: /api/v1/jobs/
    method: GET
- name: summary
  endpoint:
    path: /general/v0/general
    method: POST
- name: blob_storage_credentials
  endpoint:
    params:
      BLOB_STORAGE_ADAPTER_ACCOUNT_NAME: ''
      BLOB_STORAGE_ADAPTER_ACCOUNT_KEY: ''
      BLOB_STORAGE_ADAPTER_CONTAINER_REGION: ''
- name: database_credentials
  endpoint:
    params:
      DB_USERNAME: ''
      DB_PASSWORD: ''
      DB_HOST: ''
      DB_NAME: ''
      DB_DATABASE: ''
- name: authentication
  endpoint:
    params:
      JWT_SECRET_KEY: ''
      AUTH_STRATEGY: ''
      SESSION_SECRET: ''
      SHARED_SECRET: ''
      KEYCLOAK_CLIENT_SECRET: ''
      KEYCLOAK_ADMIN_SECRET: ''
      KEYCLOAK_ADMIN: ''
      KEYCLOAK_ADMIN_PASSWORD: ''
      API_BEARER_TOKEN: ''
- name: blob_storage_settings
  endpoint:
    params:
      BLOB_STORAGE_ADAPTER_TYPE: azure
      BLOB_STORAGE_ADAPTER_BUCKET: ''
      ETL_BLOB_CACHE_BUCKET_NAME: ''
      ETL_API_BLOB_STORAGE_ADAPTER_BUCKET: ''
      ETL_API_BLOB_STORAGE_ADAPTER_TYPE: azure
      ETL_API_DB_REMOTE_BUCKET_NAME: ''
      ETL_API_JOB_STATUS_DEST_BUCKET_NAME: ''
      JOB_STATUS_BUCKET_NAME: ''
      JOB_DB_BUCKET_NAME: ''
- name: environment
  endpoint:
    params:
      ENV: ''
      ENVIRONMENT: ''
      JOB_ENV: ''
      JOB_ENVIRONMENT: ''
- name: observability_and_opentelementry
  endpoint:
    params:
      JOB_OTEL_EXPORTER_OTLP_ENDPOINT: ''
      JOB_OTEL_METRICS_EXPORTER: ''
      JOB_OTEL_TRACES_EXPORTER: ''
      OTEL_EXPORTER_OTLP_ENDPOINT: ''
      OTEL_METRICS_EXPORTER: ''
      OTEL_TRACES_EXPORTER: ''
- name: unstructured_api_and_authentication
  endpoint:
    params: {}
- name: mlk_research
  endpoint:
    path: /examplecode/codesamples/api/mlk-research
    method: GET
- name: table_extraction
  endpoint:
    path: /examplecode/codesamples/apioss/table-extraction-from-pdf
    method: POST
- name: multi_file_processing
  endpoint:
    path: /examplecode/codesamples/oss/multi-files-api-processing
    method: POST
- name: delta_table_connector
  endpoint:
    path: /examplecode/codesamples/oss/table-source-connector
    method: POST
- name: vector_database
  endpoint:
    path: /examplecode/codesamples/oss/vector-database
    method: POST
- name: partition
  endpoint:
    path: /partition
    method: POST
    data_selector: elements
- name: partition
  endpoint:
    path: /general/partition
    method: POST
    data_selector: elements
- name: s3-firecrawl-source
  endpoint:
    path: /services/data/vXX.X/sobjects/S3Source
    method: POST
    data_selector: result
- name: pinecone-firecrawl-destination
  endpoint:
    path: /services/data/vXX.X/sobjects/PineconeDestination
    method: POST
    data_selector: result
- name: partition
  endpoint:
    path: /general
    method: POST
    data_selector: elements
- name: partition
  endpoint:
    path: /partition
    method: POST
    data_selector: elements
- name: OpenAI Embeddings
  endpoint:
    path: /openai/embeddings
    method: POST
- name: Astra DB Ingest
  endpoint:
    path: /astra/db/ingest
    method: POST
- name: Astra DB RAG
  endpoint:
    path: /astra/db/rag
    method: POST
- name: Chat Input
  endpoint:
    path: /chat/input
    method: POST
- name: Parse Data
  endpoint:
    path: /parse/data
    method: POST
- name: OpenAI
  endpoint:
    path: /v1/models/gpt-4o-mini
    method: POST
    data_selector: choices
    params: {}
- name: index
  endpoint:
    path: /$metadata#indexes/$entity
    method: GET
    data_selector: '@odata.context'
    params: {}
- name: destination
  endpoint:
    path: /destinations
    method: POST
    data_selector: destination_connector_information
- name: databricks_volume
  endpoint:
    path: /destinations
    method: POST
    data_selector: destination_connector_information
    params: {}
- name: databricks_volumes
  endpoint:
    path: /sources
    method: POST
    data_selector: destination_connector_information
    params: {}
- name: Pinecone
  endpoint:
    path: /api/v1/pinecone
    method: POST
- name: chunked_elements
  endpoint:
    path: /open-source/best-practices/chunking
    method: GET
    data_selector: chunked_content
    params: {}
- name: document_elements
  endpoint:
    path: /open-source/concepts/document-elements
    method: GET
    data_selector: document_elements
    params: {}
- name: delta_table
  endpoint:
    path: /destinations
    method: POST
    params: {}
- name: elasticsearch
  endpoint:
    path: /destinations
    method: POST
    params: {}
- name: google_cloud_storage
  endpoint:
    path: /destinations
    method: POST
    params: {}
- name: kafka
  endpoint:
    path: /destinations
    method: POST
    data_selector: destination_connector_information
- name: milvus
  endpoint:
    path: /destinations
    method: POST
    data_selector: destination_connector_information
- name: local
  endpoint:
    path: /destinations
    method: POST
    data_selector: destination_connector_information
- name: destination_connector
  endpoint:
    path: /destinations
    method: POST
    data_selector: destination_connector_information
- name: create_destination_connection_check
  endpoint:
    path: /api/v1/destinations/{destination_id}/connection-check
    method: POST
- name: create_destination_connector
  endpoint:
    path: /api/v1/destinations/
    method: POST
- name: delete_destination_connector
  endpoint:
    path: /api/v1/destinations/{destination_id}
    method: DELETE
- name: get_destination_connector
  endpoint:
    path: /api/v1/destinations/{destination_id}
    method: GET
- name: get_latest_destination_connector_connection_check
  endpoint:
    path: /api/v1/destinations/{destination_id}/connection-check
    method: GET
- name: list_destination_connectors
  endpoint:
    path: /api/v1/destinations/
    method: GET
- name: update_destination_connector
  endpoint:
    path: /api/v1/destinations/{destination_id}
    method: PUT
- name: cancel_job
  endpoint:
    path: /api/v1/jobs/{job_id}/cancel
    method: POST
- name: download_job_output
  endpoint:
    path: /api/v1/jobs/{job_id}/download
    method: GET
- name: get_job
  endpoint:
    path: /api/v1/jobs/{job_id}
    method: GET
- name: get_job_failed_files
  endpoint:
    path: /api/v1/jobs/{job_id}/failed-files
    method: GET
- name: get_job_processing_details
  endpoint:
    path: /api/v1/jobs/{job_id}/details
    method: GET
- name: list_jobs
  endpoint:
    path: /api/v1/jobs/
    method: GET
- name: summary
  endpoint:
    path: /general/v0/general
    method: POST
- name: collection
  endpoint:
    path: /collections/<collection_name>
    method: POST
    data_selector: result
    params: {}
- name: destination
  endpoint:
    path: /destinations
    method: POST
    data_selector: destination_connector_information
- name: partition
  endpoint:
    path: /api/partition
    method: POST
    data_selector: elements
- name: partition
  endpoint:
    path: /general/partition
    method: POST
    data_selector: elements
- name: partition
  endpoint:
    path: /general
    method: POST
    data_selector: elements
- name: workflows
  endpoint:
    path: /workflows
    method: POST
    data_selector: null
    params: {}
- name: jobs
  endpoint:
    path: /jobs
    method: GET
    data_selector: null
    params: {}
- name: jobs
  endpoint:
    path: /jobs/<job-id>
    method: GET
    data_selector: job_information
- name: job_details
  endpoint:
    path: /jobs/<job-id>/details
    method: GET
    data_selector: job_details
- name: failed_files
  endpoint:
    path: /jobs/<job-id>/failed-files
    method: GET
    data_selector: job_failed_files
- name: cancel_job
  endpoint:
    path: /jobs/<job-id>/cancel
    method: POST
- name: download_job_output
  endpoint:
    path: /jobs/<job-id>/download
    method: GET
- name: <name>
  endpoint:
    path: <remote-url>
    method: POST
    data_selector: config
    params:
      recursive: <true|false>
- name: index
  endpoint:
    path: /search/indexes
    method: GET
    data_selector: value
- name: <name>
  endpoint:
    path: /sources
    method: POST
    data_selector: source_connector_information
- name: dropbox
  endpoint:
    path: /sources
    method: POST
    data_selector: source_connector_information
- name: subject
  endpoint:
    path: /subjects
    method: GET
- name: section
  endpoint:
    path: /sections
    method: GET
- name: header_footer_type
  endpoint:
    path: /header_footer_types
    method: GET
- name: emphasized_text_contents
  endpoint:
    path: /emphasized_text_contents
    method: GET
- name: emphasized_text_tags
  endpoint:
    path: /emphasized_text_tags
    method: GET
- name: text_as_html
  endpoint:
    path: /text_as_html
    method: GET
- name: regex_metadata
  endpoint:
    path: /regex_metadata
    method: GET
- name: detection_class_prob
  endpoint:
    path: /detection_class_prob
    method: GET
- name: partitioner_type
  endpoint:
    path: /partitioner_type
    method: GET
- name: source_connector
  endpoint:
    path: /sources
    method: POST
    data_selector: source_connector_information
- name: couchbase
  endpoint:
    path: /destinations
    method: POST
    data_selector: destination_connector_information
    params: {}
- name: azure_ai_search
  endpoint:
    path: /destinations
    method: POST
    data_selector: destination_connector_information
    params: {}
- name: databricks_delta_table
  endpoint:
    path: /destinations
    method: POST
    data_selector: destination_connector_information
    params: {}
- name: onedrive
  endpoint:
    path: /sources
    method: POST
    data_selector: source_connector_information
- name: databricks_volume_delta_tables
  endpoint:
    path: /destinations
    method: POST
- name: elements
  endpoint:
    path: /sources/postgresql
    method: POST
    data_selector: source_connector_information
- name: databricks_volumes
  endpoint:
    path: /sources
    method: POST
- name: watsonx_data
  endpoint:
    path: /api/v1/watsonx/data
    method: POST
    data_selector: data
- name: connector
  endpoint:
    path: /sources
    method: POST
    data_selector: source_connector_information
- name: zendesk_source
  endpoint:
    path: /sources
    method: POST
    data_selector: source_connector_information
- name: workflows
  endpoint:
    path: /workflows
    method: POST
    data_selector: workflow_information
- name: kafka-cloud
  endpoint:
    path: /destinations
    method: POST
    data_selector: destination_connector_information
    params: {}
- name: milvus
  endpoint:
    path: /destinations
    method: POST
    data_selector: destination_connector_information
    params: {}
- name: Create Workflow
  endpoint:
    path: /api/v1/workflows/
    method: POST
- name: Delete Workflow
  endpoint:
    path: /api/v1/workflows/{workflow_id}
    method: DELETE
- name: Get Workflow
  endpoint:
    path: /api/v1/workflows/{workflow_id}
    method: GET
- name: List Workflows
  endpoint:
    path: /api/v1/workflows/
    method: GET
- name: Run Workflow
  endpoint:
    path: /api/v1/workflows/{workflow_id}/run
    method: POST
- name: Update Workflow
  endpoint:
    path: /api/v1/workflows/{workflow_id}
    method: PUT
- name: neo4j
  endpoint:
    path: /destinations
    method: POST
    data_selector: destination_connector_information
    params: {}
- name: blob_storage_credentials
  endpoint:
    path: /blob_storage_credentials
    method: GET
- name: database_credentials
  endpoint:
    path: /database_credentials
    method: GET
- name: authentication
  endpoint:
    path: /authentication
    method: GET
- name: collection
  endpoint:
    path: /collections
    method: POST
    data_selector: collection
    params: {}
- name: destination
  endpoint:
    path: /destinations
    method: POST
    data_selector: destination_connector_information
- name: Azure Blob Storage Trigger
  endpoint:
    path: /api/v1/workflows/{workflow-id}/run
    method: POST
    data_selector: data
- name: firecrawl_data
  endpoint:
    path: /crawls
    method: GET
- name: pinecone_index
  endpoint:
    path: /indexes
    method: POST
- name: OpenAI Embeddings
  endpoint:
    path: /openai/embeddings
    method: POST
    data_selector: results
- name: Astra DB Ingest
  endpoint:
    path: /astra/db/ingest
    method: POST
    data_selector: results
- name: Astra DB RAG
  endpoint:
    path: /astra/db/rag
    method: POST
    data_selector: results
- name: Chat Input
  endpoint:
    path: /chat/input
    method: POST
    data_selector: results
- name: Parse Data
  endpoint:
    path: /parse/data
    method: POST
    data_selector: results
- name: workflows
  endpoint:
    path: /workflows
    method: POST
    data_selector: workflow_settings
- name: jobs
  endpoint:
    path: /jobs
    method: GET
    data_selector: jobs_list
- name: Prompt
  endpoint:
    path: /prompt
    method: POST
    data_selector: records
- name: OpenAI
  endpoint:
    path: /openai
    method: POST
    data_selector: records
- name: Chat Output
  endpoint:
    path: /chat_output
    method: POST
    data_selector: records
- name: job
  endpoint:
    path: /jobs/<job-id>
    method: GET
    data_selector: job_information
- name: job_details
  endpoint:
    path: /jobs/<job-id>/details
    method: GET
    data_selector: job_details
- name: failed_files
  endpoint:
    path: /jobs/<job-id>/failed-files
    method: GET
    data_selector: job_failed_files
- name: cancel_job
  endpoint:
    path: /jobs/<job-id>/cancel
    method: POST
- name: download_job_output
  endpoint:
    path: /jobs/<job-id>/download
    method: GET
- name: confluence_spaces
  endpoint:
    path: /wiki/rest/api/space
    method: GET
    data_selector: results
    params: {}
- name: confluence_pages
  endpoint:
    path: /wiki/rest/api/content
    method: GET
    data_selector: results
    params: {}
- name: <name>
  endpoint:
    path: /sources
    method: POST
    data_selector: source_connector_information
    params: {}
- name: dropbox_app_folder
  endpoint:
    path: /dropbox/app/folder
    method: POST
    data_selector: files
    params: {}
- name: Pinecone
  endpoint:
    path: /pinecone
    method: GET
    data_selector: records
- name: OpenAI LLM
  endpoint:
    path: /openai
    method: POST
    data_selector: response
- name: element
  endpoint:
    path: /api/elements
    method: GET
    data_selector: elements
- name: dropbox_files
  endpoint:
    path: /files/list_folder
    method: POST
    data_selector: entries
- name: cleaning
  endpoint:
    path: /cleaning
    method: GET
    data_selector: elements
- name: google_drive
  endpoint:
    path: /sources
    method: POST
    data_selector: source_connector_information
- name: jira
  endpoint:
    path: /sources
    method: POST
    data_selector: source_connector_information
- name: onedrive_connector
  endpoint:
    path: /sources
    method: POST
    data_selector: source_connector_information
- name: partition_broken_paragraphs
  endpoint:
    path: /unstructured/cleaners/core/group_broken_paragraphs
    method: GET
    data_selector: examples
- name: remove_punctuation
  endpoint:
    path: /unstructured/cleaners/core/remove_punctuation
    method: GET
    data_selector: examples
- name: replace_unicode_quotes
  endpoint:
    path: /unstructured/cleaners/core/replace_unicode_quotes
    method: GET
    data_selector: examples
- name: extract_datetimetz
  endpoint:
    path: /unstructured/cleaners/extract/extract_datetimetz
    method: GET
    data_selector: examples
- name: translate_text
  endpoint:
    path: /unstructured/cleaners/translate/translate_text
    method: GET
    data_selector: examples
- name: partition_image
  endpoint:
    path: /unstructured/partition/image/partition_image
    method: GET
    data_selector: examples
- name: partition_md
  endpoint:
    path: /unstructured/partition/md/partition_md
    method: GET
    data_selector: examples
- name: partition_msg
  endpoint:
    path: /unstructured/partition/msg/partition_msg
    method: GET
    data_selector: examples
- name: partition_multiple_via_api
  endpoint:
    path: /unstructured/partition/api/partition_multiple_via_api
    method: GET
    data_selector: examples
- name: partition_odt
  endpoint:
    path: /unstructured/partition/odt/partition_odt
    method: GET
    data_selector: examples
- name: partition_org
  endpoint:
    path: /unstructured/partition/org/partition_org
    method: GET
    data_selector: examples
- name: partition_pdf
  endpoint:
    path: /unstructured/partition/pdf/partition_pdf
    method: GET
    data_selector: examples
- name: elements
  endpoint:
    path: /sources
    method: POST
    data_selector: source_connector_information
    params: {}
- name: sharepoint_files
  endpoint:
    path: /sharepoint/files
    method: GET
- name: snowflake_data
  endpoint:
    params:
      account_identifier: <account-identifier>
      user: <user>
      token: <programmatic-access-token>
- name: partition
  endpoint:
    path: /partition
    method: POST
    data_selector: elements
- name: partition_csv
  endpoint:
    path: /partition_csv
    method: POST
    data_selector: elements
- name: partition_doc
  endpoint:
    path: /partition_doc
    method: POST
    data_selector: elements
- name: partition_docx
  endpoint:
    path: /partition_docx
    method: POST
    data_selector: elements
- name: partition_email
  endpoint:
    path: /partition_email
    method: POST
    data_selector: elements
- name: partition_html
  endpoint:
    path: /partition_html
    method: POST
    data_selector: elements
- name: partition_image
  endpoint:
    path: /partition_image
    method: POST
    data_selector: elements
- name: partition_pdf
  endpoint:
    path: /partition_pdf
    method: POST
    data_selector: elements
- name: zendesk_tickets
  endpoint:
    path: /api/v2/tickets.json
    method: GET
    data_selector: tickets
- name: workflows
  endpoint:
    path: /workflows
    method: POST
- name: partition_image
  endpoint:
    path: /partition/image
    method: POST
- name: partition_md
  endpoint:
    path: /partition/md
    method: POST
- name: partition_msg
  endpoint:
    path: /partition/msg
    method: POST
- name: partition_multiple_via_api
  endpoint:
    path: /partition/multiple
    method: POST
- name: partition_odt
  endpoint:
    path: /partition/odt
    method: POST
- name: partition_org
  endpoint:
    path: /partition/org
    method: POST
- name: partition_pdf
  endpoint:
    path: /partition/pdf
    method: POST
- name: workflow
  endpoint:
    path: /workflows
    method: POST
    data_selector: workflow_nodes
- name: dropbox_source_connector
  endpoint:
    path: /dropbox/source
    method: POST
- name: Create Workflow
  endpoint:
    path: /api/v1/workflows/
    method: POST
- name: Delete Workflow
  endpoint:
    path: /api/v1/workflows/{workflow_id}
    method: DELETE
- name: Get Workflow
  endpoint:
    path: /api/v1/workflows/{workflow_id}
    method: GET
- name: List Workflows
  endpoint:
    path: /api/v1/workflows/
    method: GET
- name: Run Workflow
  endpoint:
    path: /api/v1/workflows/{workflow_id}/run
    method: POST
- name: Update Workflow
  endpoint:
    path: /api/v1/workflows/{workflow_id}
    method: PUT
- name: partition_tsv
  endpoint:
    path: /partition/tsv
    method: POST
    data_selector: elements
- name: partition_via_api
  endpoint:
    path: /partition/api
    method: POST
    data_selector: elements
- name: partition_xlsx
  endpoint:
    path: /partition/xlsx
    method: POST
    data_selector: elements
- name: partition_xml
  endpoint:
    path: /partition/xml
    method: POST
    data_selector: elements
- name: convert_to_csv
  endpoint:
    path: /staging/csv
    method: POST
    data_selector: isd_csv
- name: convert_to_dataframe
  endpoint:
    path: /staging/dataframe
    method: POST
    data_selector: df
- name: convert_to_dict
  endpoint:
    path: /staging/dict
    method: POST
    data_selector: isd
- name: dict_to_elements
  endpoint:
    path: /staging/elements
    method: POST
    data_selector: elements
- name: stage_csv_for_prodigy
  endpoint:
    path: /staging/prodigy/csv
    method: POST
    data_selector: prodigy_csv_data
- name: stage_for_argilla
  endpoint:
    path: /staging/argilla
    method: POST
    data_selector: argilla_dataset
- name: stage_for_baseplate
  endpoint:
    path: /staging/baseplate
    method: POST
    data_selector: rows
- name: stage_for_datasaur
  endpoint:
    path: /staging/datasaur
    method: POST
    data_selector: datasaur_data
- name: stage_for_label_box
  endpoint:
    path: /staging/labelbox
    method: POST
    data_selector: labelbox_config
- name: stage_for_label_studio
  endpoint:
    path: /staging/labelstudio
    method: POST
    data_selector: label_studio_data
- name: stage_for_prodigy
  endpoint:
    path: /staging/prodigy
    method: POST
    data_selector: prodigy_data
- name: blob_storage_credentials
  endpoint:
    path: /secrets/blob_storage_credentials
    method: GET
    data_selector: credentials
- name: database_credentials
  endpoint:
    path: /secrets/database_credentials
    method: GET
    data_selector: credentials
- name: authentication
  endpoint:
    path: /secrets/authentication
    method: GET
    data_selector: credentials
- name: blob_storage_settings
  endpoint:
    path: /configmaps/blob_storage_settings
    method: GET
    data_selector: settings
- name: environment
  endpoint:
    path: /configmaps/environment
    method: GET
    data_selector: environment
- name: observability_and_opentelementry
  endpoint:
    path: /configmaps/observability_and_opentelementry
    method: GET
    data_selector: otel
- name: unstructured_api_and_authentication
  endpoint:
    path: /configmaps/unstructured_api_and_authentication
    method: GET
    data_selector: api_auth
- name: create_destination_connection_check
  endpoint:
    path: /api/v1/destinations/{destination_id}/connection-check
    method: POST
- name: create_destination_connector
  endpoint:
    path: /api/v1/destinations/
    method: POST
- name: delete_destination_connector
  endpoint:
    path: /api/v1/destinations/{destination_id}
    method: DELETE
- name: get_destination_connector
  endpoint:
    path: /api/v1/destinations/{destination_id}
    method: GET
- name: get_latest_destination_connector_connection_check
  endpoint:
    path: /api/v1/destinations/{destination_id}/connection-check
    method: GET
- name: list_destination_connectors
  endpoint:
    path: /api/v1/destinations/
    method: GET
- name: update_destination_connector
  endpoint:
    path: /api/v1/destinations/{destination_id}
    method: PUT
- name: cancel_job
  endpoint:
    path: /api/v1/jobs/{job_id}/cancel
    method: POST
- name: download_job_output
  endpoint:
    path: /api/v1/jobs/{job_id}/download
    method: GET
- name: get_job
  endpoint:
    path: /api/v1/jobs/{job_id}
    method: GET
- name: get_job_failed_files
  endpoint:
    path: /api/v1/jobs/{job_id}/failed-files
    method: GET
- name: get_job_processing_details
  endpoint:
    path: /api/v1/jobs/{job_id}/details
    method: GET
- name: list_jobs
  endpoint:
    path: /api/v1/jobs/
    method: GET
- name: summary
  endpoint:
    path: /general/v0/general
    method: POST
- name: VPC Resource Map
  endpoint:
    path: /YourVPCs
    method: GET
- name: S3 source
  endpoint:
    path: /s3/source
    method: POST
    data_selector: configuration_details
    params: {}
- name: S3 destination
  endpoint:
    path: /s3/destination
    method: POST
    data_selector: configuration_details
    params: {}
- name: firecrawl
  endpoint:
    path: /crawls
    method: GET
    data_selector: records
- name: pinecone
  endpoint:
    path: /indexes
    method: POST
    data_selector: records
- name: partition
  endpoint:
    path: /api/partition
    method: POST
    data_selector: elements
- name: partition
  endpoint:
    path: /
    method: POST
    data_selector: elements
- name: OpenAI Embeddings
  endpoint:
    path: /openai/embeddings
    method: POST
    data_selector: embeddings
- name: Astra DB Ingest
  endpoint:
    path: /astra/db/ingest
    method: POST
    data_selector: results
- name: Astra DB RAG
  endpoint:
    path: /astra/db/search
    method: POST
    data_selector: searchResults
- name: partition
  endpoint:
    path: ''
    method: POST
    data_selector: ''
    params: {}
- name: source_connectors
  endpoint:
    path: /api-reference/workflow/sources/overview
    method: GET
- name: partition
  endpoint:
    path: /partition
    method: POST
    data_selector: elements
- name: doc_processor
  endpoint:
    path: /api/v1/doc_processor
    method: POST
    data_selector: processed_content
- name: Pinecone
  endpoint:
    path: /api/v1/pinecone
    method: POST
    data_selector: results
- name: subject
  endpoint:
    path: /services/data/vXX.X/sobjects/Subject
    method: GET
    data_selector: records
- name: section
  endpoint:
    path: /services/data/vXX.X/sobjects/Section
    method: GET
    data_selector: records
- name: header_footer_type
  endpoint:
    path: /services/data/vXX.X/sobjects/HeaderFooterType
    method: GET
    data_selector: records
- name: emphasized_text_contents
  endpoint:
    path: /services/data/vXX.X/sobjects/EmphasizedTextContents
    method: GET
    data_selector: records
- name: emphasized_text_tags
  endpoint:
    path: /services/data/vXX.X/sobjects/EmphasizedTextTags
    method: GET
    data_selector: records
- name: text_as_html
  endpoint:
    path: /services/data/vXX.X/sobjects/TextAsHtml
    method: GET
    data_selector: records
- name: regex_metadata
  endpoint:
    path: /services/data/vXX.X/sobjects/RegexMetadata
    method: GET
    data_selector: records
- name: detection_class_prob
  endpoint:
    path: /services/data/vXX.X/sobjects/DetectionClassProb
    method: GET
    data_selector: records
- name: partitioner_type
  endpoint:
    path: /services/data/vXX.X/sobjects/PartitionerType
    method: GET
    data_selector: records
- name: destination
  endpoint:
    path: /destinations
    method: POST
    data_selector: destination_connector_information
- name: Pinecone
  endpoint:
    path: /Pinecone
    method: POST
- name: OpenAI LLM
  endpoint:
    path: /OpenAI
    method: POST
- name: destination
  endpoint:
    path: /destinations
    method: POST
    data_selector: destination_connector_information
- name: delta_table
  endpoint:
    path: /sources
    method: POST
    data_selector: destination_connector_information
    params: {}
- name: document_elements
  endpoint:
    path: /api/v1/elements
    method: GET
    data_selector: elements
- name: destination_connector
  endpoint:
    path: /api/v1/destinations
    method: POST
    data_selector: destination_connector_information
- name: kafka-cloud
  endpoint:
    path: /destinations
    method: POST
    data_selector: destination_connector_information
    params: {}
- name: milvus
  endpoint:
    path: /destinations
    method: POST
    data_selector: destination_connector_information
    params: {}
- name: my_collection
  endpoint:
    path: /services/data/vXX.X/sobjects/my_collection
    method: POST
    data_selector: records
    params: {}
- name: extract_datetimetz
  endpoint:
    path: /extract/datetimetz
    method: GET
    data_selector: records
- name: partition_image
  endpoint:
    path: /partition/image
    method: POST
    data_selector: elements
- name: partition_md
  endpoint:
    path: /partition/md
    method: GET
    data_selector: elements
- name: partition_msg
  endpoint:
    path: /partition/msg
    method: GET
    data_selector: elements
- name: partition_multiple_via_api
  endpoint:
    path: /partition/multiple
    method: POST
    data_selector: documents
- name: partition_odt
  endpoint:
    path: /partition/odt
    method: GET
    data_selector: elements
- name: partition_org
  endpoint:
    path: /partition/org
    method: GET
    data_selector: elements
- name: partition_pdf
  endpoint:
    path: /partition/pdf
    method: GET
    data_selector: elements
- name: extract_us_phone_number
  endpoint:
    path: /extract/us_phone_number
    method: GET
    data_selector: phone_number
- name: onedrive
  endpoint:
    path: /destinations
    method: POST
    data_selector: destination_connector_information
- name: partition
  endpoint:
    path: /partition
    method: GET
    data_selector: elements
- name: partition_csv
  endpoint:
    path: /partition_csv
    method: GET
    data_selector: elements
- name: partition_doc
  endpoint:
    path: /partition_doc
    method: GET
    data_selector: elements
- name: partition_docx
  endpoint:
    path: /partition_docx
    method: GET
    data_selector: elements
- name: partition_email
  endpoint:
    path: /partition_email
    method: GET
    data_selector: elements
- name: partition_html
  endpoint:
    path: /partition_html
    method: GET
    data_selector: elements
- name: partition_image
  endpoint:
    path: /partition_image
    method: GET
    data_selector: elements
- name: partition_pdf
  endpoint:
    path: /partition/pdf
    method: POST
    data_selector: elements
    params: {}
- name: destination
  endpoint:
    path: /destinations
    method: POST
    data_selector: destination_connector_information
- name: documents
  endpoint:
    path: /path/to/documents
    method: GET
- name: destination
  endpoint:
    path: /destinations
    method: POST
    data_selector: destination_connector_information
- name: destination_connector
  endpoint:
    path: /destinations
    method: POST
    data_selector: destination_connector_information
- name: create_destination_connection_check
  endpoint:
    path: /api/v1/destinations/{destination_id}/connection-check
    method: POST
- name: create_destination_connector
  endpoint:
    path: /api/v1/destinations/
    method: POST
- name: delete_destination_connector
  endpoint:
    path: /api/v1/destinations/{destination_id}
    method: DELETE
- name: get_destination_connector
  endpoint:
    path: /api/v1/destinations/{destination_id}
    method: GET
- name: get_latest_destination_connector_connection_check
  endpoint:
    path: /api/v1/destinations/{destination_id}/connection-check
    method: GET
- name: list_destination_connectors
  endpoint:
    path: /api/v1/destinations/
    method: GET
- name: update_destination_connector
  endpoint:
    path: /api/v1/destinations/{destination_id}
    method: PUT
- name: cancel_job
  endpoint:
    path: /api/v1/jobs/{job_id}/cancel
    method: POST
- name: download_job_output
  endpoint:
    path: /api/v1/jobs/{job_id}/download
    method: GET
- name: get_job
  endpoint:
    path: /api/v1/jobs/{job_id}
    method: GET
- name: get_job_failed_files
  endpoint:
    path: /api/v1/jobs/{job_id}/failed-files
    method: GET
- name: get_job_processing_details
  endpoint:
    path: /api/v1/jobs/{job_id}/details
    method: GET
- name: list_jobs
  endpoint:
    path: /api/v1/jobs/
    method: GET
- name: summary
  endpoint:
    path: /general/v0/general
    method: POST
- name: workflows
  endpoint:
    path: /workflows
    method: POST
    data_selector: settings
- name: jobs
  endpoint:
    path: /jobs
    method: GET
    data_selector: response_list_jobs
- name: job
  endpoint:
    path: /jobs/<job-id>
    method: GET
    data_selector: job_information
- name: job_details
  endpoint:
    path: /jobs/<job-id>/details
    method: GET
    data_selector: job_details
- name: failed_files
  endpoint:
    path: /jobs/<job-id>/failed-files
    method: GET
    data_selector: job_failed_files
- name: cancel_job
  endpoint:
    path: /jobs/<job-id>/cancel
    method: POST
- name: download_job_output
  endpoint:
    path: /jobs/<job-id>/download
    method: GET
- name: partition
  endpoint:
    path: /partition
    method: POST
    data_selector: elements
- name: couchbase
  endpoint:
    path: /sources
    method: POST
    data_selector: sources
    params: {}
- name: databricks_volumes
  endpoint:
    path: /sources
    method: POST
    data_selector: sources
    params: {}
- name: partition
  endpoint:
    path: /general
    method: POST
    data_selector: elements
- name: dropbox
  endpoint:
    path: /sources/dropbox
    method: POST
- name: partition
  endpoint:
    path: /api/partition
    method: POST
    data_selector: elements
- name: dropbox_files
  endpoint:
    path: /files/list_folder
    method: POST
    data_selector: entries
- name: onedrive
  endpoint:
    path: /sources
    method: POST
    params: {}
- name: index
  endpoint:
    path: /indexes
    method: GET
    data_selector: value
    params: {}
- name: subject
  endpoint:
    path: /services/data/vXX.X/sobjects/Subject
    method: GET
    data_selector: records
- name: section
  endpoint:
    path: /services/data/vXX.X/sobjects/Section
    method: GET
    data_selector: records
- name: header_footer_type
  endpoint:
    path: /services/data/vXX.X/sobjects/HeaderFooterType
    method: GET
    data_selector: records
- name: emphasized_text_contents
  endpoint:
    path: /services/data/vXX.X/sobjects/EmphasizedTextContents
    method: GET
    data_selector: records
- name: emphasized_text_tags
  endpoint:
    path: /services/data/vXX.X/sobjects/EmphasizedTextTags
    method: GET
    data_selector: records
- name: text_as_html
  endpoint:
    path: /services/data/vXX.X/sobjects/TextAsHtml
    method: GET
    data_selector: records
- name: regex_metadata
  endpoint:
    path: /services/data/vXX.X/sobjects/RegexMetadata
    method: GET
    data_selector: records
- name: detection_class_prob
  endpoint:
    path: /services/data/vXX.X/sobjects/DetectionClassProb
    method: GET
    data_selector: records
- name: partitioner_type
  endpoint:
    path: /services/data/vXX.X/sobjects/PartitionerType
    method: GET
    data_selector: records
- name: destination_connector
  endpoint:
    path: /destinations
    method: POST
    data_selector: destination_connector_information
- name: zendesk_data
  endpoint:
    path: /api/v2/tickets.json
    method: GET
    data_selector: tickets
- name: databricks_destination
  endpoint:
    path: /destinations
    method: POST
    data_selector: destination_connector_information
- name: delta_table
  endpoint:
    path: /path/to/delta_table
    method: POST
    data_selector: records
- name: Partitioner
  type: partition
  subtype: unstructured_api
  settings:
    strategy: hi_res
- name: Enrichment
  type: prompter
  subtype: openai_image_description
  settings: {}
- name: Enrichment
  type: prompter
  subtype: openai_table_description
  settings: {}
- name: Enrichment
  type: prompter
  subtype: openai_table2html
  settings: {}
- name: Chunker
  type: chunk
  subtype: chunk_by_character
  settings:
    unstructured_api_url: null
    unstructured_api_key: null
- name: kafka
  endpoint:
    path: /destinations
    method: POST
    data_selector: destination_connector_information
- name: local
  endpoint:
    path: /destinations/local
    method: POST
    data_selector: destination_connector_information
- name: milvus
  endpoint:
    path: /destinations/milvus
    method: POST
    data_selector: destination_connector_information
- name: my_collection
  endpoint:
    path: /services/data/vXX.X/sobjects/my_collection
    method: POST
    data_selector: records
- name: create_workflow
  endpoint:
    path: /api/v1/workflows/
    method: POST
- name: delete_workflow
  endpoint:
    path: /api/v1/workflows/{workflow_id}
    method: DELETE
- name: get_workflow
  endpoint:
    path: /api/v1/workflows/{workflow_id}
    method: GET
- name: list_workflows
  endpoint:
    path: /api/v1/workflows/
    method: GET
- name: run_workflow
  endpoint:
    path: /api/v1/workflows/{workflow_id}/run
    method: POST
- name: update_workflow
  endpoint:
    path: /api/v1/workflows/{workflow_id}
    method: PUT
- name: blob_storage_credentials
  endpoint:
    params:
      BLOB_STORAGE_ADAPTER_ACCOUNT_NAME: ''
      BLOB_STORAGE_ADAPTER_ACCOUNT_KEY: ''
      BLOB_STORAGE_ADAPTER_CONTAINER_REGION: ''
- name: database_credentials
  endpoint:
    params:
      DB_USERNAME: ''
      DB_PASSWORD: ''
      DB_HOST: ''
      DB_NAME: ''
      DB_DATABASE: ''
- name: authentication
  endpoint:
    params:
      JWT_SECRET_KEY: ''
      AUTH_STRATEGY: ''
      SESSION_SECRET: ''
      SHARED_SECRET: ''
      KEYCLOAK_CLIENT_SECRET: ''
      KEYCLOAK_ADMIN_SECRET: ''
      KEYCLOAK_ADMIN: ''
      KEYCLOAK_ADMIN_PASSWORD: ''
      API_BEARER_TOKEN: ''
- name: destination
  endpoint:
    path: /destinations
    method: POST
    data_selector: destination_connector_information
- name: destination
  endpoint:
    path: /destinations
    method: POST
    data_selector: destination_connector_information
- name: destination_connector
  endpoint:
    path: /destinations
    method: POST
    data_selector: destination_connector_information
    params: {}
- name: mlk_research
  endpoint:
    path: /mlk-research
    method: GET
    data_selector: records
- name: table_extraction
  endpoint:
    path: /table-extraction
    method: POST
    data_selector: tables
- name: multi_file_processing
  endpoint:
    path: /multi-file-processing
    method: POST
    data_selector: results
- name: delta_table
  endpoint:
    path: /delta-table
    method: GET
    data_selector: records
- name: vector_database
  endpoint:
    path: /vector-database
    method: POST
    data_selector: documents
- name: firecrawl
  endpoint:
    path: /s3-firecrawl-source
    method: POST
- name: pinecone
  endpoint:
    path: /pinecone-firecrawl-destination
    method: POST
- name: workflow_run
  endpoint:
    path: /workflows/<workflow-id>/run
    method: POST
- name: workflows
  endpoint:
    path: /workflows
    method: POST
    data_selector: null
    params: {}
- name: run_workflow
  endpoint:
    path: /workflows/<workflow-id>/run
    method: POST
    data_selector: null
    params: {}
- name: list_jobs
  endpoint:
    path: /jobs
    method: GET
    data_selector: null
    params: {}
- name: get_job
  endpoint:
    path: /jobs/<job-id>
    method: GET
    data_selector: null
    params: {}
- name: OpenAI Embeddings
  endpoint:
    params:
      Model: text-embedding-3-large
- name: Astra DB Ingest
  endpoint:
    params:
      Astra DB Application Token: your Astra DB application token's value
- name: Astra DB RAG
  endpoint:
    params:
      Astra DB Application Token: your Astra DB application token's value
- name: Chat Input
  endpoint: {}
- name: Parse Data
  endpoint: {}
- name: prompt
  endpoint:
    path: /v1/chat/completions
    method: POST
    data_selector: choices
    params: {}
- name: job_details
  endpoint:
    path: /jobs/<job-id>/details
    method: GET
- name: failed_files
  endpoint:
    path: /jobs/<job-id>/failed-files
    method: GET
- name: cancel_job
  endpoint:
    path: /jobs/<job-id>/cancel
    method: POST
- name: download_job_output
  endpoint:
    path: /jobs/<job-id>/download
    method: GET
- name: source_connectors
  endpoint:
    path: /api-reference/workflow/sources/overview
    method: GET
    data_selector: response_list_sources
- name: <name>
  endpoint:
    path: /sources
    method: POST
    data_selector: source_connector_information
- name: dropbox_app_folder
  endpoint:
    path: /apps/<app-folder-name>
    method: GET
- name: projects
  endpoint:
    path: /rest/api/latest/project
    method: GET
- name: boards
  endpoint:
    path: /rest/agile/1.0/board
    method: GET
- name: issues
  endpoint:
    path: /rest/api/latest/issue
    method: GET
- name: Pinecone
  endpoint:
    method: POST
- name: OpenAI
  endpoint:
    method: POST
- name: onedrive_folder
  endpoint:
    path: <path>
    method: POST
    data_selector: source_connector_information
    params:
      recursive: <True|False>
- name: documents
  endpoint:
    path: /sites/<site>/libraries/<library>/path/<path>
    method: GET
- name: zendesk_source
  endpoint:
    path: /sources/zendesk
    method: POST
    data_selector: source_connector_information
- name: partition_csv
  endpoint:
    path: /partition_csv
    method: POST
    data_selector: elements
    params: {}
- name: partition_doc
  endpoint:
    path: /partition_doc
    method: POST
    data_selector: elements
    params: {}
- name: partition_docx
  endpoint:
    path: /partition_docx
    method: POST
    data_selector: elements
    params: {}
- name: partition_email
  endpoint:
    path: /partition_email
    method: POST
    data_selector: elements
    params: {}
- name: partition_html
  endpoint:
    path: /partition_html
    method: POST
    data_selector: elements
    params: {}
- name: partition_image
  endpoint:
    path: /partition_image
    method: POST
    data_selector: elements
    params: {}
- name: partition_md
  endpoint:
    path: /partition_md
    method: POST
    data_selector: elements
    params: {}
- name: partition_msg
  endpoint:
    path: /partition_msg
    method: POST
    data_selector: elements
    params: {}
- name: partition_multiple_via_api
  endpoint:
    path: /partition_multiple_via_api
    method: POST
    data_selector: elements
    params: {}
- name: workflows
  endpoint:
    path: /workflows
    method: POST
- name: partition_odt
  endpoint:
    path: /partition/odt
    method: POST
- name: partition_org
  endpoint:
    path: /partition/org
    method: POST
- name: partition_pdf
  endpoint:
    path: /partition/pdf
    method: POST
- name: partition_ppt
  endpoint:
    path: /partition/ppt
    method: POST
- name: partition_pptx
  endpoint:
    path: /partition/pptx
    method: POST
- name: partition_rst
  endpoint:
    path: /partition/rst
    method: POST
- name: partition_rtf
  endpoint:
    path: /partition/rtf
    method: POST
- name: partition_text
  endpoint:
    path: /partition/text
    method: POST
- name: partition_tsv
  endpoint:
    path: /partition/tsv
    method: POST
- name: partition_via_api
  endpoint:
    path: /partition/via_api
    method: POST
- name: partition_xlsx
  endpoint:
    path: /partition/xlsx
    method: POST
- name: partition_xml
  endpoint:
    path: /partition/xml
    method: POST
- name: create_workflow
  endpoint:
    path: /api/v1/workflows/
    method: POST
- name: delete_workflow
  endpoint:
    path: /api/v1/workflows/{workflow_id}
    method: DELETE
- name: get_workflow
  endpoint:
    path: /api/v1/workflows/{workflow_id}
    method: GET
- name: list_workflows
  endpoint:
    path: /api/v1/workflows/
    method: GET
- name: run_workflow
  endpoint:
    path: /api/v1/workflows/{workflow_id}/run
    method: POST
- name: update_workflow
  endpoint:
    path: /api/v1/workflows/{workflow_id}
    method: PUT
- name: pdf_ingestion
  endpoint:
    path: /ingest/pdf
    method: POST
    data_selector: results
- name: blob_storage_credentials
  endpoint:
    params:
      BLOB_STORAGE_ADAPTER_ACCOUNT_NAME: ''
      BLOB_STORAGE_ADAPTER_ACCOUNT_KEY: ''
      BLOB_STORAGE_ADAPTER_CONTAINER_REGION: ''
- name: database_credentials
  endpoint:
    params:
      DB_USERNAME: ''
      DB_PASSWORD: ''
      DB_HOST: ''
      DB_NAME: ''
      DB_DATABASE: ''
- name: chroma_collection
  endpoint:
    path: /api/chroma/collection
    method: GET
    data_selector: data
- name: chroma
  endpoint:
    path: /
    method: POST
    data_selector: records
- name: mlk_research
  endpoint:
    path: /mlk-research
    method: GET
    data_selector: data
- name: table_extraction
  endpoint:
    path: /table-extraction
    method: POST
    data_selector: tables
- name: multi_file_processing
  endpoint:
    path: /multi-file-processing
    method: POST
    data_selector: results
- name: delta_table
  endpoint:
    path: /delta-table
    method: GET
    data_selector: data
- name: vector_database
  endpoint:
    path: /vector-database
    method: POST
    data_selector: documents
- name: azure_storage
  endpoint:
    path: /
    method: POST
    data_selector: records
- name: chroma
  endpoint:
    path: /api/reference/partition/overview
    method: POST
    data_selector: data
    params: {}
- name: couchbase
  endpoint:
    path: /couchbase
    method: POST
    data_selector: records
- name: s3-firecrawl-source
  endpoint:
    path: /connectors/s3-firecrawl-source
    method: POST
- name: pinecone-firecrawl-destination
  endpoint:
    path: /connectors/pinecone-firecrawl-destination
    method: POST
- name: kafka_source
  endpoint:
    path: /kafka/source
    method: POST
    data_selector: messages
    params:
      topic: your_topic_name
      api_key: your_api_key
      secret: your_secret
- name: Astra DB Ingest
  endpoint:
    path: /ingest
    method: POST
- name: Astra DB RAG
  endpoint:
    path: /rag
    method: POST
- name: OpenAI
  endpoint:
    path: /v1/engines/gpt-4o-mini/completions
    method: POST
    data_selector: choices
    params: {}
- name: sources
  endpoint:
    path: /api/v1/sources
    method: GET
    data_selector: response_list_sources
- name: repository
  endpoint:
    path: /repos/{owner}/{repo}
    method: GET
    data_selector: data
    params: {}
- name: app_folder
  endpoint:
    path: /home/Apps/my-folder/data
    method: GET
    data_selector: files
- name: Pinecone
  endpoint:
    path: /api/v1/indexes
    method: POST
    data_selector: data
    params: {}
- name: Account
  endpoint:
    path: /services/data/vXX.X/sobjects/Account
    method: GET
- name: Campaign
  endpoint:
    path: /services/data/vXX.X/sobjects/Campaign
    method: GET
- name: Case
  endpoint:
    path: /services/data/vXX.X/sobjects/Case
    method: GET
- name: EmailMessage
  endpoint:
    path: /services/data/vXX.X/sobjects/EmailMessage
    method: GET
- name: Lead
  endpoint:
    path: /services/data/vXX.X/sobjects/Lead
    method: GET
- name: partition
  endpoint:
    path: /partition
    method: POST
    data_selector: elements
- name: partition_csv
  endpoint:
    path: /partition/csv
    method: POST
    data_selector: elements
- name: partition_email
  endpoint:
    path: /partition/email
    method: POST
    data_selector: elements
- name: partition_html
  endpoint:
    path: /partition/html
    method: POST
    data_selector: elements
- name: partition_image
  endpoint:
    path: /partition/image
    method: POST
    data_selector: elements
- name: partition_md
  endpoint:
    path: /partition/md
    method: POST
    data_selector: elements
- name: partition_msg
  endpoint:
    path: /partition/msg
    method: POST
    data_selector: elements
- name: partition_pdf
  endpoint:
    path: /partition/pdf
    method: POST
    data_selector: elements
- name: partition_docx
  endpoint:
    path: /partition/docx
    method: POST
    data_selector: elements
- name: partition_epub
  endpoint:
    path: /partition/epub
    method: POST
    data_selector: elements
- name: partition_odt
  endpoint:
    path: /partition/odt
    method: POST
    data_selector: elements
- name: partition_text
  endpoint:
    path: /partition/text
    method: POST
    data_selector: elements
- name: elements
  endpoint:
    path: /services/data/vXX.X/sobjects/ELEMENTS
    method: GET
    data_selector: records
- name: convert_to_csv
  endpoint:
    path: /unstructured/staging/base/convert_to_csv
    method: POST
    data_selector: elements
    params: {}
- name: convert_to_dataframe
  endpoint:
    path: /unstructured/staging/base/convert_to_dataframe
    method: POST
    data_selector: elements
    params: {}
- name: convert_to_dict
  endpoint:
    path: /unstructured/staging/base/convert_to_dict
    method: POST
    data_selector: elements
    params: {}
- name: dict_to_elements
  endpoint:
    path: /unstructured/staging/base/dict_to_elements
    method: POST
    data_selector: isd
    params: {}
- name: stage_csv_for_prodigy
  endpoint:
    path: /unstructured/staging/prodigy/stage_csv_for_prodigy
    method: POST
    data_selector: elements
    params: {}
- name: stage_for_argilla
  endpoint:
    path: /unstructured/staging/argilla/stage_for_argilla
    method: POST
    data_selector: elements
    params: {}
- name: tickets
  endpoint:
    path: /api/v2/tickets.json
    method: GET
- name: articles
  endpoint:
    path: /api/v2/articles.json
    method: GET
- name: stage_for_baseplate
  endpoint:
    path: /api/v1/stage_for_baseplate
    method: POST
    data_selector: rows
- name: stage_for_datasaur
  endpoint:
    path: /api/v1/stage_for_datasaur
    method: POST
    data_selector: datasaur_data
- name: stage_for_label_box
  endpoint:
    path: /api/v1/stage_for_label_box
    method: POST
    data_selector: labelbox_config
- name: stage_for_label_studio
  endpoint:
    path: /api/v1/stage_for_label_studio
    method: POST
    data_selector: label_studio_data
- name: stage_for_prodigy
  endpoint:
    path: /api/v1/stage_for_prodigy
    method: POST
    data_selector: prodigy_data
- name: stage_for_transformers
  endpoint:
    path: /api/v1/stage_for_transformers
    method: POST
    data_selector: elements
- name: stage_for_weaviate
  endpoint:
    path: /api/v1/stage_for_weaviate
    method: POST
    data_selector: data_objects
- name: topic
  endpoint:
    path: /topics
    method: GET
    data_selector: records
- name: bedrock
  endpoint:
    path: /api/bedrock
    method: GET
- name: huggingface
  endpoint:
    path: /api/huggingface
    method: GET
- name: mixedbread-ai
  endpoint:
    path: /api/mixedbread-ai
    method: GET
- name: octoai
  endpoint:
    path: /api/octoai
    method: GET
- name: openai
  endpoint:
    path: /api/openai
    method: GET
- name: togetherai
  endpoint:
    path: /api/togetherai
    method: GET
- name: vertexai
  endpoint:
    path: /api/vertexai
    method: GET
- name: voyageai
  endpoint:
    path: /api/voyageai
    method: GET
- name: elements
  endpoint:
    path: /path/to/your/endpoint
    method: POST
    data_selector: data
    params: {}
- name: OneDrive
  endpoint:
    path: /
    method: POST
- name: partition_strategy_pdf
  endpoint:
    path: /unstructured-ingest/partition-strategy/pdf
    method: POST
- name: ocr_results
  endpoint:
    path: /unstructured-ingest/ocr/results
    method: POST
- name: bounding_box_coordinates
  endpoint:
    path: /unstructured-ingest/bounding-box
    method: POST
- name: unique_element_ids
  endpoint:
    path: /unstructured-ingest/unique-ids
    method: POST
- name: file_filtering
  endpoint:
    path: /unstructured-ingest/file-filter
    method: POST
- name: destination_connector
  endpoint:
    method: POST
    params: {}
- name: chroma_data
  endpoint:
    path: /chroma
    method: POST
    data_selector: data
    params: {}
- name: pinecone-destination-connector
  endpoint:
    path: /connectors
    method: POST
    data_selector: connector
    params:
      api_key: '{{ dlt.secrets[''api_key''] }}'
- name: collection
  endpoint:
    path: /collection/{collection_name}
    method: POST
- name: chunked_elements
  endpoint:
    path: /api-reference/partition/overview
    method: POST
    data_selector: elements
    params: {}
- name: redis_connector
  endpoint:
    path: /create-connector
    method: POST
    data_selector: connector
    params: {}
- name: unstructured_ingest
  endpoint:
    path: /unstructured_ingest
    method: POST
    data_selector: records
- name: local
  endpoint:
    path: /ingestion/local
    method: POST
- name: chroma
  endpoint:
    path: /chroma
    method: POST
    data_selector: data
- name: motherduck
  endpoint:
    path: /motherduck
    method: POST
- name: couchbase
  endpoint:
    path: /couchbase
    method: POST
    data_selector: records
    params: {}
- name: unstructured_partition
  endpoint:
    path: /api-reference/partition/overview
    method: POST
- name: messages
  endpoint:
    path: /kafka/messages
    method: GET
    data_selector: records
    params:
      topic: required
      api_key: required
      secret: required
- name: redis
  endpoint:
    path: /redis
    method: POST
- name: databricks_volume
  endpoint:
    path: /databricks/volumes
    method: GET
    data_selector: records
- name: bucket_policy
  endpoint:
    path: /s3/api/get-bucket-policy
    method: GET
    data_selector: Policy
    params: {}
- name: create_bucket
  endpoint:
    path: /s3/api/create-bucket
    method: POST
    data_selector: BucketName
    params: {}
- name: elements
  endpoint:
    params:
      incremental: record_id
- name: tickets
  endpoint:
    path: /api/v2/tickets.json
    method: GET
    data_selector: tickets
- name: articles
  endpoint:
    path: /api/v2/help_center/articles.json
    method: GET
    data_selector: articles
- name: repository
  endpoint:
    path: /repos/{owner}/{repo}
    method: GET
    data_selector: repository
- name: documents
  endpoint:
    path: /sites/{site}/drive/root:/Documents
    method: GET
    data_selector: value
- name: app_folder
  endpoint:
    path: /home/Apps/<app_folder_name>
    method: GET
    data_selector: records
    params: {}
- name: dropbox
  endpoint:
    path: /dropbox
    method: POST
- name: document
  endpoint:
    path: /api/v1/documents
    method: POST
    data_selector: records
- name: document_permissions
  endpoint:
    path: /wiki/rest/api/user
    method: GET
- name: elements
  endpoint:
    path: /services/data/vXX.X/sobjects/elements
    method: GET
    data_selector: records
- name: kafka_topic
  endpoint:
    path: /api/v1/kafka/topic
    method: POST
- name: tickets
  endpoint:
    path: /api/v2/tickets.json
    method: GET
- name: articles
  endpoint:
    path: /api/v2/help_center/articles.json
    method: GET
- name: delta_table
  endpoint:
    path: /delta-table
    method: GET
    data_selector: data
    params: {}
- name: discord
  endpoint:
    path: /discord
    method: GET
    data_selector: messages
    params: {}
- name: elasticsearch_index
  endpoint:
    path: /
    method: GET
    data_selector: indices
    params: {}
- name: topic
  endpoint:
    path: /create-topics
    method: GET
- name: Milvus on IBM watsonx.data
  endpoint:
    path: /path/to/endpoint
    method: POST
    data_selector: data
    params: {}
- name: Milvus on Zilliz Cloud
  endpoint:
    path: /path/to/endpoint
    method: POST
    data_selector: data
    params: {}
- name: Milvus local
  endpoint:
    path: /path/to/endpoint
    method: POST
    data_selector: data
    params: {}
- name: elements
  endpoint:
    path: /api/elements
    method: POST
- name: elements
  endpoint:
    path: /api-reference/partition/document-elements
    method: POST
- name: connector
  endpoint:
    path: /ui/destinations/pinecone
    method: POST
    data_selector: connector
    params:
      api_key: Pinecone API key
- name: pinecone-destination-connector
  endpoint:
    path: /api/v1/connectors
    method: POST
    data_selector: data
    params: {}
- name: messages
  endpoint:
    path: /api/conversations.history
    method: GET
    params:
      channels: '{{ target_channel_ids }}'
      start_date: '{{ start_date }}'
      end_date: '{{ end_date }}'
- name: elements
  endpoint:
    path: /services/data/vXX.X/sobjects/elements
    method: GET
    data_selector: records
- name: destination_connector
  endpoint:
    path: /ui/destinations/redis
    method: POST
- name: tickets
  endpoint:
    path: /api/v2/tickets.json
    method: GET
    data_selector: tickets
- name: articles
  endpoint:
    path: /api/v2/articles.json
    method: GET
    data_selector: articles
- name: motherduck
  endpoint:
    path: /motherduck
    method: POST
    data_selector: records
    params: {}
- name: prodigy_integration
  endpoint:
    path: /open-source/core-functionality/staging
    method: GET
    data_selector: outputs
    params: {}
- name: labelbox_integration
  endpoint:
    path: /open-source/core-functionality/staging
    method: GET
    data_selector: outputs
    params: {}
- name: llama_index_integration
  endpoint:
    path: /open-source/core-functionality/staging
    method: GET
    data_selector: outputs
    params: {}
- name: local_file_processing
  endpoint:
    path: /local/processing
    method: POST
    data_selector: results
    params: {}
- name: opensearch
  endpoint:
    path: /opensearch
    method: POST
    data_selector: results
    params: {}
- name: target_database
  endpoint:
    path: /database
    method: GET
    data_selector: records
- name: Astra DB
  endpoint:
    path: /api/v1/namespaces/{namespace}/collections/{collection}
    method: POST
    data_selector: records
- name: fields
  endpoint:
    path: /$metadata/indexes/$entity
    method: GET
    data_selector: '@odata.context'
- name: bucket_policy
  endpoint:
    path: /s3/bucket_policy
    method: PUT
    data_selector: Policy
    params: {}
- name: create_bucket
  endpoint:
    path: /s3/create_bucket
    method: POST
    data_selector: Bucket
    params: {}
- name: elements
  endpoint:
    path: /services/data/vXX.X/sobjects/elements
    method: GET
    data_selector: records
- name: subject
  endpoint:
    path: /services/data/vXX.X/sobjects/Subject
    method: GET
    data_selector: records
- name: section
  endpoint:
    path: /services/data/vXX.X/sobjects/Section
    method: GET
    data_selector: records
- name: header_footer_type
  endpoint:
    path: /services/data/vXX.X/sobjects/HeaderFooterType
    method: GET
    data_selector: records
- name: emphasized_text_contents
  endpoint:
    path: /services/data/vXX.X/sobjects/EmphasizedTextContents
    method: GET
    data_selector: records
- name: emphasized_text_tags
  endpoint:
    path: /services/data/vXX.X/sobjects/EmphasizedTextTags
    method: GET
    data_selector: records
- name: text_as_html
  endpoint:
    path: /services/data/vXX.X/sobjects/TextAsHtml
    method: GET
    data_selector: records
- name: regex_metadata
  endpoint:
    path: /services/data/vXX.X/sobjects/RegexMetadata
    method: GET
    data_selector: records
- name: detection_class_prob
  endpoint:
    path: /services/data/vXX.X/sobjects/DetectionClassProb
    method: GET
    data_selector: records
- name: partitioner_type
  endpoint:
    path: /services/data/vXX.X/sobjects/PartitionerType
    method: GET
    data_selector: records
- name: connector
  endpoint:
    path: /api/search/indexes
    method: POST
- name: tickets
  endpoint:
    path: /api/v2/tickets.json
    method: GET
    data_selector: tickets
- name: articles
  endpoint:
    path: /api/v2/help_center/articles.json
    method: GET
    data_selector: articles
- name: Couchbase Capella
  endpoint:
    path: /api/v1/couchbase_capella
    method: POST
    data_selector: records
    params:
      bucket: required
      connection_string: required
      scope: optional
      collection: optional
      batch_size: optional
      collection_id_key: optional
      username: required
      password: required
- name: documents
  endpoint:
    path: /sites/<site-collection-name>/Documents
    method: GET
- name: databricks_volume
  endpoint:
    path: /api/2.0/preview/volumes
    method: POST
    data_selector: data
- name: messages
  endpoint:
    path: /api/conversations.history
    method: GET
    params: {}
- name: elements
  endpoint:
    params:
      ID Column: RECORD_ID
- name: tickets
  endpoint:
    path: /api/v2/tickets
    method: GET
    data_selector: tickets
- name: articles
  endpoint:
    path: /api/v2/help_center/articles
    method: GET
    data_selector: articles
- name: space
  endpoint:
    path: /wiki/rest/api/space
    method: GET
    data_selector: results
- name: kafka_topic
  endpoint:
    path: /kafka/topics
    method: GET
    data_selector: topics
    params: {}
- name: messages
  endpoint:
    path: /topics/{topic}
    method: GET
    data_selector: records
    params: {}
- name: collection
  endpoint:
    path: /services/data/vXX.X/sobjects/Collection
    method: POST
    data_selector: records
- name: delta_table
  endpoint:
    path: /delta-table
    method: GET
- name: discord
  endpoint:
    path: /discord
    method: GET
- name: Pinecone
  endpoint:
    path: /
    method: POST
- name: index_name
  endpoint:
    path: /_search
    method: GET
    data_selector: hits.hits
    params: {}
- name: pinecone-destination-connector
  endpoint:
    path: /connectors
    method: POST
    data_selector: data
    params: {}
- name: repository
  endpoint:
    path: /repos/{owner}/{repo}
    method: GET
- name: redis_data
  endpoint:
    path: /redis/data
    method: POST
    data_selector: records
    params: {}
- name: messages
  endpoint:
    path: /api/conversations.history
    method: GET
    params: {}
- name: elements
  endpoint:
    path: /api-reference/partition/document-elements
    method: POST
- name: elements
  endpoint:
    params:
      ID Column: RECORD_ID
- name: tickets
  endpoint:
    path: /api/v2/tickets.json
    method: GET
    data_selector: tickets
- name: articles
  endpoint:
    path: /api/v2/help_center/articles.json
    method: GET
    data_selector: articles
- name: messages
  endpoint:
    path: /api/conversations.history
    method: GET
    data_selector: messages
- name: elements
  endpoint:
    path: /services/data/vXX.X/sobjects/ELEMENTS
    method: GET
    data_selector: records
    params: {}
- name: jobs
  endpoint:
    path: /jobs
    method: GET
    data_selector: records
    params: {}
- name: tickets
  endpoint:
    path: /api/v2/tickets.json
    method: GET
- name: articles
  endpoint:
    path: /api/v2/help_center/articles.json
    method: GET
- name: Documents Library
  endpoint:
    path: /sites/{site-collection-name}/Documents
    method: GET
- name: files
  endpoint:
    path: /<container-name>/<path/to/file/or/folder>
    method: GET
    data_selector: files
    params: {}
- name: documents
  endpoint:
    path: /couchbase/documents
    method: GET
- name: volume
  endpoint:
    path: /api/2.0/preview/permissions/volumes
    method: GET
    data_selector: volumes
- name: files
  endpoint:
    path: /2/files/list_folder
    method: POST
    data_selector: entries
- name: dropbox-source-connector
  endpoint:
    path: /
    method: GET
    data_selector: records
    params: {}
- name: connector
  endpoint:
    path: /connectors
    method: POST
    params: {}
- name: Astra DB Destination
  endpoint:
    params:
      collection_name: ''
      keyspace: ''
      batch_size: 20
      flatten_metadata: false
      api_endpoint: ''
      token: ''
- name: index
  endpoint:
    path: /$metadata#indexes/$entity
    method: GET
    data_selector: '@odata.context'
    params: {}
- name: projects
  endpoint:
    path: /rest/api/latest/project
    method: GET
- name: boards
  endpoint:
    path: /rest/agile/1.0/board
    method: GET
- name: issues
  endpoint:
    path: /rest/api/latest/issue
    method: GET
- name: onedrive_files
  endpoint:
    path: /path/to/onedrive/folder
    method: GET
    data_selector: files
- name: subject
  endpoint:
    path: /workspaces/subject
    method: GET
    data_selector: records
- name: section
  endpoint:
    path: /workspaces/section
    method: GET
    data_selector: records
- name: header_footer_type
  endpoint:
    path: /workspaces/header_footer_type
    method: GET
    data_selector: records
- name: emphasized_text_contents
  endpoint:
    path: /workspaces/emphasized_text_contents
    method: GET
    data_selector: records
- name: emphasized_text_tags
  endpoint:
    path: /workspaces/emphasized_text_tags
    method: GET
    data_selector: records
- name: text_as_html
  endpoint:
    path: /workspaces/text_as_html
    method: GET
    data_selector: records
- name: regex_metadata
  endpoint:
    path: /workspaces/regex_metadata
    method: GET
    data_selector: records
- name: detection_class_prob
  endpoint:
    path: /workspaces/detection_class_prob
    method: GET
    data_selector: records
- name: partitioner_type
  endpoint:
    path: /workspaces/partitioner_type
    method: GET
    data_selector: records
- name: connector
  endpoint:
    path: /api/reference/partition/document-elements
    method: POST
    data_selector: records
- name: Couchbase_destination
  endpoint:
    path: /api/v1/destinations
    method: POST
    data_selector: data
    params:
      name: unique_name
      bucket: bucket_name
      connection_string: connection_string
      scope: _default
      collection: _default
      batch_size: 50
      collection_id_key: id
      username: username
      password: password
- name: documents
  endpoint:
    path: /sites/<tenant>.sharepoint.com/sites/<site-collection-name>/Documents
    method: GET
- name: elements
  endpoint:
    path: /services/data/vXX.X/sobjects/ELEMENTS
    method: GET
    data_selector: records
    params: {}
- name: tickets
  endpoint:
    path: /api/v2/tickets.json
    method: GET
    data_selector: tickets
- name: articles
  endpoint:
    path: /api/v2/help_center/articles.json
    method: GET
    data_selector: articles
- name: salesforce_categories
  endpoint:
    params: {}
- name: messages
  endpoint:
    method: GET
    params: {}
- name: elements
  endpoint:
    params:
      ID Column: RECORD_ID
- name: tickets
  endpoint:
    path: /api/v2/tickets.json
    method: GET
    data_selector: tickets
- name: articles
  endpoint:
    path: /api/v2/help_center/articles.json
    method: GET
    data_selector: articles
- name: workflows
  endpoint:
    path: /workflows
    method: GET
- name: workflow
  endpoint:
    path: /workflows/<workflow-id>
    method: GET
- name: create_workflow
  endpoint:
    path: /workflows
    method: POST
- name: run_workflow
  endpoint:
    path: /workflows/<workflow-id>/run
    method: POST
- name: update_workflow
  endpoint:
    path: /workflows/<workflow-id>
    method: PUT
- name: delete_workflow
  endpoint:
    path: /workflows/<workflow-id>
    method: DELETE
- name: Kafka Connector
  endpoint:
    path: /connectors
    method: POST
    data_selector: connector
    params: {}
- name: Enrichment
  endpoint:
    path: /workflows/enrichment
    method: POST
    data_selector: results
    params: {}
- name: collection
  endpoint:
    path: /api/v1/collections
    method: POST
    data_selector: data
    params: {}
- name: Chunker
  endpoint:
    path: null
    method: null
    data_selector: null
    params: {}
- name: jobs
  endpoint:
    path: /jobs
    method: GET
- name: job_details
  endpoint:
    path: /jobs/<job-id>/details
    method: GET
- name: failed_files
  endpoint:
    path: /jobs/<job-id>/failed-files
    method: GET
- name: cancel_job
  endpoint:
    path: /jobs/<job-id>/cancel
    method: POST
- name: destination_connector
  endpoint:
    path: /ui/destinations/pinecone
    method: POST
- name: pinecone-destination-connector
  endpoint:
    path: /
    method: POST
    data_selector: results
    params:
      index_name: ''
      namespace: default
      batch_size: 50
      api_key: '{{ dlt.secrets[''api_key''] }}'
- name: partition
  endpoint:
    path: /api-reference/partition
    method: POST
    data_selector: elements
- name: partition
  endpoint:
    path: /api/partition
    method: POST
    data_selector: elements
- name: Salesforce categories
  endpoint:
    path: /services/data/vXX.X/sobjects/
    method: GET
- name: Partition Endpoint
  endpoint:
    path: /api-reference/partition/api-parameters
    method: POST
- name: messages
  endpoint:
    path: /api/conversations.history
    method: GET
- name: elements
  endpoint:
    path: /services/data/vXX.X/sobjects/ELEMENTS
    method: GET
    data_selector: records
- name: partition
  endpoint:
    path: /partition
    method: POST
    data_selector: elements
- name: tickets
  endpoint:
    path: /api/v2/tickets.json
    method: GET
- name: articles
  endpoint:
    path: /api/v2/articles.json
    method: GET
- name: partition
  endpoint:
    path: /partition
    method: POST
    data_selector: elements
- name: partition
  endpoint:
    path: /general/partition
    method: POST
    data_selector: elements
- name: job
  endpoint:
    path: /api/v1/jobs
    method: GET
    data_selector: jobs
    params: {}
- name: partition
  endpoint:
    path: /general/v0/general
    method: POST
    data_selector: elements
    params:
      chunking_strategy: by_title
      max_characters: 1024
      strategy: vlm
      vlm_model_provider: openai
      vlm_model: gpt-4o
- name: Handwriting
  endpoint:
    path: /handwriting
    method: GET
    data_selector: results
- name: MultilanguageCharacters
  endpoint:
    path: /multilanguageCharacters
    method: GET
    data_selector: results
- name: partition
  endpoint:
    path: /partition
    method: POST
    data_selector: elements
- name: azure_blob_storage_connector
  endpoint:
    path: /connectors/sources/azure_blob_storage
    method: POST
    data_selector: success
    params:
      remote_url: az://<container-name>/<path/to/file/or/folder/in/container/as/needed>
      account_name: <azure_storage_account_name>
      sas_token: <sas_token_if_using_sas_authentication>
      account_key: <account_key_if_using_account_key_authentication>
      connection_string: <connection_string_if_using_connection_string_authentication>
- name: documents
  endpoint:
    path: /couchbase/documents
    method: GET
- name: partition
  endpoint:
    path: /partition
    method: POST
    data_selector: elements
    params:
      chunking_strategy: by_title
      max_characters: 1024
- name: databricks_volume
  endpoint:
    path: /path/to/volume
    method: GET
- name: files
  endpoint:
    path: /2/files/list_folder
    method: POST
    data_selector: entries
- name: partition
  endpoint:
    path: /partition
    method: POST
    data_selector: elements
- name: partition
  endpoint:
    path: /partition
    method: POST
    data_selector: elements
- name: partition
  endpoint:
    path: /partition
    method: POST
    data_selector: elements
- name: connector
  endpoint:
    path: /connectors
    method: POST
    data_selector: data
    params: {}
- name: partition
  endpoint:
    path: /general/partition
    method: POST
    data_selector: elements
    params: {}
- name: partition
  endpoint:
    path: /partition
    method: POST
    data_selector: elements
    params:
      chunking_strategy: by_title
      max_characters: 1024
      strategy: vlm
      vlm_model_provider: openai
      vlm_model: gpt-4o
- name: bucket_access
  endpoint:
    path: /s3/{bucket_name}
    method: GET
    data_selector: bucket_policy
    params: {}
- name: partition
  endpoint:
    path: /partition
    method: POST
    data_selector: elements
- name: elements
  endpoint:
    path: /services/data/vXX.X/sobjects/elements
    method: GET
    data_selector: records
    params: {}
- name: partition
  endpoint:
    path: /general/partition
    method: POST
    data_selector: elements
    params: {}
- name: tickets
  endpoint:
    path: /api/v2/tickets.json
    method: GET
- name: articles
  endpoint:
    path: /api/v2/help_center/articles.json
    method: GET
- name: element
  endpoint:
    path: /api-reference/partition/document-elements
    method: GET
    data_selector: elements
- name: workflow
  endpoint:
    path: /api/v1/workflows
    method: POST
    data_selector: workflowId
- name: document_elements
  endpoint:
    path: /api-reference/partition/document-elements
    method: GET
    data_selector: elements
- name: workflows
  endpoint:
    path: /workflows
    method: GET
- name: workflow_details
  endpoint:
    path: /workflows/<workflow-id>
    method: GET
- name: create_workflow
  endpoint:
    path: /workflows
    method: POST
- name: run_workflow
  endpoint:
    path: /workflows/<workflow-id>/run
    method: POST
- name: update_workflow
  endpoint:
    path: /workflows/<workflow-id>
    method: PUT
- name: delete_workflow
  endpoint:
    path: /workflows/<workflow-id>
    method: DELETE
- name: partition
  endpoint:
    path: /general/partition
    method: POST
    data_selector: elements
- name: extract_tables_as_html
  endpoint:
    path: /api-reference/partition/text-as-html
    method: POST
    data_selector: elements
    params: {}
- name: Enrichment
  endpoint:
    path: /enrichment
    method: POST
    data_selector: results
- name: extract_images_and_tables
  endpoint:
    path: /api-reference/partition/extract-image-block-types
    method: POST
- name: chunked_elements
  endpoint:
    path: /api-reference/partition/get-chunked-elements
    method: GET
    data_selector: elements
- name: jobs
  endpoint:
    path: /jobs
    method: GET
- name: partition
  endpoint:
    path: /api/partition
    method: POST
    data_selector: elements
- name: Partition Endpoint
  endpoint:
    path: /api-reference/partition/api-parameters
    method: POST
    data_selector: records
    params: {}
- name: chunking
  endpoint:
    path: /chunking
    method: GET
    data_selector: chunkingStrategies
    params: {}
- name: partition
  endpoint:
    path: /general/v0/general
    method: POST
    data_selector: elements
- name: partition
  endpoint:
    path: /general/partition
    method: POST
    data_selector: elements
    params: {}
- name: partition
  endpoint:
    path: /general/v0/general
    method: POST
    data_selector: elements
- name: partition
  endpoint:
    path: /general/partition
    method: POST
    data_selector: elements
- name: partition
  endpoint:
    path: /partition
    method: POST
    data_selector: elements
- name: partition
  endpoint:
    path: /
    method: POST
    data_selector: elements
- name: partition
  endpoint:
    path: /general/partition
    method: POST
    data_selector: elements
- name: partition
  endpoint:
    path: /general/partition
    method: POST
    data_selector: elements
    params:
      chunking_strategy: by_title
      max_characters: 1024
      strategy: vlm
      vlm_model_provider: openai
      vlm_model: gpt-4o
- name: partition
  endpoint:
    path: /partition
    method: POST
    data_selector: elements
- name: partition
  endpoint:
    path: /general/partition
    method: POST
    data_selector: elements
    params: {}
- name: partition
  endpoint:
    path: /general/partition
    method: POST
    data_selector: elements
    params:
      chunking_strategy: by_title
      max_characters: 1024
      strategy: vlm
      vlm_model_provider: openai
      vlm_model: gpt-4o
- name: partition
  endpoint:
    path: /general/partition
    method: POST
    data_selector: elements
    params: {}
- name: document_elements
  endpoint:
    path: /api-reference/partition/document-elements
    method: GET
    data_selector: elements
- name: partitioning_strategies
  endpoint:
    path: /api-reference/partition/partitioning
    method: GET
    data_selector: strategies
- name: element_contents
  endpoint:
    path: /api-reference/partition/get-elements
    method: GET
    data_selector: elements
- name: general_partition
  endpoint:
    path: /api-reference/partition/sdk-jsts
    method: POST
    data_selector: elements
    params: {}
- name: partition
  endpoint:
    path: /api-reference/partition
    method: POST
    data_selector: elements
- name: extract_images_and_tables
  endpoint:
    path: /api-reference/partition/extract-image-block-types
    method: POST
    data_selector: elements
- name: transform_json
  endpoint:
    path: /api-reference/partition/transform-schemas
    method: POST
- name: partitioning
  endpoint:
    path: /ui/partitioning
    method: GET
    data_selector: partitioning_strategies
    params: {}
- name: supported_languages
  endpoint:
    path: /ui/supported-languages
    method: GET
    data_selector: languages
    params: {}
- name: chunking
  endpoint:
    path: /api/chunking
    method: GET
    data_selector: chunks
notes:
- Unstructured simplifies and streamlines the preprocessing of structured and unstructured
  documents for downstream tasks.
- When you partition a document with Unstructured, the result is a list of document
  Element objects.
- Notebooks contain complete working sample code for end-to-end solutions.
- Designed for production scenarios.
- Significantly increased performance on document and table extraction.
- Access to newer and more sophisticated vision transformer models.
- Access to Unstructured’s fine-tuned OCR models.
- Access to Unstructured’s by-page and by-similarity chunking strategies.
- Adherence to security and SOC2 Type 1, SOC2 Type 2, HIPAA, GDPR, and ISO 27001 compliance
  standards.
- Incremental data loading.
- Image extraction from documents.
- More sophisticated document hierarchy detection.
- Not designed for production scenarios.
- Significantly decreased performance on document and table extraction.
- Uses OAuth2 with refresh token — requires setup of connected app in api
- Data Only Processed Within Your Company's Dedicated Infrastructure
- To sign up for Unstructured Enterprise, contact Unstructured Sales.
- To switch from an existing Unstructured Starter or Team account to Enterprise, email
  Unstructured Sales.
- GPU usage is not supported for the Unstructured open source library.
- API or UI access for document processing
- Supports 50+ document and image file types
- Some objects may return nulls in deeply nested fields
- The Unstructured API on AWS is deprecated. It is no longer supported and is not
  being actively updated.
- Manually stopping or terminating the associated Amazon EC2 instances alone will
  not reduce these ongoing charges.
- It is generally recommended to limit SSH access to a specific IP range for enhanced
  security.
- To help manage your overall costs, you should stop running the associated virtual
  machine whenever you are not using it to call the Unstructured API.
- Uses API key authentication in header.
- Get your API key by creating an Unstructured account.
- The Unstructured Partition Endpoint is intended for rapid prototyping of Unstructured's
  various partitioning strategies.
- You must select the same Region where you set up the VPC in Part I.
- The Unstructured API on Azure is deprecated.
- This page is not being actively updated.
- API key is required for authentication.
- The default URL for the Unstructured Partition Endpoint is https://api.unstructuredapp.io/general/v0/general.
- The SDK uses semantic versioning and major bumps could bring breaking changes. It
  is advised to pin your installed version.
- API provides endpoints for partitioning and chunking documents.
- Chunking strategies include basic, by_title, by_page, and by_similarity.
- Only set SSL validation to False for testing.
- Set 'coordinates' parameter to true to get bounding box coordinates.
- Set 'unique_element_ids' to true to use UUIDs instead of SHA-256 hashes for element
  IDs.
- Set 'chunking_strategy' to combine partitioning and chunking.
- Before you can create a destination connector, you must first sign in to your Unstructured
  account.
- The default URL for the Unstructured Partition Endpoint is `https://api.unstructuredapp.io/general/v0/general`.
  However, you should always use the URL that was provided to you when your Unstructured
  account was created.
- For Azure Databricks, this connector only supports Databricks managed service principals
  for authentication.
- The SDK uses semantic versioning and major bumps could bring breaking changes.
- If at least one request is successful, the responses are combined into a single
  response object.
- If you disable SSL validation, requests will accept any TLS certificate presented
  by the server.
- You must have a valid Unstructured account to create a destination connector.
- Ensure the API key and API URL are correctly specified in your code.
- The local destination connector is supported only for REST API clients such as curl
  and Postman.
- The local destination connector works only with the local source connector.
- The OneDrive connector does not support multifactor (MFA) or passwordless authentication.
- Only Qdrant Cloud is supported via the Unstructured UI or API.
- Qdrant requires the target collection to exist before Unstructured can write to
  the collection.
- Anonymous access to the bucket is supported but not recommended.
- If you are experiencing S3 connector or workflow failures after adding a new S3
  bucket or updating an existing S3 bucket, it could be due to S3 latency issues.
- Your organization might have stricter bucket policy requirements. Check with your
  AWS account administrator if you are unsure.
- The default URL for the Unstructured Workflow Endpoint is https://platform.unstructuredapp.io/api/v1.
- Uses API key for authentication.
- Using dashes (-) in the names of catalogs, schemas, tables, and volumes might cause
  isolated issues with the connector. It is recommended to use underscores (_) instead.
- Ensure that your existing VPC setup includes the necessary subnets, internet gateway,
  and route tables as outlined in this guide.
- Requires an IBM Cloud account with an API key.
- Target bucket name, region, and public endpoint must be obtained from the IBM Cloud
  account.
- Ensure the same Region is selected where the VPC was set up.
- You must first install the Unstructured Ingest CLI.
- Because you are calling a private API and therefore do not need an Unstructured
  API key.
- This local destination connector is supported only for REST API clients such as
  curl and Postman.
- The Unstructured API on Azure is deprecated. It is no longer supported and is not
  being actively updated.
- This page is not being actively updated. It might contain out-of-date information.
  This page is provided for legacy reference purposes only.
- Unstructured recommends that all documents in the target collection have a field
  named `record_id` with a `String` data type.
- The only required parameter is `files` - the file you wish to process.
- A OneDrive for business plan, or a Microsoft 365 or Office 365 Business or enterprise
  plan that includes OneDrive is required.
- A SharePoint Online plan, or a Microsoft 365 or Office 365 Business or enterprise
  plan that includes SharePoint Online is required.
- The OneDrive connector does not support any other authentication methods, such as
  multifactor (MFA) or passwordless authentication.
- The application (client) ID, Directory (tenant) ID, and Client secret for the Entra
  ID app registration are required.
- Must select the same Region where you set up the VPC in Part I
- Specifying a password is no longer recommended, as passwords are being deprecated
  by Snowflake. Use a PAT instead.
- Your Azure account will be charged on an ongoing basis for these resources, even
  if you are not actively using them.
- Only Weaviate Cloud clusters are supported for the Unstructured UI or API.
- For Weaviate installed locally, you will need the name of the target collection
  on the local instance.
- For Embedded Weaviate, you will need the instance's connection URL and the name
  of the target collection on the instance.
- Chunking functions use metadata and document elements detected with partition functions
  to split a document into appropriately-sized chunks.
- The default URL for the Unstructured Workflow Endpoint is `https://platform.unstructuredapp.io/api/v1`.
  However, you should always use the URL that was provided to you when your Unstructured
  account was created.
- Uses API key for authentication
- Set the `coordinates` parameter to `true` to get bounding box coordinates.
- Set `unique_element_ids=true` to use UUIDs instead of SHA-256 for element IDs.
- Combine partitioning and chunking by setting `chunking_strategy`.
- To sign up for a Team or Enterprise account, contact Unstructured Sales.
- The API URL was provided to you when your Unstructured account was created.
- Uses CloudFormation template for deployment
- Deployment can take several minutes
- To help manage your overall costs, you should click the Stop icon whenever you are
  not using this virtual machine to call the Unstructured API.
- Some objects like Contact may return nulls in deeply nested fields
- To manage costs, stop the virtual machine when not in use.
- Chunking strategies are available for document processing.
- Chroma Cloud uses api.trychroma.com as the host and port 8000.
- For Couchbase Capella, you will need a Couchbase Capella account and a Couchbase
  Capella cluster.
- Unstructured API requires an account to access.
- Chroma Cloud requires host as api.trychroma.com and port as 8000.
- SSL should be enabled for connection.
- The API URL is provided when your Unstructured account is created.
- This feature may lead to unexpected results when chunking because the server does
  not see the entire document context at once.
- The chunking strategy is set to None by default.
- Uses API key for authentication — requires setup of API key in Unstructured account
- This API is deprecated and not actively updated.
- Your Azure account will be charged on an ongoing basis for resources.
- Ensure to set environment variables for API key and URL.
- The API processes documents and returns structured data.
- The Unstructured Partition Endpoint is designed to work only with processing of
  local files, one file at a time.
- Unstructured is now available on the Azure Marketplace as a private offering.
- The API URL was provided when your Unstructured account was created.
- Default URL for the Unstructured Partition Endpoint is https://api.unstructuredapp.io/general/v0/general.
- Chunking and embedding are optional.
- For the Unstructured UI or the Unstructured API, only Couchbase Capella clusters
  are supported.
- For Unstructured Ingest, Couchbase Capella clusters and local Couchbase server deployments
  are supported.
- Chroma Cloud uses host api.trychroma.com and port 8000.
- Using dashes (`-`) in the names of catalogs, schemas (formerly known as databases),
  tables, and volumes might cause isolated issues with the connector. It is recommended
  to use underscores (`_`) instead of dashes in the names of catalogs, schemas, tables,
  and volumes.
- For Couchbase Capella, you will need a Couchbase Capella account.
- For a local Couchbase server, you will need installation of a local Couchbase server.
- Chroma Cloud uses api.trychroma.com as the host.
- Chroma Cloud uses port 8000.
- Chroma Cloud uses api.trychroma.com and port 8000.
- The API key is required for authentication.
- For Couchbase Capella, you will need a Couchbase Capella account, cluster, bucket,
  scope, collection, public connection string, cluster access name, and secret.
- AWS provides AWS Client VPN, which is a managed client-based VPN service that enables
  secure access AWS resources and resources in your on-premises network.
- Stop running the associated virtual machine whenever you are not using it to call
  the Unstructured API.
- Do not add a trailing slash (`/`) to the workspace URL.
- 'The document types that you want to skip table extraction for. Default: [].'
- Set UNSTRUCTURED_API_KEY to your Unstructured API key.
- Set UNSTRUCTURED_API_URL to the value of the Unstructured API URL.
- Current versions of the SharePoint connector now rely on Microsoft Entra ID app
  registrations for authentication.
- The SharePoint Online and OneDrive plans must share the same Microsoft Entra ID
  tenant.
- Set 'unique_element_ids' to true to use UUIDs in output.
- API token is required for authentication, not an OAuth token.
- You can create and save a workflow that uses a local file as a source or does not
  have a source or destination connector added.
- However, you cannot activate the workflow or run the workflow either manually or
  on a schedule until a source and destination connector are added to the workflow.
- If the workflow uses a local source location, do not choose a source connector.
- 'A workflow that uses a local source location has the following limitations: You
  cannot save the workflow.'
- You cannot send the results to a remote destination location, even if you have attached
  a destination connector to the workflow.
- However, you can save the results to a local JSON-formatted file.
- To process files locally, omit partition_by_api or set it to False.
- The MotherDuck connector uses the default schema name of `main` if not otherwise
  specified.
- The MotherDuck connector uses the default table name of `elements` if not otherwise
  specified.
- Only Couchbase Capella clusters are supported for Unstructured UI and API.
- For local Couchbase server deployments, installation of a local Couchbase server
  is required.
- Using dashes (`-`) in the names of catalogs, schemas (formerly known as databases),
  and tables might cause isolated issues with the connector. It is recommended to
  use underscores (`_`) instead of dashes in the names of catalogs, schemas, and tables.
- Unstructured recommends that all records in the target index have a field named
  `record_id` with a string data type.
- Requires tenant ID from the Chroma dashboard.
- SSL is checked by default
- Databases are typically numbered from 0 to 15, with the default being 0
- Slack has established API rate limits that could restrict the number and frequency
  of messages that can be read.
- Only Couchbase Capella clusters are supported for Unstructured UI and Couchbase
  Capella clusters and local Couchbase server deployments are supported for Unstructured
  Ingest.
- These IP address ranges are subject to change. You can always find the latest ones
  in the preceding file.
- You can create and save a workflow that does not use a valid workflow layout. However,
  you cannot activate the workflow or run the workflow either manually or on a schedule
  until the workflow is changed to use a valid workflow layout.
- Requires a Zendesk account and API token.
- You can create and save a custom workflow that uses a local file as a source or
  does not have a source or destination connector added.
- You cannot activate the workflow or run the workflow either manually or on a schedule
  until a source and destination connector are added to the workflow.
- All Milvus instances require the target collection to have a defined schema before
  Unstructured can write to the collection.
- The default database number is 0.
- The default port is 6379 unless otherwise specified.
- The default batch size is 100 unless otherwise specified.
- SSL is enabled by default.
- Unstructured Partition Endpoint is designed to work only with processing of local
  files, one file at a time.
- Authenticated access is recommended over anonymous access.
- If you disable SSL validation, requests will accept any TLS certificate presented
  by the server and ignore hostname mismatches and/or expired certificates.
- API token required for authentication, not OAuth token.
- Using dashes (-) in the names of catalogs, schemas (formerly known as databases),
  tables, and volumes might cause isolated issues with the connector. It is recommended
  to use underscores (_) instead of dashes in the names of catalogs, schemas, tables,
  and volumes.
- You must have an IBM Cloud account and an API key for the IBM Cloud account.
- An IBM Cloud Object Storage (COS) instance and a bucket within that instance are
  required.
- An HMAC access key ID and secret access key for the target COS instance are required.
- An IBM watsonx.data data store instance must be created.
- An Apache Iceberg-based catalog within the watsonx.data data store is necessary.
- The chunking strategies available include basic, by_title, by_page, and by_similarity.
- OneDrive personal accounts, and Microsoft 365 Free, Basic, Personal, and Family
  plans are not supported.
- The app registration must have the correct set of Microsoft Graph access permissions.
- Get your API key from Unstructured Support.
- Always use the API URL provided when your Unstructured account was created.
- Set coordinates parameter to true to receive bounding box coordinates in the response.
- Set unique_element_ids=true to use UUIDs instead of SHA-256 hashes for element IDs.
- Combine partitioning and chunking by setting chunking_strategy.
- If you used a bucket policy intead of having the IAM user temporarily assume an
  IAM role for authenticated bucket access, you must provide a long-term AWS access
  key and secret access key for the authenticated AWS IAM user in the account.
- For an Enterprise account, see your Unstructured account administrator for instructions.
- Use PAT instead of passwords as passwords are deprecated.
- Only Weaviate Cloud clusters are supported.
- Weaviate requires an existing collection to have a data schema before you add data.
- Disabling SSL validation makes the application vulnerable to man-in-the-middle (MitM)
  attacks.
- For .dif files, '\n' characters are supported, but '\r\n' characters will raise
  an UnsupportedFileFormatError.
- You must have an Astra account and a database in the Astra account.
- An application token for the database is required.
- Using dashes (`-`) in the names of catalogs, schemas (formerly known as databases),
  tables, and volumes might cause isolated issues with the connector. It is recommended
  to use underscores (`_`) instead of dashes in the names.
- Replace '<name>', '<host>', '<catalog>', '<schema>', '<volume>', '<volume_path>',
  '<client-secret>', '<client-id>', '<token>' with actual values.
- To send processed data from Unstructured to IBM watsonx.data, an IBM Cloud account
  and an API key are required.
- Supports only Milvus cloud-based instances for Unstructured UI and API.
- Collection must have a defined schema with fields element_id, embeddings, and record_id.
- Chunking functions use metadata and document elements detected with partition functions
  to split a document into appropriately-sized chunks for uses cases such as retrieval-augmented
  generation (RAG).
- If you do not have the API URL, email Unstructured Support at support@unstructured.io.
- Only Qdrant Cloud is supported for the Unstructured UI or API.
- Uses API key for authentication — requires generation of API key from Unstructured
  account.
- The API key works with one and only one organizational workspace.
- For a Team or Enterprise account, ensure you have selected the organizational workspace
  before generating an API key.
- For Weaviate Cloud, you will need the URL and API key for the database cluster.
- An existing collection is not required. If no collection name is specified, Unstructured
  creates a new collection.
- The Python SDK does not support testing source connectors.
- The Python SDK does not support testing destination connectors.
- Requires an Azure AI Search account and API key.
- Requires an API key to access the service
- Ensure the service account has the necessary permissions
- An IBM Cloud account is required.
- An API key for the IBM Cloud account is required.
- Supported only for REST API clients such as curl and Postman.
- The OneDrive and SharePoint Online plans must share the same Microsoft Entra ID
  tenant.
- Set coordinates parameter to true to include bounding box coordinates.
- Set unique_element_ids to true to use UUIDs instead of SHA-256 hashes for element
  IDs.
- It is designed to work only with processing of local files, one file at a time.
- For Weaviate Cloud, you will need a Weaviate database instance.
- An existing collection is not required.
- If intending to use the paid API, please define `server_url` in your request.
- The default URL for the Unstructured Workflow Endpoint is `https://platform.unstructuredapp.io/api/v1`.
- The default URL for the Unstructured Partition Endpoint is `https://api.unstructuredapp.io/general/v0/general`.
- Requires setup of IBM Cloud account and resources for integration.
- A SharePoint Online plan is also required since OneDrive is built on SharePoint
  technology.
- The default chunking strategy is set to None
- Only Qdrant Cloud is supported for UI and API.
- Target collection must exist before data can be written.
- Only Milvus cloud-based instances (such as Zilliz Cloud, and Milvus on IBM watsonx.data)
  are supported.
- OneDrive personal accounts are not supported.
- This page is provided for legacy reference purposes only.
- Access tokens are valid for only four hours after they are created.
- Your Dropbox app will not have access to upload or download files from the root
  of the app folder.
- A Google Cloud account is required
- The Google Drive API must be enabled in the account
- A Google Cloud service account and its related credentials.json key file are required
- The service account must be given access to the shared folder or shared drive
- The default port is 9092 if not otherwise specified.
- The default group ID is default_group_id if not otherwise specified.
- The default number of messages to consume is 100 if not otherwise specified.
- Using dashes (`-`) in the names of catalogs, schemas (formerly known as databases),
  tables, and volumes might cause isolated issues with the connector. It is recommended
  to use underscores (`_`) instead.
- Requires setup of infrastructure in AWS account.
- An HMAC access key ID and secret access key for the target Cloud Object Storage
  (COS) instance are required.
- An IBM watsonx.data data store instance is required.
- An Apache Iceberg-based catalog within the watsonx.data data store instance is required.
- Only Milvus cloud-based instances are supported for Unstructured UI and API.
- Ensure you have access to a valid Azure subscription
- Secrets are securely managed using the CSI driver with support for Azure Key Vault,
  AWS Secrets Manager, Google Secret Manager
- Unstructured cannot provide a schema that is guaranteed to work in all circumstances.
- The total size of all files uploaded in a Dropbox Basic account cannot exceed 2
  GB.
- Enterprise deployments isolate your Unstructured Enterprise account from all other
  Unstructured accounts.
- For Unstructured Ingest, local and non-local PostgreSQL installations are supported.
- The Unstructured Open Source library provides methods for extracting tables from
  PDF files.
- For a Dropbox Basic account, the total size of all of the files you upload and store
  in your Dropbox account cannot exceed 2 GB.
- If the target files are in the root of the bucket, provide the path formatted as
  'protocol://bucket/'
- Ensure authenticated AWS IAM user has access to the folder if files are in a folder
- Total size of files uploaded in a Dropbox Basic account cannot exceed 2 GB.
- This example uses a custom Azure function that you create and maintain.
- Any issues with file detection, timing, or function invocation could be related
  to your custom function, rather than with Unstructured.
- An Unstructured account and API key are required.
- Ensure a properly configured Amazon S3 bucket with access credentials.
- CrewAI open source works only with Python 3.10, 3.11, and 3.12.
- This example uses a custom job in Lakeflow Jobs and a custom Databricks notebook
  that you create and maintain.
- Any issues with file detection, timing, or job execution could be related to your
  custom job or notebook, rather than with Unstructured.
- For the API key, use Databricks Secrets or environment variables.
- The API requires API key for authentication.
- The maximum number of pages to crawl can be specified using the 'limit' parameter.
- Each member will continue to be able to use their personal account and personal
  workspace.
- Sensitive information such as API keys should be stored in environment variables
  or a secrets manager, not hard-coded.
- A Google Cloud account is required.
- The Google Drive API must be enabled in the account.
- A Google Cloud service account and its related credentials.json key file are required.
- The service account must have access to the shared folder or shared drive.
- Uses AWS for vector storage and embedding.
- Ensure JSON output files contain vector embeddings generated by the Titan Text Embeddings
  V2 model.
- You must use your Salesforce account to do a one-time approval of the Salesforce
  connected app by using its consumer key and callback URL.
- API token is required instead of OAuth token
- Default item type is tickets if none provided
- Default batch size is 2
- You can create and save a custom workflow that uses a local file as a source or
  does not have a source or destination connector added. However, you cannot activate
  the workflow or run the workflow either manually or on a schedule until a source
  and destination connector are added to the workflow.
- 'A workflow that uses a local source location has the following limitations: You
  cannot save the workflow. You cannot send the results to a remote destination location,
  even if you have attached a destination connector to the workflow. However, you
  can save the results to a local JSON-formatted file.'
- For workflows that use Chunker and Enrichment nodes together, the Chunker node should
  be placed after all Enrichment nodes. Placing the Chunker node before any Enrichment
  nodes could cause incomplete or no enrichment results to be generated.
- Supports pagination and sorting.
- Set coordinates parameter to true to get bounding boxes.
- Set unique_element_ids=true to use UUIDs for IDs.
- 'Security, privacy, and ownership: Your organization might have strict data security
  requirements to keep your data and models within a virtual private cloud (VPC).'
- 'Compliance and data sovereignty: Certain industries and locales might have regulatory
  requirements that require data to be processed and for data and models to be stored
  in specific cloud provider regions.'
- 'Customization: Enterprise deployments allow for more customization and control
  options over your environments.'
- 'Testing and development: Enterprise deployments can be useful for multi-environment
  testing and development purposes, allowing you to experiment with Unstructured in
  a testing environment without affecting your production environment.'
- Enterprise deployments allow for more customization and control options over your
  environments.
- Total size of all files uploaded cannot exceed 2 GB for a Dropbox Basic account.
- Requires Unstructured API key for authentication.
- For your Unstructured API key, you can use Databricks Secrets or an environment
  variable.
- Uses API key for authentication, ensure it is set in environment variables.
- Crawled pages are saved as HTML files in the specified S3 bucket.
- You can create an API key for the IBM Cloud account.
- An IBM Cloud Object Storage (COS) instance is required.
- As an MCP security best practice, sensitive information such as API keys should
  be stored in environment variables or a secrets manager, not hard-coded in MCP server
  code.
- The .env file is a common way to store environment variables in Python projects
  outside of MCP server code.
- The local destination connector is supported only for REST API clients.
- This example uses custom Power Automate flows that you create and maintain.
- Any issues with file detection, timing, or flow invocation could be related to your
  custom flows, rather than with Unstructured.
- Uses Amazon S3 events to trigger workflows automatically.
- Vector bucket must generate JSON output files.
- Ensure to query the vector index by the 'text' field.
- Only Qdrant Cloud is supported for Unstructured UI and API.
- Target collection must exist before writing to it.
- If you experience S3 connector or workflow failures after adding a new S3 bucket
  or updating an existing S3 bucket, it could be due to S3 latency issues.
- If SSL encryption is enabled for the Redis database, use 'rediss://' instead of
  'redis://'.
- Some objects like Document may return nulls in deeply nested fields
- To use UUIDs in the output instead, set unique_element_ids=true.
- Set coordinates=true to include bounding box coordinates in the response.
- To call the Unstructured Partition Endpoint, you need an Unstructured account and
  an Unstructured API key.
- The API URL was provided when the Unstructured account was created.
- You must provide Unstructured's IDs for the file to download and the workflow's
  output node.
- For a Team or Enterprise account, make sure you have selected the organizational
  workspace you want to create an API key for.
- Requires a valid Unstructured account and API key.
- Use the app key and app secret values for your Dropbox app.
- Do not add a trailing slash (/) to the workspace URL.
- Using dashes (-) in the names of catalogs, schemas, tables, and volumes might cause
  isolated issues with the connector. It is recommended to use underscores (_) instead
  of dashes.
- Requires a Jira account with the correct permissions to access projects, boards,
  and issues.
- For Jira Cloud, API token authentication is recommended.
- Ensure the API key has the correct permissions for accessing watsonx.data services.
- Ensure to create an API key for IBM Cloud account before proceeding.
- Authenticated access requires blocking all public access to the bucket.
- Local destination connector is supported only for REST API clients.
- Milvus cloud-based instances are supported, including Zilliz Cloud and Milvus on
  IBM watsonx.data.
- Qdrant requires the target collection to exist before Unstructured can write to
  it.
- For Weaviate Cloud clusters, the URL and API key for the database cluster are required.
- An existing collection is not required. If a collection name is not specified, a
  new collection will be created.
- The following information applies only to in-VPC deployments of Unstructured Enterprise.
- For dedicated instance deployments of Unstructured Enterprise, contact your Unstructured
  sales representative.
- Ensure you have Unstructured API key and access to an S3 bucket containing the target
  files.
- To stop triggering the job, click Pause in the Job details pane under Schedules
  & Triggers.
- If generating an SAS token, set Read and List permissions for reading, and Write
  and List for writing.
- Requires AWS credentials for accessing the S3 bucket
- Requires Pinecone API key for accessing the Pinecone index
- This example uses a custom Google Apps Script that you create and maintain.
- If you are getting unexpected or no results, be sure to check your custom script's
  execution logs first for any informational and error messages.
- Only Couchbase Capella clusters are supported.
- The workspace URL should not have a trailing slash.
- Ingests processed data and associated vector embeddings into Astra DB.
- Use temperature setting for response variability.
- Requires a service account key formatted as a single-line string.
- Ensure the Google Cloud Storage bucket has appropriate roles applied.
- The user must have the correct permissions in your Jira Cloud account or Jira Data
  Center installation to access the target projects, boards, and issues.
- Requires an Unstructured API key to access the API.
- Ensure the UNSTRUCTURED_API_KEY is set in the environment variables.
- Python installed on your local development machine.
- An AWS account is required.
- This operation will permanently delete all vector entries in the vector index.
- This operation will permanently delete a vector index.
- This operation will permanently delete a vector bucket.
- Requires Microsoft Entra ID app registration with permissions including Sites.ReadWrite.All
  and User.Read.All.
- Uses OpenAI API key for authentication
- A workflow with a local source cannot be set to run on a repeating schedule.
- The workflow cannot be run from the Unstructured user interface (UI).
- You can leave the default values for all of the other Parameters fields.
- Uses Unstructured API for processing various data formats.
- The `by_title` chunking strategy preserves section boundaries and optionally page
  boundaries.
- Any issues with file detection, timing, or job execution could be related to your
  custom job or notebook.
- Designed to work only with processing of local files, one file at a time.
- This component works only with the file extensions .pdf, .docx, and .txt.
- Uses OpenAI API key for authentication.
- Temperature is set to 0.1.
- Requires an Unstructured account and API key.
- The Microsoft Presidio SDK is not offered, maintained, or supported by Unstructured.
- A unique name for this connector is required.
- The endpoint URL for Azure AI Search is required.
- The name of the index for Azure AI Search is required.
- The API key for Azure AI Search is required.
- An Unstructured account is required, and an API key must be generated.
- Only Databricks managed service principals are supported for Azure.
- Uses a custom Power Automate flow that you create and maintain.
- Any issues with file detection, timing, or flow invocation could be related to your
  custom flow.
- Uses API Key for authentication
- You can also create destination connectors with the Unstructured user interface
  (UI).
- It is generally recommended to limit SSH access to a specific IP range for enhanced
  security. This can be done by setting the SSHLocation to the IP address or range
  associated with your organization.
- The target collection must exist before writing to it.
- The chunking strategies include 'basic', 'by_title', 'by_page', and 'by_similarity'.
- The default output format is 'application/json'.
- Use PAT instead of passwords for authentication.
- You must track PAT expiration dates.
- You can combine partitioning and chunking in a single request by setting the chunking_strategy
  parameter.
- To start using the Unstructured Partition Endpoint right away, skip ahead to the
  quickstart now!
- You must specify all of the settings for the connector, even for settings that are
  not changing.
- The API URL is provided when your account is created
- Default scoring profile is null.
- Uses OAuth2 with authorization code flow — requires app key and app secret from
  Dropbox.
- Set download_attachments to true to download attachments from Jira issues.
- If you are new to Unstructured, sign up for an account first.
- Ensure to follow the requirements for each specific destination.
- Local PostgreSQL installations are not supported for the Unstructured UI.
- The default database name for Amazon RDS for PostgreSQL and Azure Database for PostgreSQL
  is 'postgres'.
- Authenticated bucket access is recommended over anonymous access.
- Requires API key for authentication.
- The app must have the scopes `Sites.ReadWrite.All` and `User.Read.All`.
- You are now ready to start creating a destination connector!
- The workflow cannot be run from the Unstructured user interface (UI), even though
  the workflow is visible in the UI.
- Only Milvus cloud-based instances are supported for Unstructured UI or API.
- Requires setup of connected app in API
- This sample code utilizes the Unstructured Open Source Library.
- Issues with file detection, timing, or function invocation could be related to your
  custom function.
- Enter only the name of the bucket. Do not prefix the bucket's name with s3://. Do
  not include any trailing slash (/) after the bucket name.
- Any issues with file detection, timing, or script execution could be related to
  your custom script, rather than with Unstructured.
- To get the ID for destination connectors, see List destination connectors.
- Requires an Unstructured account and an API key.
- If you are generating an SAS token, be sure to set Read, List, and Write permissions
  as required.
- User must have the correct permissions to access the target spaces and pages.
- This example uses a custom Power Automate flow that you create and maintain.
- You must create a subfolder inside of the app folder for your Dropbox app to upload
  and download files from.
- Uses Pinecone serverless index for embeddings.
- Requires OpenAI API key for LLM.
- Ensure the service account has the necessary permissions in Google Cloud Storage.
- Chunking is performed on document elements. It is a separate step performed after
  partitioning.
- A single element that by itself exceeds the maximum chunk size is divided into two
  or more chunks using text-splitting.
- Requires a Google Cloud account with the Google Drive API enabled.
- Requires a Jira Cloud account or Jira Data Center installation.
- Set download_attachments to true to download attachments from Jira issues. The default
  is false.
- Set cloud to true to specify using Jira Cloud or false to specify using Jira Data
  Center. The default is to use Jira Data Center.
- Local PostgreSQL installations are not supported.
- The default database name is `postgres` unless a custom database name was specified.
- Use authenticated bucket read or write access or both instead.
- Previous versions of the SharePoint connector relied on SharePoint app principals
  for authentication.
- The partition function can handle a variety of file types including .docx, .pdf,
  .html, and .csv.
- A workflow with a local source has limitations regarding scheduling and UI execution.
- Output format can be 'text/html' or 'application/json'. Default is 'text/html'.
- Include page breaks is true by default.
- Unique element IDs are true by default.
- Ensure the necessary permissions are granted for Azure resources.
- Set up the required Secrets and ConfigMaps before deployment.
- Requires setup of API key for access
- Any issues with file detection, timing, or function invocation could be related
  to your custom function.
- This API is deprecated and is no longer supported.
- Your Azure account will be charged on an ongoing basis for these resources.
- Requires setup of AWS S3 bucket with access permissions.
- Requires setup of Pinecone serverless index.
- 'Supports multiple chunking strategies: basic, by_title, by_page, by_similarity.'
- Requires Unstructured account and API key.
- Sensitive information such as API keys should be stored in environment variables.
- 'The Value should now look similar to the following: https://platform.unstructuredapp.io/api/v1/workflows/11111111-1111-1111-1111-111111111111/run'
- The Azure AI Search index that you use must have an index schema that is compatible
  with the schema of the documents that Unstructured produces for you.
- Requires a Pinecone account and API key.
- Ensure all records in the target index have a field named `record_id`.
- Only Databricks managed service principals are supported for OAuth authentication.
- Uses OAuth2 with refresh token — requires setup of connected app in unstructured
- Some elements may return nulls in deeply nested fields
- Ensure to set up the appropriate IAM roles for the service account.
- You need an API key from Unstructured to access the API.
- Requires a Microsoft Entra ID app registration with access to the target OneDrive
  account.
- Does not support multifactor (MFA) or passwordless authentication.
- The unstructured library includes functions to partition, chunk, clean, and stage
  raw source documents.
- If a PDF is copy protected, partition_pdf can process the document with the 'hi_res'
  strategy but cannot process the document with the 'fast' strategy.
- Only Qdrant Cloud is supported for Unstructured UI or API.
- Ensure you have the correct App key, App secret, and Refresh token.
- Staging functions in the Unstructured open source library are being deprecated in
  favor of destination connectors in the Unstructured Ingest CLI and Unstructured
  Ingest Python library.
- Prodigy recommends .jsonl format for feeding data to API loaders.
- Must select the same Region where you set up the VPC in Part I.
- Do not add a trailing slash to the workspace URL.
- Requires setup of Dropbox app to generate app key and secret.
- For authenticated bucket access, AWS IAM user must have at minimum the permissions
  of `s3:ListBucket`, `s3:GetObject`, and `s3:PutObject`.
- A Snowflake account and its account identifier are required.
- A Snowflake user, which can be a service user (recommended) or a human user, is
  also required.
- Requires a valid Zendesk account and API token.
- Ensure you have an IBM Cloud account and the required API key.
- Even if you only plan to use OneDrive, you still need a plan that includes SharePoint
  Online, because OneDrive is built on SharePoint technology.
- SSH key exported in PEM format
- After your organization has signed the Enterprise agreement, a member of the Unstructured
  technical enablement team will reach out to you to begin the deployment onboarding
  process.
- An existing collection is not required. If no name is specified, Unstructured creates
  a new collection.
- Requires an API Key for access.
- The Delta Table connector requires a Databricks account.
- Ensure that the bucket name and timestamp are correctly formatted in the Bucket
  URI.
- If you're generating an SAS token, set Read, List, Write permissions accordingly.
- Requires an Unstructured API key for access.
- To minimize the risk of Claude for Desktop's hard timeout limit of 60 seconds for
  MCP server responses, use small files (less than 400 KB).
- The example code in this walkthrough is provided as a general reference only.
- If an existing index name is specified, and Unstructured generates embeddings, but
  the number of dimensions that are generated does not match the existing index's
  embedding settings, the run will fail.
- Unstructured can use the field named `record_id` with a string data type to do intelligent
  document overwrites.
- unstructured simplifies and streamline the preprocessing of structured and unstructured
  documents for downstream tasks.
- To use any model with the partition, set the strategy to hi_res.
- The hi_res_model_name parameter supports the yolox and detectron2_onnx arguments.
- If the target files are in a folder, make sure the authenticated AWS IAM user has
  access to the folder.
- 'The following options assume that you are calling the embedding provider directly.
  If you are calling Unstructured''s software-as-a-service (SaaS) for processing instead,
  do not include any of the following options: --embedding-api-key, --embedding-aws-access-key-id,
  --embedding-aws-secret-access-key, --embedding-aws-region.'
- Couchbase Capella clusters and local Couchbase server deployments are supported.
- Requires an API key for authentication.
- If generating an SAS token, ensure to set Read and List permissions.
- The remote URL takes the format az://<container-name>/<path/to/file/or/folder/in/container/as/needed>
- Use Azure Blob Storage events to automatically run Unstructured ETL+ workflows
- Check custom function's invocation traces for any informational and error messages
- You must specify the API URL only if you are not using the default API URL for Unstructured
  Ingest, which applies to Starter and Team accounts.
- The default API URL for Unstructured Ingest is https://api.unstructuredapp.io/general/v0/general.
- Ensure to replace <your-bucket-name> and <timestamp> in the Bucket URI.
- Uses a custom Google Apps Script that you create and maintain.
- Do not add a trailing slash (`/`) to the host URL.
- Each time you click the play icon in the Astra DB Ingest component, Unstructured
  reprocesses the specified local file. If this file does not change, this could result
  in multiple duplicate records being inserted into the specified Astra DB collection.
- Uses OpenAI API for text-based LLM.
- Ensure to provide a valid OpenAI API Key.
- The default API URL for Unstructured Ingest is https://api.unstructuredapp.io/general/v0/general,
  which is the API URL for the Unstructured Partition Endpoint.
- Sensitive information such as API keys should be stored in environment variables
  or a secrets manager.
- Requires a GitHub personal access token for authentication.
- Access to private repositories requires appropriate permissions.
- Uses API Key for authentication.
- Access tokens are valid for only four hours.
- To have Unstructured automatically refresh expired Dropbox App access tokens, do
  not provide an access token.
- Uses different partitioning strategies to handle various document types.
- Current versions of the SharePoint connector rely on Microsoft Entra ID app registrations
  for authentication.
- The API supports various document types for partitioning.
- You might need to wait up to a few hours before any related S3 connectors and workflows
  begin working without failures.
- The following options assume that you are calling the embedding provider directly.
  If you are calling Unstructured's software-as-a-service (SaaS) for processing instead,
  do not include any of the following options.
- The MotherDuck connector uses the default schema name of main if not otherwise specified.
- The MotherDuck connector uses the default table name of elements if not otherwise
  specified.
- Specify languages for better OCR results using the 'languages' parameter.
- Additional arguments for PDF processing can include coordinates, unique element
  IDs, and concurrency levels.
- If you create a new index or use an existing one, Unstructured recommends that all
  records in the target index have a field named `record_id` with a string data type.
- SSL should be enabled for the connection.
- Only Couchbase Capella clusters are supported for the Unstructured UI or API.
- Couchbase Capella clusters and local Couchbase server deployments are supported
  for Unstructured Ingest.
- For MongoDB Atlas, SCRAM-SHA-1 is not supported for authentication.
- If an existing collection name is specified, and Unstructured generates embeddings,
  but the number of dimensions that are generated does not match the existing collection's
  embedding settings, the run will fail.
- If a collection name is not specified, Unstructured creates a new collection in
  your namespace.
- You must specify the API URL only if you are not using the default API URL for Unstructured
  Ingest.
- For maximum compatibility, Unstructured recommends a specific table schema in MotherDuck.
- For Couchbase Capella, you will need a Couchbase Capella account, a Couchbase Capella
  cluster, a bucket, scope, and collection on the cluster.
- The cluster's public connection string, access name (username), and secret (password)
  are required.
- To send files to the Unstructured Partition Endpoint, specify --partition-by-api
  or partition_by_api=True.
- If you do not have an API key, get one now.
- Requires a Redis database, username, password, and database number.
- The workspace user or service principal must have the minimum set of privileges
  to read from or write to the existing volume in Unity Catalog.
- Your organization might have stricter bucket policy requirements.
- Dropbox app will not have access to upload or download files from the root of the
  app folder.
- The API token must be used instead of an OAuth token.
- Previous versions relied on SharePoint app principals for authentication, which
  are deprecated.
- Chunking will fail if you set both partition_by_api to False and chunking_strategy
  to by_page or by_similarity.
- Access tokens are valid for only four hours and need to be replaced.
- Chunking will fail if you set both `partition_by_api` to `False` and `chunking_strategy`
  to `by_page` or `by_similarity`. However, the rest of your data processing pipeline
  should be unaffected by this setting.
- Unstructured recommends that you use the Unstructured user interface (UI) or the
  Unstructured API instead of the Unstructured Ingest CLI or the Unstructured Ingest
  Python library.
- Unstructured processes all tables from all bases within an Airtable organization
  by default.
- You must create a subfolder inside of the app folder for your Dropbox app to upload
  or download files from.
- You must create a database application token.
- 'For API token authentication: CONFLUENCE_USERNAME and CONFLUENCE_API_TOKEN - The
  name or email address, and API token of the target Confluence user.'
- The API token is required for authentication.
- If no item type is specified, the default is tickets.
- Batch size default is 2.
- Requires Discord access token and channel IDs for processing.
- For Elastic Cloud instances, an Elastic Cloud service instance is required.
- For self-managed Elasticsearch, a self-managed Elasticsearch instance is needed.
- Anonymous access to the bucket is supported but not recommended. (Use authenticated
  bucket read or write access or both instead.)
- 'The Entra ID app registration must have the following Graph API permission levels
  of the application (not delegated) type: Mail.Read, Mail.ReadBasic, User.Read.All.'
- Uses Unstructured API key and API URL for processing files.
- Create an environment variable named ALLOW_AMBIENT_CREDENTIALS_S3, and set its value
  to true.
- A Pinecone account is required.
- A Pinecone API key is required.
- A Pinecone serverless index is required.
- If you lose this API key's value later, you will not be able to get it back.
- Previous versions of the SharePoint connector relied on SharePoint app principals
  for authentication. Current versions of the SharePoint connector no longer support
  these SharePoint app principals.
- The minimum viable schema for Unstructured contains only the fields `element_id`,
  `embeddings`, and `record_id`.
- API keys are required to call the Unstructured API's endpoints.
- To send files to the Unstructured Partition Endpoint, specify partition_by_api=True.
- Organizational accounts apply only to Unstructured Team and Enterprise accounts.
- Redis databases are typically numbered from 0 to 15, with the default database number
  typically being 0.
- Use Redis connection properties or connection string to connect to the Redis database.
- The Azure AI Search index must have an index schema compatible with the schema of
  the documents produced by Unstructured.
- Requires a Zendesk account and an API token.
- The default item type is tickets.
- For username and password authentication, the UPN for the OneDrive account in the
  Entra ID tenant is required.
- A Salesforce account is required.
- An Unstructured account is required for billing purposes.
- The API token must be used for authentication, not an OAuth token.
- The user must have the correct permissions in your Confluence account to access
  the target spaces and pages.
- 'A workflow that uses a local source location has the following limitations: You
  cannot save the workflow. You cannot send the results to a remote destination location,
  even if you have attached a destination connector to the workflow.'
- For Zilliz Cloud, a public endpoint is required.
- Collection must have a defined schema before Unstructured can write to it.
- AWS credentials need to be available for use with the storage options.
- For Elastic Cloud, you will need the Elastic Cloud service instance's API key.
- API key generated during account creation must be saved for later use.
- The Outlook user's email address is required.
- The Entra ID app registration must have specified Graph API permission levels.
- Local file processing does not use an Unstructured API key or API URL.
- If you are experiencing S3 connector or workflow failures after adding a new S3
  bucket or updating an existing S3 bucket, it could be due to S3 latency issues.
  You might need to wait up to a few hours before any related S3 connectors and workflows
  begin working without failures.
- API Token is required for authentication, not an OAuth token.
- Default item type is tickets if no value is provided.
- If the workflow uses a local source location, you cannot save the workflow.
- If the workflow uses a local source location, you cannot send the results to a remote
  destination location.
- The jobs dashboard provides a centralized view for managing and monitoring the execution
  of data processing tasks within your workflows.
- Requires Read and List permissions for accessing data in the container.
- SAS token is recommended for authentication.
- API keys are required to authenticate calls to the Unstructured API.
- You do not need an API key to use the Unstructured user interface.
- Only authorized Unstructured representatives can create organizational accounts.
- Only authorized Unstructured representatives can delete organizational accounts.
- files.content.read permission is required for the Dropbox app.
- Workspace usage is not stopped if the budget limit is exceeded.
- To use this chunking strategy, choose Chunk by title in the Chunkers section of
  a Chunker node in a workflow.
- To use this chunking strategy, choose Chunk by page in the Chunkers section of a
  Chunker node in a workflow.
- To use this chunking strategy, choose Chunk by similarity in the Chunkers section
  of a Chunker node in a workflow.
- To process Jira projects, provide the IDs for the target projects.
- To process Jira boards, the IDs for the target boards must be provided.
- To process Jira issues, the IDs for the target issues must be provided.
- Unstructured Enterprise accounts support the Federal Information Processing Standard
  (FIPS) for Amazon S3.
- Requires Microsoft Entra ID app registration with the correct set of Microsoft Graph
  access permissions.
- API token must be used instead of OAuth token.
- Requires a Salesforce account and connected app
- The consumer key (client ID) must be obtained from the Salesforce connected app
- The API token is required and cannot be an OAuth token.
- Default item type to parse is tickets.
- Unstructured generates image summary descriptions, table summary descriptions, and
  table-to-HTML output only for files that contain images or tables and are also eligible
  for processing with the following partitioning strategies.
- The collection must have a defined schema before Unstructured can write to the collection.
- Uses the default schema name of `main` if not otherwise specified.
- Uses the default table name of `elements` if not otherwise specified.
- The only supported value for retry strategy is backoff.
- ConnectorConfigInput and ConnectorType classes are deprecated.
- Leave Index Name blank.
- Leave Namespace set to the default value of default.
- Leave Batch Size set to the default value of 50.
- If True, splits the PDF file into smaller chunks of pages.
- If True, the partitioning continues even if some pages fail.
- 'Set the number of concurrent request to the maximum value: 15.'
- The maximum number of records to upload in a single batch is 100 unless otherwise
  specified.
- Uses API key for authentication — the key should be set as an environment variable.
- Requires setup of connected app in Salesforce
- You must set an environment variable named UNSTRUCTURED_API_KEY to use the API.
- API token (not OAuth token) is required for authentication.
- Set the coordinates parameter to true to add bounding boxes to responses.
- Element IDs can be switched to UUIDs by setting unique_element_ids=true.
- You can create and save a workflow that uses a local file as a source or does not
  have a source or destination connector added. However, you cannot activate the workflow
  or run the workflow either manually or on a schedule until a source and destination
  connector are added to the workflow.
- Handles PDF processing with splitting options.
- Unstructured recommends that you choose the Auto partitioning strategy in most cases.
- Fast partitioning skips processing handwriting.
- High Res partitioning produces unusable results for handwriting.
- Uses API key for authentication — must be set as environment variable UNSTRUCTURED_API_KEY
- If an output directory does not exist for the corresponding input directory, then
  create it.
- The chunking_strategy is set to None by default, and no chunking is performed.
- Unique element IDs can be set to true for random IDs instead of deterministic SHA-256
  hashes.
- Requires setup of Dropbox app for API access
- Use the correct API URL provided when creating your Unstructured account.
- Uses API key for authentication — requires setup of client credentials
- Get a refresh token for your Dropbox app using the access code generated.
- By default, the chunking_strategy is set to None, and no chunking is performed.
- If a green Successful message appears, then you have successfully created the connector.
- Use environment variables for API key and URL.
- Elastic Cloud instances are supported.
- A Jira Cloud account or Jira Data Center installation is required.
- Uses API key for authentication — requires setting environment variable UNSTRUCTURED_API_KEY
- Unique element IDs are enabled
- Element IDs are SHA-256 hashes by default, set 'unique_element_ids=true' for UUIDs
- Unique element IDs are required for processing.
- PDF files can be split into pages.
- API token is required for authentication, not OAuth token.
- 'A workflow that uses a local source location has limitations: You cannot save the
  workflow and cannot send the results to a remote destination location.'
- When a new page is detected, the existing chunk is completed and a new one is started,
  even if the next element would fit in the prior chunk.
- 'For .dif, \n characters in .dif files are supported, but \r\n characters will raise
  the error UnsupportedFileFormatError: Partitioning is not supported for the FileType.UNK
  file type.'
- Choose your partitioning strategy wisely.
- Split PDF page on the client side before sending it as batches to Unstructured for
  processing.
- Uses OAuth2 authentication.
- Specify the settings for a workflow node in the settings object.
- Unstructured can potentially generate image summary descriptions, table summary
  descriptions, and table-to-HTML output only for workflows that are configured with
  specific Partitioner node settings.
- Chunked elements may not contain all associated content.
- Uses json-converter package to transform JSON files.
- Unstructured has deprecated the Unstructured API on AWS and Azure.
- 'Note: You will use this DNS Name to replace the <application-load-balancer-dns-name>
  for the following healthcheck and data processing steps.'
- The `split_pdf_page` parameter is True by default.
- 'Unstructured never generates image summary descriptions, table summary descriptions,
  or table-to-HTML output for workflows that are configured as follows: With a Partitioner
  node set to use the Fast partitioning strategy.'
- Uses various chunking strategies to manage document elements and improve retrieval
  precision.
- This setting applies only to the chunking strategies Chunk by character, Chunk by
  title, and Chunk by page.
- Use with caution as this can introduce noise into otherwise clean semantic units.
- This setting applies only to the chunking strategy Chunk by similarity.
- You need to set an environment variable named UNSTRUCTURED_API_KEY.
- You need to set an environment variable named UNSTRUCTURED_API_URL.
- Choose one of the available embedding providers and models in the Select Embedding
  Model section of an Embedder node in a workflow.
- Pay attention to the number of dimensions listed next to each model.
- By default, the element ID is a SHA-256 hash of the element text.
- Handles files recursively and processes PDFs
- Set environment variable UNSTRUCTURED_API_KEY for API key.
- Set environment variable UNSTRUCTURED_API_URL for API URL.
- If an output directory does not exist for the corresponding input directory, it
  will be created.
- The element ID is a SHA-256 hash of the element text.
- Uses API key for authentication — requires setup of API key in environment variables.
- Unique element IDs are required for processing
- Uses API key for authentication — requires setting up environment variables for
  security.
- Supports partitioning of files for processing
- 'Available options: auto, fast, hi_res, ocr_only, vlm'
- A `Table` element is always isolated and never combined with another element.
- To speed up PDF file processing, the Unstructured SDK for Python and the Unstructured
  SDK for JavaScript/TypeScript provide parameters to help speed up processing a large
  PDF file.
- Each element in the document elements contains fields for that element’s type, its
  ID, the extracted text, and associated metadata.
- Extract the contents of an element’s text_as_html JSON object.
- This example uses a PDF file with an embedded table.
- Extracts Base64-encoded representation of images and tables from PDF documents.
- Chunked elements are represented in a specific JSON format.
- To get all elements that were used to derive chunked content, extract the contents
  of the element’s orig_elements field, which is compressed Base64 gzipped.
- The json-converter package is not owned or supported by Unstructured.
- Unstructured has deprecated the Unstructured API on AWS and Azure. These APIs are
  no longer supported and are not being actively updated.
- Manually shutting down the associated Azure virtual machine when you are not using
  it can help reduce ongoing charges.
- Unstructured recommends choosing the Auto partitioning strategy in most cases.
- Choosing a specific strategy other than Auto could produce undesirable results.
- Uses chunking strategies to manage document elements
- Supports multiple chunking strategies including by title, by page, and by similarity
errors:
- 'REQUEST_LIMIT_EXCEEDED: Throttle API calls or reduce frequency'
- 'QUERY_TIMEOUT: Break down filters or add selectivity'
- '401 Unauthorized: Recheck OAuth scopes or token expiration'
- 'INVALID_REQUEST: Check the request format and parameters'
- '401 Unauthorized: API key is missing, please provide an API key in the header.'
- '401 Unauthorized: Check if the API key is valid.'
- 'HTTPValidationError: Validation error for the request parameters.'
- 'UserWarning: If intending to use the paid API, please define `server_url` in your
  request.'
- 'ERROR: Server responded with 404 - {"detail":"Not Found"}'
- 'SDKError: API error occurred: Status 401 {"detail":"API key is malformed, please
  type the API key correctly in the header."}'
- 'API error occurred: Status 404 {"detail":"Not Found"}'
- 'UnstructuredClientError: Error partitioning the file'
- '401 Unauthorized: Recheck API key or token expiration'
- The API key, API URL, or both are missing or malformed in your script or code.
- The API key is no longer valid, or the API key and API URL combination is not valid.
- '400 Bad Request: Invalid input parameters'
- '401 Unauthorized: Invalid API key'
- '404 Not Found: Collection not found'
- '401 Unauthorized: Recheck API key or its permissions.'
- '401 Unauthorized: Recheck API key or token expiration.'
- Throttle API calls or reduce frequency
- Break down filters or add selectivity
- '503 Service Unavailable: Check minimum free memory requirements.'
- '401 Unauthorized: Check API key'
- '429 Too Many Requests: Throttle API calls'
- '429 Too Many Requests: Throttle API calls or reduce frequency'
- 'Error processing {filename}: {e}'
- 'Error: Input JSON schema field mappings file not found.'
- 'Error: Input JSON file not found.'
- '400 Bad Request: Check request parameters or file format.'
- 'Error processing file: Check the file path or permissions.'
- '401 Unauthorized: Recheck API key or credentials'
- '401 Unauthorized: Check your API key.'
- '404 Not Found: Ensure the endpoint is correct.'
- '400 Bad Request: Check your request parameters and data formats.'
- '401 Unauthorized: Recheck API key or permissions.'
- '500 Internal Server Error: Retry the request or check service status.'
- 'Error partitioning {filename}: {e.message}'
- '401 Unauthorized: Check API key and permissions'
- '404 Not Found: Verify endpoint URL'
- '404 Not Found: Check if the collection exists.'
- '401 Unauthorized: Check your API key and permissions.'
- '401 Unauthorized: Check your API key'
- '403 Forbidden: Check your permissions or bucket policy'
- '404 Not Found: Verify the bucket name or resource path'
- '400 Bad Request: Check the request format and parameters'
- '401 Unauthorized: Ensure API key is valid'
- '429 Too Many Requests: Rate limit exceeded, try again later'
- 'Microsoft.Resources/subscriptions/resourceGroups/write: to create the resource
  group'
- 'Microsoft.Resources/subscriptions/resourceGroups/read: to read the resource group'
- 'Microsoft.ContainerService/managedClusters/write: to create the AKS cluster'
- 'Microsoft.ContainerService/managedClusters/read: to read the AKS cluster'
- 'Microsoft.ContainerService/agentPools/write: to create the node pools'
- 'Microsoft.ContainerService/agentPools/read: to read the node pools'
- 'Microsoft.ManagedIdentity/userAssignedIdentities/write: to create the managed identities'
- 'Microsoft.ManagedIdentity/userAssignedIdentities/read: to read managed identities'
- 'Microsoft.Storage/storageAccounts/write: to create the storage account for CSI
  driver provisioning'
- 'Microsoft.Storage/storageAccounts/read: to read the storage account'
- The Unstructured API key, API URL, or both are missing or malformed in your script
  or code.
- The API key, API URL, or both are not present in your current session.
- '401 Unauthorized: Recheck username/password or API token.'
- '404 Not Found: Verify project, board, or issue ID.'
- '401 Unauthorized: Check your API key and its permissions.'
- '403 Forbidden: Access denied for the requested resource.'
- 'Error: Timed out waiting for bucket to be created.'
- 'Error: Failed to remove the block public policy access setting.'
- 'Error: Failed to apply the bucket policy.'
- '401 Unauthorized: Recheck API key or its presence in the header.'
- '400 Bad Request: Ensure request format is correct.'
- '400 Bad Request: Check the request format and parameters.'
- '401 Unauthorized: Verify access token and permissions.'
- '403 Forbidden: Confirm access rights to the requested resource.'
- '401 Unauthorized: Invalid API key provided.'
- 'HTTPValidationError: Validation error (HTTP 422)'
- 'ServerError: Server error (HTTP 5XX)'
- 'ResponseValidationError: Response validation/type mismatch'
- '404 Not Found: Ensure the collection exists before writing.'
- '401 Unauthorized: Check your API key and ensure it is set correctly'
- '401 Unauthorized: Check your API key and permissions'
- '401 Unauthorized: Check your access token and permissions.'
- '401 Unauthorized: Recheck API key or credentials.'
- '403 Forbidden: Check permissions for accessing the resource.'
- 'Unauthorized: Check authentication credentials.'
- 'Forbidden: Verify permissions for resources.'
- 'Not Found: Ensure API endpoints are correct.'
- '401 Unauthorized: Check your API key for Pinecone or Firecrawl.'
- '403 Forbidden: Ensure your AWS access key has the right permissions.'
- '401 Unauthorized: API key is missing or invalid.'
- 'INVALID_API_KEY: Check your API key for errors.'
- 'INDEX_NOT_FOUND: The specified index does not exist.'
- If Tesseract is not available and the document has extractable text, fallback to
  'fast'.
- If detectron2_onnx is not installed, partition_pdf will fail for copy protected
  PDFs.
- '401 Unauthorized: Recheck API key or account status'
- 'invalid_access_token: The access token provided is invalid.'
- 'insufficient_scope: The user does not have permission for this action.'
- '401 Unauthorized: Check your API token and email.'
- '404 Not Found: Verify the subdomain and API endpoint.'
- '401 Unauthorized: Check API key.'
- '404 Not Found: Verify endpoint path.'
- '500 Internal Server Error: Try again later.'
- 'Error: Timed out waiting for bucket creation.'
- '404 Not Found: Check the endpoint path.'
- 'Unauthorized: Check API key or permissions.'
- '401 Unauthorized: Recheck application token or permissions'
- 'REQUEST_LIMIT_EXCEEDED: Throttle API calls or reduce frequency.'
- 'QUERY_TIMEOUT: Break down filters or add selectivity.'
- '401 Unauthorized: Recheck OAuth scopes or token expiration.'
- '401 Unauthorized: Check if the access token is valid and has the required permissions.'
- 'Access token expired: Generate a new access token.'
- '401 Unauthorized: Check your credentials.'
- '404 Not Found: Verify the index name.'
- 'Unauthorized: Recheck API key value or permissions.'
- '401 Unauthorized: Check username and password.'
- '400 Bad Request: Ensure the collection has the minimum viable schema.'
- '401 Unauthorized: Recheck your username and password.'
- '400 Bad Request: Check your request parameters.'
- 'API_KEY_NOT_FOUND: Ensure the API key is correct and active.'
- 'UNAUTHORIZED: Check if the API key has the necessary permissions.'
- '401 Unauthorized: Check your email and API token.'
- '404 Not Found: Verify the endpoint path.'
- 'Error processing: Check if the API key is valid'
- 'REQUEST_FAILED: Verify input file and parameters'
- '400 Bad Request: Check your request format or parameters.'
- '401 Unauthorized: Ensure your API key is valid.'
- '429 Too Many Requests: Rate limit exceeded.'
- '200: Successful processing'
- 'Error: Check API key or server URL'
- '401 Unauthorized: Check your API key and ensure it is correct'
- 'Invalid_client: Check your App key and App secret.'
- '400 Bad Request: Check your request parameters'
- '400 Bad Request: Check your input data format.'
- '401 Unauthorized: Verify API key.'
- '500 Internal Server Error: Retry the request.'
- 'UnsupportedFileFormatError: Partitioning is not supported for the FileType.UNK
  file type.'
- 'ImportError: cannot import name ‘Mapping’ from ‘collections’'
- '404: Not Found'
- '401: API key is malformed, please type the API key correctly in the header.'
- '400 Bad Request: Check the request parameters.'
- '401 Unauthorized: Verify the API key.'
- 'Error processing file: Check the file format or connection settings'
- '401 Unauthorized: Check if the API key is set correctly.'
- 'Error: Check API key and request parameters'
- 'SDKError: API error occurred: Status 401'
- 'API error occurred: Status 404'
auth_info:
  mentioned_objects:
  - UnstructuredClient
  - Application (client) ID
  - Directory (tenant) ID
  - Client secret
  - User Principal Name (UPN)
  - CreateDestinationRequest
  - CreateDestinationConnector
  - Connected App
  - Consumer Key
  - Salesforce categories
  - OauthToken
  - AuthProvider
  - NamedCredential
  - api_key
  - Microsoft Entra ID app registration
  - QdrantClient
  - CreateSourceRequest
  - CreateSourceConnector
  - JiraCloud
  - JiraDataCenter
  - ApiKey
  - AccessToken
  - AppKey
  - AppSecret
  - VectorParams
  - API Keys
  - Couchbase Capella
  - Unity Catalog
  - Unstructured API Key
  - JWT_SECRET_KEY
  - AUTH_STRATEGY
  - SESSION_SECRET
  - SHARED_SECRET
  - KEYCLOAK_CLIENT_SECRET
  - KEYCLOAK_ADMIN_SECRET
  - KEYCLOAK_ADMIN
  - KEYCLOAK_ADMIN_PASSWORD
  - API_BEARER_TOKEN
  - API Key
  - Service Principal
  - unstructured-api-key
  - API token
  - API_KEY
  - S3_BUCKET
  - Unstructured Workflow Endpoint
  - AZURE_STORAGE_REMOTE_URL
  - AZURE_STORAGE_ACCOUNT_NAME
  - AZURE_STORAGE_ACCOUNT_KEY
  - AZURE_STORAGE_CONNECTION_STRING
  - AZURE_STORAGE_SAS_TOKEN
  - GithubAccessConfig
  - GitHubAccessToken
  - OAuth consumer key
  - ElasticsearchAccessConfig
  - apiKeyAuth
  - files.content.read
client:
  base_url: https://platform.unstructured.io
source_metadata: null
