resources:
- name: dataset
  endpoint:
    path: /api/dataset/
    method: POST
    data_selector: results
- name: column
  endpoint:
    path: /api/column/
    method: POST
    data_selector: results
- name: query
  endpoint:
    path: /api/query/
    method: POST
    data_selector: results
- name: images
  endpoint:
    path: /api/dataset/images
    method: POST
    data_selector: images
- name: embeddings
  endpoint:
    path: /api/dataset/embeddings
    method: POST
    data_selector: embeddings
- name: labels
  endpoint:
    path: /api/dataset/labels
    method: POST
    data_selector: labels
- name: dataset
  endpoint:
    path: /api/dataset/
    method: POST
    data_selector: records
- name: query
  endpoint:
    path: /api/query/
    method: GET
    data_selector: results
- name: dataset
  endpoint:
    path: /api/dataset
    method: POST
    data_selector: records
    params: {}
- name: column
  endpoint:
    path: /api/column
    method: POST
    data_selector: records
    params: {}
- name: query
  endpoint:
    path: /api/query
    method: POST
    data_selector: records
    params: {}
- name: dataset
  endpoint:
    path: /dataset
    method: POST
    data_selector: datasets
    params: {}
- name: images
  endpoint:
    path: /images
    method: POST
    data_selector: images
    params: {}
- name: embeddings
  endpoint:
    path: /embeddings
    method: POST
    data_selector: embeddings
    params: {}
- name: bounding_box
  endpoint:
    path: /bounding_box
    method: GET
    data_selector: records
- name: 3d_bounding_box
  endpoint:
    path: /3d_bounding_box
    method: GET
    data_selector: records
- name: intrinsics
  endpoint:
    path: /intrinsics
    method: GET
    data_selector: records
- name: segmentation_mask
  endpoint:
    path: /segmentation_mask
    method: GET
    data_selector: records
- name: binary_mask
  endpoint:
    path: /binary_mask
    method: GET
    data_selector: records
- name: coco_keypoints
  endpoint:
    path: /coco_keypoints
    method: GET
    data_selector: records
- name: point
  endpoint:
    path: /point
    method: GET
    data_selector: records
- name: polygon
  endpoint:
    path: /polygon
    method: GET
    data_selector: records
- name: VectorStore
  endpoint:
    path: /VectorStore
    method: GET
    data_selector: summary
    params: {}
- name: Dataset
  endpoint:
    path: /Dataset
    method: GET
    data_selector: create_tensor
    params: {}
- name: Tensor
  endpoint:
    path: /Tensor
    method: GET
    data_selector: info
    params: {}
- name: nifti_tensor
  endpoint:
    path: /nifti_tensor
    method: POST
    data_selector: nifti_samples
- name: point_cloud_tensor
  endpoint:
    path: /point_cloud_tensor
    method: POST
    data_selector: point_cloud_samples
- name: mesh_tensor
  endpoint:
    path: /mesh_tensor
    method: POST
    data_selector: mesh_samples
- name: embedding_tensor
  endpoint:
    path: /embedding_tensor
    method: POST
    data_selector: embedding_samples
- name: sequence_tensor
  endpoint:
    path: /sequence_tensor
    method: POST
    data_selector: sequence_samples
- name: link_tensor
  endpoint:
    path: /link_tensor
    method: POST
    data_selector: link_samples
- name: train
  endpoint:
    path: hub://activeloop/semantic-seg-train
    method: GET
    data_selector: records
- name: val
  endpoint:
    path: hub://activeloop/semantic-seg-val
    method: GET
    data_selector: records
- name: DeepLakeDataLoader
  endpoint:
    path: /deeplake/enterprise/dataloader
    method: GET
    data_selector: records
- name: training
  endpoint:
    path: /train
    method: POST
    data_selector: job_id
- name: status
  endpoint:
    path: /status
    method: GET
    data_selector: status
- name: list_jobs
  endpoint:
    path: /list_jobs
    method: GET
    data_selector: jobs
- name: evaluate
  endpoint:
    path: /evaluate
    method: POST
    data_selector: recalls
- name: search
  endpoint:
    path: /search
    method: POST
    data_selector: results
- name: dataset
  endpoint:
    path: /dataset
    method: POST
    data_selector: records
    params: {}
- name: bbox_tensor
  endpoint:
    path: /create_tensor
    method: POST
    data_selector: tensor
    params: {}
- name: 3d_bbox_tensor
  endpoint:
    path: /create_tensor
    method: POST
    data_selector: tensor
    params: {}
- name: intrinsics_tensor
  endpoint:
    path: /create_tensor
    method: POST
    data_selector: tensor
    params: {}
- name: segment_mask_tensor
  endpoint:
    path: /create_tensor
    method: POST
    data_selector: tensor
    params: {}
- name: binary_mask_tensor
  endpoint:
    path: /create_tensor
    method: POST
    data_selector: tensor
    params: {}
- name: keypoints_coco_tensor
  endpoint:
    path: /create_tensor
    method: POST
    data_selector: tensor
    params: {}
- name: point_tensor
  endpoint:
    path: /create_tensor
    method: POST
    data_selector: tensor
    params: {}
- name: polygon_tensor
  endpoint:
    path: /create_tensor
    method: POST
    data_selector: tensor
    params: {}
- name: nifti_tensor
  endpoint:
    path: /nifti_tensor
    method: POST
    data_selector: nifti
- name: point_cloud_tensor
  endpoint:
    path: /point_cloud_tensor
    method: POST
    data_selector: point_cloud
- name: mesh_tensor
  endpoint:
    path: /mesh_tensor
    method: POST
    data_selector: mesh
- name: embedding_tensor
  endpoint:
    path: /embedding_tensor
    method: POST
    data_selector: embedding
- name: sequence_tensor
  endpoint:
    path: /sequence_tensor
    method: POST
    data_selector: sequence
- name: link_tensor
  endpoint:
    path: /link_tensor
    method: POST
    data_selector: link
- name: vector_store
  endpoint:
    path: /vector_store
    method: GET
- name: train
  endpoint:
    path: /hub://activeloop/coco-train
    method: GET
    data_selector: records
    params: {}
- name: val
  endpoint:
    path: /hub://activeloop/coco-val
    method: GET
    data_selector: records
    params: {}
- name: train
  endpoint:
    path: /deep_memory/train
    method: POST
    data_selector: job_id
- name: status
  endpoint:
    path: /deep_memory/status
    method: GET
    data_selector: status
- name: list_jobs
  endpoint:
    path: /deep_memory/list_jobs
    method: GET
    data_selector: jobs
- name: evaluate
  endpoint:
    path: /deep_memory/evaluate
    method: POST
    data_selector: recalls
- name: dataset
  endpoint:
    path: /dataset
    method: GET
    data_selector: records
    params: {}
- name: dataset
  endpoint:
    path: /dataset
    method: GET
    data_selector: records
    params: {}
- name: dataset
  endpoint:
    path: /path/to/dataset
    method: GET
    data_selector: records
- name: tensor
  endpoint:
    path: /tensor
    method: GET
    data_selector: data
    params: {}
- name: dataset
  endpoint:
    path: /api/dataset
    method: GET
    data_selector: datasets
    params: {}
- name: info
  endpoint:
    path: /api/info
    method: GET
    data_selector: info
    params: {}
- name: link
  endpoint:
    path: /api/link
    method: GET
    data_selector: links
    params: {}
- name: linked_sample
  endpoint:
    path: /linked_sample
    method: GET
- name: linked_tiled_sample
  endpoint:
    path: /linked_tiled_sample
    method: GET
- name: partial_sample
  endpoint:
    path: /partial_sample
    method: GET
- name: compute_function
  endpoint:
    path: /compute_function
    method: GET
- name: dataset
  endpoint:
    path: /api/dataset/
    method: POST
    data_selector: ''
    params: {}
- name: LocalProvider
  endpoint:
    path: /deeplake/core/storage/LocalProvider
    method: GET
    data_selector: records
    params: {}
- name: MemoryProvider
  endpoint:
    path: /deeplake/core/storage/MemoryProvider
    method: GET
    data_selector: records
    params: {}
- name: dataset
  endpoint:
    path: /path/to/dataset
    method: GET
    data_selector: records
- name: Dataset
  endpoint:
    path: /dataset
    method: GET
- name: rename_group
  endpoint:
    path: /deeplake/core/dataset/rename_group
    method: POST
    data_selector: None
    params: {}
- name: rename_tensor
  endpoint:
    path: /deeplake/core/dataset/rename_tensor
    method: POST
    data_selector: None
    params: {}
- name: reset
  endpoint:
    path: /deeplake/core/dataset/reset
    method: POST
    data_selector: None
    params: {}
- name: sample_by
  endpoint:
    path: /deeplake/core/dataset/sample_by
    method: POST
    data_selector: None
    params: {}
- name: save_view
  endpoint:
    path: /deeplake/core/dataset/save_view
    method: POST
    data_selector: None
    params: {}
- name: set_token
  endpoint:
    path: /deeplake/core/dataset/set_token
    method: POST
    data_selector: None
    params: {}
- name: summary
  endpoint:
    path: /deeplake/core/dataset/summary
    method: GET
    data_selector: None
    params: {}
- name: tensorflow
  endpoint:
    path: /deeplake/core/dataset/tensorflow
    method: POST
    data_selector: None
    params: {}
- name: update
  endpoint:
    path: /deeplake/core/dataset/update
    method: POST
    data_selector: None
    params: {}
- name: update_creds_key
  endpoint:
    path: /deeplake/core/dataset/update_creds_key
    method: POST
    data_selector: None
    params: {}
- name: visualize
  endpoint:
    path: /deeplake/core/dataset/visualize
    method: GET
    data_selector: None
    params: {}
- name: Tensor
  endpoint:
    path: /deeplake/core/tensor
    method: GET
    data_selector: records
- name: dataset
  endpoint:
    path: /api/dataset/
    method: POST
    data_selector: dataset
    params: {}
- name: column
  endpoint:
    path: /api/column/
    method: POST
    data_selector: column
    params: {}
- name: query
  endpoint:
    path: /api/query/
    method: POST
    data_selector: results
    params: {}
- name: dataset
  endpoint:
    path: /api/dataset/
    method: POST
    data_selector: records
- name: query
  endpoint:
    path: /api/query/
    method: POST
    data_selector: results
- name: dataset
  endpoint:
    path: /dataset
    method: POST
    data_selector: records
    params: {}
- name: commit
  endpoint:
    path: /commit
    method: POST
    data_selector: records
    params: {}
- name: query
  endpoint:
    path: /query
    method: GET
    data_selector: records
    params: {}
- name: images
  endpoint:
    path: /images
    method: POST
    data_selector: records
    params: {}
- name: embeddings
  endpoint:
    path: /embeddings
    method: POST
    data_selector: records
    params: {}
- name: labels
  endpoint:
    path: /labels
    method: POST
    data_selector: records
    params: {}
notes:
- Deep Lake is a database specifically designed for machine learning and AI applications.
- Deep Lake is designed for machine learning and AI applications.
- Native integration with PyTorch and TensorFlow.
- Deep Lake does not support compression of raw nifti data.
- Chunk-wise compression is not supported for audio, video and point_cloud htypes.
- Requires setup of connected app in Deep Lake.
- Use C++ dataloader for performance, available only for registered users.
- Setting `overwrite` to `True` will delete all of your data if it exists! Be very
  careful when setting this parameter.
- Setting `access_method` to download will overwrite the local copy of the dataset
  if it was previously downloaded.
- Currently only local source paths and image classification datasets / csv files
  are supported for automatic ingestion.
- 'Supported filetypes: png/jpeg/jpg/csv.'
- Currently only local source paths and image classification datasets are supported
  for automatic ingestion.
- pad_data_in is only applicable if data_in is a Deep Lake dataset.
- Some datasets may require additional credentials.
- Uses OAuth2 with refresh token — requires setup of connected app in api
- Pytorch does not support uint16, uint32, uint64 dtypes. These are implicitly type
  casted to int32, int64 and int64 respectively.
- Covers exception handling for various deeplake operations
- Uses LocalProvider for file storage operations.
- MemoryProvider stores data in memory.
- 'Native support for major cloud providers: Amazon S3, Google Cloud Storage, Azure
  Blob Storage.'
- Deep Lake is optimized for machine learning and AI applications
- Asynchronous data loading and querying are supported.
- Optimized for ML workloads with efficient data streaming
- Handles billions of samples directly from the cloud
errors:
- '401 Unauthorized: Recheck your authentication credentials.'
- 'UserNotLoggedInException: When user is not authenticated'
- 'InvalidTokenException: If the specified token is invalid'
- 'TokenPermissionError: When there are permission or other errors related to token'
- 'DatasetCorruptError: If loading source dataset fails with DatasetCorruptedError'
- 'InvalidInputDataError: If data_in passed to transform is invalid. It should support
  __getitem__ and __len__ operations. Using scheduler other than ''threaded'' with
  deeplake dataset having base storage as memory as data_in will also raise this.'
- 'InvalidOutputDatasetError: If all the tensors of ds_out passed to transform don’t
  have the same length. Using scheduler other than ''threaded'' with deeplake dataset
  having base storage as memory as ds_out will also raise this.'
- 'TensorMismatchError: If one or more of the outputs generated during transform contain
  different tensors than the ones present in ''ds_out'' provided to transform.'
- 'UnsupportedSchedulerError: If the scheduler passed is not recognized. Supported
  values include: ''serial'', ''threaded'', and ''processed''.'
- 'TransformError: All other exceptions raised if there are problems while running
  the pipeline.'
- 'REQUEST_LIMIT_EXCEEDED: Throttle API calls or reduce frequency'
- 'QUERY_TIMEOUT: Break down filters or add selectivity'
- '401 Unauthorized: Recheck OAuth scopes or token expiration'
- 'TensorAlreadyExistsError: If the tensor already exists and `exist_ok` is `False`.'
- 'TensorGroupAlreadyExistsError: Duplicate tensor groups are not allowed.'
- 'InvalidTensorNameError: If `name` is in dataset attributes.'
- 'NotImplementedError: If trying to override `chunk_compression`.'
- 'TensorMetaInvalidHtype: If invalid htype is specified.'
- 'ValueError: If an illegal argument is specified.'
- 'TensorGroupDoesNotExistError: If tensor group of name `name` does not exist in
  the dataset.'
- 'TensorAlreadyExistsError: Duplicate tensors are not allowed.'
- 'InvalidTensorGroupNameError: If `name` is in dataset attributes.'
- 'RenameError: If `new_name` points to a group different from `name`.'
- 'ReadOnlyModeError: When attempting to save a view inplace and the user doesn’t
  have write access.'
- 'DatasetViewSavingError: If HEAD node has uncommitted changes.'
- 'TypeError: If `id` is not of type `str`.'
- 'InvalidPathException: If the source directory does not exist.'
- 'SamePathException: If the source and destination path are same.'
- 'AutoCompressionError: If the source directory is empty or does not contain a valid
  extension.'
- 'InvalidFileExtension: If the most frequent file extension is found to be ‘None’
  during auto-compression.'
- 'ExternalCommandError: Command execution failed.'
- 'KaggleError: General error related to Kaggle.'
- 'InvalidPathException: The provided path is invalid.'
- 'AuthenticationException: Authentication failed. Please try logging in again.'
- 'ResourceNotFoundException: The resource you are looking for was not found. Check
  if the name or id is correct.'
- 'BadRequestException: The request was malformed or invalid.'
- 'ServerException: Internal Activeloop server error.'
- 'UnauthorizedException: Authentication required to access this resource.'
- MergeConflictError
- CheckoutError
- CommitError
- EmptyCommitError
- TensorModifiedError
- GCSDefaultCredsNotFoundError
- InvalidOperationError
- AgreementError
- AgreementNotAcceptedError
- RenameError
- BufferError
- InfoError
- OutOfChunkCountError
- OutOfSampleCountError
- SampleHtypeMismatchError
- EmptyTensorError
- DatasetViewSavingError
- ManagedCredentialsNotFoundError
- UnableToReadFromUrlError
- InvalidTokenException
- TokenPermissionError
- 'ImportError: if indra is not installed'
- 'ValueError: if embedding_function is not specified either during initialization
  or during training'
- 'KeyError: If an object is not found at the path.'
- 'ReadOnlyError: If the provider is in read-only mode.'
- 'AUTHENTICATION_FAILED: Authentication failed. Please try logging in again.'
- 'RESOURCE_NOT_FOUND: The resource you are looking for was not found. Check if the
  name or id is correct.'
- 'OVER_LIMIT: You are over the allowed limits for this operation.'
- 'SERVER_ERROR: Internal Activeloop server error.'
- 'BAD_GATEWAY: Invalid response from Activeloop server.'
- 'GATEWAY_TIMEOUT: Activeloop server took too long to respond.'
- 'LOCKED: The resource is currently locked.'
- 'MergeConflictError: Conflict tensors may need resolution'
- 'CheckoutError: Error during checkout process'
- 'CommitError: Issues encountered during commit'
- 'EmptyCommitError: Commit cannot be empty'
- 'TensorModifiedError: Tensor was modified unexpectedly'
- 'GCSDefaultCredsNotFoundError: Default credentials not found for GCS'
- 'InvalidOperationError: Invalid operation attempted'
- 'AgreementError: Agreement issue encountered'
- 'AgreementNotAcceptedError: Required agreements not accepted'
- 'RenameError: Only name of the dataset can be different in new path'
- 'BufferError: Buffer related issue'
- 'InfoError: Information retrieval error'
- 'OutOfChunkCountError: Exceeded maximum chunk count'
- 'OutOfSampleCountError: Exceeded maximum sample count'
- 'SampleHtypeMismatchError: Sample type mismatch detected'
- 'EmptyTensorError: Tensor is empty'
- 'DatasetViewSavingError: Error saving dataset view'
- 'ManagedCredentialsNotFoundError: Managed credentials not found'
- 'UnableToReadFromUrlError: Unable to read from specified URL'
- 'InvalidTokenException: Provided token is invalid'
- 'TokenPermissionError: Permission issue with the token'
auth_info:
  mentioned_objects:
  - deeplake.load
  - Dataset.commit_id
client:
  base_url: https://docs.deeplake.ai/4.3/
source_metadata: null
