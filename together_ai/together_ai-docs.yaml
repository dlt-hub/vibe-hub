resources:
- name: code_models
  endpoint:
    path: /reference/completions-1
    method: GET
    data_selector: models
    params: {}
- name: chat_models
  endpoint:
    path: /inference/chat-models
    method: GET
- name: image_models
  endpoint:
    path: /inference/image-models
    method: GET
- name: vision_models
  endpoint:
    path: /inference/vision-models
    method: GET
- name: audio_models
  endpoint:
    path: /inference/audio-models
    method: GET
- name: create_chat_completion
  endpoint:
    path: /chat/completions
    method: POST
    data_selector: choices
    params: {}
- name: batch
  endpoint:
    path: /v1/chat/completions
    method: POST
    data_selector: id
- name: batch_completion
  endpoint:
    path: /v1/chat/completions
    method: POST
    data_selector: results
- name: Llama 4 Maverick
  endpoint:
    path: /v1/chat/completions
    method: POST
    data_selector: choices
    params: {}
- name: Llama 4 Maverick
  endpoint:
    path: /chat/completions
    method: POST
    data_selector: choices
    params: {}
- name: Llama 4 Scout
  endpoint:
    path: /chat/completions
    method: POST
    data_selector: choices
    params: {}
- name: chat_completions
  endpoint:
    path: /chat/completions
    method: POST
    data_selector: choices
    params: {}
- name: chat_completion
  endpoint:
    path: /chat/completions
    method: POST
    data_selector: choices
- name: chat
  endpoint:
    path: /chat/completions
    method: POST
    data_selector: choices
    params: {}
- name: function_calling
  endpoint:
    path: /docs/function-calling
    method: GET
    data_selector: tools
    params: {}
- name: vision
  endpoint:
    path: /playground/chat/meta-llama/Llama-3.2-11B-Vision-Instruct-Turbo
    method: POST
    data_selector: output
- name: model_query
  endpoint:
    path: /chat/completions
    method: POST
    data_selector: choices
- name: image_query
  endpoint:
    path: /chat/completions
    method: POST
    data_selector: choices
    params: {}
- name: video_query
  endpoint:
    path: /chat/completions
    method: POST
    data_selector: choices
    params: {}
- name: transcription
  endpoint:
    path: /audio/transcriptions
    method: POST
    data_selector: response
    params: {}
- name: translation
  endpoint:
    path: /audio/translations
    method: POST
    data_selector: response
    params: {}
- name: deepseek-ai
  endpoint:
    path: /chat/completions
    method: POST
    data_selector: choices
    params: {}
- name: chat
  endpoint:
    path: /chat
    method: POST
    data_selector: choices
- name: chat_completion
  endpoint:
    path: /chat/completions
    method: POST
    data_selector: choices
    params: {}
- name: chat_completion
  endpoint:
    path: /chat/completions
    method: POST
    data_selector: choices
    params: {}
- name: embeddings
  endpoint:
    path: /embeddings
    method: POST
- name: rerank
  endpoint:
    path: /rerank
    method: POST
- name: chat_completions
  endpoint:
    path: /chat/completions
    method: POST
- name: chat_completion
  endpoint:
    path: /api/chat
    method: POST
    data_selector: messages
- name: answer
  endpoint:
    path: /api/answer
    method: POST
    data_selector: question
- name: chat_completion
  endpoint:
    path: /chat/completions
    method: POST
    data_selector: choices
    params:
      model: deepseek-ai/DeepSeek-R1
      max_tokens: 500
- name: text_to_image
  endpoint:
    path: /text_to_image
    method: POST
    data_selector: image
    params:
      model: black-forest-labs/FLUX.1-schnell
- name: generateText
  endpoint:
    path: /generateText
    method: POST
    data_selector: text
- name: streamText
  endpoint:
    path: /streamText
    method: POST
    data_selector: textStream
- name: chat_completions
  endpoint:
    path: /chat/completions
    method: POST
    data_selector: choices
- name: OCR
  endpoint:
    path: /chat/completions
    method: POST
    data_selector: choices[0].message.content
- name: DeepSeek-V3
  endpoint:
    path: /models/deepseek-ai/DeepSeek-V3
    method: POST
- name: fine_tuning
  endpoint:
    path: /v1/completions
    method: POST
    data_selector: model
    params: {}
- name: create_image
  endpoint:
    path: /images/generations
    method: POST
    data_selector: data
- name: models
  endpoint:
    path: /models
    method: GET
- name: files
  endpoint:
    path: /files
    method: POST
- name: model
  endpoint:
    path: /models
    method: GET
    data_selector: models
    params: {}
- name: hardware
  endpoint:
    path: /hardware
    method: GET
    data_selector: data
    params: {}
- name: audio_generation_request
  endpoint:
    path: /audio/speech
    method: POST
    data_selector: response
    params: {}
- name: audio_transcription
  endpoint:
    path: /audio/transcriptions
    method: POST
- name: audio_translation
  endpoint:
    path: /audio/translations
    method: POST
    data_selector: text
- name: completions
  endpoint:
    path: /completions
    method: POST
- name: create_embedding
  endpoint:
    path: /embeddings
    method: POST
    data_selector: data
- name: rerank
  endpoint:
    path: /rerank
    method: POST
    data_selector: object
    params: {}
- name: batch_jobs
  endpoint:
    path: /batches
    method: GET
    data_selector: records
- name: batches
  endpoint:
    path: /batches
    method: POST
    data_selector: job
    params: {}
- name: batch_job
  endpoint:
    path: /batches/{id}
    method: GET
- name: chat_completion
  endpoint:
    path: /client/chat/completions
    method: POST
    data_selector: response
    params: {}
- name: rerank
  endpoint:
    path: /rerank
    method: POST
    data_selector: results
- name: embeddings
  endpoint:
    path: /embeddings
    method: POST
    data_selector: data
- name: getSources
  endpoint:
    path: /api/getSources
    method: POST
    data_selector: webPages.value
- name: getAnswer
  endpoint:
    path: /api/getAnswer
    method: POST
    data_selector: response
- name: movies
  endpoint:
    path: /datasets/movies.json
    method: GET
    data_selector: movies
    params: {}
- name: rerank
  endpoint:
    path: /rerank
    method: POST
    data_selector: results
- name: generate_code
  endpoint:
    path: /api/generateCode
    method: POST
    data_selector: choices
    params: {}
- name: dataset_upload
  endpoint:
    path: /upload
    method: POST
    data_selector: result
- name: script_generation
  endpoint:
    path: /v1/podcasts/generate
    method: POST
    data_selector: script
- name: chat
  endpoint:
    path: /api/chat
    method: POST
    data_selector: messages
    params: {}
- name: getSources
  endpoint:
    path: /api/getSources
    method: POST
    data_selector: webPages.value
    params: {}
- name: getParsedSources
  endpoint:
    path: /api/getParsedSources
    method: POST
    data_selector: textContent
    params: {}
- name: chat
  endpoint:
    path: /api/chat
    method: POST
    data_selector: response
    params: {}
notes:
- Free model has reduced rate limits compared to paid versions.
- Uses OAuth2 with refresh token — requires setup of connected app in api
- Some objects like Contact may return nulls in deeply nested fields
- Set your account’s API key to an environment variable named TOGETHER_API_KEY
- API key required to access the API.
- Batches are best effort completion within 24 hours.
- Make sure your together version number is >1.5.13.
- New accounts come with free credits to start.
- Supports querying with multiple images.
- Currently this model supports 5 images as input.
- Kimi K2 shines in scenarios requiring autonomous problem-solving – specifically
  with coding & tool use.
- These models are only available to Build Tier 1 or higher users.
- Current limitations include unsupported GPT-OSS 20B model and some sampling parameters.
- Streaming responses can be returned by setting the stream option to true.
- You must always instruct your model to only respond in JSON format.
- Certain models support function calling.
- Uses API key for authentication.
- API key is set to an environment variable named TOGETHER_API_KEY
- API key must be set as an environment variable named TOGETHER_API_KEY
- Use high-quality audio files for better transcription accuracy
- Minimize background noise
- Requires setup of Together AI API key.
- Uses OAuth2 with refresh token.
- 'To return logprobs from the API, add logprobs: 1 to your API call.'
- Direct Requests use your Together AI API key in your Hugging Face user account settings.
- Uses API key for authentication
- Rate limits apply to API calls.
- Define clear schemas for your expected output, making it easier to validate and
  process the extracted data.
- Always implement robust error handling for cases where the OCR might fail or return
  unexpected results.
- Rate limits restrict how often a user or client can access our API within a set
  timeframe.
- Rate limits in APIs are a standard approach, and they serve to safeguard against
  abuse or misuse of the API, helping to ensure equitable access to the API with consistent
  performance.
- Together does not store your input or output by default.
- Temporary caching may be used for performance unless otherwise configured.
- New API keys will not be available to copy after creation. Make sure to copy the
  API and save it in a secure location.
- If the default API key is compromised, it can be regenerated.
- Fine-tuning jobs will have statuses including Pending, Queued, Running, Uploading,
  and Completed
- Authorization requires Bearer authentication header.
- Uses Together AI API key for authentication
- Reranker models are computationally expensive and slower.
- Requires API key from Microsoft for Bing API
- API key is required for access.
- Together’s Rerank API allows you to seamlessly integrate supported rerank models
  into your enterprise applications.
- The Llama 3.1 405B model is recommended for generating code.
- Streaming responses are supported for immediate UI feedback.
- API keys for Together and E2B are required.
- Requires API key for access.
- Requires an API key from Microsoft to access Bing's API
errors:
- '200'
- '400'
- '401'
- '404'
- '429'
- '503'
- '504'
- '400: Invalid request format - Check JSONL syntax and required fields'
- '401: Authentication failed - Verify API key'
- '404: Batch not found - Check batch ID'
- '429: Rate limit exceeded - Reduce request frequency'
- '500: Server error - Retry with exponential backoff'
- 'VALIDATING: The input file is being validated before the batch can begin'
- 'IN_PROGRESS: Batch is in progress'
- 'COMPLETED: Batch processing completed successfully'
- 'FAILED: Batch processing failed'
- 'EXPIRED: Batch exceeded deadline'
- 'CANCELLED: Batch was cancelled'
- Latency issues in real-time applications.
- 'REQUEST_LIMIT_EXCEEDED: Throttle API calls or reduce frequency'
- 'QUERY_TIMEOUT: Break down filters or add selectivity'
- '401 Unauthorized: Recheck OAuth scopes or token expiration'
- '401 Unauthorized: Check API key.'
- '401 Unauthorized: Recheck API key validity'
- '401 Unauthorized: Check API key'
- '400 Bad Request: Check file format and parameters'
- '401 Unauthorized: Ensure API key is valid'
- '429 Too Many Requests: Rate limit exceeded'
- '401 Unauthorized: Check your access token.'
- '400 Bad Request: Check request parameters.'
- '401 Unauthorized: Check your API key.'
- 'RateLimitError: Throttle API calls or reduce frequency'
- Failed to extract receipt information
- '429: Rate limit exceeded'
- '400 - Invalid Request: Ensure your request is a Valid JSON and your API Key is
  correct. Also ensure you’re using the right prompt format - which is different for
  Mistral and LLaMA models.'
- '401 - Authentication Error: Ensure you are using the correct API Key and supplying
  it correctly.'
- '402 - Payment Required: Adjust your billing settings or make a payment to resume
  service.'
- '403 - Bad Request: Set max_tokens to a lower number. If querying a chat model,
  you may set max_tokens to null and let the model decide when to stop generation.'
- '404 - Not Found: Check your request is being made to the correct endpoint and that
  the model being queried is available.'
- '429 - Rate limit: Throttle the rate at which requests are sent to our servers.'
- '500 - Server Error: This error is caused by an issue on our servers. Please try
  again after a brief wait.'
- '503 - Engine Overloaded: Please try again after a brief wait.'
- '429 Too Many Requests: You can request higher limits via the Together dashboard
  or by contacting support.'
- '403 Forbidden: API Key is incorrect'
- Insufficient balance to cover the cost of the job
- '403 Forbidden: Check your API key or authorization'
- 400 Bad Request
- 401 Unauthorized
- 429 Too Many Requests
- '200: OK'
- '400: Bad Request'
- '401: Unauthorized'
- '429: Too Many Requests'
- '401 Unauthorized: Recheck API key or token expiration'
- '201: Job created (potentially with warnings)'
- '500: Internal Server Error'
- 403 Forbidden
- 404 Not Found
- 500 Internal Server Error
- '401 Unauthorized: Check if the API key is correct.'
- '401 Unauthorized: Check OAuth token validity.'
- '400 Bad Request: Ensure request body is correctly formatted.'
- 'FileNotFoundError: Dataset file not found'
- 'ValueError: Failed to upload dataset'
auth_info:
  mentioned_objects:
  - Together AI API Key
client:
  base_url: https://api.together.xyz
  headers:
    Accept: application/json
source_metadata: null
