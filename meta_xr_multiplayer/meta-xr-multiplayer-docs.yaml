resources:
- name: VRC Privacy Policy Requirements
  endpoint:
    path: /horizon/resources/publish-quest-req/#privacy-policy-requirements
    method: GET
    data_selector: requirements
    params: {}
- name: Data Use Checkup
  endpoint:
    path: /horizon/resources/publish-data-use/
    method: GET
    data_selector: data_use_checkup
    params: {}
- name: Developer Data Use Policy
  endpoint:
    path: /horizon/policy/data-use
    method: GET
    data_selector: developer_data_use_policy
    params: {}
- name: localization
  endpoint:
    path: /horizon/design/localization
    method: GET
    data_selector: content
    params: {}
- name: controllers
  endpoint:
    path: /horizon/design/controllers
    method: GET
- name: hands
  endpoint:
    path: /horizon/design/hands
    method: GET
- name: voice
  endpoint:
    path: /horizon/design/voice
    method: GET
- name: head_gaze
  endpoint:
    path: /horizon/design/head
    method: GET
- name: keyboard
  endpoint:
    path: /horizon/design/keyboard
    method: GET
- name: mouse
  endpoint:
    path: /horizon/design/mouse
    method: GET
- name: gamepad
  endpoint:
    path: /horizon/design/gamepad
    method: GET
- name: stylus
  endpoint:
    path: /horizon/design/stylus
    method: GET
- name: Dos & don’ts
- name: Hands Technology
  endpoint:
    path: /horizon/design/hands-technology/
    method: GET
- name: Hands Interaction Types
  endpoint:
    path: /horizon/design/hands-interaction-types/
    method: GET
- name: Hands Best Practices
  endpoint:
    path: /horizon/design/hands-best-practices/
    method: GET
- name: Github samples
  endpoint:
    path: https://github.com/oculus-samples
    method: GET
- name: First Hand
  endpoint:
    path: https://www.meta.com/experiences/first-hand/5030224183773255/?srsltid=AfmBOopNEIQAJ2zAXC5ksFvZ8szhSr-SJE8F5kJskHuzEkZYbbYCnFMf
    method: GET
- name: Move Fast
  endpoint:
    path: https://www.meta.com/experiences/move-fast/6087525674710349/?srsltid=AfmBOoqJStv9SKgemaDfoS9snvBZ8hIW3EXuBQO1mfjgFW8dEuKLWGl0
    method: GET
- name: Interaction SDK Samples
  endpoint:
    path: https://www.meta.com/experiences/interaction-sdk-samples/5605166159514983/?srsltid=AfmBOoryLOWnoF-Me0_Tw-NpJYDzyfJ5Ehw1f7noO5k0BlzxEGQ-EMZ6
    method: GET
- name: hand_tracking
  endpoint:
    path: /horizon/design/hands/
    method: GET
- name: hands_best_practices
  endpoint:
    path: /horizon/design/hands-best-practices/
    method: GET
- name: fast_motion_mode
  endpoint:
    path: /horizon/documentation/unity/fast-motion-mode/
    method: GET
- name: wide_motion_mode
  endpoint:
    path: /horizon/documentation/unity/unity-wide-motion-mode/
    method: GET
- name: multimodal_mode
  endpoint:
    path: /horizon/documentation/unity/unity-wide-motion-mode/
    method: GET
- name: controllers
  endpoint:
    path: /horizon/design/controllers/
    method: GET
    data_selector: controllers
    params: {}
- name: keyboard
  endpoint:
    path: /horizon/design/interactions-input-peripherals
    method: GET
    data_selector: ''
    params: {}
- name: mouse
  endpoint:
    path: /horizon/design/interactions-input-peripherals
    method: GET
    data_selector: ''
    params: {}
- name: stylus
  endpoint:
    path: /horizon/design/interactions-input-peripherals
    method: GET
    data_selector: ''
    params: {}
- name: gamepad
  endpoint:
    path: /horizon/design/interactions-input-peripherals
    method: GET
    data_selector: ''
    params: {}
- name: core_interaction_model
  endpoint:
    path: /horizon/design/interactions-input-hierarchy/
    method: GET
    data_selector: input_methods
    params: {}
- name: specialized_input
  endpoint:
    path: /horizon/design/interactions-input-hierarchy/
    method: GET
    data_selector: specialized_input_methods
    params: {}
- name: locomotion_types
  endpoint:
    path: /horizon/design/locomotion-types/
    method: GET
    data_selector: data
    params: {}
- name: user_preferences
  endpoint:
    path: /horizon/design/locomotion-user-preferences/
    method: GET
    data_selector: data
    params: {}
- name: input_maps
  endpoint:
    path: /horizon/design/locomotion-input-maps/
    method: GET
    data_selector: data
    params: {}
- name: virtual_environments
  endpoint:
    path: /horizon/design/locomotion-virtual-environments/
    method: GET
    data_selector: data
    params: {}
- name: comfort_usability
  endpoint:
    path: /horizon/design/locomotion-comfort-usability/
    method: GET
    data_selector: data
    params: {}
- name: locomotion_types
  endpoint:
    path: /locomotion/types
    method: GET
    data_selector: locomotion
- name: movement_style
  endpoint:
    path: /horizon/design/locomotion-user-preferences/movement-style
    method: GET
    data_selector: records
- name: turn_style
  endpoint:
    path: /horizon/design/locomotion-user-preferences/turn-style
    method: GET
    data_selector: records
- name: additionals
  endpoint:
    path: /horizon/design/locomotion-user-preferences/additionals
    method: GET
    data_selector: records
- name: comfort_assistance
  endpoint:
    path: /horizon/design/locomotion-user-preferences/comfort-assistance
    method: GET
    data_selector: records
- name: Meta Haptics Studio
  endpoint:
    path: /horizon/documentation/unity/unity-haptics-studio-get-started
    method: GET
    data_selector: design_haptics
    params: {}
- name: Haptics SDK for Unity
  endpoint:
    path: /horizon/documentation/unity/unity-haptics-sdk
    method: GET
    data_selector: integrate_haptics_unity
    params: {}
- name: Haptics SDK for Unreal
  endpoint:
    path: /horizon/documentation/unreal/unreal-haptics-sdk
    method: GET
    data_selector: integrate_haptics_unreal
    params: {}
- name: Haptics Native SDK
  endpoint:
    path: /horizon/documentation/native/experimental/exp-haptics-native/
    method: GET
    data_selector: integrate_haptics_native
    params: {}
- name: Buttons
  endpoint:
    path: /horizon/design/buttons/
    method: GET
    data_selector: resources
    params: {}
- name: Meta Horizon OS UI Set
  endpoint:
    path: /horizon/documentation/unity/unity-isdk-uiset
    method: GET
- name: Meta Spatial SDK
  endpoint:
    path: /horizon/documentation/spatial-sdk/spatial-sdk-ui-overview
    method: GET
- name: Default Slider
  endpoint:
    path: /horizon/design/sliders/default
    method: GET
- name: Text Slider
  endpoint:
    path: /horizon/design/sliders/text
    method: GET
- name: Discrete Slider
  endpoint:
    path: /horizon/design/sliders/discrete
    method: GET
- name: virtual_keyboard
  endpoint:
    path: /horizon/design/virtual-keyboard/
    method: GET
    data_selector: ''
    params: {}
- name: panels
  endpoint:
    path: /horizon/design/panels/
    method: GET
    data_selector: panels
    params: {}
- name: tooltips
  endpoint:
    path: /horizon/tooltips
    method: GET
    data_selector: tooltips
    params: {}
- name: premade_assets
  endpoint:
    path: /horizon/design/art-assets/
    method: GET
    data_selector: resources
    params: {}
- name: hiring_artists
  endpoint:
    path: /horizon/design/art-assets/
    method: GET
    data_selector: resources
    params: {}
- name: creating_art_assets
  endpoint:
    path: /horizon/design/art-assets/
    method: GET
    data_selector: resources
    params: {}
- name: art_assets
  endpoint:
    path: /horizon/design/art-assets
    method: GET
    data_selector: records
- name: Avatar Hands
  endpoint:
    path: /horizon/design/hands/avatar-hands
    method: GET
    data_selector: records
- name: Custom Hands
  endpoint:
    path: /horizon/design/hands/custom-hands
    method: GET
    data_selector: records
- name: Hands in Passthrough
  endpoint:
    path: /horizon/design/hands/hands-in-passthrough
    method: GET
    data_selector: records
- name: Button dimensions
  endpoint:
    path: /wrist_buttons/specs/button_dimensions
    method: GET
    data_selector: dimensions
    params: {}
- name: Wrist button coordinates
  endpoint:
    path: /wrist_buttons/specs/coordinates
    method: GET
    data_selector: coordinates
    params: {}
- name: localization
  endpoint:
    path: /horizon/design/localization/
    method: GET
    data_selector: content
    params: {}
- name: controllers
  endpoint:
    path: /horizon/design/controllers
    method: GET
- name: hands
  endpoint:
    path: /horizon/design/hands
    method: GET
- name: voice
  endpoint:
    path: /horizon/design/voice
    method: GET
- name: head_gaze
  endpoint:
    path: /horizon/design/head
    method: GET
- name: keyboard
  endpoint:
    path: /horizon/design/keyboard
    method: GET
- name: mouse
  endpoint:
    path: /horizon/design/mouse
    method: GET
- name: gamepad
  endpoint:
    path: /horizon/design/gamepad
    method: GET
- name: stylus
  endpoint:
    path: /horizon/design/stylus
    method: GET
- name: visual_output
  endpoint:
    path: /horizon/design/display
    method: GET
    data_selector: high-resolution displays
- name: audio_output
  endpoint:
    path: /horizon/design/audio
    method: GET
    data_selector: spatial audio
- name: haptic_feedback
  endpoint:
    path: /horizon/design/haptics-overview
    method: GET
    data_selector: haptic feedback mechanisms
- name: hand_tracking
  endpoint:
    path: /horizon/design/hands
    method: GET
    data_selector: hands
- name: interaction_sdk
  endpoint:
    path: /horizon/design/interactions-sdk
    method: GET
    data_selector: sdk
- name: Hands Technology
  endpoint:
    path: /horizon/design/hands-technology/
    method: GET
- name: Hands Interaction Types
  endpoint:
    path: /horizon/design/hands-interaction-types/
    method: GET
- name: Hands Best Practices
  endpoint:
    path: /horizon/design/hands-best-practices/
    method: GET
- name: Github samples
  endpoint:
    path: https://github.com/oculus-samples
    method: GET
- name: First Hand
  endpoint:
    path: https://www.meta.com/experiences/first-hand/5030224183773255/?srsltid=AfmBOopNEIQAJ2zAXC5ksFvZ8szhSr-SJE8F5kJskHuzEkZYbbYCnFMf
    method: GET
- name: Move Fast
  endpoint:
    path: https://www.meta.com/experiences/move-fast/6087525674710349/?srsltid=AfmBOoqJStv9SKgemaDfoS9snvBZ8hIW3EXuBQO1mfjgFW8dEuKLWGl0
    method: GET
- name: Interaction SDK Samples
  endpoint:
    path: https://www.meta.com/experiences/interaction-sdk-samples/5605166159514983/?srsltid=AfmBOoryLOWnoF-Me0_Tw-NpJYDzyfJ5Ehw1f7noO5k0BlzxEGQ-EMZ6
    method: GET
- name: input_hierarchy
  endpoint:
    path: /horizon/design/interactions-input-hierarchy/
    method: GET
    data_selector: inputs
    params: {}
- name: locomotion_types
  endpoint:
    path: /horizon/design/locomotion-types/
    method: GET
- name: user_preferences
  endpoint:
    path: /horizon/design/locomotion-user-preferences/
    method: GET
- name: input_maps
  endpoint:
    path: /horizon/design/locomotion-input-maps/
    method: GET
- name: virtual_environments
  endpoint:
    path: /horizon/design/locomotion-virtual-environments/
    method: GET
- name: comfort_and_usability
  endpoint:
    path: /horizon/design/locomotion-comfort-usability/
    method: GET
- name: Meta Haptics Studio
  endpoint:
    path: /horizon/documentation/unity/unity-haptics-studio-get-started
    method: GET
    data_selector: ''
    params: {}
- name: Meta Haptics SDK for Unity
  endpoint:
    path: /horizon/documentation/unity/unity-haptics-sdk
    method: GET
    data_selector: ''
    params: {}
- name: Meta Haptics SDK for Unreal
  endpoint:
    path: /horizon/documentation/unreal/unreal-haptics-sdk
    method: GET
    data_selector: ''
    params: {}
- name: Meta Haptics Native SDK
  endpoint:
    path: /horizon/documentation/native/experimental/exp-haptics-native/
    method: GET
    data_selector: ''
    params: {}
- name: haptic_effects
  endpoint:
    path: /haptic/effects
    method: POST
    data_selector: effects
    params: {}
- name: haptic_patterns
  endpoint:
    path: /haptic/patterns
    method: GET
    data_selector: patterns
    params: {}
- name: buttons
  endpoint:
    path: /horizon/design/buttons/
    method: GET
    data_selector: resources
    params: {}
- name: Meta Horizon OS UI Set
  endpoint:
    path: /horizon/documentation/unity/unity-isdk-uiset
    method: GET
- name: Meta Spatial SDK
  endpoint:
    path: /horizon/documentation/spatial-sdk/spatial-sdk-ui-overview
    method: GET
- name: dropdowns
  endpoint:
    path: /horizon/design/dropdowns
    method: GET
    data_selector: dropdowns
    params: {}
- name: panels
  endpoint:
    path: /horizon/design/panels
    method: GET
    data_selector: panels
    params: {}
- name: avatars
  endpoint:
    path: /api/v1/avatars
    method: GET
    data_selector: data
    params: {}
- name: hand_representation
  endpoint:
    path: /horizon/design/hand-representation
    method: GET
    data_selector: content
    params: {}
- name: meta_wrist_button
  endpoint:
    path: /horizon/design/wrist-buttons/
    method: GET
    data_selector: ''
    params: {}
- name: button_dimensions
  endpoint:
    path: button/dimensions
    method: GET
    data_selector: dimensions
    params: {}
- name: wrist_button_coordinates
  endpoint:
    path: button/coordinates
    method: GET
    data_selector: coordinates
    params: {}
- name: meta_xr_simulator_mac_arm
  endpoint:
    path: /horizon/downloads/package/meta-xr-simulator-mac-arm/
    method: GET
- name: meta_xr_simulator_windows
  endpoint:
    path: /horizon/downloads/package/meta-xr-simulator-windows/
    method: GET
- name: renderdoc_meta_fork_mac
  endpoint:
    path: /horizon/downloads/package/renderdoc-meta-fork-for-mac-installer/
    method: GET
- name: renderdoc_meta_fork_windows
  endpoint:
    path: /horizon/downloads/package/renderdoc-oculus/
    method: GET
- name: meta_horizon_os_ui_set
  endpoint:
    path: /horizon/downloads/package/meta-horizon-os-ui-set/
    method: GET
- name: meta_xr_audio_sdk_unity
  endpoint:
    path: /horizon/downloads/package/meta-xr-audio-sdk-unity/
    method: GET
- name: meta_haptics_sdk_unity
  endpoint:
    path: /horizon/downloads/package/meta-haptics-sdk-unity/
    method: GET
- name: meta_haptics_studio_windows
  endpoint:
    path: /horizon/downloads/package/meta-haptics-studio-win/
    method: GET
- name: meta_haptics_studio_mac
  endpoint:
    path: /horizon/downloads/package/meta-haptics-studio-macos/
    method: GET
- name: meta_xr_all_in_one_sdk_upm
  endpoint:
    path: /horizon/downloads/package/meta-xr-sdk-all-in-one-upm/
    method: GET
- name: meta_voice_sdk_upm
  endpoint:
    path: /horizon/downloads/package/meta-voice-sdk/
    method: GET
- name: programs
  endpoint:
    path: /horizon-worlds/programs
    method: GET
    data_selector: records
- name: faq
  endpoint:
    path: /horizon-worlds/learn/documentation/mhcp-program/faq/mhcp-faq
    method: GET
    data_selector: records
- name: Meta Spatial SDK
  endpoint:
    path: /horizon/develop/spatial-sdk/
    method: GET
- name: Web and PWAs
  endpoint:
    path: /horizon/develop/web/
    method: GET
- name: Meta XR Simulator
  endpoint:
    path: /horizon/documentation/unity/xrsim-intro/
    method: GET
- name: Meta Developer Account
  endpoint:
    path: /horizon/manage/verify/
    method: POST
    data_selector: verification
    params: {}
- name: Epic Games Account
  endpoint:
    path: https://accounts.unrealengine.com/
    method: GET
    data_selector: account
    params: {}
- name: GitHub Account
  endpoint:
    path: https://github.com/
    method: GET
    data_selector: account
    params: {}
- name: Developer Dashboard
  endpoint:
    path: /horizon/manage/
    method: GET
    data_selector: dashboard
    params: {}
- name: Meta XR Plugin
  endpoint:
    path: /horizon/documentation/unreal/unreal-quick-start-install-unreal-engine
    method: GET
- name: Unreal Engine 5 Source Code
  endpoint:
    path: /horizon/documentation/unreal/unreal-create-and-configure-new-project/
    method: GET
- name: Unreal Engine 4 Source Code
  endpoint:
    path: /horizon/documentation/unreal/unreal-create-and-configure-new-project/
    method: GET
- name: Oculus-Samples GitHub Repository
  endpoint:
    path: https://github.com/oculus-samples
    method: GET
- name: GitHub Tags
  endpoint:
    path: https://github.com/Oculus-VR/UnrealEngine/tags
    method: GET
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: Pointer Event
  endpoint:
    path: /pointer/events
    method: GET
    data_selector: PointerEvent
- name: Hand Pose Data
  endpoint:
    path: /HandPoseData
    method: GET
    data_selector: HandPoseData
    params: {}
- name: Hand Grab Pose
  endpoint:
    path: /HandGrabPose
    method: GET
    data_selector: HandGrabPose
    params: {}
- name: Distance Grab Niagara System
  endpoint:
    path: /DistanceGrab/Settings
    method: GET
    data_selector: parameters
    params: {}
- name: Ray Grab Niagara System
  endpoint:
    path: /GrabInteraction/InterationSDK/Grabber/InterationSDK/RayGrabNiagaraSystem
    method: GET
    data_selector: parameters
    params: {}
- name: Widget Component
  endpoint:
    path: /sdk/widgets/component
    method: GET
    data_selector: properties
    params: {}
- name: Interactable
  endpoint:
    path: /sdk/widgets/interactable
    method: GET
    data_selector: properties
    params: {}
- name: Audio
  endpoint:
    path: /sdk/widgets/audio
    method: GET
    data_selector: audioComponents
    params: {}
- name: audio_analysis
  endpoint:
    path: /audio/analysis
    method: POST
    data_selector: results
- name: design_tools
  endpoint:
    path: /design/tools
    method: GET
    data_selector: tools
- name: body_tracking
  endpoint:
    path: /api/body_tracking
    method: GET
    data_selector: bodyPoses
    params: {}
- name: face_tracking
  endpoint:
    path: /api/face_tracking
    method: GET
    data_selector: facialExpressions
    params: {}
- name: eye_tracking
  endpoint:
    path: /api/eye_tracking
    method: GET
    data_selector: eyeGaze
    params: {}
- name: MyPawn
  endpoint:
    path: /create/pawn
    method: POST
    data_selector: pawn_data
- name: SuggestBodyTrackingCalibrationOverride
  endpoint:
    path: /SuggestBodyTrackingCalibrationOverride
    method: POST
    data_selector: response
    params: {}
- name: ResetBodyTrackingCalibration
  endpoint:
    path: /ResetBodyTrackingCalibration
    method: POST
    data_selector: response
    params: {}
- name: AC_BoneHide
  endpoint:
    path: Blueprints/AC_BoneHide
    method: GET
- name: AC_AndroidPermissions
  endpoint:
    path: Blueprints/AC_AndroidPermissions
    method: GET
- name: AC_DeformationLogic
  endpoint:
    path: Blueprints/Deformation/AC_DeformationLogic
    method: GET
- name: AC_DriveSkeletalUpdateLogic
  endpoint:
    path: Blueprints/AC_DriveSkeletalUpdateLogic
    method: GET
- name: AC_TwistDistribution
  endpoint:
    path: Blueprints/TwistDistribution/AC_TwistDistribution
    method: GET
- name: BP_AuraOculusPawn
  endpoint:
    path: Blueprints/Avatars/BP_AuraOculusPawn
    method: GET
- name: BP_AxisGizmo
  endpoint:
    path: Blueprints/Debug/BP_AxisGizmo
    method: GET
- name: BP_MovementSampleGameMode
  endpoint:
    path: Blueprints/BP_MovementSampleGameMode
    method: GET
- name: BP_OculusPawn
  endpoint:
    path: Blueprints/Avatars/BP_OculusPawn
    method: GET
- name: BP_Printer
  endpoint:
    path: Blueprints/Debug/BP_Printer
    method: GET
- name: BP_SceneHandler
  endpoint:
    path: Blueprints/BP_SceneHandler
    method: GET
- name: WBP_BodyTrackingSettings
  endpoint:
    path: Blueprints/Widgets/WBP_BodyTrackingSettings
    method: GET
- name: WBP_LevelSwitch
  endpoint:
    path: Blueprints/Widgets/WBP_LevelSwitch
    method: GET
- name: WBP_Recalibrate
  endpoint:
    path: Blueprints/Widgets/WBP_Recalibrate
    method: GET
- name: WBP_SkeletonDebugSettings
  endpoint:
    path: Blueprints/Widgets/WBP_SkeletonDebugSettings
    method: GET
- name: Body
  endpoint:
    path: /Body
    method: GET
    data_selector: data
- name: Face
  endpoint:
    path: /Face
    method: GET
    data_selector: data
- name: Eye
  endpoint:
    path: /Eye
    method: GET
    data_selector: data
- name: FaceTrackingSettings
  endpoint:
    path: /OculusXR/Movement/FaceTracking
    method: GET
- name: user_profile
  endpoint:
    path: /api/v1/user/profile
    method: GET
    data_selector: data
    params: {}
- name: age_category
  endpoint:
    path: /services/data/vXX.X/sobjects/AgeCategory
    method: GET
    data_selector: records
- name: quest_tools
  endpoint:
    path: /services/data/vXX.X/sobjects/QuestTools
    method: GET
    data_selector: records
- name: TtsMemoryCache
  endpoint:
    path: ''
    method: ''
    data_selector: ''
    params:
      Is Clip Capacity Enabled: ''
      Clip Capacity: ''
      Is Memory Capacity Enabled: ''
      Memory Capacity in Kilobytes: ''
- name: TtsStorageCache
  endpoint:
    path: ''
    method: ''
    data_selector: ''
    params:
      Cache Directory: ''
      Default Cache Location:
      - None
      - Content
      - Persistent
      - Temporary
- name: example_resource
  endpoint:
    path: /example/endpoint
    method: GET
    data_selector: data
    params: {}
- name: Reverb Submix
  endpoint:
    path: /horizon/documentation/unreal/meta-xr-audio-sdk-unreal-req-setup/
    method: GET
    data_selector: settings
    params: {}
- name: Acoustic Models
  endpoint:
    path: /horizon/documentation/unreal/meta-xr-acoustic-ray-tracing-unreal-overview/
    method: GET
    data_selector: models
    params: {}
- name: MetaXRAudioFMOD
  endpoint:
    path: /horizon/downloads/package/meta-xr-audio-sdk-fmod
    method: GET
    data_selector: plugin
- name: UnrealEngine
  endpoint:
    path: /horizon/downloads/package/meta-xr-audio-sdk-unreal
    method: GET
    data_selector: plugin
- name: MetaXRAudioReflections
  endpoint:
    path: /services/data/vXX.X/sobjects/MetaXRAudioReflections
    method: GET
    data_selector: records
    params: {}
- name: MetaXRAudioRoom
  endpoint:
    path: /services/data/vXX.X/sobjects/MetaXRAudioRoom
    method: GET
    data_selector: records
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: example_resource
  endpoint:
    path: /example/path
    method: GET
    data_selector: records
    params: {}
- name: acoustic_geometry
  endpoint:
    path: /acoustic_geometry
    method: POST
    data_selector: geometry_data
    params:
      include_child_meshes: true
- name: Meta XR Acoustic Map
  endpoint:
    path: /acoustic/map
    method: POST
    data_selector: map_data
    params: {}
- name: MetaXRAcousticMaterial
  endpoint:
    path: /Audio/MetaXR/MetaXRAcousticMaterial
    method: GET
    data_selector: properties
    params: {}
- name: MetaXRAcousticMaterialProperties
  endpoint:
    path: /Audio/MetaXR/MetaXRAcousticMaterialProperties
    method: GET
    data_selector: properties
    params: {}
- name: Meta XR Acoustic Control Zone
  endpoint:
    path: /horizon/documentation/unreal/meta-xr-acoustic-ray-tracing-unreal-control-zone
    method: GET
    data_selector: parameters
    params: {}
- name: Meta XR Acoustics Settings
  endpoint:
    path: /horizon/documentation/unreal/meta-xr-acoustic-ray-tracing-unreal-troubleshooting/
    method: GET
    data_selector: ''
    params: {}
- name: user_data
  endpoint:
    path: /api/v1/user
    method: GET
    data_selector: data
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: example_resource
  endpoint:
    path: /example/endpoint/path
    method: GET
    data_selector: records
    params: {}
- name: PTBackground
  endpoint:
    path: /PTBackground
    method: GET
    data_selector: assets
    params: {}
- name: PTLighting
  endpoint:
    path: /PTLighting
    method: GET
    data_selector: assets
    params: {}
- name: PTOpacity
  endpoint:
    path: /PTOpacity
    method: GET
    data_selector: assets
    params: {}
- name: PTStyles
  endpoint:
    path: /PTStyles
    method: GET
    data_selector: assets
    params: {}
- name: PTColorMap
  endpoint:
    path: /PTColorMap
    method: GET
    data_selector: assets
    params: {}
- name: PTColorLut
  endpoint:
    path: /PTColorLut
    method: GET
    data_selector: assets
    params: {}
- name: PTColorScaleAndOffset
  endpoint:
    path: /PTColorScaleAndOffset
    method: GET
    data_selector: assets
    params: {}
- name: PTLayer_Placement
  endpoint:
    path: /PTLayer_Placement
    method: GET
    data_selector: assets
    params: {}
- name: PTMaskedBrush
  endpoint:
    path: /PTMaskedBrush
    method: GET
    data_selector: assets
    params: {}
- name: PTMasking
  endpoint:
    path: /PTMasking
    method: GET
    data_selector: assets
    params: {}
- name: StartEnvironmentDepth
  endpoint:
    path: /horizon/documentation/unreal/unreal-depthapi-overview/
    method: GET
    data_selector: depth information
    params: {}
- name: SetXROcclusionsMode
  endpoint:
    path: /horizon/documentation/unreal/unreal-passthrough-overview/
    method: GET
    data_selector: occlusions
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: spatial_data_permission
  endpoint:
    path: /horizon/documentation/spatial-data-permission
    method: GET
    data_selector: permission_data
    params: {}
- name: Semantic Labels
  endpoint:
    path: /semantic/classification
    method: GET
    data_selector: labels
    params: {}
- name: Scene Mesh
  endpoint:
    path: /horizon/documentation/unity/unity-mr-utility-kit-overview
    method: GET
    data_selector: sceneMesh
    params: {}
- name: scene_actor_functionalities
  endpoint:
    path: /horizon/documentation/unity/unity-scene-migrate-mruk
    method: GET
    data_selector: records
- name: Clear Scene
  endpoint:
    path: /clear_scene
    method: POST
    data_selector: Output
    params: {}
- name: Set Visibility To All Scene Anchors
  endpoint:
    path: /set_visibility_to_all_scene_anchors
    method: POST
    data_selector: Output
    params: {}
- name: Set Visibility To Scene Anchors by Semantic Label
  endpoint:
    path: /set_visibility_to_scene_anchors_by_semantic_label
    method: POST
    data_selector: Output
    params: {}
- name: Get Actors by Semantic Label
  endpoint:
    path: /get_actors_by_semantic_label
    method: GET
    data_selector: Output
    params: {}
- name: Scene Actor
  endpoint:
    path: /getActorsBySemanticLabel
    method: GET
    data_selector: actorReferences
    params: {}
- name: spatial_anchor
  endpoint:
    path: /spatial/anchor
    method: POST
    data_selector: data
- name: Get Shared Anchors
  endpoint:
    path: /GetSharedAnchors
    method: GET
    data_selector: results
- name: advertise_session
  endpoint:
    path: /StartSessionAdvertisementAsync
    method: POST
    data_selector: Result
    params: {}
- name: stop_advertise_session
  endpoint:
    path: /StopSessionAdvertisementAsync
    method: POST
    data_selector: Result
    params: {}
- name: discover_sessions
  endpoint:
    path: /DiscoverSessionsAsync
    method: POST
    data_selector: sessions
    params: {}
- name: stop_discover_sessions
  endpoint:
    path: /StopDiscoverSessions
    method: POST
    data_selector: Result
    params: {}
- name: Shared Anchors Sample
  endpoint:
    path: https://github.com/oculus-samples/Unreal-SharedAnchorsSample
    method: GET
- name: Colocation Discovery Sample
  endpoint:
    path: https://github.com/oculus-samples/Unreal-ColocationDiscoverySample
    method: GET
- name: Unreal-SpatialAnchorsSample
  endpoint:
    path: https://github.com/oculus-samples/Unreal-SpatialAnchorsSample
    method: GET
- name: spatial_anchors
  endpoint:
    path: /horizon/spatial_anchors
    method: GET
    data_selector: data
    params: {}
- name: create_spatial_anchor
  endpoint:
    path: /create_spatial_anchor
    method: POST
    data_selector: Anchor
    params: {}
- name: save_anchors
  endpoint:
    path: /save_anchors
    method: POST
    data_selector: Anchors
    params: {}
- name: discover_anchors
  endpoint:
    path: /discover_anchors
    method: POST
    data_selector: Discovery Result
    params: {}
- name: erase_anchors
  endpoint:
    path: /erase_anchors
    method: POST
    data_selector: Anchors
    params: {}
- name: share_anchors
  endpoint:
    path: /share_anchors
    method: POST
    data_selector: Shared Anchors
    params: {}
- name: share_anchors_with_group
  endpoint:
    path: /share_anchors_with_group
    method: POST
    data_selector: Success
    params: {}
- name: get_shared_anchors
  endpoint:
    path: /get_shared_anchors
    method: POST
    data_selector: Shared Anchors
    params: {}
- name: get_shared_anchors_from_group
  endpoint:
    path: /get_shared_anchors_from_group
    method: POST
    data_selector: Success
    params: {}
- name: scene
  endpoint:
    path: /horizon/documentation/unreal/unreal-scene-overview/
    method: GET
    data_selector: scene_data
- name: audio
  endpoint:
    path: /horizon/documentation/unreal/meta-xr-audio-sdk-unreal/
    method: GET
    data_selector: audio_data
- name: platform_sdk
  endpoint:
    path: /horizon/documentation/unreal/ps-platform-intro/
    method: GET
    data_selector: platform_data
- name: movement_sdk
  endpoint:
    path: /horizon/documentation/unreal/unreal-movement-overview/
    method: GET
    data_selector: movement_data
- name: GameInstance
  endpoint:
    path: /horizon/documentation/unreal/gameinstance
    method: GET
    data_selector: records
- name: EntitlementCheck
  endpoint:
    path: /horizon/documentation/unreal/ps-entitlement-check
    method: GET
    data_selector: records
- name: microphone_properties
  endpoint:
    path: /microphone/properties
    method: GET
    data_selector: default_properties
    params: {}
- name: audio_rendering_properties
  endpoint:
    path: /audio/rendering/properties
    method: GET
    data_selector: default_rendering_properties
    params: {}
- name: group_presence
  endpoint:
    path: /horizon/ps-group-presence-overview
    method: GET
- name: GroupPresenceOptions
  endpoint:
    path: /horizon/reference/platform-unity/v81/class_oculus_platform_group_presence_options/
    method: GET
    data_selector: options
- name: Launch Invite Dialog
  endpoint:
    path: /ovr_GroupPresence_LaunchInvitePanel
    method: POST
    data_selector: ovrMessage_GroupPresence_LaunchInvitePanel
- name: Launch Roster Dialog
  endpoint:
    path: /ovr_GroupPresence_LaunchRosterPanel
    method: POST
    data_selector: ovrMessage_GroupPresence_LaunchRosterPanel
- name: Set Group Presence
  endpoint:
    path: /ovr_GroupPresence_Set
    method: POST
    data_selector: ovrMessage_GropPresence_Set
- name: Set Group Presence Destination
  endpoint:
    path: /ovr_GroupPresence_SetDestination
    method: POST
    data_selector: ovrMessage_GroupPresence_SetDestination
- name: Set Group Presence Is Joinable
  endpoint:
    path: /ovr_GroupPresence_SetIsJoinable
    method: POST
    data_selector: ovrMessage_GroupPresence_SetIsJoinable
- name: Set Group Presence Lobby Session
  endpoint:
    path: /ovr_GroupPresence_SetLobbySession
    method: POST
    data_selector: ovrMessage_GroupPresence_SetLobbySession
- name: Set Group Presence Match Session
  endpoint:
    path: /ovr_GroupPresence_SetMatchSession
    method: POST
    data_selector: ovrMessage_SetNatchSession
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
- name: destination
  endpoint:
    path: /<appid>/app_deeplink_public
    method: POST
    data_selector: url
    params: {}
- name: create_invite_link
  endpoint:
    path: /horizon/documentation/unreal/ps-destinations-implementation
    method: GET
- name: GetInvitableUsers
  endpoint:
    path: /GroupPresence/GetInvitableUsers
    method: GET
    data_selector: data
- name: SendInvites
  endpoint:
    path: /GroupPresence/SendInvites
    method: POST
    data_selector: invites
- name: GetSentInvites
  endpoint:
    path: /GroupPresence/GetSentInvites
    method: GET
    data_selector: data
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
- name: Launch Rejoin Dialog
  endpoint:
    path: /rejoin/dialog
    method: POST
    data_selector: response
    params:
      lobby_session_id: ''
      match_session_id: ''
- name: GroupPresence
  endpoint:
    path: /horizon/reference/platform/v81/o_v_r_requests_group_presence_8h/
    method: GET
    data_selector: GroupPresence
    params: {}
- name: ApplicationLifecycle
  endpoint:
    path: /horizon/reference/platform/v81/o_v_r_requests_application_lifecycle_8h/
    method: GET
    data_selector: ApplicationLifecycle
    params: {}
- name: User
  endpoint:
    path: /horizon/reference/platform/v81/o_v_r_requests_user_8h/
    method: GET
    data_selector: User
    params: {}
- name: multiplayer_testing
  endpoint:
    path: /horizon/documentation/unreal/multiplayer-testing
    method: GET
    data_selector: content
    params: {}
- name: platform_sdk
  endpoint:
    path: /horizon/documentation/unreal/platform-sdk
    method: GET
    data_selector: content
    params: {}
- name: group_presence
  endpoint:
    path: /horizon/manage
    method: GET
    data_selector: presence_data
    params: {}
- name: invite
  endpoint:
    path: /horizon/manage
    method: POST
    data_selector: invite_data
    params: {}
- name: create_user_notifications
  endpoint:
    path: /user_notifications/create
    method: POST
    data_selector: notification
    params: {}
- name: event_based_notifications
  endpoint:
    path: /user_notifications/event
    method: GET
    data_selector: notifications
    params: {}
- name: user_notifications
  endpoint:
    path: /horizon/manage/user_notifications
    method: GET
    data_selector: notifications
    params: {}
- name: user_notifications
  endpoint:
    path: /user_notifications
    method: GET
- name: notifications
  endpoint:
    path: /horizon/user_notifications
    method: POST
    data_selector: notification
    params: {}
- name: send_notification
  endpoint:
    path: /<NOTIFICATION_PUSH_TOKEN>/send_notification
    method: POST
    data_selector: success
notes:
- Explore the latest developments in AI, mixed reality and wearables from our Keynotes
  and Developer sessions.
- Uses OAuth2 with refresh token — requires setup of connected app in api
- Some objects may return nulls in deeply nested fields
- Developers must maintain responsibility for their community and foster a positive
  environment.
- Every developer must provide a Privacy Policy to Meta as part of the VRC Privacy
  Policy requirements.
- Apps may only request the minimum number of permissions required to function.
- Localization requires a bilingual file-oriented process.
- Ensure string IDs are static and do not change during the export process.
- Depth API supports dynamic occlusion, but has limited accuracy beyond four meters.
- Depth API does not support moving virtual content bouncing off of physical objects.
- Long periods of exposure to full passthrough may result in visual discomfort, motion
  sickness, disorientation, or negative after-effects.
- Users should be encouraged to take intermittent breaks. If they feel discomfort,
  they should not start again until they no longer feel discomfort.
- Scene health and safety considerations depend on the type of experience.
- Do not use scene mesh for reskinning or stylizing the environment.
- ASC is not a safety feature.
- Multiplayer experiences can have fully remote, local, or a mix of user types.
- The risk of contact increases with more users in the activity space.
- Avoid encouraging rapid or unexpected movements during local multiplayer as these
  behaviors increase risk of injury and property damage.
- Combining Scene API with the Depth API supports proper depth order between virtual
  content and the physical space. If not used, virtual content will block the user’s
  view of physical objects.
- Always turn on the boundary before transitioning from mixed reality or immersive
  experiences.
- When transitioning between mixed reality and fully immersive experiences, provide
  time for users to reorient and adapt to changes before introducing task demands.
- Consider the amount of virtual content included relative to the type of activity
  required of the user. For experiences with a high degree of movement, consider decreasing
  the amount and size of virtual content that could obscure the user’s view of their
  physical activity space.
- Avoid encouraging users to move outside of the boundary. Space outside the boundary
  may contain clutter or obstacles and because the user has a reduced field of view,
  these obstacles will be harder to detect.
- Dynamic elements (for example, pets and people) are not part of the scene and can
  be hidden from view by virtual content.
- The scene is not a safety feature. It does not provide safety warnings when users
  get close to physical objects.
- The head is fundamental to human anatomy and plays a crucial role in our ability
  to exist and interact with the world around us.
- Leverage the head's spatial position to strategically place interactables for optimal
  comfort and accessibility.
- Disable or modify orientation and position tracking, as it can cause discomfort
  and break immersion.
- Require interactions outside the user's boundary configuration or defined play area
  unless locomotion or indirect interactions have been introduced.
- Hand tracking technology utilizes the sensors and cameras on the Meta Quest headset.
- Various factors can influence accuracy, including hand location relative to cameras,
  lighting conditions, occlusions, and more.
- Uses hand tracking for interactions in VR.
- Controllers are handheld input devices that can be used to extend the input capabilities
  of hands.
- Controller tracking can deliver sub-millimeter precision.
- Keep functions aligned with common practices to make the controllers become intuitive.
- Ensure that interactions can be performed with either hand when two controllers
  are available.
- Avoid representing the 3DOF controller as a hand or hand-like object in-app.
- Utilizes voice as the primary input modality for interaction.
- 'Large Data Requirements: Training high-quality TTS models requires large amounts
  of data, which can be time-consuming and expensive to collect.'
- 'Training Complexity: Training TTS models can be complex and require significant
  expertise in areas like machine learning, signal processing, and linguistics.'
- Ensure Transparent Activation. Provide clear mic activation awareness through earcons
  or conversational cues to ensure users are aware of when their voice is being captured.
- Provide Clear Privacy Controls. Offer users the option to opt-in to voice experiences
  where their voice will be captured, respecting their privacy.
- Focus on the happy path with robust Error Handling and Repair paths.
- Understand the common user intents and utterances, and the blocks that commonly
  occur when users attempt to use the system.
- Establish consistent, systemic repair attempts that keep the context of the experience
  in mind. Conversation Design standards expect two attempts at repair and then a
  handoff to a live person or giving the user another solution.
- Make sure to triage the error - is it a soft error or a hard error? Soft are errors
  in the design logic or data, while hard errors are backend service failures.
- Provide users with visual or auditory cues when the system detects high levels of
  background noise, prompting them to move to a quieter location or adjust their microphone.
- Focus on the most important aspect of speech within the technical limitations.
- Provide accurate details such as names, dates, locations, and quantities for effective
  speech recognition interactions.
- Offer explanations and alternatives to mitigate errors and maintain user satisfaction.
- Use Part of Speech (POS) tagging to enable a more accurate interpretation.
- Have the system clearly announce the available menu options and allow users to select
  a specific option using voice commands.
- Provide shortcut options for frequently used actions.
- Provide alternative input methods during multimodal interactions.
- Ensure that the system is accessible and usable for all users, including those with
  disabilities.
- Consider the visual components and audio-only interactions.
- 'Use the POUR guiding principle of accessible design: Perceivable, Operable, Understandable,
  and Robust.'
- Use robust New User Experience to educate users.
- Prioritize user understanding and resolution in the design of the error handling
  system.
- Input handoff in Horizon OS is designed to provide a seamless transition between
  different input methods.
- Locomotion types include teleportation and slide.
- Physical locomotion can limit spatial creativity in design.
- Artificial locomotion can add dynamic elements like ladders, gaps, and ledges.
- Comfort and usability are crucial when designing a fully immersive locomotion system.
- A comfortable fully immersive experience minimizes sensory mismatches and aligns
  closely with physical world experiences.
- High-resolution displays are the primary visual output in the headset.
- Spatial audio delivers a 3D audio experience by adapting to the user's head movements.
- Controllers feature haptic feedback mechanisms that enhance user interaction.
- Current Meta Quest headsets cover the sRGB color space gamut.
- Meta Quest Pro offers expanded color capabilities by covering the Display P3 gamut.
- Lighting and effects enhance engagement and immersion in virtual environments.
- Audio plays a crucial role in crafting immersive, engaging, and accessible experiences.
- Effective sound design provides critical feedback to users on their interactions
  as well as their location, essential for spatial experiences.
- Designing the environment to take into account the limitations of acoustic simulation
  technology can help improve the overall audio experience.
- 'Meta offers two different acoustic simulation technologies: Shoebox Reverb (efficient
  but less accurate) and Acoustic Ray Tracing (ART) (computationally more intensive
  but more plausible results).'
- Overlapping sounds can make it difficult to separate the contents, which can be
  tiring to users.
- By understanding and applying these concepts, designers can create audio experiences
  that not only captivate users but also foster a deeper connection to the digital
  world, ensuring a more impactful and lasting engagement.
- Haptics play a crucial role in crafting immersive experiences.
- Haptics enhance accessibility and engagement for users who are visually or hearing
  impaired.
- Haptic design is often given low priority in project planning.
- Many digital products rely on haptics.
- Multi-select dropdowns are generally discouraged due to usability concerns.
- The virtual keyboard appears in the user’s field of view and they can interact with
  it using input methods like controllers and hands.
- 'It is recommended when users need to input text: for example, when filling out
  forms, sending messages, or searching for information.'
- The default panel size is 1024dp × 640dp.
- The minimum panel size is 384dp × 500dp.
- Tooltips should be used throughout the system to allow users to disambiguate and
  reveal information about UI elements, as needed.
- High-quality assets build a cohesive virtual space.
- Poorly designed assets risk reducing immersion and performance.
- To create immersive experiences on the Meta Quest and other supported device hardware,
  it’s crucial to balance art and performance.
- Most titles need late-stage optimization to meet final performance goals.
- The button’s size and hit target encourage accurate and successful interactions
  without being large enough to interfere with avatar embodiment or intersect with
  virtual clothing.
- The position of the wrist button does not shift, nor is adjustable.
- 'Duration: The app has no direct control on how long the system splash screen is
  shown.'
- 'Allows only static 2D images: There is no option to add animated elements like
  a rotating 3D asset or a progress bar in this phase.'
- Spatial audio is essential to deliver an immersive experience because it provides
  powerful cues that make the user feel they are actually in the 3D environment.
- Headphone audio will be the standard for immersive experiences into the future.
- Bluetooth technology is not recommended for audio output.
- Developers should evaluate their apps’ design and content to support a comfortable
  and safe experience for users.
- High-resolution displays are enhanced by resolution, refresh rate, field of view,
  and lens technology.
- Head tracking technology uses embedded sensors and cameras for positional tracking.
- Users can select different guardian setups such as Stationary and Roomscale.
- Interactables should be positioned at a comfortable height to prevent users from
  constantly looking down, thereby reducing neck strain and enhancing the overall
  experience.
- Ensuring a natural line of sight aligns with ergonomic principles promotes longer,
  more enjoyable sessions without discomfort.
- Various factors can influence the accuracy of the controllers, including environment
  variability.
- Avoid forcing users to relearn controls or repeatedly look at their controllers.
- Voice input enhances inclusivity, reduces cognitive load, and eases friction in
  user interfaces.
- Designing interactions that take into account the user's context can lead to more
  accurate and relevant responses.
- Continuously test and refine the system to ensure that it is effective and respectful.
- Supports a wide range of input modalities including spatial input sources like controllers
  and specialized devices.
- Passthrough allows users to have more awareness of the physical environment; however,
  it is not equivalent to natural human vision.
- Uses scene understanding capabilities to interact with physical environments
- Be careful of other users in local multiplayer.
- Uses factory calibration for consistent color depiction across Meta Quest headsets.
- Sound design and audio UX play a crucial role in creating immersive and engaging
  experiences in passthrough and fully immersive applications.
- By understanding and applying these concepts, designers can create audio experiences
  that not only captivate users but also foster a deeper connection to the digital
  world.
- Haptic design is often treated as an afterthought in project planning.
- Consider haptics as a core component of product design.
- Default panel size is 1024dp x 640dp.
- Minimum panel size is 384dp x 500dp.
- User’s avatars usually reflect the user’s position, movement, and gestures.
- Avatar movements should feel natural, plausible and comfortable.
- The wrist button size remains constant to provide proper affordance as an interactive
  surface.
- Keep artwork within 1500x1500px to avoid unwanted cropping at the margins.
- Lighting conditions in passthrough can vary drastically between users.
- Do not reduce artwork containing text to a size that generates aliasing artifacts
  or negatively affects readability.
- Explore a New Era of Mixed Reality with the Passthrough Camera API
- Exclusive access to a curated community of VR developers and development resources.
- Meta account is required to join the program
- Creation tools are not yet available on MacOS or Linux
- Ensure to follow the Human Interface Design Guidelines for best practices.
- Requires a verified Meta developer account to develop Meta Horizon OS apps.
- Epic Games and GitHub accounts must be linked.
- All supported Unreal Engine branches can create applications for all Meta Quest
  headset generations.
- It is not necessary to install the Meta XR plugin separately when installing Meta’s
  fork of UE 5.0+.
- Changes to support Oculus development in UE 4.27 are only available via the Oculus-VR
  fork of UE 4.27.
- The only way to install a version of Unreal Engine 4 with the plugin is by compiling
  from the Oculus-VR fork.
- Currently the Epic Native OpenXR backend is only available when using the Oculus
  VR Fork Unreal Version.
- We are in the process of migrating all features from OVRPlugin to the Epic Native
  OpenXR Plugin.
- Some objects like Contact may return nulls in deeply nested fields
- This guide assumes knowledge of how to model your custom mesh, bind it to a skeleton,
  and export it into Unreal.
- Pointer Event objects aren’t events but payloads that represent the result of an
  interaction.
- Requires setup of connected app in Meta APIs
- Hand Pose Data assets can currently only be authored in Unreal Editor via the HandPoseStudio
  level in the Samples.
- The default location for Hand Pose Data assets created is OculusInteractionSamples/HandPoses.
- Custom Distance Grab Visuals
- User properties passed into the Niagara system include User.GrabLocation, User.GrabVector,
  User.GrabTargetLocation, User.GrabTargetVector, User.GrabbableLocation, User.GrabbableVector,
  User.IsGrabbing, User.IsGrabTargetValid, User.PinchStrength, User.IsPinching.
- User parameters will be passed into the Niagara system each frame.
- Interaction SDK events are passed through to the UI at a low level.
- Uses Oculus XR Controller for motion tracking.
- Requires setup of custom Pawn Blueprint class.
- Touch Plus Controllers do not support localized haptics like the Meta Quest Touch
  Pro.
- Enabling support for hand tracking grants your app access to certain user data,
  such as the user’s estimated hand size and hand pose data. This data is only permitted
  to be used for enabling hand tracking within your app and is expressly forbidden
  for any other purpose.
- When using Link on PC, pose data for controllers is unavailable when you’re not
  actively using them (such as when they’re lying on a table).
- Requires setup of connected app in Meta
- Some endpoints may have specific requirements
- Expected values for amplitude and frequency are any value between zero and one,
  inclusive.
- Larger data will cause more CPU overhead which could further affect game performance.
- Eye tracking requires eye meshes rigged to bones.
- Face tracking on devices without inward-facing cameras relies on audio.
- Our tracking services offer three implementation options, each of which with unique
  advantages and disadvantages.
- The first is recommended as it meets most use cases.
- All the start tracking nodes are designed to be used together.
- The Unreal Project must be set up to support body, face, or eye Tracking with the
  Meta XR Plugin installed.
- The OculusXRMovement plugin must be installed and enabled.
- Some templates like the VR Template have rules indicating a dependency and may cause
  the Meta XR plugin to not work properly.
- Auto-calibration routines run within the first ten seconds of the service being
  created.
- If using manual calibration, height should have a 1-2 cm offset to allow for shoes.
- You can use AC_AndroidPermissions in your project to help you request permissions
  on the device.
- Live Link starts body tracking automatically.
- The joint set cannot be changed in runtime without restarting body tracking.
- Each app requires a matching Wit.ai app and a Wit Configuration file.
- Uses OAuth2 for authentication
- Requires user consent for data access.
- Rate limits apply to API calls.
- Use Wit.ai to manage your app versioning so you can work on the next version while
  still having a stable production version.
- Improve discoverability and usability for voice interactions in your app by building
  some in-app user education.
- Make sure your microphone is unmuted and selected as the input device in your computer
  settings.
- Ensure that voice is enabled in the project’s `DefaultEngine.ini` file.
- Audio is crucial for creating a persuasive VR or MR experience.
- It is important to pass only monophonic sounds to Meta spatializers.
- The Meta Spatializer is highly optimized and extremely efficient, but there is some
  overhead for spatializing sounds compared to traditional 3D panning methods.
- Uses OAuth2 with refresh token.
- 'The minimum Unreal Engine version that we support for this plugin is: Unreal Engine
  5.1.1'
- You should not install the plugin for both the engine and a project as this is not
  recommended by Epic Games.
- You may need to restart the editor for this change to take effect.
- It is important to recognize that the input of the binaural spatialization process
  is a mono stream and the output is a stereo stream.
- When using early reflections, be sure to set non-cubical room dimensions.
- Note that you can apply a single Sound Attenuation object to multiple Sound Cue’s
  if they all require the same settings.
- The Meta XR Audio reverb is a singleton. Only one reverb can be instantiated on
  one submix.
- Minimum SDK version for FMOD is 2.00.00
- Minimum Unreal Engine version is 5.1.1
- Uses Meta XR Audio Plugin for FMOD.
- The MetaXRAudio Reflections plugin is shared by all sources. This means the plugin
  is a singleton and only one instance of this plugin can exist in your FMOD project.
- This documentation will no longer be updated and will be managed on AudioKinetic's
  website instead.
- The documentation will no longer be updated and will be managed on AudioKinetic's
  website instead.
- You need the DLL when using the Wwise authoring app on Windows and on Mac because
  on Mac the Wwise authoring app runs in Wine.
- If you do not tag any geometry, you may end up hearing the Shoebox Room as a fallback.
- If you tag the geometry, but do not prebake an acoustic map, you may not get any
  reverb.
- Acoustic Map requires rebaking when scene geometries or materials are modified.
- Materials can be applied recursively to child meshes.
- Multiple acoustic materials can be assigned to the same mesh.
- This script can be used in conjunction with Material scripts to just provide some
  higher level fine tuning, or it can be used independently without any materials
  for a simplified tuning experience.
- The Meta XR Acoustics Settings parameters are tools that operate at a project level.
- Ensure that you have the correct permissions set for the OAuth token.
- Dynamic objects will have limited effect on sound rendering when using baked acoustics.
- Ensure that dynamic objects do NOT have the “static” button checked.
- The Meta XR Audio visualizers are useful for validating you work while setting up
  a project.
- World locking is enabled by default, but can be disabled by deselecting Enable World
  Lock in the project settings under Plugins > Mixed Reality Utility Kit.
- If you’re using the stock engine, the 'EnvironmentDepth' node will not be available.
  You need to use the Meta fork of Unreal Engine.
- Requires setup of connected app in api
- Avoid using a auto-loading engine splash screen. Use a combination of a system splash
  screen and custom startup levels instead.
- Set your System Splash Screen Background to Passthrough (Contextual).
- The lighting and color in this sample may cause seizures in people with epilepsy
  or sensitivity to light and color.
- Hiding the layer by setting the opacity to zero does not save any resources, neither
  computation nor memory.
- The feature is only available on Quest3/Quest3S devices.
- Depth API is only supported on Quest 3.
- Having Passthrough in your app is a requirement for receiving environment depth.
- Occlusions flicker near surfaces due to Z-fighting.
- Occlusions aren’t matching the real-world and lag behind during fast motion.
- Enable Scene Support in Project Settings.
- Request Runtime permissions for Scene using com.oculus.permission.USE_SCENE.
- To build realistic MR apps, use both Scene API and Depth API to cover a broad set
  of use cases.
- If space setup is not initiated, the Depth API cannot take advantage of the scene
  model when computing the depth maps.
- Starting from v62, Space Setup allows the user to scan and maintain multiple rooms
  (spaces) instead of a single room.
- Existing applications will not have multiple rooms returned, starting from v65,
  new SDK versions will support multiple rooms being returned by default.
- An app that wants to use Scene Model or Depth data needs to request spatial data
  permission during the app’s runtime.
- It is recommended to request the permission only when using the functionality.
- While building mixed reality experiences, we highly recommend evaluating your content
  to offer your users a comfortable and safe experience.
- As a general rule, we recommend deferring loading scene models until it is necessary.
- The best practice is to suggest users to capture a new scene if they are present
  outside of the current one.
- It is possible for surfaces such as walls, tables, and generally any scene element
  to drift a few centimeters during and across app and device sessions.
- If your experience displays interactive elements on a surface, such as a wall or
  tabletop, it is important for these elements to remain interactive, even if the
  surface has drifted a few centimeters below the physical table or wall surface.
- If your application requires a watertight room layout, you can generate one from
  the scene elements.
- OculusXRSceneActor is deprecated. Use MR Utility Kit for new development.
- Request the USE_SCENE permission inside your application.
- Developers should avoid improper occlusion, which occurs when virtual content does
  not respect the physicality of the user’s environment.
- Co-location increases the number of individuals in a shared physical space with
  restricted visibility of their surroundings.
- Supports creating, saving, discovering, erasing, destroying, and sharing spatial
  anchors.
- An array of Anchor UUIDs to retrieve is passed into the Get Shared Anchors function.
- On success the list of UUIDs is iterated over in a For Each loop.
- Shared Spatial Anchors are forward compatible, but they are not always backward
  compatible.
- The device setting ‘Enhanced Spatial Services’ must be enabled.
- Colocation Sessions Enabled must be true in the Meta XR Plugin settings.
- The sample provides example code for handling and maintaining spatial anchors, which
  you may reuse in your own projects.
- Create or reuse a spatial anchor within three meters of the object to ensure accuracy.
- Anchors cannot be moved. If the content must be moved, delete the old anchor and
  create a new one.
- The device setting Enhanced Spatial Services must be enabled for Shared Spatial
  Anchors to function.
- Users can find it under Settings > Privacy > Device Permissions > Enhanced Spatial
  Services.
- Ensure to follow the setup guidelines for authentication.
- The result code for Discover Anchors isn’t visible in the blueprint and thus you
  cannot respond to errors from within your Blueprint Graph.
- Integrating the Passthrough API is the first step in combining virtual and augmented
  reality experiences.
- Data Use Checkup is a requirement whereby an admin from your team must certify that
  your API access to platform features complies with Developer Policies.
- Apps for children can’t use platform features.
- All developers, including mobile developers, need to install the Oculus Quest runtime
  from the setup guide.
- Uses OAuth2 with refresh token — requires setup of connected app in Meta
- Meta Horizon OS platform features are integrated directly into the Unreal Editor.
- Ensure you have properly set up your app signing settings.
- Meta Horizon OS has the ability to mute the microphone in your app.
- Meta Horizon OS has the ability to convert sample rates.
- Multiplayer features are currently supported only in immersive apps and are not
  available in non-immersive environments, such as 2D panel apps or standard Android
  apps.
- Creating destinations for your app requires having an app created and uploaded to
  the Developer Dashboard.
- All titles, descriptions, and images must fall within the Meta Quest community standard
  guidelines.
- Requires setup of connected app in Meta platform
- A user must have group presence enabled and IsJoinable set to True for features
  like App Invites to work.
- If DestinationApiName is not set, travel to the user will not work.
- If lobbysessionid is not set, travel to the user will not work.
- If isJoinable is not set to true, travel to the user will not work.
- Invite to App does not provide VoIP or networking solutions.
- Ensure your app is immersive and can operate in VR/MR mode; otherwise, the destination
  setting will not function with your app.
- Your app must be immersive, meaning it must operate in VR/MR mode.
- Currently, the Invite to App feature does not support non-immersive environments.
- You must have at least one destination created for your app.
- You must have enabled group presence for users within your app.
- Users cannot see invites from, or send invites to, users they have blocked.
- Child users under 13 cannot access this Platform SDK feature.
- Some apps may be using the legacy Rooms system, which is why the room_id is included.
  Rooms is scheduled to be deprecated in March 2023.
- Display an error message if all users have left the session.
- The application is launched with a deeplink containing group presence information.
- Users can share copresence in different configurations using group presence lobbies
  and matches.
- This documentation details early functionality that is still under active development.
- Single process testing is generally less resource intensive.
- Multiple process testing is generally more accurate than single process testing
  but is far more resource-intensive.
- As of the v66 release, the inactive player’s head pose is not updated when the HMD
  moves.
- There may be noticeable performance penalties from running multiple PIE windows.
- You can send an invitation only to a test user. The sender should be online and
  located at a valid destination.
- Requires user authentication to send notifications.
- Follower notifications are limited to a maximum of 1 notification sent per day from
  your organization.
- Notifications may be subject to rate limits.
- Event-based notifications for mobile are primarily sent to the Meta Horizon mobile
  app.
- Event-based notifications for headset are sent to a user’s Meta Horizon headset.
errors:
- 'REQUEST_LIMIT_EXCEEDED: Throttle API calls or reduce frequency'
- 'QUERY_TIMEOUT: Break down filters or add selectivity'
- '401 Unauthorized: Recheck OAuth scopes or token expiration'
- 'Tracking volume exceeded: Ensure hands are within the camera''s tracking volume.'
- High intensity lighting or direct sunlight may cause degradation in tracking quality.
- Activate the microphone without user consent or by default. Default microphone activation
  can lead to unintended audio capture, compromising user privacy.
- Underestimate the special needs of Voice experiences concerning Cognitive Load.
  Two to three choices are ideal, and be sure to design so that the user has a mental
  model with a clear path to understand where they are in the design.
- Be ambiguous when designing using NLP models as the system may struggle if the information
  is not clear.
- Overwhelm users with information but instead use breadcrumbing techniques for clear
  and consistent navigation.
- Limit the control the user has over their biometric data and how it’s used.
- Obscure or limit information on how the users audio data is being used and protected.
- 'Invalid asset format: Ensure the file format is supported.'
- 'Performance issues: Limit texture resolution for best performance.'
- Don’t position interactive content close to wrist button location.
- Don’t place critical status updates or signals in close proximity of the wrist buttons.
- Manage cognitive load by limiting the amount of information users need to carry
  in their heads.
- Virtual content can appear to spawn outside the designated activity space, outside
  a user’s physical space, and intersect with physical objects.
- '400 Bad Request: Check the request parameters.'
- '401 Unauthorized: Ensure the token is valid.'
- '401 Unauthorized: Meta account in good standing is required'
- '403 Forbidden: Check eligibility criteria for joining the program'
- 'INVALID_REQUEST: Check the API request parameters.'
- 'UNAUTHORIZED: Verify your authentication token.'
- '403 Forbidden: User not authorized to access this resource.'
- '404 Not Found: The requested resource does not exist.'
- '401 Unauthorized: Check your credentials.'
- 'InvalidMaterial: Check if the material is assigned correctly.'
- 'MaterialNotFound: Ensure the material exists in the project.'
- 'INVALID_TOKEN: Check if the token is valid and not expired.'
- 'ACCESS_DENIED: Ensure the app has the necessary permissions.'
- 'The M_Highlights material does not work: This is probably because you’re using
  it with the stock Unreal Engine and the node ScreenPosition is not connected to
  anything.'
- Z-fighting may occur when two virtual objects are rendered at the same depth.
- Avoid using the mesh for visual effects.
- Avoid content placement on objects or furniture.
- Avoid climbing and jumping on furniture.
- Avoid relying on normal accuracy.
- Avoid slow collisions and resting contacts.
- Things can get stuck.
- 'Failure_SpaceCloudStorageDisabled: Inform users to turn on Enhanced Spatial Services'
- 'EOculusXRAnchorResult::Failure_SpaceCloudStorageDisabled: Cloud storage disabled.'
- 'EOculusXRAnchorResult::Failure_SpaceMappingInsufficient: Mapping insufficient.'
- 'EOculusXRAnchorResult::Failure_SpaceNetworkRequestFailed: Network request failed.'
- 'EOculusXRAnchorResult::Failure_SpaceNetworkTimeout: Network timeout.'
- '401 Unauthorized: Check your authentication credentials.'
- '404 Not Found: Verify the endpoint URL.'
- '500 Internal Server Error: Try again later.'
- '400: Bad Request'
- '401: Unauthorized Request'
- '403: Forbidden Request'
- '404: Not Found'
- '500: Internal Server Error'
- The session is full
- The network failed to establish a connection and timed out
- The destination is unavailable for the current user
- The destination is in DLC that the user does not have
- Tutorial has not been completed yet
- The session is not available for the current user
- The session cannot be found or is no longer available
- The match already started
- The user’s level is not high enough
- The level is not unlocked yet
- The app needs to be updated first
- The user has a child account
- Currently the head pose is shared between all users when using multiple PIE windows
  to test multiplayer.
- '400 Bad Request: Check notification payload structure.'
- '404 Not Found: Ensure the endpoint is correct.'
- '401 Unauthorized: Verify user permissions.'
auth_info:
  mentioned_objects:
  - OauthToken
  - AuthProvider
  - NamedCredential
client:
  base_url: https://developers.meta.com/horizon
  auth:
    type: oauth2
source_metadata: null
