resources:
- name: topic
  endpoint:
    path: /v1/topics
    method: GET
    data_selector: data
- name: schema
  endpoint:
    path: /v1/schemas
    method: GET
    data_selector: data
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: audit_logs
  endpoint:
    path: /audit-logs
    method: GET
    data_selector: logs
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: clusters
  endpoint:
    path: /cmk/v2/clusters
    method: POST
    data_selector: spec
    params: {}
- name: topics
  endpoint:
    path: /kafka/v3/clusters/{cluster_id}/topics
    method: POST
    data_selector: topic_name
    params: {}
- name: connectors
  endpoint:
    path: /connect/v1/environments/{environment_id}/clusters/{cluster_id}/connectors
    method: POST
    data_selector: name
    params: {}
- name: DatagenSourceConnector_users
  endpoint:
    path: /connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors/{connector_name}
    method: DELETE
- name: users
  endpoint:
    path: /kafka/v3/clusters/{kafka_cluster_id}/topics/{topic_name}
    method: DELETE
- name: users_mask
  endpoint:
    path: /kafka/v3/clusters/{kafka_cluster_id}/topics/{topic_name}
    method: DELETE
- name: topics
  endpoint:
    path: /api/v1/topics
    method: GET
    data_selector: data
    params: {}
- name: topics
  endpoint:
    path: /topics
    method: GET
    data_selector: records
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: topics
  endpoint:
    path: /kafka/v3/clusters/<cluster-id>/topics
    method: GET
    data_selector: data
- name: create_topic
  endpoint:
    path: /kafka/v3/clusters/<cluster-id>/topics
    method: POST
    data_selector: kind
    params: {}
- name: topic_config
  endpoint:
    path: /kafka/v3/clusters/<cluster-id>/topics/<topic-name>/configs
    method: GET
    data_selector: data
    params: {}
- name: update_topic_config
  endpoint:
    path: /kafka/v3/clusters/<cluster-id>/topics/<topic-name>/configs/<property-name>
    method: PUT
    data_selector: ''
    params: {}
- name: batch_update_topic_configs
  endpoint:
    path: /kafka/v3/clusters/<cluster-id>/topics/<topic-name>/configs:alter
    method: POST
    data_selector: ''
    params: {}
- name: delete_topic
  endpoint:
    path: /kafka/v3/clusters/<cluster-id>/topics/<topic-name>
    method: DELETE
    data_selector: ''
    params: {}
- name: kafka_cluster
  endpoint:
    path: /clusters
    method: GET
    data_selector: clusters
    params:
      incremental: updated_at
- name: topic
  endpoint:
    path: /topics
    method: GET
    data_selector: topics
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: topics
  endpoint:
    path: /v1/topics
    method: GET
    data_selector: data
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: stream
  endpoint:
    path: /api/v1/streams
    method: GET
    data_selector: records
    params: {}
- name: topics
  endpoint:
    path: /v1/topics
    method: GET
    data_selector: data
    params: {}
- name: schemas
  endpoint:
    path: /v1/schemas
    method: GET
    data_selector: data
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: topics
  endpoint:
    path: /v1/topics
    method: GET
    data_selector: data
    params: {}
- name: topic
  endpoint:
    path: /api/v1/topics
    method: GET
    data_selector: data
    params:
      incremental: updated_at
- name: consumer_group
  endpoint:
    path: /api/v1/consumer-groups
    method: GET
    data_selector: data
    params: {}
- name: topics
  endpoint:
    path: /v1/topics
    method: GET
    data_selector: data
    params: {}
- name: schemas
  endpoint:
    path: /v1/schemas
    method: GET
    data_selector: data
    params: {}
- name: example_resource
  endpoint:
    path: /api/v1/resource
    method: GET
    data_selector: data
    params: {}
- name: audit_logs
  endpoint:
    path: /v1/audit-logs
    method: GET
    data_selector: records
- name: eventlogs
  endpoint:
    path: /eventlogs
    method: POST
    data_selector: queries
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: kafka_clusters
  endpoint:
    path: /v1/clusters
    method: GET
    data_selector: clusters
- name: topics
  endpoint:
    path: /v1/topics
    method: GET
    data_selector: topics
- name: create_cluster
  endpoint:
    path: /cmk/v2/clusters
    method: POST
    data_selector: spec
- name: cluster
  endpoint:
    path: /abc-f3a90de
    method: GET
    data_selector: metadata
    params: {}
- name: clusters
  endpoint:
    path: /cmk/v2/clusters
    method: GET
    data_selector: data
    params:
      environment: required
      page_size: optional
- name: cluster_details
  endpoint:
    path: /cmk/v2/clusters/{id}
    method: GET
    data_selector: data
    params:
      id: required
      environment: required
- name: clusters
  endpoint:
    path: /cmk/v2/clusters/{id}
    method: PATCH
    data_selector: spec
    params:
      id: Required
- name: kafka_topics
  endpoint:
    path: /v1/topics
    method: GET
    data_selector: data
    params: {}
- name: kafka_clusters
  endpoint:
    path: /v1/clusters
    method: GET
    data_selector: data
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: create_cluster
  endpoint:
    path: /cmk/v2/clusters
    method: POST
    data_selector: spec
- name: kafka_cluster
  endpoint:
    path: /v2/kafka-clusters/abc-f3a90de
    method: GET
    data_selector: metadata
    params: {}
- name: clusters
  endpoint:
    path: /cmk/v2/clusters
    method: GET
    data_selector: data
    params:
      environment: environment_id
      page_size: '10'
- name: cluster_details
  endpoint:
    path: /cmk/v2/clusters/{id}
    method: GET
    data_selector: data
    params:
      environment: environment_id
- name: clusters
  endpoint:
    path: /cmk/v2/clusters/{id}
    method: PATCH
    data_selector: spec
    params: {}
- name: cluster_types
  endpoint:
    path: /clusters/types
    method: GET
    data_selector: cluster_limits
    params: {}
- name: topic
  endpoint:
    path: /topics
    method: GET
    data_selector: data
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: cluster_settings
  endpoint:
    path: /kafka/v3/clusters/<cluster-id>/broker-configs
    method: PUT
    data_selector: value
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: cluster_link
  endpoint:
    path: /kafka/link
    method: POST
    data_selector: link
    params: {}
- name: mirror_topic
  endpoint:
    path: /kafka/mirror
    method: POST
    data_selector: mirror
    params: {}
- name: topics
  endpoint:
    path: /api/v1/topics
    method: GET
    data_selector: records
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: topics
  endpoint:
    path: /v1/topics
    method: GET
    data_selector: data
- name: clusters
  endpoint:
    path: /v1/clusters
    method: GET
    data_selector: data
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: audit_log
  endpoint:
    path: /audit-logs
    method: GET
    data_selector: records
- name: source_cluster
  endpoint:
    path: /kafka/cluster
    method: CREATE
    data_selector: cluster_id
    params:
      type: basic
      cloud: aws
      region: us-west-2
- name: destination_cluster
  endpoint:
    path: /kafka/cluster
    method: CREATE
    data_selector: cluster_id
    params:
      type: dedicated
      cloud: aws
      region: us-east-1
      cku: 1
      availability: single-zone
- name: create_cluster_link
  endpoint:
    path: /kafka/link
    method: CREATE
    data_selector: link_name
    params:
      source_cluster: $source_id
      destination_cluster: $destination_id
      source_bootstrap_server: $source_endpoint
      source_api_key: $source_api_key
      source_api_secret: $source_api_secret
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: cluster_link
  endpoint:
    path: /kafka/v3/links
    method: POST
    data_selector: link
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: cluster
  endpoint:
    path: /kafka/cluster
    method: GET
    data_selector: clusters
- name: topic
  endpoint:
    path: /kafka/topic
    method: GET
    data_selector: topics
- name: cluster_links
  endpoint:
    path: /links
    method: GET
    data_selector: links
    params: {}
- name: mirror_topics
  endpoint:
    path: /mirrors
    method: GET
    data_selector: mirrors
    params: {}
- name: cluster_link
  endpoint:
    path: /kafka/link
    method: POST
    data_selector: link
    params: {}
- name: cloud-topic
  endpoint:
    path: /services/data/vXX.X/sobjects/cloud-topic
    method: GET
    data_selector: records
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: kafka_cluster
  endpoint:
    path: /clusters
    method: GET
    data_selector: clusters
- name: topic
  endpoint:
    path: /topics
    method: GET
    data_selector: topics
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: mirror_topic
  endpoint:
    path: /api/mirror_topic
    method: POST
    data_selector: data
    params: {}
- name: consumer_offset_sync
  endpoint:
    path: /api/consumer_offset_sync
    method: POST
    data_selector: data
    params:
      sync_interval: 30 seconds
- name: topic
  endpoint:
    path: /topics
    method: GET
    data_selector: records
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: audit_logs
  endpoint:
    path: /v1/audit-logs
    method: GET
    data_selector: records
    params:
      incremental: timestamp
- name: audit_logs
  endpoint:
    path: /audit-log
    method: GET
    data_selector: logs
- name: event
  endpoint:
    path: /audit-logs
    method: GET
    data_selector: events
- name: audit_logs
  endpoint:
    path: /audit-logs
    method: GET
- name: cluster
  endpoint:
    path: /api/clusters
    method: GET
    data_selector: clusters
    params: {}
- name: topic
  endpoint:
    path: /api/topics
    method: GET
    data_selector: topics
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: cluster_link
  endpoint:
    path: /api/v3/cluster-links
    method: POST
    data_selector: cluster_links
    params:
      acl.sync.enable: false
      acl.sync.ms: 5000
      consumer.offset.sync.enable: false
      consumer.offset.sync.ms: 30000
      link.mode: destination
      mirror.start.offset.spec: earliest
      topic.config.sync.ms: 5000
- name: cluster_link
  endpoint:
    path: /v1/cluster-links
    method: POST
    data_selector: data
    params: {}
- name: cluster_link
  endpoint:
    path: /kafka/v3/clusters/<cluster-ID>/links
    method: POST
    data_selector: link
    params: {}
- name: topics
  endpoint:
    path: /v1/topics
    method: GET
    data_selector: data
    params: {}
- name: schemas
  endpoint:
    path: /v1/schemas
    method: GET
    data_selector: data
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: cluster_link
  endpoint:
    path: /cluster/link
    method: POST
    data_selector: link
    params: {}
- name: cluster_links
  endpoint:
    path: /kafka/v3/clusters/<cluster-ID>/links
    method: GET
    data_selector: links
- name: consumer_group
  endpoint:
    path: /kafka/v3/clusters/<cluster-ID>/links/<link-name>/configs
    method: GET
    data_selector: configs
- name: topics
  endpoint:
    path: /v1/topics
    method: GET
    data_selector: data
    params: {}
- name: mirror_topic
  endpoint:
    path: /kafka/v3/clusters/{cluster_id}/links/{link_name}/mirrors
    method: POST
    data_selector: source_topic_name
    params: {}
- name: auto_create_mirror_topics
  endpoint:
    path: /api/v1/mirror-topics/auto-create
    method: POST
    data_selector: results
    params:
      enable: 'true'
      filters: '{"topicFilters":[{"name":"*","patternType":"LITERAL","filterType":"INCLUDE"}]}'
- name: delete_mirror_topic
  endpoint:
    path: /api/v1/mirror-topics/delete
    method: DELETE
    data_selector: results
    params: {}
- name: topics
  endpoint:
    path: /api/v1/topics
    method: GET
    data_selector: records
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: network_link_service
  endpoint:
    path: /networking/v1/network-link-services
    method: POST
    data_selector: spec
    params: {}
- name: network_link_endpoint
  endpoint:
    path: /networking/v1/network-link-endpoints
    method: POST
    data_selector: spec
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: oauth_configuration
  endpoint:
    path: /oauth/link
    method: POST
    data_selector: link
- name: cluster_link_configuration
  endpoint:
    path: /cluster-link-config
    method: POST
    data_selector: configs
    params: {}
- name: cluster_link_count
  endpoint:
    path: /metrics/io.confluent.kafka.server/cluster_link_count
    method: GET
    data_selector: metrics
    params: {}
- name: cluster_link_mirror_topic_count
  endpoint:
    path: /metrics/io.confluent.kafka.server/cluster_link_mirror_topic_count
    method: GET
    data_selector: metrics
    params: {}
- name: cluster_link_task_count
  endpoint:
    path: /metrics/io.confluent.kafka.server/cluster_link_task_count
    method: GET
    data_selector: metrics
    params: {}
- name: cluster_link_mirror_transition_in_error
  endpoint:
    path: /metrics/io.confluent.kafka.server/cluster_link_mirror_transition_in_error
    method: GET
    data_selector: metrics
    params: {}
- name: cluster_link_source_response_bytes
  endpoint:
    path: /metrics/io.confluent.kafka.server/cluster_link_source_response_bytes
    method: GET
    data_selector: metrics
    params: {}
- name: cluster_link_destination_response_bytes
  endpoint:
    path: /metrics/io.confluent.kafka.server/cluster_link_destination_response_bytes
    method: GET
    data_selector: metrics
    params: {}
- name: cluster_link_mirror_topic_bytes
  endpoint:
    path: /metrics/io.confluent.kafka.server/cluster_link_mirror_topic_bytes
    method: GET
    data_selector: metrics
    params: {}
- name: cluster_link_mirror_topic_offset_lag
  endpoint:
    path: /metrics/io.confluent.kafka.server/cluster_link_mirror_topic_offset_lag
    method: GET
    data_selector: metrics
    params: {}
- name: cluster_active_link_count
  endpoint:
    path: /metrics/io.confluent.kafka.server/cluster_active_link_count
    method: GET
    data_selector: aggregations
    params:
      intervals: now-24h/now
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: mirror_topic
  endpoint:
    path: /metrics/mirror_topic
    method: GET
    data_selector: metrics
    params: {}
- name: kafka_cluster
  endpoint:
    path: /kafka/v3/clusters
    method: GET
    data_selector: clusters
    params: {}
- name: topics
  endpoint:
    path: /kafka/v3/clusters/{cluster_id}/topics
    method: GET
    data_selector: topics
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: Schemas
  endpoint:
    path: /schemas
    method: GET
    data_selector: records
- name: service_quota
  endpoint:
    path: /v1/service_quotas
    method: GET
    data_selector: quotas
    params: {}
- name: consumer
  endpoint:
    path: ./diyrepl/consumer.properties
    method: GET
    data_selector: properties
    params: {}
- name: producer
  endpoint:
    path: ./diyrepl/producer.properties
    method: GET
    data_selector: properties
    params: {}
- name: replication
  endpoint:
    path: ./diyrepl/replication.properties
    method: GET
    data_selector: properties
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: consumer
  endpoint:
    path: ./diyrepl/consumer.properties
    method: GET
    data_selector: properties
    params: {}
- name: producer
  endpoint:
    path: ./diyrepl/producer.properties
    method: GET
    data_selector: properties
    params: {}
- name: replication
  endpoint:
    path: ./diyrepl/replication.properties
    method: GET
    data_selector: properties
    params: {}
- name: schemas
  endpoint:
    path: /schemas
    method: GET
    data_selector: records
- name: topics
  endpoint:
    path: /topics
    method: GET
    data_selector: records
- name: example_resource
  endpoint:
    path: /services/data/vXX.X/sobjects/ExampleResource
    method: GET
    data_selector: records
    params: {}
- name: topics
  endpoint:
    path: /api/v2/topics
    method: GET
    data_selector: records
- name: resize_cluster
  endpoint:
    path: /cmk/v2/clusters/lkc-00000?environment=env-test1
    method: PATCH
    data_selector: spec
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: client_quota
  endpoint:
    path: /kafka/quota
    method: POST
    data_selector: data
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: confluent_environment
  endpoint:
    path: /confluent_environment
    method: POST
    data_selector: id
    params:
      display_name: Development
- name: confluent_kafka_cluster
  endpoint:
    path: /confluent_kafka_cluster
    method: POST
    data_selector: id
    params:
      display_name: basic_kafka_cluster
      availability: SINGLE_ZONE
      cloud: AWS
      region: us-east-2
- name: confluent_service_account
  endpoint:
    path: /confluent_service_account
    method: POST
    data_selector: id
    params:
      display_name: app-manager
      description: Service account to manage Kafka cluster
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
- name: environment
  endpoint:
    path: /confluent_environment
    method: POST
    data_selector: id
    params:
      display_name: Development
- name: kafka_cluster
  endpoint:
    path: /confluent_kafka_cluster
    method: POST
    data_selector: id
    params:
      display_name: basic_kafka_cluster
      availability: SINGLE_ZONE
      cloud: AWS
      region: us-east-2
- name: service_account
  endpoint:
    path: /confluent_service_account
    method: POST
    data_selector: id
    params:
      display_name: app-manager
      description: Service account to manage Kafka cluster
- name: Confluent Invitation
  endpoint:
    path: https://registry.terraform.io/providers/confluentinc/confluent/latest/docs/resources/confluent_invitation
    method: GET
- name: Confluent Provider Integration
  endpoint:
    path: https://registry.terraform.io/providers/confluentinc/confluent/latest/docs/resources/confluent_provider_integration
    method: GET
- name: Connect Artifact
  endpoint:
    path: https://registry.terraform.io/providers/confluentinc/confluent/latest/docs/resources/confluent_connect_artifact
    method: GET
- name: Connector
  endpoint:
    path: https://registry.terraform.io/providers/confluentinc/confluent/latest/docs/resources/confluent_connector
    method: GET
- name: Connector Plugin
  endpoint:
    path: https://registry.terraform.io/providers/confluentinc/confluent/latest/docs/resources/confluent_plugin
    method: GET
- name: Flink Artifact
  endpoint:
    path: https://registry.terraform.io/providers/confluentinc/confluent/latest/docs/resources/confluent_flink_artifact
    method: GET
- name: Flink Compute Pool
  endpoint:
    path: https://registry.terraform.io/providers/confluentinc/confluent/latest/docs/resources/confluent_flink_compute_pool
    method: GET
- name: Flink Connection
  endpoint:
    path: https://registry.terraform.io/providers/confluentinc/confluent/latest/docs/resources/confluent_flink_connection
    method: GET
- name: Cluster Link
  endpoint:
    path: https://registry.terraform.io/providers/confluentinc/confluent/latest/docs/resources/confluent_cluster_link
    method: GET
- name: Kafka Client Quota
  endpoint:
    path: https://registry.terraform.io/providers/confluentinc/confluent/latest/docs/resources/confluent_kafka_client_quota
    method: GET
- name: Kafka Cluster
  endpoint:
    path: https://registry.terraform.io/providers/confluentinc/confluent/latest/docs/resources/confluent_kafka_cluster
    method: GET
- name: Kafka Topic
  endpoint:
    path: https://registry.terraform.io/providers/confluentinc/confluent/latest/docs/resources/confluent_kafka_topic
    method: GET
- name: ksqlDB Cluster
  endpoint:
    path: https://registry.terraform.io/providers/confluentinc/confluent/latest/docs/resources/confluent_ksql_cluster
    method: GET
- name: Business Metadata
  endpoint:
    path: https://registry.terraform.io/providers/confluentinc/confluent/latest/docs/resources/confluent_business_metadata
    method: GET
- name: Tag
  endpoint:
    path: https://registry.terraform.io/providers/confluentinc/confluent/latest/docs/resources/confluent_tag
    method: GET
- name: Access Point
  endpoint:
    path: https://registry.terraform.io/providers/confluentinc/confluent/latest/docs/resources/confluent_access_point?session_ref=direct&url_ref=https%3A%2F%2Fdocs.confluent.io%2Fcloud%2Fcurrent%2Fclusters%2Fterraform-provider.html
    method: GET
- name: Certificate Authority
  endpoint:
    path: https://registry.terraform.io/providers/confluentinc/confluent/latest/docs/resources/confluent_certificate_authority?session_ref=direct&url_ref=https%3A%2F%2Fdocs.confluent.io%2Fcloud%2Fcurrent%2Fclusters%2Fterraform-provider.html
    method: GET
- name: Certificate Pool
  endpoint:
    path: https://registry.terraform.io/providers/confluentinc/confluent/latest/docs/resources/confluent_certificate_pool?session_ref=direct&url_ref=https%3A%2F%2Fdocs.confluent.io%2Fcloud%2Fcurrent%2Fclusters%2Fterraform-provider.html
    method: GET
- name: DNS Record
  endpoint:
    path: https://registry.terraform.io/providers/confluentinc/confluent/latest/docs/resources/confluent_dns_record?session_ref=direct&url_ref=https%3A%2F%2Fdocs.confluent.io%2Fcloud%2Fcurrent%2Fclusters%2Fterraform-provider.html
    method: GET
- name: DNS Forwarder
  endpoint:
    path: https://registry.terraform.io/providers/confluentinc/confluent/latest/docs/resources/confluent_dns_forwarder?session_ref=direct&url_ref=https%3A%2F%2Fdocs.confluent.io%2Fcloud%2Fcurrent%2Fclusters%2Fterraform-provider.html
    method: GET
- name: Gateway
  endpoint:
    path: https://registry.terraform.io/providers/confluentinc/confluent/latest/docs/resources/confluent_gateway?session_ref=direct&url_ref=https%3A%2F%2Fdocs.confluent.io%2Fcloud%2Fcurrent%2Fclusters%2Fterraform-provider.html
    method: GET
- name: IP Filter
  endpoint:
    path: https://registry.terraform.io/providers/confluentinc/confluent/latest/docs/resources/confluent_ip_filter?session_ref=direct&url_ref=https%3A%2F%2Fdocs.confluent.io%2Fcloud%2Fcurrent%2Fclusters%2Fterraform-provider.html
    method: GET
- name: Peering
  endpoint:
    path: https://registry.terraform.io/providers/confluentinc/confluent/latest/docs/resources/confluent_peering?session_ref=direct&url_ref=https%3A%2F%2Fdocs.confluent.io%2Fcloud%2Fcurrent%2Fclusters%2Fterraform-provider.html
    method: GET
- name: Private Link Access
  endpoint:
    path: https://registry.terraform.io/providers/confluentinc/confluent/latest/docs/resources/confluent_private_link_access?session_ref=direct&url_ref=https%3A%2F%2Fdocs.confluent.io%2Fcloud%2Fcurrent%2Fclusters%2Fterraform-provider.html
    method: GET
- name: Transit Gateway Attachment
  endpoint:
    path: https://registry.terraform.io/providers/confluentinc/confluent/latest/docs/resources/confluent_transit_gateway_attachment?session_ref=direct&url_ref=https%3A%2F%2Fdocs.confluent.io%2Fcloud%2Fcurrent%2Fclusters%2Fterraform-provider.html
    method: GET
- name: API key
  endpoint:
    path: https://registry.terraform.io/providers/confluentinc/confluent/latest/docs/resources/confluent_api_key?session_ref=direct&url_ref=https%3A%2F%2Fdocs.confluent.io%2Fcloud%2Fcurrent%2Fclusters%2Fterraform-provider.html
    method: GET
- name: BYOK key
  endpoint:
    path: https://registry.terraform.io/providers/confluentinc/confluent/latest/docs/resources/confluent_byok_key?session_ref=direct&url_ref=https%3A%2F%2Fdocs.confluent.io%2Fcloud%2Fcurrent%2Fclusters%2Fterraform-provider.html
    method: GET
- name: Environment
  endpoint:
    path: https://registry.terraform.io/providers/confluentinc/confluent/latest/docs/resources/confluent_environment?session_ref=direct&url_ref=https%3A%2F%2Fdocs.confluent.io%2Fcloud%2Fcurrent%2Fclusters%2Fterraform-provider.html
    method: GET
- name: Group Mapping
  endpoint:
    path: https://registry.terraform.io/providers/confluentinc/confluent/latest/docs/resources/confluent_group_mapping?session_ref=direct&url_ref=https%3A%2F%2Fdocs.confluent.io%2Fcloud%2Fcurrent%2Fclusters%2Fterraform-provider.html
    method: GET
- name: Identity Pool
  endpoint:
    path: https://registry.terraform.io/providers/confluentinc/confluent/latest/docs/resources/confluent_identity_pool?session_ref=direct&url_ref=https%3A%2F%2Fdocs.confluent.io%2Fcloud%2Fcurrent%2Fclusters%2Fterraform-provider.html
    method: GET
- name: Identity Provider
  endpoint:
    path: https://registry.terraform.io/providers/confluentinc/confluent/latest/docs/resources/confluent_identity_provider?session_ref=direct&url_ref=https%3A%2F%2Fdocs.confluent.io%2Fcloud%2Fcurrent%2Fclusters%2Fterraform-provider.html
    method: GET
- name: Kafka ACL
  endpoint:
    path: https://registry.terraform.io/providers/confluentinc/confluent/latest/docs/resources/confluent_kafka_acl?session_ref=direct&url_ref=https%3A%2F%2Fdocs.confluent.io%2Fcloud%2Fcurrent%2Fclusters%2Fterraform-provider.html
    method: GET
- name: Role Binding
  endpoint:
    path: https://registry.terraform.io/providers/confluentinc/confluent/latest/docs/resources/confluent_role_binding?session_ref=direct&url_ref=https%3A%2F%2Fdocs.confluent.io%2Fcloud%2Fcurrent%2Fclusters%2Fterraform-provider.html
    method: GET
- name: Service Account
  endpoint:
    path: https://registry.terraform.io/providers/confluentinc/confluent/latest/docs/resources/confluent_service_account?session_ref=direct&url_ref=https%3A%2F%2Fdocs.confluent.io%2Fcloud%2Fcurrent%2Fclusters%2Fterraform-provider.html
    method: GET
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: service_quotas
  endpoint:
    path: /api/v1/service-quotas
    method: GET
    data_selector: data
    params: {}
- name: API keys
- name: Connectors
- name: Confluent Cloud Environments
- name: Kafka ACLs
- name: Kafka clusters
- name: Kafka topics
- name: Networks
- name: Peering networks
- name: Private Link Access
- name: Role bindings
- name: Service accounts
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: topics
  endpoint:
    path: /v2/topics
    method: GET
    data_selector: data
    params: {}
- name: schemas
  endpoint:
    path: /v2/schemas
    method: GET
    data_selector: data
    params: {}
- name: schema
  endpoint:
    path: /schemas
    method: GET
    data_selector: records
- name: kafka_cluster
  endpoint:
    path: /kafka/v3/clusters
    method: GET
    data_selector: data
    params: {}
- name: schema_registry
  endpoint:
    path: /schemas/v1/subjects
    method: GET
    data_selector: subjects
    params: {}
- name: kafka_client
  endpoint:
    path: /clients
    method: GET
    data_selector: clients
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: audit_logs
  endpoint:
    path: /audit_logs
    method: GET
    data_selector: records
- name: page_visits
  endpoint:
    path: /kafka/topics/page_visits
    method: POST
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: my-file-sink
  endpoint:
    path: /connectors/
    method: POST
    data_selector: config
    params: {}
- name: page_visits
  endpoint:
    path: topics
    method: GET
- name: connect-offsets
  endpoint:
    path: /connect-offsets
    method: GET
- name: connect-configs
  endpoint:
    path: /connect-configs
    method: GET
- name: connect-status
  endpoint:
    path: /connect-status
    method: GET
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: my-file-sink
  endpoint:
    path: /connectors/
    method: POST
    data_selector: 'null'
    params: {}
- name: page_visits
  endpoint:
    path: page_visits
    method: GET
- name: schema_registry
  endpoint:
    path: /schema-registry
    method: GET
    data_selector: records
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: temperature
  endpoint:
    path: /topics/temperature
    method: POST
    data_selector: messages
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: kafka_cluster
  endpoint:
    path: /v1/clusters
    method: GET
    data_selector: clusters
    params: {}
- name: schema_registry
  endpoint:
    path: /v1/schemas
    method: GET
    data_selector: schemas
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: schema_registry
  endpoint:
    path: /schema-registry
    method: GET
- name: ksqlDB
  endpoint:
    path: /ksql
    method: GET
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: topic
  endpoint:
    path: /topics
    method: GET
    data_selector: records
    params: {}
- name: schema
  endpoint:
    path: /schemas
    method: GET
    data_selector: records
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: kafka_cluster
  endpoint:
    path: /clusters
    method: GET
    data_selector: clusters
    params: {}
- name: topics
  endpoint:
    path: /topics
    method: GET
    data_selector: topics
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
- name: audit_logs
  endpoint:
    path: /audit-logs
    method: GET
    data_selector: logs
    params: {}
- name: clusters
  endpoint:
    path: /clusters
    method: GET
    data_selector: clusters
    params: {}
- name: topics
  endpoint:
    path: /topics
    method: GET
    data_selector: topics
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: topics
  endpoint:
    path: /v1/topics
    method: GET
    data_selector: data
- name: cluster
  endpoint:
    path: /clusters
    method: GET
    data_selector: clusters
    params:
      incremental: updated_at
- name: topic
  endpoint:
    path: /topics
    method: GET
    data_selector: topics
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: kafka_cluster
  endpoint:
    path: /kafka/v1/clusters
    method: GET
    data_selector: clusters
    params: {}
- name: schema_registry
  endpoint:
    path: /schemas/v1/schemas
    method: GET
    data_selector: schemas
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: kafka_cluster
  endpoint:
    path: /api/v1/clusters
    method: GET
    data_selector: clusters
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: audit_logs
  endpoint:
    path: /v1/audit-logs
    method: GET
    data_selector: records
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: consumer_group
  endpoint:
    path: /consumer-groups
    method: GET
    data_selector: groups
- name: consumer_groups
  endpoint:
    path: /kafka-consumer-groups
    method: GET
    data_selector: groups
    params: {}
- name: describe_group
  endpoint:
    path: /kafka-consumer-groups/{groupId}/describe
    method: GET
    data_selector: description
    params: {}
- name: reset_offsets
  endpoint:
    path: /kafka-consumer-groups/{groupId}/reset-offsets
    method: POST
    data_selector: offsets
    params: {}
- name: schemas
  endpoint:
    path: /schemas
    method: GET
    data_selector: records
- name: topics
  endpoint:
    path: /topics
    method: GET
    data_selector: records
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: audit_logs
  endpoint:
    path: /audit-logs
    method: GET
    data_selector: records
    params: {}
- name: share_groups
  endpoint:
    path: /kafka/share/groups
    method: GET
    data_selector: groups
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: producer_configuration
  endpoint:
    path: /platform/current/installation/configuration/producer-configs.html
    method: GET
    data_selector: configs
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: audit_logs
  endpoint:
    path: /audit-logs
    method: GET
    data_selector: records
    params: {}
- name: kafka_clusters
  endpoint:
    path: /clusters
    method: GET
    data_selector: clusters
    params: {}
- name: schemas
  endpoint:
    path: /schemas
    method: GET
    data_selector: schemas
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: audit_logs
  endpoint:
    path: /audit-logs
    method: GET
    data_selector: records
- name: service_quota
  endpoint:
    path: /service-quotas
    method: GET
    data_selector: quotas
- name: client_metrics
  endpoint:
    path: /metrics
    method: GET
    data_selector: metrics
    params: {}
- name: schema
  endpoint:
    path: /schemas
    method: GET
    data_selector: records
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: kafka_clusters
  endpoint:
    path: /kafka/v1/clusters
    method: GET
    data_selector: clusters
    params: {}
- name: topics
  endpoint:
    path: /kafka/v1/topics
    method: GET
    data_selector: topics
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: topics
  endpoint:
    path: /api/v1/topics
    method: GET
    data_selector: data
    params: {}
- name: cluster
  endpoint:
    path: /clusters
    method: GET
    data_selector: clusters
    params: {}
- name: topic
  endpoint:
    path: /topics
    method: GET
    data_selector: topics
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: producer
  endpoint:
    path: /producer/configurations
    method: GET
    data_selector: configurations
    params: {}
- name: consumer
  endpoint:
    path: /consumer/configurations
    method: GET
    data_selector: configurations
    params: {}
- name: streams
  endpoint:
    path: /streams/configurations
    method: GET
    data_selector: configurations
    params: {}
- name: topics
  endpoint:
    path: /v1/topics
    method: GET
    data_selector: data
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: topics
  endpoint:
    path: /v1/topics
    method: GET
    data_selector: results
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: topic
  endpoint:
    path: /api/v1/topics
    method: GET
    data_selector: topics
    params: {}
- name: consumer_group
  endpoint:
    path: /api/v1/consumer-groups
    method: GET
    data_selector: consumer_groups
    params: {}
- name: create_topics
  endpoint:
    path: /admin/create_topics
    method: POST
    data_selector: futures
    params: {}
- name: delete_topics
  endpoint:
    path: /admin/delete_topics
    method: POST
    data_selector: futures
    params: {}
- name: list_topics
  endpoint:
    path: /admin/list_topics
    method: GET
    data_selector: topics
    params: {}
- name: list_consumer_groups
  endpoint:
    path: /admin/list_consumer_groups
    method: GET
    data_selector: consumer_groups
    params: {}
- name: describe_consumer_groups
  endpoint:
    path: /admin/describe_consumer_groups
    method: POST
    data_selector: futures
    params: {}
- name: describe_topics
  endpoint:
    path: /admin/describe_topics
    method: POST
    data_selector: futures
    params: {}
- name: NewTopic
  endpoint:
    path: /confluent_kafka/admin/NewTopic
    method: GET
    data_selector: parameters
    params: {}
- name: NewPartitions
  endpoint:
    path: /confluent_kafka/admin/NewPartitions
    method: GET
    data_selector: parameters
    params: {}
- name: ConfigSource
  endpoint:
    path: /confluent_kafka/admin/ConfigSource
    method: GET
    data_selector: attributes
    params: {}
- name: ConfigEntry
  endpoint:
    path: /confluent_kafka/admin/ConfigEntry
    method: GET
    data_selector: attributes
    params: {}
- name: ConfigResource
  endpoint:
    path: /confluent_kafka/admin/ConfigResource
    method: GET
    data_selector: attributes
    params: {}
- name: ResourceType
  endpoint:
    path: /confluent_kafka/admin/ResourceType
    method: GET
    data_selector: attributes
    params: {}
- name: ResourcePatternType
  endpoint:
    path: /confluent_kafka/admin/ResourcePatternType
    method: GET
    data_selector: attributes
    params: {}
- name: AlterConfigOpType
  endpoint:
    path: /confluent_kafka/admin/AlterConfigOpType
    method: GET
    data_selector: attributes
    params: {}
- name: AclOperation
  endpoint:
    path: /confluent_kafka/admin/AclOperation
    method: GET
    data_selector: attributes
    params: {}
- name: AclPermissionType
  endpoint:
    path: /confluent_kafka/admin/AclPermissionType
    method: GET
    data_selector: attributes
    params: {}
- name: AclBinding
  endpoint:
    path: /confluent_kafka/admin/AclBinding
    method: GET
    data_selector: attributes
    params: {}
- name: AclBindingFilter
  endpoint:
    path: /acls
    method: GET
    data_selector: aclBindings
    params: {}
- name: ScramMechanism
  endpoint:
    path: /scram
    method: GET
    data_selector: scramMechanisms
    params: {}
- name: UserScramCredentialsDescription
  endpoint:
    path: /users/scram
    method: GET
    data_selector: scramCredentials
    params: {}
- name: ConsumerGroupListing
  endpoint:
    path: /consumerGroups
    method: GET
    data_selector: consumerGroups
    params: {}
- name: DeletedRecords
  endpoint:
    path: /admin/deleted_records
    method: GET
    data_selector: low_watermark
    params: {}
- name: MemberAssignment
  endpoint:
    path: /admin/member_assignment
    method: GET
    data_selector: topic_partitions
    params: {}
- name: MemberDescription
  endpoint:
    path: /admin/member_description
    method: GET
    data_selector: member_id
    params: {}
- name: consumer
  endpoint:
    path: /consumer
    method: GET
    data_selector: messages
    params: {}
- name: Serializer
  endpoint:
    path: /modules/confluent_kafka/serialization.html#Serializer
    method: GET
    data_selector: records
- name: Deserializer
  endpoint:
    path: /modules/confluent_kafka/serialization.html#Deserializer
    method: GET
    data_selector: records
- name: ListConsumerGroupsResult
  endpoint:
    path: /admin/list_consumer_groups
    method: GET
    data_selector: valid
- name: ConsumerGroupDescription
  endpoint:
    path: /admin/describe_consumer_groups
    method: GET
    data_selector: members
- name: partition_assignment_strategy
  endpoint:
    path: /partition/assignment/strategy
    method: GET
    data_selector: strategies
    params: {}
- name: session_timeout
  endpoint:
    path: /session/timeout
    method: GET
    data_selector: timeout
    params: {}
- name: heartbeat_interval
  endpoint:
    path: /heartbeat/interval
    method: GET
    data_selector: interval
    params: {}
- name: delete_records
  endpoint:
    path: /AdminClient/delete_records
    method: POST
    data_selector: futures
    params:
      request_timeout: socket.timeout.ms/1000.0
- name: elect_leaders
  endpoint:
    path: /AdminClient/elect_leaders
    method: POST
    data_selector: future
    params:
      request_timeout: socket.timeout.ms*1000.0
      operation_timeout: socket.timeout.ms/1000.0
- name: ListConsumerGroupsResult
  endpoint:
    path: /admin/list_consumer_groups
    method: GET
    data_selector: valid
- name: ConsumerGroupDescription
  endpoint:
    path: /admin/describe_consumer_groups
    method: GET
    data_selector: members
- name: DeletedRecords
  endpoint:
    path: /admin/deleted_records
    method: GET
    data_selector: low_watermark
- name: classic_protocol
  endpoint:
    path: ''
    method: ''
    data_selector: ''
    params:
      group.protocol: classic
      partition.assignment.strategy: <range,roundrobin,sticky
      session.timeout.ms: 45000
      heartbeat.interval.ms: 15000
- name: next_gen_protocol
  endpoint:
    path: ''
    method: ''
    data_selector: ''
    params:
      group.protocol: consumer
- name: ConsumerGroupDescription
  endpoint:
    path: /v2/consumer-group-description
    method: GET
    data_selector: ConsumerGroupDescriptions
    params: {}
- name: ConsumerGroupListing
  endpoint:
    path: /v2/consumer-group-listing
    method: GET
    data_selector: ConsumerGroupListings
    params: {}
- name: ConsumerGroupMetadata
  endpoint:
    path: /v2/consumer-group-metadata
    method: GET
    data_selector: ConsumerGroupMetadata
    params: {}
- name: kafka_cluster
  endpoint:
    path: /api/v1/clusters
    method: GET
    data_selector: clusters
    params: {}
- name: topics
  endpoint:
    path: /api/v1/topics
    method: GET
    data_selector: topics
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: audit_logs
  endpoint:
    path: /audit-logs
    method: GET
    data_selector: records
- name: billing
  endpoint:
    path: /billing
    method: GET
    data_selector: records
- name: kafka_cluster
  endpoint:
    path: /v2/clusters
    method: GET
    data_selector: clusters
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: kafka_cluster
  endpoint:
    path: /v1/clusters
    method: GET
    data_selector: clusters
    params: {}
- name: topic
  endpoint:
    path: /v1/topics
    method: GET
    data_selector: topics
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: topics
  endpoint:
    path: /v1/topics
    method: GET
    data_selector: topics
    params: {}
- name: producer
  endpoint:
    path: /producer
    method: POST
    data_selector: records
    params: {}
- name: consumer
  endpoint:
    path: /consumer
    method: GET
    data_selector: records
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: producer_example
  endpoint:
    path: /clients/cloud/groovy/ProducerExample
    method: POST
    data_selector: records
    params:
      configPath: $HOME/.confluent/java.config
      topic: test1
- name: consumer_example
  endpoint:
    path: /clients/cloud/groovy/ConsumerExample
    method: POST
    data_selector: records
    params:
      configPath: $HOME/.confluent/java.config
      topic: test1
- name: streams_example
  endpoint:
    path: /clients/cloud/groovy/StreamsExample
    method: POST
    data_selector: records
    params:
      configPath: $HOME/.confluent/java.config
      topic: test1
- name: topic
  endpoint:
    path: /topics
    method: GET
    data_selector: records
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: kafka_topic
  endpoint:
    path: /kafka/topics/test1
    method: POST
    data_selector: records
- name: subjects
  endpoint:
    path: /subjects
    method: GET
    data_selector: subjects
- name: subject_info
  endpoint:
    path: /subjects/test2-value/versions/1
    method: GET
    data_selector: schema
- name: topic
  endpoint:
    path: /api/v1/topics
    method: GET
    data_selector: data
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: kafka_cluster
  endpoint:
    path: /v1/clusters
    method: GET
    data_selector: clusters
    params: {}
- name: topics
  endpoint:
    path: /v1/clusters/{cluster_id}/topics
    method: GET
    data_selector: topics
    params: {}
- name: kafka_topic
  endpoint:
    path: /kafka/topics
    method: POST
    data_selector: topic_name
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: producer
  endpoint:
    path: /clients/cloud/kotlin/ProducerExample
    method: POST
    data_selector: produced_records
- name: consumer
  endpoint:
    path: /clients/cloud/kotlin/ConsumerExample
    method: POST
    data_selector: consumed_records
- name: streams
  endpoint:
    path: /clients/cloud/kotlin/StreamsExample
    method: POST
    data_selector: streamed_records
- name: kafka_clusters
  endpoint:
    path: /v1/clusters
    method: GET
    data_selector: clusters
- name: topics
  endpoint:
    path: /v1/topics
    method: GET
    data_selector: data
- name: consumer_groups
  endpoint:
    path: /v1/consumer-groups
    method: GET
    data_selector: data
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: producer
  endpoint:
    path: /clients/cloud/rust/producer
    method: POST
    data_selector: records
- name: consumer
  endpoint:
    path: /clients/cloud/rust/consumer
    method: GET
    data_selector: records
- name: topics
  endpoint:
    path: /api/v1/topics
    method: GET
    data_selector: data
    params: {}
- name: schemas
  endpoint:
    path: /api/v1/schemas
    method: GET
    data_selector: data
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: kafka_topic
  endpoint:
    path: /v1/topics
    method: GET
    data_selector: data
    params: {}
- name: kafka_cluster
  endpoint:
    path: /v1/clusters
    method: GET
    data_selector: data
    params: {}
- name: topic
  endpoint:
    path: /v1/topics
    method: GET
    data_selector: data
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
- name: Kafka clusters
  endpoint:
    path: /connect/kafka_clusters
    method: GET
- name: Topics
  endpoint:
    path: /connect/topics
    method: GET
- name: Schemas
  endpoint:
    path: /connect/schemas
    method: GET
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: kafka_cluster
  endpoint:
    path: /kafka/v3/clusters
    method: GET
    data_selector: data
    params: {}
- name: topic
  endpoint:
    path: /kafka/v3/clusters/{cluster.id}/topics
    method: GET
    data_selector: data
    params: {}
- name: input_topic
  endpoint:
    path: /input_topic
    method: POST
    data_selector: messages
- name: output_topic
  endpoint:
    path: /output_topic
    method: GET
    data_selector: messages
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: input_topic
  endpoint:
    path: /topics/input_topic
    method: POST
    data_selector: records
- name: output_topic
  endpoint:
    path: /topics/output_topic
    method: POST
    data_selector: records
- name: topics
  endpoint:
    path: /v1/topics
    method: GET
    data_selector: data
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: user_accounts
  endpoint:
    path: /v1/user-accounts
    method: GET
    data_selector: data
- name: workload_identities
  endpoint:
    path: /v1/workload-identities
    method: GET
    data_selector: data
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: ksqlDB clusters
  endpoint:
    path: /ksqldbcm/v2/clusters
    method: GET
    data_selector: data
    params:
      environment: environment_id
      page_size: page_size
      page_token: token
- name: create ksqlDB cluster
  endpoint:
    path: /ksqldbcm/v2/clusters
    method: POST
    data_selector: spec
    params: {}
- name: read ksqlDB cluster
  endpoint:
    path: /ksqldbcm/v2/clusters/{id}
    method: GET
    data_selector: spec
    params:
      environment: environment_id
- name: delete ksqlDB cluster
  endpoint:
    path: /ksqldbcm/v2/clusters/{id}
    method: DELETE
    data_selector: ''
    params:
      environment: environment_id
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: kafka_topics
  endpoint:
    path: /kafka/v3/clusters/{cluster_id}/topics
    method: GET
    data_selector: data
    params:
      incremental: created_at
- name: schemas
  endpoint:
    path: /schemas/v1/subjects/{subject}/versions
    method: GET
    data_selector: schemas
    params: {}
- name: ksql
  endpoint:
    path: /ksql
    method: POST
    data_selector: streams
    params: {}
- name: schemas
  endpoint:
    path: /schemas
    method: GET
    data_selector: records
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: pq_pageviews
  endpoint:
    path: /pksqlc-e8086.us-west2.gcp.confluent.cloud:443
    method: GET
    data_selector: records
    params: {}
- name: pq_pageviews_metrics
  endpoint:
    path: /pksqlc-e8086.us-west2.gcp.confluent.cloud:443
    method: GET
    data_selector: records
    params: {}
- name: schema
  endpoint:
    path: /schemas
    method: GET
    data_selector: records
    params: {}
- name: topic
  endpoint:
    path: /topics
    method: GET
    data_selector: records
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: streams
  endpoint:
    path: /ksql/streams
    method: GET
    data_selector: streams
- name: tables
  endpoint:
    path: /ksql/tables
    method: GET
    data_selector: tables
- name: types
  endpoint:
    path: /ksql/types
    method: GET
    data_selector: types
- name: topic
  endpoint:
    path: /topics
    method: GET
    data_selector: records
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: cluster
  endpoint:
    path: /clusters
    method: GET
    data_selector: clusters
    params: {}
- name: topic
  endpoint:
    path: /topics
    method: GET
    data_selector: topics
    params: {}
- name: agent_configuration
  endpoint:
    path: /agent/configuration
    method: CREATE
    data_selector: configuration
    params: {}
- name: kafka_clusters
  endpoint:
    path: /kafka/v1/clusters
    method: GET
    data_selector: clusters
    params: {}
- name: schemas
  endpoint:
    path: /schemas/v1/schemas
    method: GET
    data_selector: schemas
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: udf_tool
  endpoint:
    path: /create/tool/udf_tool
    method: POST
    data_selector: tool
    params: {}
- name: mcp_tool
  endpoint:
    path: /create/tool/mcp_tool
    method: POST
    data_selector: tool
    params: {}
- name: my_model
  endpoint:
    path: /create/model/my_model
    method: POST
    data_selector: model
    params: {}
- name: agent_with_tools
  endpoint:
    path: /create/agent/agent_with_tools
    method: POST
    data_selector: agent
    params: {}
- name: kafka_clusters
  endpoint:
    path: /v1/clusters
    method: GET
    data_selector: clusters
    params: {}
- name: schemas
  endpoint:
    path: /v1/schemas
    method: GET
    data_selector: schemas
    params: {}
- name: account_lookup_tool
  endpoint:
    path: /create-tool/account_lookup_tool
    method: POST
    data_selector: tool
    params: {}
- name: support_api_tool
  endpoint:
    path: /create-tool/support_api_tool
    method: POST
    data_selector: tool
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: customer_messages
  endpoint:
    path: /customer-messages
    method: CREATE
    data_selector: result
    params: {}
- name: support_responses
  endpoint:
    path: /support-responses
    method: CREATE
    data_selector: result
    params: {}
- name: risk_assessed_transactions
  endpoint:
    path: /risk-assessed-transactions
    method: CREATE
    data_selector: result
    params: {}
- name: investigated_transactions
  endpoint:
    path: /investigated-transactions
    method: CREATE
    data_selector: result
    params: {}
- name: fraud_decisions
  endpoint:
    path: /fraud-decisions
    method: INSERT
    data_selector: result
    params: {}
- name: device_health_summary
  endpoint:
    path: /device-health-summary
    method: CREATE
    data_selector: result
    params: {}
- name: maintenance_recommendations
  endpoint:
    path: /maintenance-recommendations
    method: INSERT
    data_selector: result
    params: {}
- name: user_content
  endpoint:
    path: /user-content
    method: CREATE
    data_selector: result
    params: {}
- name: conversation_state
  endpoint:
    path: /conversation-state
    method: CREATE
    data_selector: result
    params: {}
- name: moderation_decisions
  endpoint:
    path: /moderation-decisions
    method: INSERT
    data_selector: result
    params: {}
- name: clusters
  endpoint:
    path: /clusters
    method: GET
    data_selector: resources
- name: topics
  endpoint:
    path: /topics
    method: GET
    data_selector: resources
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: AI_COMPLETE
- name: AI_EMBEDDING
- name: AI_FORECAST
- name: AI_TOOL_INVOKE
- name: ML_DETECT_ANOMALIES
- name: ML_EVALUATE
- name: ML_PREDICT
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: AI_COMPLETE
- name: AI_EMBEDDING
- name: AI_FORECAST
- name: AI_TOOL_INVOKE
- name: ML_DETECT_ANOMALIES
- name: ML_EVALUATE
- name: ML_PREDICT
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: audit_logs
  endpoint:
    path: /audit-logs
    method: GET
    data_selector: records
- name: service_quotas
  endpoint:
    path: /service-quotas
    method: GET
    data_selector: records
- name: anomaly_detection
  endpoint:
    path: /ml_detect_anomalies
    method: POST
    data_selector: anomalies
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: orders
  endpoint:
    path: /orders
    method: POST
    data_selector: forecast
    params: {}
- name: topic
  endpoint:
    path: /v1/topics
    method: GET
    data_selector: topics
- name: schema
  endpoint:
    path: /v1/schemas
    method: GET
    data_selector: schemas
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: azureopenai_connection
  endpoint:
    path: /openai/deployments/<your-deployment-id>/chat/completions?api-version=2025-01-01-preview
    method: CREATE
    data_selector: response
    params: {}
- name: deepwiki_mcp_connection
  endpoint:
    path: /sse
    method: CREATE
    data_selector: tools
    params: {}
- name: topics
  endpoint:
    path: /api/v1/topics
    method: GET
    data_selector: data
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: deepwiki_mcp_connection
  endpoint:
    path: /sse
    method: CREATE CONNECTION
    data_selector: api-key
    params: {}
- name: azure-openai_connection
  endpoint:
    path: /openai/deployments/<your-deployment-id>/chat/completions?api-version=2025-01-01-preview
    method: CREATE CONNECTION
    data_selector: api-key
    params: {}
- name: azureopenai_mcp_model
  endpoint:
    path: /model
    method: CREATE MODEL
    data_selector: response
    params: {}
- name: text_stream
  endpoint:
    path: /table
    method: CREATE TABLE
    data_selector: response
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: ML_BUCKETIZE
  endpoint:
    path: /ml/bucketize
    method: GET
    data_selector: records
    params: {}
- name: ML_CHARACTER_TEXT_SPLITTER
  endpoint:
    path: /ml/character_text_splitter
    method: GET
    data_selector: records
    params: {}
- name: ML_FILE_FORMAT_TEXT_SPLITTER
  endpoint:
    path: /ml/file_format_text_splitter
    method: GET
    data_selector: records
    params: {}
- name: ML_LABEL_ENCODER
  endpoint:
    path: /ml/label_encoder
    method: GET
    data_selector: records
    params: {}
- name: ML_MAX_ABS_SCALER
  endpoint:
    path: /ml/max_abs_scaler
    method: GET
    data_selector: records
    params: {}
- name: ML_MIN_MAX_SCALER
  endpoint:
    path: /ml/min_max_scaler
    method: GET
    data_selector: records
    params: {}
- name: ML_NGRAMS
  endpoint:
    path: /ml/ngrams
    method: GET
    data_selector: records
    params: {}
- name: ML_NORMALIZER
  endpoint:
    path: /ml/normalizer
    method: GET
    data_selector: records
    params: {}
- name: ML_ONE_HOT_ENCODER
  endpoint:
    path: /ml/one_hot_encoder
    method: GET
    data_selector: records
    params: {}
- name: ML_RECURSIVE_TEXT_SPLITTER
  endpoint:
    path: /ml/recursive_text_splitter
    method: GET
    data_selector: records
    params: {}
- name: ML_ROBUST_SCALER
  endpoint:
    path: /ml/robust_scaler
    method: GET
    data_selector: scaler
    params: {}
- name: ML_STANDARD_SCALER
  endpoint:
    path: /ml/standard_scaler
    method: GET
    data_selector: scaler
    params: {}
- name: service_account
  endpoint:
    path: /v1/service-accounts
    method: GET
    data_selector: service_accounts
- name: api_keys
  endpoint:
    path: /v1/api-keys
    method: GET
    data_selector: api_keys
- name: ML_PREDICT
  endpoint:
    path: /ml/predict
    method: POST
    data_selector: predictions
    params: {}
- name: ML_DETECT_ANOMALIES
  endpoint:
    path: /ml/detect_anomalies
    method: POST
    data_selector: anomalies
    params: {}
- name: ML_EVALUATE
  endpoint:
    path: /ml/evaluate
    method: POST
    data_selector: evaluation_metrics
    params: {}
- name: KEY_SEARCH_AGG
  endpoint:
    path: /key_search_agg
    method: POST
    data_selector: search_results
    params: {}
- name: ML_FORECAST
  endpoint:
    path: /ml/forecast
    method: POST
    data_selector: forecast
    params: {}
- name: claims_verified
  endpoint:
    path: /claims_verified
    method: SELECT
    data_selector: records
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: topic
  endpoint:
    path: /topics
    method: GET
    data_selector: records
    params: {}
- name: cluster
  endpoint:
    path: /clusters
    method: GET
    data_selector: records
    params: {}
- name: topics
  endpoint:
    path: /topics
    method: GET
    data_selector: records
- name: schemas
  endpoint:
    path: /schemas
    method: GET
    data_selector: records
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: topics
  endpoint:
    path: /v1/topics
    method: GET
    data_selector: topics
    params: {}
- name: clusters
  endpoint:
    path: /v1/clusters
    method: GET
    data_selector: clusters
    params: {}
- name: create_embeddings_action
  endpoint:
    path: /create/embeddings
    method: POST
    data_selector: embedding_data
- name: streaming_data
  endpoint:
    path: /v1/streaming/data
    method: GET
    data_selector: records
- name: bedrock_embed
  endpoint:
    path: /model/<MODEL_ID>/invoke
    method: POST
    data_selector: response
    params:
      aws_access_key_id: <your-aws-access-key-id>
      aws_secret_access_key: <your-aws-secret-access-key>
      aws_session_token: <your-aws-session-token>
- name: azure_embed
  endpoint:
    path: /openai/deployments/<your-deployment-name>/embeddings?api-version=2024-06-01
    method: POST
    data_selector: response
    params:
      api-key: <your-azure-api-key>
- name: google_text_cli
  endpoint:
    path: /v1beta/models/gemini-2.0-flash:generateContent
    method: POST
    data_selector: output
    params:
      api-key: <your-gcp-api-key>
- name: sentimentmodel
  endpoint:
    path: /v1/chat/completions
    method: POST
    data_selector: sentiment
    params:
      api-key: <your-api-key>
- name: stream
  endpoint:
    path: /v1/streams
    method: GET
    data_selector: data
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: rest_books_key_search
  endpoint:
    path: search.json
    method: GET
    data_selector: docs
    params: {}
- name: mongodb_movies_key_search
  endpoint:
    path: ''
    method: ''
    data_selector: ''
    params: {}
- name: schemas
  endpoint:
    path: /schemas
    method: GET
    data_selector: records
- name: mongodb_movies_full_text_search
  endpoint:
    path: /create_table/mongodb_movies_full_text_search
    method: CREATE
    data_selector: mongodb
    params:
      mongodb.connection: mongodb_connection
      mongodb.database: sample_mflix
      mongodb.collection: movies
      mongodb.index: default
- name: couchbase_color_full_text_search
  endpoint:
    path: /create_table/couchbase_color_full_text_search
    method: CREATE
    data_selector: couchbase
    params:
      couchbase.connection: couchbase_connection
      couchbase.bucket: color-vector-sample
      couchbase.scope: color
      couchbase.collection: rgb
      couchbase.index: rgb-vector
- name: topics
  endpoint:
    path: /v1/topics
    method: GET
    data_selector: data
    params: {}
- name: couchbase_color
  endpoint:
    path: /couchbase_color
    method: CREATE
    data_selector: brightness, description, embedding_vector_dot
    params:
      couchbase.connection: couchbase_connection
      couchbase.bucket: color-vector-sample
      couchbase.scope: color
      couchbase.collection: rgb
      couchbase.index: rgb-vector
- name: elastic
  endpoint:
    path: /elastic
    method: CREATE
    data_selector: vector, text
    params:
      elastic.connection: elastic_connection
      elastic.index: wikipedia_vector_index
- name: mongodb
  endpoint:
    path: /mongodb
    method: CREATE
    data_selector: title, plot, plot_embedding
    params:
      mongodb.connection: mongodb_connection
      mongodb.database: sample_mflix
      mongodb.collection: movies_embeddings
      mongodb.index: idx_plot_embedding
      mongodb.numcandidates: '100'
- name: pinecone
  endpoint:
    path: /pinecone
    method: CREATE
    data_selector: text, embeddings
    params:
      pinecone.connection: pinecone_connection
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: cleanup.policy
  endpoint:
    path: /configuration/cleanup.policy
    method: GET
    data_selector: default
    params: {}
- name: compression.type
  endpoint:
    path: /configuration/compression.type
    method: GET
    data_selector: default
    params: {}
- name: default.replication.factor
  endpoint:
    path: /configuration/default.replication.factor
    method: GET
    data_selector: default
    params: {}
- name: delete.retention.ms
  endpoint:
    path: /configuration/delete.retention.ms
    method: GET
    data_selector: default
    params: {}
- name: file.delete.delay.ms
  endpoint:
    path: /configuration/file.delete.delay.ms
    method: GET
    data_selector: default
    params: {}
- name: flush.messages
  endpoint:
    path: /configuration/flush.messages
    method: GET
    data_selector: default
    params: {}
- name: flush.ms
  endpoint:
    path: /configuration/flush.ms
    method: GET
    data_selector: default
    params: {}
- name: index.interval.bytes
  endpoint:
    path: /configuration/index.interval.bytes
    method: GET
    data_selector: default
    params: {}
- name: max.message.bytes
  endpoint:
    path: /configuration/max.message.bytes
    method: GET
    data_selector: default
    params: {}
- name: max.compaction.lag.ms
  endpoint:
    path: /configuration/max.compaction.lag.ms
    method: GET
    data_selector: default
    params: {}
- name: message.downconversion.enable
  endpoint:
    path: /configuration/message.downconversion.enable
    method: GET
    data_selector: default
    params: {}
- name: message.timestamp.after.max.ms
  endpoint:
    path: /configuration/message.timestamp.after.max.ms
    method: GET
    data_selector: default
    params: {}
- name: message.timestamp.before.max.ms
  endpoint:
    path: /configuration/message.timestamp.before.max.ms
    method: GET
    data_selector: default
    params: {}
- name: message.timestamp.difference.max.ms
  endpoint:
    path: /configuration/message.timestamp.difference.max.ms
    method: GET
    data_selector: default
    params: {}
- name: message.timestamp.type
  endpoint:
    path: /configuration/message.timestamp.type
    method: GET
    data_selector: default
    params: {}
- name: min.cleanable.dirty.ratio
  endpoint:
    path: /configuration/min.cleanable.dirty.ratio
    method: GET
    data_selector: default
    params: {}
- name: min.compaction.lag.ms
  endpoint:
    path: /configuration/min.compaction.lag.ms
    method: GET
    data_selector: default
    params: {}
- name: min.insync.replicas
  endpoint:
    path: /configuration/min.insync.replicas
    method: GET
    data_selector: default
    params: {}
- name: num.partitions
  endpoint:
    path: /configuration/num.partitions
    method: GET
    data_selector: default
    params: {}
- name: preallocate
  endpoint:
    path: /configuration/preallocate
    method: GET
    data_selector: default
    params: {}
- name: retention.bytes
  endpoint:
    path: /configuration/retention.bytes
    method: GET
    data_selector: default
    params: {}
- name: retention.ms
  endpoint:
    path: /configuration/retention.ms
    method: GET
    data_selector: default
    params: {}
- name: segment.bytes
  endpoint:
    path: /configuration/segment.bytes
    method: GET
    data_selector: default
    params: {}
- name: segment.index.bytes
  endpoint:
    path: /configuration/segment.index.bytes
    method: GET
    data_selector: default
    params: {}
- name: segment.jitter.ms
  endpoint:
    path: /configuration/segment.jitter.ms
    method: GET
    data_selector: default
    params: {}
- name: segment.ms
  endpoint:
    path: /configuration/segment.ms
    method: GET
    data_selector: default
    params: {}
- name: unclean.leader.election.enable
  endpoint:
    path: /configuration/unclean.leader.election.enable
    method: GET
    data_selector: default
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: message_browser
  endpoint:
    path: /message/browser
    method: GET
    data_selector: messages
- name: topics
  endpoint:
    path: /topics
    method: GET
    data_selector: topics
- name: produce_messages
  endpoint:
    path: /topics/produce
    method: POST
    data_selector: produced_messages
- name: download_messages
  endpoint:
    path: /topics/download
    method: GET
    data_selector: downloaded_messages
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: kafka_clusters
  endpoint:
    path: /kafka/v3/clusters
    method: GET
    data_selector: data
    params: {}
- name: topics
  endpoint:
    path: /kafka/v3/clusters/{cluster_id}/topics
    method: GET
    data_selector: data
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: provider_shares
  endpoint:
    path: /cdx/v1/provider-shares
    method: GET
    data_selector: data
    params: {}
- name: schemas
  endpoint:
    path: /api/schemas
    method: GET
    data_selector: records
    params: {}
- name: consumer_shared_resources
  endpoint:
    path: /cdx/v1/consumer-shared-resources
    method: GET
    data_selector: data
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: consumer_shared_resources
  endpoint:
    path: /cdx/v1/consumer-shared-resources
    method: GET
    data_selector: data
- name: redeem_shared_token
  endpoint:
    path: /cdx/v1/shared-tokens:redeem
    method: POST
    data_selector: ''
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: Kafka Topics
  endpoint:
    path: /api/tableflow/kafka_topics
    method: GET
    data_selector: topics
    params: {}
- name: Iceberg Tables
  endpoint:
    path: /api/tableflow/iceberg_tables
    method: GET
    data_selector: tables
    params: {}
- name: Delta Lake Tables
  endpoint:
    path: /api/tableflow/delta_lake_tables
    method: GET
    data_selector: tables
    params: {}
- name: topic
  endpoint:
    path: /api/v1/topics
    method: GET
    data_selector: data
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: avro_primitive_types
  endpoint:
    path: /schemas/avro/primitive
    method: GET
    data_selector: records
- name: avro_logical_types
  endpoint:
    path: /schemas/avro/logical
    method: GET
    data_selector: records
- name: avro_complex_types
  endpoint:
    path: /schemas/avro/complex
    method: GET
    data_selector: records
- name: confluent_specific_types
  endpoint:
    path: /schemas/confluent/specific
    method: GET
    data_selector: records
- name: topics
  endpoint:
    path: /v1/topics
    method: GET
    data_selector: data
    params: {}
- name: schemas
  endpoint:
    path: /v1/schemas
    method: GET
    data_selector: data
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: Debezium
  endpoint:
    path: /debezium
    method: GET
    data_selector: records
    params:
      after.state.only: 'true'
- name: schemas
  endpoint:
    path: /schemas
    method: GET
    data_selector: records
    params: {}
- name: topics
  endpoint:
    path: /topics
    method: GET
    data_selector: records
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
- name: topics
  endpoint:
    path: /topics
    method: GET
    data_selector: records
    params: {}
- name: topic
  endpoint:
    path: /topics
    method: GET
    data_selector: records
    params: {}
- name: consumer_group
  endpoint:
    path: /consumer_groups
    method: GET
    data_selector: records
    params: {}
- name: service_quotas
  endpoint:
    path: /v1/service-quotas
    method: GET
    data_selector: data
    params: {}
- name: billing
  endpoint:
    path: /v1/billing
    method: GET
    data_selector: data
    params: {}
- name: topics
  endpoint:
    path: /v1/topics
    method: GET
    data_selector: data
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: schema
  endpoint:
    path: /schemas
    method: GET
    data_selector: records
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: auditable_event_methods
  endpoint:
    path: /api/audit-logging/event-methods
    method: GET
    data_selector: records
- name: stock-trades
  endpoint:
    path: /topics/stock-trades
    method: GET
- name: topics
  endpoint:
    path: /v1/topics
    method: GET
    data_selector: data
    params: {}
- name: stock-trades
  endpoint:
    path: /topics/stock-trades
    method: POST
    data_selector: data
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: audit_logs
  endpoint:
    path: /audit-logs
    method: GET
    data_selector: logs
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: topics
  endpoint:
    path: /v1/topics
    method: GET
    data_selector: data
    params: {}
- name: clusters
  endpoint:
    path: /v1/clusters
    method: GET
    data_selector: data
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: AWS Glue Data Catalog
  endpoint:
    path: /integrate-with-aws-glue-catalog
    method: GET
- name: Snowflake Open Catalog/Apache Polaris
  endpoint:
    path: /integrate-with-snowflake-open-catalog
    method: GET
- name: Databricks Unity Catalog
  endpoint:
    path: /integrate-with-unity-catalog
    method: GET
- name: topics
  endpoint:
    path: /v1/topics
    method: GET
    data_selector: data
    params: {}
- name: clusters
  endpoint:
    path: /v1/clusters
    method: GET
    data_selector: data
    params: {}
- name: Iceberg tables
  endpoint:
    path: /services/tableflow/iceberg
    method: GET
- name: topics
  endpoint:
    path: /topics
    method: GET
    data_selector: records
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: Iceberg tables
  endpoint:
    path: /path/to/iceberg/tables
    method: GET
    data_selector: tables
    params: {}
- name: topics
  endpoint:
    path: /v1/topics
    method: GET
    data_selector: data
    params: {}
- name: clusters
  endpoint:
    path: /v1/clusters
    method: GET
    data_selector: data
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: external_catalog
  endpoint:
    path: /create/external_catalog
    method: POST
- name: topics
  endpoint:
    path: /v1/topics
    method: GET
    data_selector: data
    params: {}
- name: clusters
  endpoint:
    path: /v1/clusters
    method: GET
    data_selector: data
    params: {}
- name: incident
  endpoint:
    path: /api/now/table/incident
    method: GET
    data_selector: result
    params:
      sysparm_query: active=true
- name: change_request
  endpoint:
    path: /api/now/table/change_request
    method: GET
    data_selector: result
    params:
      sysparm_query: state!=6
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: catalog
  endpoint:
    path: /tableflow/catalog
    method: POST
- name: topic
  endpoint:
    path: /v1/topics
    method: GET
    data_selector: data
    params: {}
- name: cluster
  endpoint:
    path: /v1/clusters
    method: GET
    data_selector: data
    params: {}
- name: topics
  endpoint:
    path: /v1/topics
    method: GET
    data_selector: data
- name: schemas
  endpoint:
    path: /v1/schemas
    method: GET
    data_selector: data
- name: topic
  endpoint:
    path: /api/v1/topics
    method: GET
    data_selector: data
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: Iceberg_Tables
  endpoint:
    path: /path/to/iceberg/tables
    method: GET
    data_selector: tables
    params: {}
- name: Topics
  endpoint:
    path: /api/v1/topics
    method: GET
    data_selector: data
    params: {}
- name: Schemas
  endpoint:
    path: /api/v1/schemas
    method: GET
    data_selector: data
    params: {}
- name: topics
  endpoint:
    path: /api/v1/topics
    method: GET
    data_selector: data
    params: {}
- name: clusters
  endpoint:
    path: /api/v1/clusters
    method: GET
    data_selector: data
    params: {}
- name: iceberg_table
  endpoint:
    path: /create_iceberg_table
    method: POST
    data_selector: iceberg_table
    params: {}
- name: kafka_cluster
  endpoint:
    path: /api/clusters
    method: GET
    data_selector: clusters
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: iceberg_catalog
  endpoint:
    path: /iceberg/catalog
    method: GET
- name: topics
  endpoint:
    path: /api/v1/topics
    method: GET
    data_selector: data
- name: clusters
  endpoint:
    path: /api/v1/clusters
    method: GET
    data_selector: data
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: topics
  endpoint:
    path: /v1/topics
    method: GET
    data_selector: data
    params: {}
- name: TableflowTopics
  endpoint:
    path: /tableflow/topics
    method: GET
    data_selector: topics
- name: CatalogIntegration
  endpoint:
    path: /catalog/integration
    method: GET
    data_selector: catalogIntegrations
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: audit_logs
  endpoint:
    path: /v1/audit_logs
    method: GET
    data_selector: logs
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: topics
  endpoint:
    path: /v1/topics
    method: GET
    data_selector: data
    params: {}
- name: clusters
  endpoint:
    path: /v1/clusters
    method: GET
    data_selector: data
    params: {}
- name: topics
  endpoint:
    path: /topics
    method: GET
    data_selector: records
- name: topic
  endpoint:
    path: /api/v1/topics
    method: GET
    data_selector: data
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: audit_logs
  endpoint:
    path: /audit-logs
    method: GET
    data_selector: logs
    params: {}
- name: metrics
  endpoint:
    path: /metrics
    method: GET
    data_selector: metric_data
    params: {}
- name: topic
  endpoint:
    path: /v1/topics
    method: GET
    data_selector: topics
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: kafka_clusters
  endpoint:
    path: /v1/kafka/clusters
    method: GET
    data_selector: clusters
    params: {}
- name: topics
  endpoint:
    path: /v1/topics
    method: GET
    data_selector: topics
    params: {}
- name: topics
  endpoint:
    path: /v1/topics
    method: GET
    data_selector: data
    params: {}
- name: streams
  endpoint:
    path: /v1/streams
    method: GET
    data_selector: data
    params: {}
- name: kafka_topics
  endpoint:
    path: /kafka/v3/topics
    method: GET
    data_selector: data
    params:
      incremental: updated_at
- name: kafka_consumers
  endpoint:
    path: /kafka/v3/consumers
    method: GET
    data_selector: data
    params: {}
- name: payment_method
  endpoint:
    path: /payment/methods
    method: POST
    data_selector: paymentMethods
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: PrivateLink Attachment
  endpoint:
    path: /networking/v1/private-link-attachments
    method: POST
    data_selector: ''
    params: {}
- name: PrivateLink Attachment Connection
  endpoint:
    path: /networking/v1/private-link-attachment-connections
    method: POST
    data_selector: ''
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: service_quota
  endpoint:
    path: /v1/service-quotas
    method: GET
    data_selector: quotas
- name: billing_metrics
  endpoint:
    path: /v1/billing/metrics
    method: GET
    data_selector: metrics
- name: schemas
  endpoint:
    path: /schemas
    method: GET
    data_selector: records
    params: {}
- name: register_cluster
  endpoint:
    path: /unified-stream-manager/kafka/register
    method: POST
    data_selector: confirmation
    params: {}
- name: deregister_cluster
  endpoint:
    path: /unified-stream-manager/kafka/deregister
    method: POST
    data_selector: confirmation
    params: {}
- name: audit_logs
  endpoint:
    path: /v1/audit-logs
    method: GET
    data_selector: logs
    params: {}
- name: register_connect_cluster
  endpoint:
    path: /connect/register
    method: POST
- name: deregister_connect_cluster
  endpoint:
    path: /connect/deregister
    method: POST
- name: topic
  endpoint:
    path: /topics
    method: GET
    data_selector: records
    params: {}
- name: stream
  endpoint:
    path: /api/v1/streams
    method: GET
    data_selector: data
- name: topic
  endpoint:
    path: /api/v1/topics
    method: GET
    data_selector: data
- name: clusters
- name: topics
- name: connectors
- name: kafka_clusters
  endpoint:
    path: /v1/kafka-clusters
    method: GET
    data_selector: clusters
- name: topics
  endpoint:
    path: /v1/topics
    method: GET
    data_selector: topics
- name: kafka_topics
  endpoint:
    path: /v3/clusters/{cluster_id}/topics
    method: GET
    data_selector: data
    params: {}
- name: kafka_consumer_groups
  endpoint:
    path: /v3/clusters/{cluster_id}/consumer-groups
    method: GET
    data_selector: data
    params: {}
- name: clusters
  endpoint:
    path: /clusters
    method: GET
- name: topics
  endpoint:
    path: /topics
    method: GET
- name: connectors
  endpoint:
    path: /connectors
    method: GET
- name: cluster_overview
  endpoint:
    path: /cluster/overview
    method: GET
    data_selector: metrics
    params: {}
- name: broker_metrics
  endpoint:
    path: /brokers
    method: GET
    data_selector: broker_metrics
    params: {}
- name: topic
  endpoint:
    path: /topics
    method: GET
    data_selector: records
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: topic_reporting
  endpoint:
    path: /monitor/topics
    method: GET
    data_selector: topics
- name: topics
  endpoint:
    path: /api/v1/topics
    method: GET
    data_selector: data
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: clusters
  endpoint:
    path: /api/clusters
    method: GET
    data_selector: data
    params: {}
- name: topics
  endpoint:
    path: /api/topics
    method: GET
    data_selector: data
    params: {}
- name: service_quotas
  endpoint:
    path: /v1/service-quotas
    method: GET
    data_selector: data
    params: {}
- name: cluster
  endpoint:
    path: /clusters
    method: GET
    data_selector: clusters
    params: {}
- name: topic
  endpoint:
    path: /topics
    method: GET
    data_selector: topics
    params: {}
- name: usm_agent_access_logs
  endpoint:
    path: /var/log/confluent/usm-agent/usm-agent_access.log
    method: GET
- name: usm_agent_application_logs
  endpoint:
    path: /var/log/confluent/usm-agent/usm-agent_application.log
    method: GET
- name: usm_agent_traffic_captures
  endpoint:
    path: /var/log/confluent/usm-agent/tap/
    method: GET
- name: example_resource
  endpoint:
    path: /services/data/vXX.X/sobjects/ExampleResource
    method: GET
    data_selector: records
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: environments
  endpoint:
    path: /org/v2/environments
    method: GET
    data_selector: data
    params: {}
- name: environment
  endpoint:
    path: /org/v2/environments/{id}
    method: GET
    data_selector: display_name
    params: {}
- name: environment
  endpoint:
    path: /org/v2/environments/{env-2jjwwq}
    method: PATCH
    data_selector: stream_governance_config
    params:
      governance-package: advanced
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: topics
  endpoint:
    path: /v1/topics
    method: GET
    data_selector: data
    params: {}
- name: Stream Lineage Roles
  endpoint:
    path: /access-control/rbac/roles
    method: GET
    data_selector: roles
    params: {}
- name: audit_logs
  endpoint:
    path: /audit-logs
    method: GET
    data_selector: records
- name: billing
  endpoint:
    path: /billing
    method: GET
    data_selector: records
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: entities
  endpoint:
    path: /api/v1/entities
    method: GET
    data_selector: records
- name: tags
  endpoint:
    path: /api/v1/tags
    method: GET
    data_selector: records
- name: business_metadata
  endpoint:
    path: /api/v1/business_metadata
    method: GET
    data_selector: records
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: audit_logs
  endpoint:
    path: /audit-logs
    method: GET
    data_selector: records
- name: tagdefs
  endpoint:
    path: /catalog/v1/types/tagdefs
    method: GET
    data_selector: records
    params: {}
- name: search
  endpoint:
    path: /catalog/v1/search/basic
    method: GET
    data_selector: entities
    params: {}
- name: tags
  endpoint:
    path: /catalog/v1/entity/tags
    method: POST
    data_selector: entityType
    params: {}
- name: tag_attributes
  endpoint:
    path: /catalog/v1/entity/type/sr_field/name/{entityName}/tags
    method: GET
    data_selector: entityType
    params: {}
- name: tag_schema_version
  endpoint:
    path: /catalog/v1/entity/tags
    method: POST
    data_selector: entityType
    params: {}
- name: search_schemas
  endpoint:
    path: /catalog/v1/search/basic
    method: GET
    data_selector: entities
    params:
      types: sr_schema
- name: list_topics
  endpoint:
    path: /catalog/v1/search/basic
    method: GET
    data_selector: entities
    params:
      types: kafka_topic
- name: search_topics_by_tag
  endpoint:
    path: /catalog/v1/search/basic
    method: GET
    data_selector: entities
    params:
      type: kafka_topic
- name: connectors
  endpoint:
    path: /catalog/v1/search/basic
    method: GET
    data_selector: entities
    params:
      types: cn_connector
- name: business_metadata_definition
  endpoint:
    path: /catalog/v1/types/businessmetadatadefs
    method: POST
    data_selector: records
- name: schema
  endpoint:
    path: /subjects/{subject-name}/versions
    method: POST
    data_selector: records
- name: business_metadata
  endpoint:
    path: /catalog/v1/entity/businessmetadata
    method: POST
    data_selector: attributes
    params: {}
- name: search_business_metadata
  endpoint:
    path: /catalog/v1/search/attribute
    method: GET
    data_selector: entities
    params: {}
- name: remove_business_metadata
  endpoint:
    path: /catalog/v1/entity/type/sr_schema/name/{entityName}/businessmetadata/team
    method: DELETE
    data_selector: response
    params: {}
- name: delete_business_metadata_definition
  endpoint:
    path: /catalog/v1/types/businessmetadatadefs/{typeName}
    method: DELETE
    data_selector: response
    params: {}
- name: topic
  endpoint:
    path: /api/v1/topics
    method: GET
    data_selector: data
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: service_quota
  endpoint:
    path: /service-quotas
    method: GET
    data_selector: quotas
- name: billing_metrics
  endpoint:
    path: /billing/metrics
    method: GET
    data_selector: metrics
- name: topic
  endpoint:
    path: /v1/topics
    method: GET
    data_selector: topics
    params: {}
- name: cluster
  endpoint:
    path: /v1/clusters
    method: GET
    data_selector: clusters
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: schemas
  endpoint:
    path: /schemas
    method: GET
    data_selector: records
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: schemas
  endpoint:
    path: /api/schemas
    method: GET
    data_selector: schemas
    params: {}
- name: schemas
  endpoint:
    path: /schemas
    method: GET
    data_selector: schemas
- name: inference
  endpoint:
    path: /inference
    method: POST
    data_selector: inferred_schema
- name: schemas
  endpoint:
    path: /schemas
    method: GET
    data_selector: records
- name: topics
  endpoint:
    path: /topics
    method: GET
    data_selector: records
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: topics
  endpoint:
    path: /v1/topics
    method: GET
    data_selector: data
- name: consumers
  endpoint:
    path: /v1/consumers
    method: GET
    data_selector: data
- name: topics
  endpoint:
    path: /v1/topics
    method: GET
    data_selector: data
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: subjects
  endpoint:
    path: /subjects
    method: DELETE
- name: subjects
  endpoint:
    path: /subjects
    method: GET
    data_selector: schemas
    params:
      deleted: 'true'
- name: audit_logs
  endpoint:
    path: /audit-logs
    method: GET
    data_selector: logs
- name: service_quota
  endpoint:
    path: /service-quotas
    method: GET
    data_selector: quotas
- name: Schema ID Validation Configuration
  endpoint:
    path: /schema-id-validation/config
    method: GET
    data_selector: configurations
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: exporter
  endpoint:
    path: /schema-registry/exporter
    method: POST
    data_selector: exporter
    params: {}
- name: exporter_list
  endpoint:
    path: /schema-registry/exporter/list
    method: GET
    data_selector: exporters
    params: {}
- name: exporter_status
  endpoint:
    path: /schema-registry/exporter/status
    method: GET
    data_selector: status
    params: {}
- name: exporters
  endpoint:
    path: /exporters
    method: GET
    data_selector: exporters
- name: create_exporter
  endpoint:
    path: /exporters
    method: POST
    data_selector: exporter
- name: exporter_info
  endpoint:
    path: /exporters/{name}
    method: GET
    data_selector: exporter
- name: exporter_config
  endpoint:
    path: /exporters/{name}/config
    method: GET
    data_selector: config
- name: exporter_status
  endpoint:
    path: /exporters/{name}/status
    method: GET
    data_selector: status
- name: update_exporter
  endpoint:
    path: /exporters/{name}/config
    method: PUT
    data_selector: updated_exporter
- name: pause_exporter
  endpoint:
    path: /exporters/{name}/pause
    method: PUT
    data_selector: paused_exporter
- name: resume_exporter
  endpoint:
    path: /exporters/{name}/resume
    method: PUT
    data_selector: resumed_exporter
- name: reset_exporter
  endpoint:
    path: /exporters/{name}/reset
    method: PUT
    data_selector: reset_exporter
- name: delete_exporter
  endpoint:
    path: /exporters/{name}
    method: DELETE
    data_selector: deleted_exporter
- name: topics
  endpoint:
    path: /v1/topics
    method: GET
    data_selector: topics
    params: {}
- name: schemas
  endpoint:
    path: /v1/schemas
    method: GET
    data_selector: schemas
    params: {}
- name: exporter
  endpoint:
    path: /schema-registry/exporters
    method: GET
    data_selector: exporters
    params: {}
- name: exporter_status
  endpoint:
    path: /schema-registry/exporter/status
    method: GET
    data_selector: status
    params: {}
- name: exporter_configuration
  endpoint:
    path: /schema-registry/exporter/configuration
    method: GET
    data_selector: configuration
    params: {}
- name: oauth-exporter
  endpoint:
    path: /schema-registry/exporter
    method: CREATE
    data_selector: exporter
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: exporter
  endpoint:
    path: /schema-registry/exporter
    method: GET
- name: exporters
  endpoint:
    path: /exporters
    method: GET
- name: exporter_info
  endpoint:
    path: /exporters/{name}
    method: GET
- name: exporter_config
  endpoint:
    path: /exporters/{name}/config
    method: GET
- name: exporter_status
  endpoint:
    path: /exporters/{name}/status
    method: GET
- name: update_exporter
  endpoint:
    path: /exporters/{name}/config
    method: PUT
- name: pause_exporter
  endpoint:
    path: /exporters/{name}/pause
    method: PUT
- name: resume_exporter
  endpoint:
    path: /exporters/{name}/resume
    method: PUT
- name: reset_exporter
  endpoint:
    path: /exporters/{name}/reset
    method: PUT
- name: delete_exporter
  endpoint:
    path: /exporters/{name}
    method: DELETE
- name: oauth-exporter
  endpoint:
    path: /exporter
    method: POST
    data_selector: config
- name: schema_registry
  endpoint:
    path: /schemas
    method: GET
    data_selector: records
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: exporter
  endpoint:
    path: /schema-registry/exporter
    method: GET
- name: subjects
  endpoint:
    path: /subjects
    method: GET
- name: schemas
  endpoint:
    path: /schemas
    method: GET
- name: exporters
  endpoint:
    path: /exporters
    method: GET
- name: create_exporter
  endpoint:
    path: /exporters
    method: POST
- name: exporter_info
  endpoint:
    path: /exporters/{name}
    method: GET
- name: exporter_config
  endpoint:
    path: /exporters/{name}/config
    method: GET
- name: exporter_status
  endpoint:
    path: /exporters/{name}/status
    method: GET
- name: update_exporter
  endpoint:
    path: /exporters/{name}/config
    method: PUT
- name: pause_exporter
  endpoint:
    path: /exporters/{name}/pause
    method: PUT
- name: resume_exporter
  endpoint:
    path: /exporters/{name}/resume
    method: PUT
- name: reset_exporter
  endpoint:
    path: /exporters/{name}/reset
    method: PUT
- name: delete_exporter
  endpoint:
    path: /exporters/{name}
    method: DELETE
- name: oauth-exporter
  endpoint:
    path: /api/v1/exporters
    method: POST
    data_selector: exporter
- name: streams
  endpoint:
    path: /streams
    method: GET
    data_selector: records
    params: {}
- name: kafka_topic
  endpoint:
    path: /v1/topics
    method: GET
    data_selector: topics
    params: {}
- name: schema_registry
  endpoint:
    path: /schema-registry
    method: GET
- name: stream
  endpoint:
    path: /v1/streams
    method: GET
    data_selector: data
    params:
      incremental: updated_at
- name: topic
  endpoint:
    path: /v1/topics
    method: GET
    data_selector: data
    params: {}
- name: service_quota
  endpoint:
    path: /v1/service-quotas
    method: GET
    data_selector: quotas
    params: {}
- name: transactions
  endpoint:
    path: /subjects/transactions-value/versions/latest
    method: GET
    data_selector: schema
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: topic
  endpoint:
    path: /v1/topics
    method: GET
    data_selector: topics
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: stocks-value
  endpoint:
    path: /subjects/stocks-value/versions/latest
    method: GET
- name: Schema Registration
  endpoint:
    path: '/subjects/(string: subject)/versions'
    method: POST
- name: Schema Lookup
  endpoint:
    path: '/subjects/(string: subject)'
    method: POST
- name: topics
  endpoint:
    path: /v1/topics
    method: GET
    data_selector: data
    params: {}
- name: clusters
  endpoint:
    path: /v1/clusters
    method: GET
    data_selector: data
    params: {}
- name: topics
  endpoint:
    path: /v1/topics
    method: GET
    data_selector: data
    params: {}
- name: clusters
  endpoint:
    path: /v1/clusters
    method: GET
    data_selector: data
    params: {}
- name: user_accounts
  endpoint:
    path: /user-accounts
    method: GET
    data_selector: records
- name: referenced_by
  endpoint:
    path: /subjects/{subject}/versions/{version}/referencedby
    method: GET
- name: schemas_ids
  endpoint:
    path: /schemas/ids/{id}/versions
    method: GET
- name: stocks
  endpoint:
    path: /subjects/stocks-value/versions/latest
    method: GET
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: Kafka Producer
  endpoint:
    path: /kafka/producer
    method: POST
    data_selector: records
- name: Kafka Consumer
  endpoint:
    path: /kafka/consumer
    method: GET
    data_selector: records
- name: schemas
  endpoint:
    path: /schemas/types
    method: GET
    data_selector: types
    params: {}
- name: transactions-avro
  endpoint:
    path: /subjects/transactions-avro-value/versions/latest
    method: GET
    data_selector: schema
    params: {}
- name: cluster
  endpoint:
    path: /clusters
    method: GET
    data_selector: clusters
    params: {}
- name: topic
  endpoint:
    path: /topics
    method: GET
    data_selector: topics
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: schemas_types
  endpoint:
    path: /schemas/types
    method: GET
    data_selector: schemas
    params: {}
- name: transactions_proto_value
  endpoint:
    path: /subjects/transactions-proto-value/versions/latest/schema
    method: GET
    data_selector: schema
    params: {}
- name: kafka_clusters
  endpoint:
    path: /v1/clusters
    method: GET
    data_selector: clusters
- name: schemas
  endpoint:
    path: /v1/schemas
    method: GET
    data_selector: schemas
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: KafkaJsonSchemaSerializer
  endpoint:
    path: /serializer
    method: POST
- name: KafkaJsonSchemaDeserializer
  endpoint:
    path: /deserializer
    method: POST
- name: schemas
  endpoint:
    path: /schemas/types
    method: GET
    data_selector: types
    params: {}
- name: compatibility
  endpoint:
    path: /config
    method: GET
    data_selector: compatibilityLevel
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: schema_registry_config
  endpoint:
    path: /config
    method: PUT
    data_selector: defaultRuleSet
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: topic
  endpoint:
    path: /v1/topics
    method: GET
    data_selector: data
    params:
      incremental: updated_at
- name: audit_logs
  endpoint:
    path: /audit-logs
    method: GET
    data_selector: records
    params: {}
- name: kafka_topics
  endpoint:
    path: /kafka/v3/topics
    method: GET
    data_selector: data
- name: kafka_consumer_groups
  endpoint:
    path: /kafka/v3/consumer-groups
    method: GET
    data_selector: data
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: schema_registry
  endpoint:
    path: /schemas
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: user_accounts
  endpoint:
    path: /user-accounts
    method: GET
    data_selector: accounts
    params: {}
- name: workload_identities
  endpoint:
    path: /workload-identities
    method: GET
    data_selector: identities
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
- name: schemas
  endpoint:
    path: /schemas
    method: GET
    data_selector: ''
    params: {}
- name: subjects
  endpoint:
    path: /subjects
    method: GET
    data_selector: ''
    params: {}
- name: schema_by_id
  endpoint:
    path: /schemas/ids/{schema-ID}
    method: GET
    data_selector: ''
    params: {}
- name: schema_by_id_schema
  endpoint:
    path: /schemas/ids/{schema-ID}/schema
    method: GET
    data_selector: ''
    params: {}
- name: subjects_for_schema_id
  endpoint:
    path: /schemas/ids/{schema-ID}/subjects
    method: GET
    data_selector: ''
    params: {}
- name: versions_for_schema_id
  endpoint:
    path: /schemas/ids/{schema-ID}/versions
    method: GET
    data_selector: ''
    params: {}
- name: list_subjects
  endpoint:
    path: /subjects
    method: GET
    data_selector: ''
    params: {}
- name: schema_by_version
  endpoint:
    path: /subjects/{subject}/versions/{version}
    method: GET
    data_selector: ''
    params: {}
- name: list_schemas_referencing_a_schema
  endpoint:
    path: /subjects/{subject}/versions/{version}/referencedby
    method: GET
- name: get_schema_string_by_version
  endpoint:
    path: /subjects/{subject}/versions/{version}/schema
    method: GET
- name: list_versions_under_subject
  endpoint:
    path: /subjects/{subject}/versions
    method: GET
- name: register_schema_under_a_subject
  endpoint:
    path: /subjects/{subject}/versions
    method: POST
- name: lookup_schema_under_subject
  endpoint:
    path: /subjects/{subject}
    method: POST
- name: delete_a_subject
  endpoint:
    path: /subjects/{subject}
    method: DELETE
- name: delete_version_of_schema
  endpoint:
    path: /subjects/{subject}/versions/{version}
    method: DELETE
- name: get_global_compatibility_level
  endpoint:
    path: /config
    method: GET
- name: update_global_compatibility_level
  endpoint:
    path: /config
    method: PUT
- name: get_compatibility_level_on_subject
  endpoint:
    path: /config/{subject}
    method: GET
- name: update_subject_compatibility_level
  endpoint:
    path: /config/{subject}
    method: PUT
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: audit_logs
  endpoint:
    path: /audit-logs
    method: GET
    data_selector: logs
    params: {}
- name: kafka_cluster
  endpoint:
    path: /kafka/clusters
    method: GET
    data_selector: clusters
- name: schema_registry_cluster
  endpoint:
    path: /schema-registry/clusters
    method: GET
    data_selector: clusters
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: download
  endpoint:
    path: schema-registry:download
    method: POST
    data_selector: schemas
    params:
      schemaRegistryUrls: http://192.168.99.100:8081
      outputDirectory: src/main/avro
      subjectPatterns:
      - ^TestSubject000-(key|value)$
- name: set-compatibility
  endpoint:
    path: schema-registry:set-compatibility
    method: POST
    data_selector: compatibilityLevels
    params:
      schemaRegistryUrls: http://192.168.99.100:8081
      compatibilityLevels:
        order: BACKWARD
        product: FORWARD_TRANSITIVE
        customer: null
        __GLOBAL: BACKWARD_TRANSITIVE
- name: test-local-compatibility
  endpoint:
    path: schema-registry:test-local-compatibility
    method: POST
    data_selector: compatibilityLevels
    params:
      schemas:
        order: src/main/avro/order.avsc
        product: src/main/avro/product.avsc
        customer: src/main/avro/customer.avsc
      previousSchemaPaths:
        order: src/main/avro/order.avsc
        product: src/main/avro/products/
        customer: src/main/avro/customer.avsc
      compatibilityLevels:
        order: BACKWARD
        product: FORWARD
        customer: NONE
- name: test-compatibility
  endpoint:
    path: schema-registry:test-compatibility
    method: POST
    data_selector: subjects
    params:
      schemaRegistryUrls: http://192.168.99.100:8081
      subjects:
        order: src/main/avro/order.avsc
        product: src/main/avro/product.avsc
        customer: src/main/avro/customer.avsc
- name: derive-schema
  endpoint:
    path: schema-registry:derive-schema
    method: POST
    data_selector: schema
    params:
      messagePath: path/to/messages.json
      outputPath: path/to/output/schema.avsc
- name: customer
  endpoint:
    path: src/main/avro/customer.avsc
    method: POST
    data_selector: schemas
    params: {}
- name: order
  endpoint:
    path: src/main/avro/order.avsc
    method: POST
    data_selector: schemas
    params: {}
- name: flight
  endpoint:
    path: src/main/resources/flight.proto
    method: POST
    data_selector: schemas
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: schemas
  endpoint:
    path: /api/schemas
    method: GET
    data_selector: schemas
    params: {}
- name: Amazon CloudWatch Logs Source
  endpoint:
    path: /connectors/amazon-cloudwatch-logs-source
    method: GET
- name: Amazon CloudWatch Metrics Sink
  endpoint:
    path: /connectors/amazon-cloudwatch-metrics-sink
    method: GET
- name: Amazon DynamoDB Sink
  endpoint:
    path: /connectors/amazon-dynamodb-sink
    method: GET
- name: Amazon Kinesis Source
  endpoint:
    path: /connectors/amazon-kinesis-source
    method: GET
- name: Amazon Redshift Sink
  endpoint:
    path: /connectors/amazon-redshift-sink
    method: GET
- name: Amazon S3 Sink
  endpoint:
    path: /connectors/amazon-s3-sink
    method: GET
- name: Amazon S3 Source
  endpoint:
    path: /connectors/amazon-s3-source
    method: GET
- name: Amazon SQS Source
  endpoint:
    path: /connectors/amazon-sqs-source
    method: GET
- name: AWS Lambda Sink
  endpoint:
    path: /connectors/aws-lambda-sink
    method: GET
- name: Azure Blob Storage Sink
  endpoint:
    path: /connectors/azure-blob-storage-sink
    method: GET
- name: Azure Blob Storage Source
  endpoint:
    path: /connectors/azure-blob-storage-source
    method: GET
- name: Azure Cognitive Search Sink
  endpoint:
    path: /connectors/azure-cognitive-search-sink
    method: GET
- name: Azure Cosmos DB Sink
  endpoint:
    path: /connectors/azure-cosmos-db-sink
    method: GET
- name: Azure Event Hubs Source
  endpoint:
    path: /connectors/azure-event-hubs-source
    method: GET
- name: ClickHouse Sink
  endpoint:
    path: /connectors/clickhouse-sink
    method: GET
- name: Couchbase Source
  endpoint:
    path: /connectors/couchbase-source
    method: GET
- name: Datadog Metrics Sink
  endpoint:
    path: /connectors/datadog-metrics-sink
    method: GET
- name: Elasticsearch Service Sink
  endpoint:
    path: /connectors/elasticsearch-service-sink
    method: GET
- name: GitHub Source
  endpoint:
    path: /connectors/github-source
    method: GET
- name: Google Cloud Pub/Sub Source
  endpoint:
    path: /connectors/google-cloud-pubsub-source
    method: GET
- name: HTTP Sink
  endpoint:
    path: /connectors/http-sink
    method: GET
- name: HTTP Source
  endpoint:
    path: /connectors/http-source
    method: GET
- name: Jira Source
  endpoint:
    path: /connectors/jira-source
    method: GET
- name: Microsoft SQL Server Source
  endpoint:
    path: /connectors/microsoft-sql-server-source
    method: GET
- name: MongoDB Atlas Sink
  endpoint:
    path: /connectors/mongodb-atlas-sink
    method: GET
- name: MySQL Source
  endpoint:
    path: /connectors/mysql-source
    method: GET
- name: New Relic Metrics Sink
  endpoint:
    path: /connectors/new-relic-metrics-sink
    method: GET
- name: Salesforce SObject Sink
  endpoint:
    path: /connectors/salesforce-sobject-sink
    method: GET
- name: ServiceNow Source
  endpoint:
    path: /connectors/servicenow-source
    method: GET
- name: Snowflake Sink
  endpoint:
    path: /connectors/snowflake-sink
    method: GET
- name: example_resource
  endpoint:
    path: /services/data/vXX.X/sobjects/ExampleResource
    method: GET
    data_selector: records
    params: {}
- name: ActiveMQSource
  endpoint:
    path: /connectors
    method: POST
    data_selector: connector
    params: {}
- name: schemas
  endpoint:
    path: /schemas
    method: GET
    data_selector: records
    params: {}
- name: AlloyDbSinkConnector_0
  endpoint:
    path: /connectors
    method: POST
- name: kafka_cluster
  endpoint:
    path: /v1/clusters
    method: GET
    data_selector: clusters
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: cloudwatch-logs
  endpoint:
    path: /services/data/vXX.X/sobjects/CloudWatchLogs
    method: GET
    data_selector: records
- name: schemas
  endpoint:
    path: /api/schemas
    method: GET
    data_selector: records
- name: CloudWatchMetricsSink_0
  endpoint:
    path: /services/data/vXX.X/sobjects/CloudWatchMetricsSink
    method: POST
    data_selector: records
    params: {}
- name: DynamoDB
  endpoint:
    path: /
    method: GET
    data_selector: records
- name: NumTable
  endpoint:
    path: /services/data/vXX.X/sobjects/NumTable
    method: GET
    data_selector: records
    params: {}
- name: DynamoDbCdcSourceConnector_0
  endpoint:
    path: /connectors/DynamoDbCdcSourceConnector_0
    method: POST
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
- name: dynamodb
  endpoint:
    path: /services/data/vXX.X/sobjects/DynamoDB
    method: POST
    data_selector: records
    params:
      aws.dynamodb.pk.hash: partition
      aws.dynamodb.pk.sort: offset
- name: DynamoDbSinkConnector_0
  endpoint:
    path: /connectors
    method: POST
    data_selector: config
    params: {}
- name: offsets
  endpoint:
    path: /connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors/{connector_name}/offsets
    method: GET
- name: offset_update
  endpoint:
    path: /connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors/{connector_name}/offsets/request
    method: POST
- name: offset_status
  endpoint:
    path: /connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors/{connector_name}/offsets/request/status
    method: GET
- name: kinesis-testing
  endpoint:
    path: ''
    method: ''
    data_selector: ''
    params: {}
- name: topics
  endpoint:
    path: /topics
    method: GET
    data_selector: records
    params: {}
- name: schemas
  endpoint:
    path: /schemas
    method: GET
    data_selector: records
    params: {}
- name: redshift-sink-connector
  endpoint:
    path: /connectors
    method: POST
    data_selector: connector
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: Kafka Cluster credentials
  endpoint:
    path: /connectors
    method: POST
    data_selector: connectors
    params: {}
- name: confluent-s3-sink-time
  endpoint:
    path: /connectors/confluent-s3-sink-time
    method: POST
    data_selector: properties
    params: {}
- name: confluent-s3-sink-field
  endpoint:
    path: /connectors/confluent-s3-sink-field
    method: POST
    data_selector: properties
    params: {}
- name: topics
  endpoint:
    path: /v1/topics
    method: GET
    data_selector: data
    params: {}
- name: confluent-s3-sink-time
  endpoint:
    path: /connectors/confluent-s3-sink-time
    method: POST
- name: confluent-s3-sink-field
  endpoint:
    path: /connectors/confluent-s3-sink-field
    method: POST
- name: dead_letter_queue
  endpoint:
    path: errors.deadletterqueue.topic.name
    method: GET
    data_selector: default
    params: {}
- name: schema_context
  endpoint:
    path: schema.context.name
    method: GET
    data_selector: default
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: PrivateLink Endpoint
  endpoint:
    path: /services/data/vXX.X/sobjects/PrivateLinkEndpoint
    method: POST
    data_selector: records
    params:
      name: Name of the PrivateLink Endpoint
      privateLinkServiceName: com.amazonaws.<region>.<service>
      highAvailability: 'true'
- name: DNS Record
  endpoint:
    path: /services/data/vXX.X/sobjects/DNSRecord
    method: POST
    data_selector: records
    params:
      accessPoint: Egress PrivateLink Endpoint created
      domain: <service>.<region>.amazonaws.com
- name: kafka_cluster
  endpoint:
    path: /clusters
    method: GET
    data_selector: clusters
    params: {}
- name: topics
  endpoint:
    path: /topics
    method: GET
    data_selector: topics
    params: {}
- name: offsets
  endpoint:
    path: /connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors/{connector_name}/offsets
    method: GET
- name: update_offset
  endpoint:
    path: /connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors/{connector_name}/offsets/request
    method: POST
- name: offset_status
  endpoint:
    path: /connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors/{connector_name}/offsets/request/status
    method: GET
- name: sqs
  endpoint:
    path: /123456789012/MyQueue
    method: GET
    data_selector: records
- name: sqs
  endpoint:
    path: /services/AmazonSQS
    method: GET
- name: topics
  endpoint:
    path: /api/v1/topics
    method: GET
    data_selector: data
    params: {}
- name: clusters
  endpoint:
    path: /api/v1/clusters
    method: GET
    data_selector: data
    params: {}
- name: success_topic
  endpoint:
    path: /success-<connector-id>
    method: GET
- name: error_topic
  endpoint:
    path: /error-<connector-id>
    method: GET
- name: LambdaSinkConnector_0
  endpoint:
    path: /connectors
    method: POST
- name: schemas
  endpoint:
    path: /schemas
    method: GET
    data_selector: records
    params: {}
- name: topics
  endpoint:
    path: /topics
    method: GET
    data_selector: records
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
- name: confluent-azure-blob-sink-time
  endpoint:
    method: POST
    data_selector: properties
    params: {}
- name: confluent-azure-blob-sink-field
  endpoint:
    method: POST
    data_selector: properties
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: confluent-azure-blob-sink-time
  endpoint:
    method: CREATE
    params:
      name: confluent-azure-blob-sink-time
      connector.class: AzureBlobSink
      kafka.auth.mode: KAFKA_API_KEY
      kafka.api.key: <my-kafka-api-key>
      kafka.api.secret: <my-kafka-api-secret>
      topics: pageviews
      input.data.format: AVRO
      azblob.account.name: <storage-account-name>
      azblob.account.key: <storage-account-key>
      azblob.container.name: <container-name>
      output.data.format: AVRO
      topics.dir: json_logs/daily
      partitioner.class: TimeBasedPartitioner
      locale: en
      timezone: UTC
      time.interval: DAILY
      flush.size: '1000'
      tasks.max: '1'
- name: confluent-azure-blob-sink-field
  endpoint:
    method: CREATE
    params:
      name: confluent-azure-blob-sink-field
      connector.class: AzureBlobSink
      kafka.auth.mode: KAFKA_API_KEY
      kafka.api.key: <my-kafka-api-key>
      kafka.api.secret: <my-kafka-api-secret>
      topics: <topic-1>, <topic-2>
      input.data.format: AVRO
      azblob.account.name: <storage-account-name>
      azblob.account.key: <storage-account-key>
      azblob.container.name: <container-name>
      output.data.format: AVRO
      partitioner.class: FieldPartitioner
      partition.field.name: <field-name-1>,<field-name-2>
      flush.size: '1000'
      tasks.max: '2'
- name: topics
  endpoint:
    path: /api/v1/topics
    method: GET
    data_selector: data
    params: {}
- name: Egress Private Link Endpoint
  endpoint:
    path: /create/egress-private-link-endpoint
    method: POST
    data_selector: endpointDetails
    params: {}
- name: DNS Record
  endpoint:
    path: /create/dns-record
    method: POST
    data_selector: dnsRecordDetails
    params: {}
- name: offsets
  endpoint:
    path: /connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors/{connector_name}/offsets
    method: GET
- name: offset_update
  endpoint:
    path: /connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors/{connector_name}/offsets/request
    method: POST
- name: offset_status
  endpoint:
    path: /connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors/{connector_name}/offsets/request/status
    method: GET
- name: AzureBlobSource
  endpoint:
    path: /path/to/azure/blob/storage
    method: GET
- name: topic
  endpoint:
    path: /topics
    method: GET
    data_selector: topics
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: AzureCognitiveSearchSink_0
  endpoint:
    path: /services/data/vXX.X/sobjects/AzureCognitiveSearchSink
    method: GET
- name: CosmosDbSinkConnector_0
  endpoint:
    path: /connectors
    method: POST
    data_selector: config
    params:
      topics: pageviews
      connect.cosmos.containers.topicmap: pageviews#Container2
      connect.cosmos.databasename: myDBname
      connect.cosmos.master.key: '****************************************'
      connect.cosmos.connection.endpoint: https://myaccount.documents.azure.com:443/
      input.data.format: AVRO
      cosmos.id.strategy: FullKeyStrategy
      tasks.max: '1'
- name: topics
  endpoint:
    path: /topics
    method: GET
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: CosmosDbSinkV2Connector_0
  endpoint:
    path: /services/data/vXX.X/sobjects/CosmosDbSinkV2
    method: GET
    data_selector: records
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: offsets
  endpoint:
    path: /connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors/{connector_name}/offsets
    method: GET
    data_selector: offsets
- name: update_offsets
  endpoint:
    path: /connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors/{connector_name}/offsets/request
    method: POST
    data_selector: offsets
- name: delete_offsets
  endpoint:
    path: /connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors/{connector_name}/offsets/request
    method: POST
    data_selector: offsets
- name: get_offset_status
  endpoint:
    path: /connect/v1/environments/{environment_id}/clusters/{kafka_cluster_id}/connectors/{connector_name}/offsets/request/status
    method: GET
    data_selector: status
- name: CosmosDbSourceV2Connector_0
  endpoint:
    path: /services/data/vXX.X/sobjects/CosmosDbSourceV2
    method: GET
    data_selector: records
    params: {}
- name: kafka_cluster
  endpoint:
    path: /v1/clusters
    method: GET
    data_selector: clusters
    params: {}
- name: schema_registry
  endpoint:
    path: /v1/schemas
    method: GET
    data_selector: schemas
    params: {}
- name: adls-sink-connector
  endpoint:
    path: /connectors/adls-sink-connector
    method: POST
    data_selector: records
    params: {}
- name: azure-eventhubs-source
  endpoint:
    path: /connectors/azure-eventhubs-source
    method: POST
    data_selector: connector
    params: {}
- name: kafka_cluster
  endpoint:
    path: /clusters
    method: GET
    data_selector: clusters
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
- name: AzureFunctionsSink
  endpoint:
    path: /api/HttpTrigger1
    method: POST
- name: topics
  endpoint:
    path: /v1/topics
    method: GET
    data_selector: data
    params: {}
- name: schemas
  endpoint:
    path: /v1/schemas
    method: GET
    data_selector: data
    params: {}
- name: AzureLogAnalyticsSink
  endpoint:
    path: /connectors
    method: POST
    data_selector: config
    params: {}
- name: AzureServiceBusSource
  endpoint:
    path: /connectors/azure-service-bus-source
    method: POST
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: AzureSqlDwSinkConnector_0
  endpoint:
    path: /connectors/AzureSqlDwSink
    method: POST
    data_selector: config
    params: {}
- name: kafka
  endpoint:
    path: /kafka
    method: GET
- name: topics
  endpoint:
    path: /v1/topics
    method: GET
    data_selector: data
    params: {}
- name: ClickHouse
  endpoint:
    path: /
    method: POST
    data_selector: records
- name: topic_to_table_mapping
  endpoint:
    topic2TableMap: your_topic_name=your_table_name
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: ClickHouse
  endpoint:
    path: /
    method: POST
    data_selector: records
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: ActiveMQ
  endpoint:
    path: /api/activemq
    method: GET
- name: Amazon S3
  endpoint:
    path: /api/s3
    method: GET
- name: kafka_clusters
  endpoint:
    path: /v2/clusters
    method: GET
    data_selector: clusters
    params: {}
- name: Egress PrivateLink Endpoint
  endpoint:
    path: /create/egress-privatelink-endpoint
    method: POST
    data_selector: endpoint
    params: {}
- name: DNS Record
  endpoint:
    path: /create/dns-record
    method: POST
    data_selector: dns_record
    params: {}
- name: kafka_cluster
  endpoint:
    path: /v1/clusters
    method: GET
    data_selector: data
    params: {}
- name: topic
  endpoint:
    path: /v1/topics
    method: GET
    data_selector: data
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: couchbase
  endpoint:
    path: /couchbase
    method: GET
    data_selector: records
    params: {}
- name: couchbase
  endpoint:
    path: /couchbase
    method: GET
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: Couchbase Capella private endpoint
  endpoint:
    path: /path/to/private/endpoint
    method: POST
    data_selector: endpoint_details
    params:
      VPC_ID: your-vpc-id
      Subnet_ID: your-subnet-id
- name: Confluent Cloud Egress PrivateLink Endpoint
  endpoint:
    path: /path/to/egress/privatelink/endpoint
    method: POST
    data_selector: endpoint_details
    params:
      Service: Couchbase
      Endpoint_Name: your-endpoint-name
      PrivateLink_service_name: your-private-link-service-name
      High_Availability: 'true'
- name: Kafka Topics
  endpoint:
    path: /topics
    method: GET
- name: Couchbase Collection
  endpoint:
    path: /couchbase/collection
    method: POST
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: topics
  endpoint:
    path: /v1/topics
    method: GET
    data_selector: data
    params: {}
- name: CouchbaseSinkConnector_0
  endpoint:
    path: /services/data/vXX.X/sobjects/CouchbaseSink
    method: GET
- name: topics
  endpoint:
    path: /v1/topics
    method: GET
    data_selector: data
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: Couchbase Capella private endpoint
  endpoint:
    path: /private-endpoints
    method: POST
    data_selector: endpoint
    params: {}
- name: Confluent Cloud Egress PrivateLink Endpoint
  endpoint:
    path: /egress-private-link-endpoints
    method: POST
    data_selector: endpoint
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: pageviews
  endpoint:
    path: /sql/protocolv1/o/123456789101112/1004-123456-voice40
    method: POST
- name: kafka_cluster
  endpoint:
    path: /api/clusters
    method: GET
    data_selector: clusters
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: pageviews
  endpoint:
    path: /sql/protocolv1/o/123456789101112/1004-123456-voice40
    method: GET
notes:
- Uses OAuth2 with refresh token  requires setup of connected app in api
- Some objects like Contact may return nulls in deeply nested fields
- Uses OAuth2 with refresh token  requires setup of connected app in Confluent Cloud
- Some API endpoints may have rate limits
- Data governance initiatives aim to manage the availability, integrity, and security
  of data used across an organization.
- This quick start gets you up and running with Confluent Cloud using a Basic Kafka
  cluster.
- A topic is a unit of organization for a cluster and is essentially an append-only
  log.
- Delete resources created to avoid unexpected charges to your account.
- Streaming mode is recommended for sending a batch of records.
- Non-streaming mode is not recommended for sending multiple records.
- Your VPC must be able to communicate with the Confluent Cloud Schema Registry public
  internet endpoint.
- The API key for Confluent Cloud Schema Registry is distinct from the API key you
  created for Kafka clusters.
- Some objects may return nulls in deeply nested fields
- Free credit expires after 30 days.
- If you do not enter a credit card or claim a Promo Code within 30 days of suspension,
  we delete your resources but preserve your organization and users.
- Requires setup of OAuth2 for accessing the API
- Ensure proper scope is set for OAuth2 tokens
- All scripted Confluent Cloud examples use real Confluent Cloud resources and may
  be billable.
- After you are done running a Confluent Cloud example, destroy all Confluent Cloud
  resources to avoid accruing hourly charges for services.
- All of these scripted Confluent Cloud examples use real Confluent Cloud resources
  and may be billable.
- Replicator must have authorization to read Kafka data from the origin cluster and
  write Kafka data in the destination Confluent Cloud cluster.
- Replicator should be run with a Confluent Cloud service account, not super user
  credentials.
- Confluent Replicator license topic must have replication factor set to 3 for Confluent
  Cloud
- New user topics that Confluent Replicator creates must have replication factor set
  to 3 for Confluent Cloud
- The origin on-premises Kafka cluster can have a varied set of security features
  enabled, but for simplicity in this example we show no security configurations,
  just PLAINTEXT.
- Set the management topics to replication factor of 3 as required by Confluent Cloud.
- By default, ccloud-stack does not enable Confluent Cloud ksqlDB, but if you explicitly
  enable it, hourly charges may apply.
- Requires setup of API access in Confluent Cloud
- Rate limits apply based on account type
- Confluent Cloud examples that use actual Confluent Cloud resources may be billable.
- If you just run `ccloud-stack` without explicitly enabling Confluent Cloud ksqlDB,
  then there is no billing charge until you create a topic, produce data to the Kafka
  cluster, or provision any other fully-managed service.
- Enable Private Networking with Schema Registry PrivateLink
- Enable Private Networking for Schema Registry with a Public Endpoint
- If you run `ccloud-stack` with enabling Confluent Cloud ksqlDB (1 CSU), then you
  will begin to accrue charges immediately.
- Any Confluent Cloud example uses real Confluent Cloud resources.
- After you are done running a Confluent Cloud example, manually verify that all Confluent
  Cloud resources are destroyed to avoid unexpected charges.
- Uses OAuth2 with refresh token  requires setup of connected app in Confluent
- This example uses real resources from other cloud providers, including AWS Kinesis
  or RDS PostgreSQL.
- Ensure that OAuth scopes are correctly configured.
- Check for any rate limits when making API requests.
- This example uses real resources from other cloud providers.
- Ensure proper authentication setup is done before integration.
- Ensure proper OAuth scopes are configured.
- Ensure OAuth scopes are correctly set for access.
- Always verify that resources in Confluent Cloud have been destroyed.
- Fully-managed data streaming platform with a cloud-native Kafka engine (KORA) for
  elastic scaling, with enterprise security, stream processing, governance.
- Requires OAuth2 authentication for API access
- API requests must include an authorization header with an API key and secret.
- The number of Confluent Unit for Kafka (CKU) determines the capacity of Dedicated
  clusters.
- Status phase may indicate provisioning state.
- Max page size for listing clusters is 100. Default is 10.
- Limitations on API call frequency apply
- Ensure proper configuration of OAuth clients for access.
- The Kafka cluster is provisioned in a SINGLE_ZONE availability.
- Specify the environment ID to list clusters.
- Max page size for clusters is 100.
- You cannot restore a deleted cluster.
- OAuth2 with refresh token requires setup of connected app in Confluent Cloud
- Freight clusters are currently available in select AWS regions.
- 'Freight clusters do not support the following: Idempotent producer, Transactions,
  DELETE_RECORDS, REPLICA_STATUS.'
- Performance per partition varies depending on your individual configuration, and
  these benchmarks do not guarantee performance.
- Requires setup of a connected app in Confluent Cloud.
- Some API calls may be rate-limited.
- You cannot edit cluster settings on Confluent Cloud on Basic, Standard, Enterprise,
  and Freight clusters.
- The default maximum timeout for registered consumers is 1200000 ms (20 minutes).
- Only single-zone Dedicated Kafka clusters are available in Jio regions.
- Stream Governance packages purchased in Jio regions support a maximum SLA of 99.95%.
- Azure VNet Peering for Dedicated clusters is the only private networking option
  available.
- No other features are supported in Jio regions.
- Uses OAuth2 for authentication
- Confluent Cloud architecture provides a centralized global control plane and multiple
  satellite instances.
- Cluster links must be created and managed on the destination cluster.
- Cluster links can only be created with destination clusters that are Dedicated or
  Enterprise Confluent Cloud clusters.
- Cluster Linking is fully-managed in Confluent Cloud, so you dont need to manage
  or tune data flows.
- Cluster Linking can use egress static IP addresses on AWS destination clusters.
- Cluster links on Confluent Cloud that use OAuth must be created using either the
  Confluent CLI or REST API.
- Do not delete a source topic for an active mirror topic, as it can cause issues
  with Cluster Linking.
- Kafka transactions such as 'exactly once' semantics not supported on mirror topics
- Limited access to promoted or failover topics while the source cluster is unavailable
- Requires setup of OAuth2 with a connected app in Confluent Cloud
- Ensure OAuth scopes are correctly set up for accessing resources
- A Confluent Cloud cluster has an hourly charge, and charges for any data into, out
  of, or stored on the cluster.
- Mirror topics are read-only.
- OAuth2 authentication is required for access
- Your destination cluster must be a Dedicated or Enterprise Confluent Cloud cluster
  with secure public endpoints.
- 'The source cluster must be one of the following cluster types: BASIC, BASIC_LEGACY,
  STANDARD, DEDICATED-with-secure-public-endpoints.'
- The mirror topic name (on the Destination) must be the same as the Source topic
  name.
- Make sure that you use the Destination cluster ID in the command to create the mirror
  topic.
- This tutorial covered a basic use case for sharing data across topics in the same
  or disparate clusters, regions, and clouds.
- Destination cluster must be a Dedicated cluster.
- Source cluster can be a Basic, Standard, Dedicated, or Enterprise cluster.
- Topic renaming is not yet supported.
- Cluster Linking is an asynchronous process, there may be lagged data.
- Consumers must tolerate a small number of duplicate messages.
- The default sync interval for consumer offsets is 30 seconds.
- The `truncate-and-restore` process truncates any divergent records written after
  the failover point.
- Requires a Dedicated Confluent Cloud cluster with Public internet.
- This tutorial requires Confluent Enterprise and is not supported in Confluent Community
  or Apache Kafka.
- Use a service account API key for production
- Ensure proper ACLs are set for cluster links
- A user or service account with CloudClusterAdmin RBAC role on the Tier 2 cluster
  is required.
- A service account with DeveloperRead and DeveloperManage permissions for the topics
  you want to replicate, or the ACLs to READ and DESCRIBE-CONFIGS on the topics that
  you want to replicate.
- When deleting a cluster link, check that all mirror topics are in the STOPPED state.
- Uses OAuth2 with refresh token  requires setup of connected app in api.
- API supports incremental loading based on timestamp.
- Confluent will make non-breaking changes to the schema without advance notice.
- Requires a valid Confluent Cloud account and API key
- Bidirectional cluster links sync consumer offsets from both regular topics and mirror
  topics.
- Both clusters must be configured to enable bidirectional links.
- ACL sync is only supported between two Confluent Cloud clusters that belong to the
  same Confluent Cloud organization.
- Ensure API key has appropriate permissions for access
- Bidirectional cluster links are not supported if either of the clusters is a Basic
  or Standard Confluent Cloud cluster.
- Both cluster link objects on both clusters must be deleted to stop data from flowing.
- Mirror topic names must be entered manually because the in-browser autocomplete
  does not work for bidirectional cluster links.
- Do not include in the sync filter ACLs that are managed independently on the destination
  cluster.
- Be careful not to forget the `"` characters and the ending `;`
- OAuth2 with refresh token is required
- Some API limits may apply based on the account type
- Mirror topics are created by and owned by a cluster link.
- Auto-creating mirror topics saves time and effort.
- Prefixing is not available on Confluent Platform version 7.1 or earlier.
- ACL syncing and prefixing cannot be enabled together on a single cluster link.
- The 'reverse' commands only work with hybrid links if the on-premises cluster is
  on Confluent Platform 7.7 or later.
- Do not attempt to use the Failback APIs with Terraform, as they do not support it.
- Do not delete a source topic that is being mirrored by a mirror topic.
- Using Schema Linking requires schemas to be in the default context of the Confluent
  Cloud Schema Registry.
- Cluster links must be between clusters in the same Confluent Cloud Organization.
  Cross-organization cluster linking between private networking clusters is not supported.
- This configuration does not support combinations with other networking types, such
  as PrivateLink, or with other cloud providers, such as Google Cloud or Microsoft
  Azure.
- A cluster link is created on the destination with certain configurations.
- This type of cluster link cannot be created on the Confluent Cloud Console.
- Multi-zone clusters are always recommended for clusters that run production traffic.
- Some enterprise companies require disaster recovery for only a single cloud region
  outage at a time.
- The cluster link requires only read ACLs on the source cluster.
- No ACLs or credentials are required on the destination cluster in Confluent Cloud.
- Cluster link requires specific RBAC roles or Kafka ACLs on the source cluster to
  read data and metadata.
- An existing cluster link can change its authentication mechanism from API Key to
  OAuth, or vice versa.
- The cluster link itself requires only read ACLs on the source cluster.
- When sharing data between teams, the owner of the source cluster can limit READ
  access to the mirror topics on the destination cluster on a topic-by-topic basis.
- Cluster Linking in Confluent Cloud supports both single-cloud and multi-cloud deployments
  for clusters with private networking.
- Metrics on Enterprise and high link count clusters may lack link_name.
- Bidirectional and source-initiated links are unsupported on Enterprise clusters
  in the same region.
- Cluster Linking has asynchronous replication, meaning it does not have an RPO==0
  option out-of-the-box.
- Cluster Linking works with compacted topics; which are mirrored as such from source
  to destination.
- Bidirectional links between two clusters is possible as long as you are mirroring
  different topics.
- Cluster Linking preserves the same number of partitions on any topics it mirrors.
- Cluster Linking cannot create a circular dependency or infinite loop.
- Some objects may require specific access permissions
- 'Failure causes that can be repaired include the following:'
- 'UNSUPPORTED_MESSAGE_FORMAT: Source leader epoch went backwards, source topic may
  have been recreated.'
- 'RECORD_TOO_LARGE: Truncation below high watermark. This can be caused by unclean
  source leader election or other errors such as inability to detect source topic
  recreation.'
- TRUNCATION_BELOW_HIGH_WATERMARK
- Requires setup of connected app in Confluent Cloud
- API responses may vary based on account permissions
- Replace `bootstrap.servers` and `sasl.jaas.config` here with the corresponding values
  for the Confluent Cloud clusters.
- Replace bootstrap.servers and sasl.jaas.config with the corresponding values for
  the Confluent Cloud clusters.
- In replication.properties, replace 'Movies' for the topic.whitelist with the topics
  you want to replicate.
- Confluent Platform is required for these workflows because Replicator is bundled
  with Confluent Platform.
- Fully-managed data streaming platform with a cloud-native Kafka engine
- Most clusters are provisioned in less than two hours.
- Resizing a cluster on average takes about 30-60 minutes per CKU.
- Client Quotas can be used to support multi-tenancy by rate limiting distinct applications
  as necessary.
- Requires setup of connected app in API
- Requires Confluent Cloud administrator account to create and manage quotas.
- Ensure to use the latest API version for optimal performance
- Ensure correct OAuth scopes are configured in the connected app.
- For detailed instructions, click the link for the component you want to connect.
- Confluent for Kubernetes provides a cloud-native and automated way to deploy Confluent
  Platform components connected to Confluent Cloud.
- The confluent.metrics.topic.max.message.bytes property must be set to 8388608.
- Uses OAuth2 with client credentials  requires setup of a service account in Confluent
  Cloud.
- Control Center (Legacy) does not show system health details. This is because Confluent
  Cloud does not provide the instrumentation from Confluent Metrics Reporter outside
  of the Confluent Cloud. Confluent Platform internally monitors the system and broker
  health and takes actions based on that monitoring. We recommend you enable Reduced
  infrastructure mode for Control Center (Legacy).
- Topics hosted in Confluent Cloud and viewed in Control Center (Legacy) do not display
  Availability, Offset and Size values on their Topics detail page. In this scenario,
  these fields display 0.
- Control Center (Legacy) requires an Apache Kafka cluster to store data. Control
  Center (Legacy) creates partitions for data storage, that count toward partition
  limits, and data throughput within Confluent Cloud.
- When a Control Center (Legacy) cluster is bootstrapped to Confluent Cloud, no metrics
  are available for the cluster. Therefore, metrics alerts do not work as expected.
- Some API calls may have rate limits
- Ensure you have installed the librdkafka library on your system or included it in
  your projects build process.
- For librdkafka v2.11 or later, ssl.ca.location is typically not required.
- Ensure OAuth scopes are configured correctly for access.
- You must manually create topics for source connectors to write to.
- Some API endpoints may have specific rate limits
- You must include certain properties in the connector configuration if using enterprise
  license.
- You must include the following properties in the connector configuration if you
  are using a self-managed connector that requires an enterprise license.
- Save the API key and secret. You need this information to configure your applications
  that communicate with Confluent Cloud.
- If set to true, API requests that fail will include extra debugging information,
  including stack traces.
- 'REQUIRED: Specifies the bootstrap servers for your Kafka cluster. It is used for
  selecting the primary Schema Registry instance and for storing the registered schema
  data.'
- 'REQUIRED: Specifies Confluent Cloud authentication.'
- Configures Schema Registry to use SASL authentication.
- Configures Schema Registry for SSL encryption.
- Specifies the name of the topic to store schemas in.
- You cannot use the ~/.ccloud/config.json generated by Confluent Cloud CLI for other
  Confluent Platform components or clients.
- Requires setup of connected app in api
- Check API key scope and cluster binding.
- Verify API key and secret and security protocol configuration.
- Ensure proper networking setup for private clusters.
- Verify correct endpoint from cluster settings.
- Some operations may require specific permissions.
- Rate limits apply to API requests.
- Ensure client credentials are correctly configured in secrets.
- API calls are rate-limited.
- Confluent recommends upgrading to the latest client since current fixes are generally
  not found in older clients.
- All connections to Confluent Cloud are encrypted using Transport Layer Security
  (TLS)
- Self-managed encryption keys must be configured when creating Enterprise or Dedicated
  clusters.
- You cannot switch between automatic (default) and self-managed encryption modes
  after cluster provisioning.
- Some objects like Topic may return nulls in deeply nested fields
- Uses OAuth2
- CSFLE provides the strongest data protection by encrypting sensitive fields before
  data leaves your applications.
- Choose CSFLE for applications that handle highly sensitive data (financial, healthcare,
  government).
- Use client quotas to prevent resource contention.
- Implement audit logging for security monitoring and compliance
- Automate compliance report generation for regulatory requirements (SOX, GDPR, HIPAA)
- Design audit log queries and playbooks for security incident investigation
- Track authentication patterns, failed login attempts, and privilege escalation
- Monitor for unusual access patterns, cross-region activity, and resource access
  anomalies
- Implement automated checking for security policy violations and configuration drift
- Uses OAuth2 with refresh token for authentication.
- All clients that connect to Confluent Cloud must support SASL_PLAIN or SASL_OAUTHBEARER
  (with OAuth-OIDC configured) and TLS 1.2 encryption.
- Avoid intermediate certificate pinning because it can introduce connection failures.
- Uses API key and secret for authentication
- API requires setup of connected app in Confluent Cloud
- Ensure to set up OAuth credentials in the Confluent Cloud console
- All clients must support TLS 1.2 encryption and either SASL_PLAIN or SASL_OAUTHBEARER
  authentication.
- Access to Confluent Cloud with an active cluster is required
- API key and secret must be saved after creation
- The new consumer rebalance protocol improves consumer group scalability by removing
  the group-wide synchronization barrier.
- Some APIs may have rate limits
- Share groups are available to Java clients only.
- Confluent Cloud users cannot set broker configuration properties.
- The handling of transactional records in share groups is governed by the share.isolation.level
  configuration property, which applies to the entire share group.
- You are required to set bootstrap.servers property to find the Kafka cluster.
- client.id is optional but recommended for debugging.
- Supports Transport Layer Security (TLS) encryption.
- Clients must include a Server Name Indication (SNI) extension in the TLS handshake.
- 'Additional considerations specifically for Confluent Cloud: Network throughput
  and latency, Separate environments for development, testing, and production, Cloud-specific
  security authentication and authorization'
- Some endpoints may have rate limits that need to be considered.
- Some API endpoints may require specific permissions.
- Rate limits are enforced on all API calls.
- Resetting consumer offsets requires the ability to read from topics and modify consumer
  group configurations.
- Benchmark testing is important because there is no one-size-fits-all recommendation
  for the configuration parameters you need to develop Kafka applications to Confluent
  Cloud.
- You should run benchmark tests if you plan to tune Kafka clients beyond the defaults.
- Manage SSO configurations and troubleshoot related issues.
- To optimize for throughput, producers and consumers must move as much data as possible
  within a given amount of time.
- Higher number of topic partitions results in higher throughput.
- Larger batch sizes result in fewer requests to Confluent Cloud.
- Compression is applied on full batches of data.
- Ensure correct OAuth2 setup for Confluent Cloud
- Ensure proper OAuth scopes are configured for the application.
- Producers automatically batch messages.
- Enabling compression requires more CPU cycles, but reduces network bandwidth usage.
- Uses OAuth2 with refresh token
- Confluent Cloud enforces a replication factor of 3 to ensure data durability.
- Users must have appropriate permissions to access the resources.
- Increase session.timeout.ms (default 45000)
- 'num.standby.replicas: 1 or more (default 0)'
- Ensure to setup OAuth app before accessing the API.
- Connect to external services requires proper configuration.
- Freight clusters support producer and consumer zone alignment to minimize cross-zone
  network charges.
- Requires a connected app for OAuth2 setup
- Rate limits apply to API calls
- Requires broker version v0.11.0.0 or later.
- This class is experimental and likely to be removed, or subject to incompatible
  API changes in future versions of the library.
- 'On close() or unsubscribe with auto-commit enabled: Member retries committing offsets
  until a timeout expires.'
- Currently uses the default remote session timeout.
- Future KIP-1092 will allow custom commit timeouts.
- 'The overall request timeout in seconds, including broker lookup, request transmission,
  operation time on broker, and response. Default: socket.timeout.ms/1000.0.'
- message and offsets are mutually exclusive. The stored offsets will be committed
  according to auto.commit.interval.ms or manual offset-less commit(). Note that
  enable.auto.offset.store must be set to False when using this API.
- Starting with confluent-kafka-python 2.12.0, the next generation consumer group
  rebalance protocol is production-ready.
- The new consumer group protocol is not enabled by default.
- KIP-848 fences new member on duplicate group.instance.id
- KIP-848 retries until remote timeout on auto-commit
- Session & heartbeat now controlled by broker
- 'Kafka admin client: create, view, alter, and delete topics and resources.'
- Default request timeout is socket.timeout.ms/1000.0
- message and offsets are mutually exclusive.
- enable.auto.offset.store must be set to False when using this API.
- The partitions list contains only partitions being added or revoked, not the full
  partition list as in the classic consumer.assign().
- A group made up entirely of classic consumers runs under the classic protocol.
- The group is upgraded to the consumer protocol as soon as at least one consumer
  protocol member joins.
- The group is downgraded back to the classic protocol if the last consumer protocol
  member leaves while classic members remain.
- Both rolling upgrade (classic  consumer) and rolling downgrade (consumer  classic)
  are supported.
- Installation on any of these platforms is meant to be seamless, without any C/C++
  compilation required.
- Topic creation is non-atomic and may succeed for some topics but fail for others,
  make sure to check the result for topic-specific errors.
- Requires broker version >= 0.10.1.0
- 'Default: false for SetAdminOptionIncludeAuthorizedOperations'
- 'Default: ReadUncommitted for AdminOptionIsolationLevel'
- 'Default: nil for AdminOptionMatchConsumerGroupStates'
- 'Default: 0 for AdminOptionOperationTimeout'
- 'Default: socket.timeout.ms for AdminOptionRequestTimeout'
- 'Default: false for AdminOptionRequireStableOffsets'
- 'Default: false for AdminOptionValidateOnly'
- Ensure that proper permissions are set for the API keys used.
- Confluent provides one year of extended compatibility for customers Confluent Cloud
  clusters.
- Starting February 2026, deprecated client requests will no longer be accepted and
  will result in errors.
- Requires setup of OAuth in Confluent Cloud.
- OAuth2 with refresh token is required for API access
- Ensure proper setup of the connected app
- The easiest way to follow this tutorial is with Confluent Cloud because you dont
  have to run a local Kafka cluster.
- You can alternatively use the supported CLI or REST API, or the community-supported
  ccloud-stack utility for Confluent Cloud.
- Requires an active Confluent Cloud account
- API keys must be kept confidential
- Integration with Single Sign-On (SSO) is supported.
- Best practices for OAuth setup are recommended.
- Best practice for higher availability in Apache Kafka clients prior to 3.0 session.timeout.ms=45000
- Best practice for Kafka producer to prevent data loss acks=all
- Required connection configs for Kafka producer, consumer, and admin must be set
  in a local file.
- Uses Confluent Cloud for Kafka cluster setup
- Best practice for higher availability in Apache Kafka clients prior to 3.0
- Requires connection configuration parameters to connect to Kafka cluster.
- Requires connected app setup for OAuth2.
- Check for API version compatibility.
- Use Confluent Cloud to avoid running a local Kafka cluster.
- Configuration file should be created at $HOME/.confluent/librdkafka.config
- Some requests may require specific permissions based on the scope of the token
- Requires setup of API key and secret
- Ensure proper permissions are granted for the API key
- Required connection configs for Kafka producer, consumer, and admin
- Best practice for higher availability in librdkafka clients prior to 1.7
- Uses SASL_SSL for authentication
- Configuration parameters include bootstrap.servers, security.protocol, sasl.mechanisms,
  sasl.username, and sasl.password
- Requires setup of OAuth client in Confluent Cloud
- May have rate limits on API calls
- Confluent Cloud connections require reauthenticating after four hours.
- Requires OAuth2 configuration for access
- Rate limits apply on API requests
- Use OAuth2 for authentication
- Ensure proper permissions are set for accessing resources
- Early Access release is not available in Confluent Cloud.
- Enabling the Streams Rebalance Protocol requires that brokers and clients are running
  Kafka 4.1.
- Kafka Streams metrics can be collected broker-side by using the broker plugin.
- 'Downgrading from Kafka Streams 3.5.x or later to Kafka Streams 3.4.x or earlier
  requires special attention: starting in the 3.5.0 release, Kafka Streams uses a
  new serialization format for repartition topics.'
- For a downgrade, first switch the config from upgrade.from to the version youre
  downgrading to.
- Kafka Streams can distribute its standby replicas over distinct racks.
- Interactive Queries v2 is a preview feature.
- This website includes content developed at the Apache Software Foundation under
  the terms of the Apache License v2.
- Requires setup of OAuth2 client in Confluent Cloud
- API endpoints may vary based on access level and user permissions
- ksqlDB is fully hosted on Confluent Cloud.
- User-defined functions (UDFs, UDAFs, and UDTFs) arent supported.
- Fully managed ksqlDB is not available on Enterprise clusters. Only self-managed
  ksqlDB is supported.
- To enable your ksqlDB cluster to access all the resources that you have permissions
  to access, select User accounts and click your account name.
- To enable fine-grained control over access to specific resources, select Service
  accounts and click an existing service account or create a new one.
- 'Each request must include an Authorization: Basic {key} header.'
- Monitor the storage utilization metric and ensure that you take appropriate action
  if utilization approaches 100%
- Requires OAuth2 setup for authentication
- Some API responses may vary based on user permissions
- You must use a resource-specific key created for the ksqlDB cluster.
- API keys for Confluent Cloud or the Kafka cluster dont work and cause an authorization
  error.
- Manage SSO User Accounts
- Manage User Identity Providers
- Pull query results use an eventually consistent consistency model.
- Pull queries can consume up to 48MB per hour, per CSU of bandwidth.
- Only accounts that have the CloudClusterAdmin, EnvironmentAdmin, or OrganizationAdmin
  role can grant the KsqlAdmin role.
- If the ksqlDB cluster requires access to Schema Registry, you must grant the ResourceOwner
  role to the principal.
- Uses OAuth2 with refresh token  requires setup of connected app in schema registry
- Confluent will never automatically upgrade your ksqlDB application to use a backward-incompatible
  release.
- Source data that the old application processed may no longer be available in Kafka
  for the new application to process.
- Secure integration with external systems.
- Credential management for sensitive credentials.
- Integration may require additional setup on Confluent Cloud.
- Streaming agents are an Open Preview feature in Confluent Cloud.
- A Preview feature is a Confluent Cloud component that is being introduced to gain
  early feedback from developers.
- Ensure that the Schema Registry is enabled before making API calls.
- The agent runtime is built on Flink and provides a comprehensive logging and metrics
  system.
- Retry mechanism for transient failures is included.
- Some resources may have rate limits
- Uses OAuth2 with refresh token  requires setup of connected app in API
- Streaming Agents support various configuration options to customize their behavior.
- Ensure proper OAuth scopes are set for API access.
- Use step-by-step analysis to understand agent behavior
- Compare successful and failed sessions
- Look for patterns in tool call failures
- Monitor resource usage during replay
- Use visualization tools for complex workflows
- Uses OpenAI API key for authentication.
- Requires a Confluent Cloud account and Flink compute pool.
- The Real-time Context Engine is available as an Early Access Program feature in
  Confluent Cloud.
- Early Access Program features are intended for evaluation use in development and
  testing environments only, and not for production use.
- Anomaly detection uses statistical and machine learning techniques to identify data
  points that deviate from expected patterns.
- Forecasting helps predict future values in time-series data by analyzing historical
  trends.
- Forecasting accuracy can vary greatly, based on many parameters, and there is no
  guarantee of correctness in predictions made by using ARIMA and machine learning.
- Requires OAuth2 authentication for access.
- The AI_TOOL_INVOKE function is available for preview.
- Ensure proper permissions are granted to the service account
- Use the ML_PREDICT function to run predictions with registered AI models.
- The ML_DETECT_ANOMALIES function uses ARIMA model to identify outliers in time-series
  data.
- The ML_EVALUATE function aggregates a table and returns model evaluation metrics.
- Ensure the API key has the correct permissions for accessing topics and schemas.
- An embedding is a numerical representation that captures relationships and meaning
  within complex data.
- In a Retrieval-Augmented Generation (RAG) workflow, an embedding helps to retrieve
  the most relevant information, ensuring AI delivers precise, context-aware results.
- Requires OAuth2 authentication.
- Cluster and topic data may vary based on user permissions.
- Only string and VARCHAR columns can be appended to the embedding.
- Searching external tables is an Open Preview feature in Confluent Cloud.
- External calls in stream processing enable powerful use cases like real-time enrichment
  and AI orchestration but may introduce risks.
- 'External calls in stream processing enable powerful use cases like real-time enrichment
  and AI orchestration but may introduce risks: reprocessing can overwhelm external
  systems with replay traffic, network failures or high latency can cascade to entire
  pipelines, and historical replays may get current data instead of point-in-time
  state, breaking audit consistency.'
- Text Search is an Open Preview feature in Confluent Cloud.
- A Preview feature can be used for evaluation and non-production testing purposes.
- To create a topic with Infinite Storage, select Infinite for Retention time.
- If you have more than 1000 topics, Cloud Console may not display metrics for all
  the topics.
- To create a topic with Infinite Storage, select 'Show advanced settings' and choose
  'Infinite' for 'Retention time'.
- By default, message browser displays newer data at the top of the messages pane.
- You can only filter results that are displayed.
- Message browser displays messages that have associated schemas.
- Requires setup of connected app in Confluent
- Usage limits may apply depending on the plan
- You can only share data by inviting users through email.
- There is no support for sharing via Cluster Linking.
- You are limited on the amount of data that can be shared. Currently the limit is
  10 MB per second, per share.
- To use the CLI for Stream Sharing, you must have CLI v3.
- Enterprise Kafka clusters do not support Stream Sharing.
- Basic, Standard, and Dedicated Kafka clusters support Stream Sharing.
- Stream Sharing does not support all private network options for Dedicated Kafka
  clusters.
- 'The following networking options are supported: Public internet, AWS PrivateLink,
  Azure Private Link, and Google Cloud Private Service Connect.'
- To share streams over a private endpoint, both data provider and data recipient
  must use the same cloud provider.
- Wildcard principals for topics apply to Stream Sharing data recipients.
- To share schema enabled topics, your organization must use Confluent Cloud Schema
  Registry.
- Shared data includes a topic description and any tags added to the topic.
- Ensure correct API version is used.
- You must already have, or you must create, a Confluent Cloud account associated
  with the email address that the data was shared to.
- You have one week to access the link to shared data or redeem the access token.
- Tableflow Delta Lake tables support only Bring Your Own Storage (BYOS).
- Fully-managed data streaming platform with a cloud-native Kafka engine.
- Tableflow supports only S3 Standard Storage Class buckets located in the same region
  as your Kafka cluster.
- You should start with an empty bucket when you first enable Tableflow.
- Only TopicNameStrategy is supported.
- No schema changes are allowed for keys.
- Dropping columns is not supported.
- Avro schemas can be materialized into corresponding Iceberg types.
- After-state only = true must be configured for the CDC connector
- When using append write mode, tombstones.on.delete should be set to false or error
  handling mode set to skip
- When using upsert write mode, tombstones.on.delete should be set to true
- The GB-processed billing dimension is not enabled for Delta Lake tables.
- Tableflow upsert support will have an additional charge starting in early 2026.
- Requires a valid API key and secret
- Rate limits apply to all endpoints
- Ensure API key permissions are properly configured
- Write mode cant be changed while Tableflow is enabled. To change write mode, you
  must disable Tableflow, change your Kafka or Flink configurations, and then re-enable
  Tableflow, which creates a new table.
- Tableflow does not support the `*-debezium-registry` value format in append and
  upsert write modes.
- Tableflow does not support the `json-registry` value format in upsert write mode.
- In upsert mode, Tableflow maintains an index that contains messages keys for faster
  insertion. The total size of all keys must not exceed the index size.
- In upsert mode, Tableflow does not support evolving the key schemas.
- OAuth2 with refresh token is required for API access.
- Materializing a newly created topic as an Iceberg table can take a few minutes.
- For low-throughput topics in which Kafka segments have not been filled, Tableflow
  tries optimistically to publish data every 15 minutes.
- For low-throughput topics in which Kafka segments have not been filled, Tableflow
  tries optimistically to publish data every 15 minutes. This is best-effort and not
  guaranteed.
- Requires setup of a Confluent Cloud account.
- Materializing a newly created topic as a table can take a few minutes.
- Requires OAuth2 setup for accessing API.
- Some endpoints may return different status codes based on the request
- There are no additional configurations required to use Confluent Managed Storage
  with Tableflow.
- The Tableflow Iceberg REST Catalog doesnt support credential vending for customer-managed
  storage buckets.
- Catalogs used with Tableflow must have access to the KMS key that encrypts the Tableflow
  data.
- Requires setup of Confluent Cloud account
- Some endpoints may have rate limits
- Ensure API keys are properly configured in the Confluent Cloud console.
- Consider Tableflow-managed tables in Glue as read-only.
- Do not modify, optimize, or alter them directly in Glue, Lake Formation, or other
  external tools.
- Ensure OAuth2 connected app is configured properly.
- Topics must be materialized in order for catalog synchronization to complete. Enable
  Tableflow on a topic before enabling your external catalog provider.
- Uses OAuth2 for authentication.
- Ensure to set proper scopes during app registration.
- Tableflow Unity Catalog integration uses Databricks Unity Catalog Open Preview for
  creating external tables by using Unity Catalog open APIs.
- Refer to the REST API Quick Start for additional guidance.
- Requires a valid API key and secret for authentication.
- Uses OAuth2  requires setup of connected app in Confluent Cloud
- Ensure AWS Athena has read-only access to the Glue catalog and the storage bucket.
- Snapshot query is an Early Access Program feature in Confluent Cloud for Apache
  Flink.
- AWS Glue Data Catalog integration must be configured for Snowflake.
- Requires OAuth2 authentication for accessing the API
- 'S3 Region Example: us-west-2'
- Some endpoints may require additional permissions.
- Snapshot retention involves managing metadata that enables you to query a previous
  state of your table, also known as 'time-travel queries'.
- Tableflow creates a snapshot every time it commits a change to your table.
- Tableflow always maintains a minimum number of snapshots, but you can configure
  how long additional snapshots should be retained before they are expired by setting
  the retention_ms configuration.
- When a snapshot is past its expiration time or more than 1000 snapshots exist, Tableflow
  removes the snapshot from the table asynchronously.
- The default error-handling mode is suspend.
- Be aware of rate limits on API calls
- Access to Tableflow typically mirrors access to Apache Kafka resources.
- Tableflow emits a general status including issues like Config Issue or Degraded.
- Requires additional setup for API key management.
- Ensure OAuth scopes are properly configured.
- The Apache Iceberg REST Catalog is not supported in private networking-enabled
  clusters, so you must use external catalog integrations like AWS Glue Data Catalog.
- You cant use Confluent-managed storage in Private Network-enabled clusters.
- The catalog integrations, like Snowflake Open Catalog/Apache Polaris, are not supported
  via private networking.
- Tableflow is available for Early Access in these Azure regions.
- An Early Access feature is a component of Confluent Cloud introduced to gain feedback.
  This feature should be used only for evaluation and non-production testing purposes
  or to provide feedback to Confluent, particularly as it becomes more widely available
  in follow-on preview editions.
- Some API calls may require specific permissions.
- Ensure to handle rate limits as per API guidelines
- Check for potential latency in API responses
- Some API calls may require special permissions.
- To enable USM for your Confluent Cloud organization, contact Confluent Support.
- Ensure that OAuth scopes are correctly assigned.
- Rate limits may apply based on the account tier.
- Your Confluent Cloud user account must have the OrgAdmin role.
- Your Confluent Cloud account must include the Advanced Governance package.
- Requires OAuth2 setup for accessing resources
- Requires setup of OAuth2 credentials in Confluent Cloud
- Some API responses may include nested objects
- API supports both REST and GraphQL access.
- Ensure valid OAuth credentials are used.
- You can connect to only one environment in a region from a single VPC or on-premises
  network.
- Cross-region AWS PrivateLink Attachment Connections are not supported.
- OAuth2 with refresh token is required for authentication
- Some metrics may have a delay in reporting
- The service account must have both the USMAgent and DataSteward roles.
- Requires an API key with Schema Registry scope.
- Requires an API key with Cloud resource management scope.
- No data from your Confluent Platform cluster appears in Confluent Cloud until you
  successfully deploy the agent in your Confluent Platform environment.
- Ensure that your Confluent Cloud environment has the Advanced Governance package,
  which is required for USM.
- Ensure to configure the OAuth application in Confluent Cloud for access.
- Check for rate limits when querying the API.
- Sensitive values, such as secrets and credentials, must be configured only in properties
  of type PASSWORD.
- After registration, connector metadata begins to appear in Confluent Cloud.
- Uses OAuth2 with refresh token  requires setup of OAuth app in Confluent.
- Some resources may have rate limits.
- Uses OAuth2 with refresh token  requires setup of Confluent Cloud service account
- Some API responses may contain nested structures that require additional parsing
- Requires configuration for OAuth 2.0 authentication.
- The confluent.catalog.collector.max.bytes.per.snapshot setting increases the maximum
  packet size to 2 MB.
- The confluent.telemetry.exporter._usm.events.request.timeout.ms setting increases
  the event exporter request timeout to 180,000 ms (3 minutes).
- The Connectors page is for monitoring only.
- All management operations must be performed in your Confluent Platform environment
  using the Confluent Control Center.
- The USM Agent includes diagnostic tools to help diagnose and resolve connectivity
  and configuration issues.
- API rate limits may apply
- Before investigating specific error scenarios, run the 'usm-agent-validz' tool.
- If the validation command succeeds, your basic connectivity and credentials are
  correct.
- Uses OAuth2 authentication
- Schema Registry is available on both Confluent Cloud and Confluent Platform.
- To learn about schema formats, create schemas, and use producers and consumers to
  send messages to topics.
- The Essentials package is automatically attached to your environment by default.
- The governance package will not be created automatically for Confluent CLI v3 or
  lower.
- You can upgrade to an Advanced governance package, but it is not possible to downgrade
  from Advanced to Essentials.
- Data Portal is available in Confluent Cloud for users with a Stream Governance package
  enabled in their environments.
- User-generated metadata should be appended to topics to make them discoverable and
  present them effectively on the Data Portal.
- The topic access request workflow is not available for topics on Basic clusters.
- The collaboration workflow for topic access requests through email is dependent
  upon having owner names and emails appended to topics.
- Users need search Stream Catalog permissions to use the Data Portal, at a minimum
  DataDiscovery role.
- To approve access requests to topics, users need topic read and write granting permissions.
- Users need query permissions on one or more compute pools to query data with Apache
  Flink, at a minimum FlinkDeveloper role.
- If you do not see the option **See in Stream Lineage**, then you do not have the
  required permissions.
- Developer roles do not grant access to Stream Lineage.
- The Essentials package only allows users to visualize the flow of data from the
  past 10 minutes.
- Point-in-time feature is only available on Advanced package.
- Requires setup of OAuth credentials in Confluent Cloud.
- Access to certain resources may require additional permissions.
- Stream Catalog only supports prefix searches; it does not support wildcard search.
- Business metadata is only available in the Advanced package for Stream Governance.
- The Catalog REST API doesnt maintain global sorting when you search for a combination
  of USM and Confluent Cloud resource types.
- You cannot add business metadata to Unified Stream Manager entity types.
- Tags can be created to apply to only specific entities or to apply to any entity.
- Tagging requires the use of specific entity types and names.
- Business metadata is not supported for Unified Stream Manager entity types.
- Currently, only prefix search on string attributes is supported.
- Be aware of quota limits on API calls
- The GraphQL API is a read-only API that only supports queries, and not mutations
  nor subscriptions.
- Results can be paginated with the limit and offset arguments.
- You must opt for either the Essentials or Advanced package to use it.
- Schema Registry is a key component of Stream Governance
- Supports Avro, JSON Schema, and Protobuf serializers and deserializers
- Only single-zone Dedicated Kafka clusters are available in Jio Cloud regions.
- Stream Governance packages purchased in Jio Cloud regions support a maximum SLA
  of 99.95%.
- Inference process analyzes the message value only.
- At least one and up to 10 messages must be present for inference.
- A single Schema Registry is available per Environment.
- Access Control to Schema Registry is based on API key and secret.
- High availability (HA) is achieved by having multiple nodes within a cluster always
  in running state.
- Make sure to configure your API key with the required permissions.
- Simply deleting schemas will not free up space in the registry because this will
  always result in a soft delete and schema IDs are not reusable.
- 'Caution: This tool provides you with the ability to Hard delete a schema in the
  Schema Registry, so use this option with caution.'
- Deleting schemas results in a soft delete and schema IDs are not reusable.
- Confluent Cloud supports 'hard delete' of a schema as a two-step process.
- A hard delete requires a version number as input; not just version:latest, which
  results in a soft delete only.
- Ensure to handle pagination for large datasets.
- Schema validation feature does not reject tombstone records (null value) even if
  there is no schema ID associated with the record.
- On Confluent Cloud, you can have a maximum of 10 exporters with the Essentials package
  and 100 in the Advanced package.
- One exporter can transfer multiple schemas.
- There is no upper limit on the number of schemas that can be transferred using an
  exporter.
- Use context wildcard ':' to denote subjects under all contexts.
- Exporters can specify to export only specific subjects and contexts.
- The limit on the number of exporters allowed at any one time per Schema Registry
  is 10.
- OAuth is recommended for exporters when integrating with identity providers.
- Uses Role-Based Access Control (RBAC) for topics requiring ResourceOwner
- Ensure the proxy allows bidirectional communication
- OAuth provides secure, token-based authentication that eliminates the need for long-lived
  API keys.
- Ensure to manage OAuth scopes properly during integration
- Running the ccloud-stack utility generates a configuration file with connection
  information.
- Ensure to copy the configuration file to $HOME/.confluent/java.config.
- API calls are subject to rate limits.
- Ensure correct scopes are set for OAuth2.
- Run this tutorial in a new Confluent Cloud environment so it doesnt interfere with
  your other work.
- 'To get the Schema Registry REST ENDPOINT, do one of the following: From the Confluent
  Cloud Console or from the Confluent CLI.'
- If you want to enable use.latest.version for producers, you must disable auto schema
  registration by setting auto.register.schemas to false, and use.latest.version to
  true.
- Setting auto.register.schemas to false disables auto-registration of the event type,
  so that it does not override the latest schema in the subject.
- The Confluent Schema Registry default compatibility type BACKWARD is non-transitive.
- Schema Registry is a managed schema repository that supports data storage and exchange
  for both stream processing and data at rest.
- Schema IDs are unique within a (tenant, context) combination.
- Ensure to follow best practices for OAuth setup.
- API calls may be subject to limits based on your plan.
- The Confluent Schema Registry default compatibility type is `BACKWARD`.
- A REST API call to compatibility mode is global meaning it overrides any compatibility
  parameters set in schema registry properties files.
- Schema format extensibility is limited to Confluent Platform. This is not an option
  for Schema Registry on Confluent Cloud.
- ksqlDB uses only the default TopicNameStrategy, and does not currently support multiple
  schemas in a single topic.
- Schema normalization is disabled by default. It is highly recommended that you enable
  schema normalization.
- JSON and PROTOBUF_NOSR are not supported.
- This applies to the named versions of Confluent Platform only, not Confluent Cloud.
- 'This misbehavior is fixed with the release of Confluent Platform 7.5.3 and 7.4.4,
  but you must add the kafka-avro-console-producer property: --property avro.use.logical.type.converters=true'
- The REST Proxy does not support setting the above property as of now.
- This is resolved in REST Proxy 7.7.0. Until this fix is backported, use the REST
  Proxy 7.4.2-(2 or lower) or 7.5.1-(1 or lower) as an interim workaround to avoid
  this issue altogether.
- Uses OAuth2 with refresh token  requires setup of a service account in Confluent
  Cloud
- Rate limits apply to API calls.
- Ensure to handle token expiration gracefully.
- Schema format extensibility is limited to Confluent Platform.
- Clients 7.7.4 and later support auto retries for 429 exceptions.
- Uses API key and secret for Confluent Cloud cluster
- Ensure Kafka cluster is created and API keys are generated
- Supports arbitrary schema types like JSON, PROTOBUF, AVRO.
- Uses KafkaProtobufSerializer to send messages of Protobuf type to Kafka.
- Uses KafkaProtobufDeserializer to receive messages of any Protobuf type from Kafka.
- Supports arbitrary schema types.
- Default subject level compatibility is BACKWARD.
- The console consumer does not currently support Protobuf `Any` type. `Any` is an
  advanced Protobuf feature that requires the Protobuf type to be registered with
  a TypeRegistry.
- The Confluent `kafka-protobuf-serializer` works with Google Protobuf v.3. Google
  Protobuf v.4 is currently not supported.
- The 'import public' feature of protobuf2 and protobuf3 is not supported in the Java,
  which means that it is not supported in the Schema Registry tools.
- Do not upload Google/Protobuf dependencies into Schema Registry.
- Requires setup of a connected app in Confluent Cloud
- By default, json.fail.invalid.schema is set to false.
- Default for json.value.type is Object.class.getName().
- Support for arbitrary schema types.
- Compatibility settings can affect schema registration.
- 'Currently, there is no way to set `additionalProperties: false` using the CREATE
  TABLE statement via hints or WITH() clause in Apache Flink on Confluent Cloud.'
- Schema rules are only available on Confluent Enterprise and Confluent Cloud with
  the Stream Governance 'Advanced' package.
- Schema rules are only supported in version 7.4 or above.
- Requires setup of Advanced Stream Governance package for Confluent Cloud.
- Uses OAuth2 for authentication  requires setup of OAuth clients.
- Schema Registry is designed to be distributed, with single-primary architecture.
- Some topics may return nulls in deeply nested fields
- Ensure OAuth scopes are correctly set for data access
- Rate limits apply to API requests
- Uses API key for authentication.
- Some internal clients may continue to access Schema Registry through public internet.
- Schema Registry PrivateLink is currently available only in select regions on AWS,
  Azure, and Google Cloud.
- Custom connectors cannot use Schema Registry configured with private access.
- Uses PrivateLink Attachment for private networking.
- IP filtering is only applicable for Schema Registry APIs.
- Ensure scopes are properly configured in OAuth client.
- Requires setup of OAuth2 for API access.
- On Confluent Platform, the first versions with this functionality are 7.4.9, 7.5.8,
  7.6.5, 7.7.3, 7.8.2, and 7.9.0. Post 7.9.0, this feature is included.
- Only supports schema subjects with default context.
- Protobuf schemas are not supported as part of AsyncAPI version 2.
- Multiple schemas can be returned.
- Arrays are expected to have a single data type.
- All fields are optional in JSON Schema.
- Schema Registry requires OAuth authentication for access.
- Confluent connectors will not support data systems or versions that are no longer
  supported by their vendors.
- The connector guarantees at least once delivery.
- Supports multiple tasks for improved performance.
- If you require private networking for fully-managed connectors, make sure to set
  up the proper networking beforehand.
- Defaults for connection.port is 5432.
- Default db.timezone is UTC.
- Requires setup of connected app in API.
- The connector supports running one or more tasks.
- The connector can start at one task to support all import data and can scale up
  to one task per log stream.
- There is a Kafka topic format property (CLI property `kafka.topic.format`) you can
  use to customize the topic names for each log stream.
- Schema Registry must be enabled to use a Schema Registry-based format.
- Uses AWS Access Keys for authentication
- Log group must be specified for the connector to function
- The connector will only accept Struct objects as the Kafka record.
- Performance is limited by Amazon to 150 transactions per second.
- The connector supports customizable API endpoints.
- Freight clusters support only service accounts for Kafka authentication.
- This option is recommended for production.
- This is used during initial application bootstrap when a checkpoint doesnt exist
  for a shard or its parents.
- Used only in CDC mode.
- Each unique combination of a connector and a DynamoDB table stream creates its own
  dedicated checkpointing table.
- Low RCU on the DynamoDB tables will lead to throttling and slow down the snapshot
  process.
- Tables can be auto-created based on topic names and auto-evolved based on the record
  schema.
- Defaults to dlq-${connector} if not set.
- Defaults to JSON for input.data.format.
- Ensure to configure network security settings for external access.
- The connector does not convert Kinesis base64-encoded data before storing the data
  in Kafka.
- Uses password authentication or AWS IAM role-based authentication.
- Auto-creation of tables and limited auto-evolution are supported.
- If you use object tagging in the S3 bucket, set the connector configuration property
  s3.object.tagging to true.
- If you use AWS Key Management Service (KMS), you must modify the key policy to grant
  IAM user account permission for the kms:GenerateDataKey and kms:Decrypt actions.
- The S3 Sink connector does not allow recursive schema types.
- Configuration properties can be set in JSON format.
- The `rotate.schedule.interval.ms` property allows you to configure a regular schedule
  for when files are closed and uploaded to storage.
- Defaults to dlq-${connector} if not set.
- You need to have Confluent Cloud Schema Registry configured if using a schema-based
  message format like AVRO, JSON_SR, and PROTOBUF.
- API is rate limited, plan requests accordingly.
- If not used, the connector uses the default schema configured for Schema Registry.
- 'WARNING: This property should be used with CAUTION for SOURCE CONNECTORS as it
  may lead to dataloss.'
- 'At least once delivery: The connector guarantees that records are delivered at
  least once.'
- 'Supports multiple tasks: The connector supports running one or more tasks.'
- 'Client-side field level encryption (CSFLE) support: The connector supports CSFLE
  for sensitive data.'
- 'Offset management capabilities: The connector supports offset management.'
- 'Supported input data formats: The connector supports Avro, Bytes, CSV, JSON, and
  Parquet input formats.'
- The supported compression types for Parquet formats are snappy, gzip, and none.
- The connector can support Parquet input files up to 2GB in size.
- 'Provider integration support: The connector supports IAM role-based authorization
  using Confluent Provider Integration.'
- An AWS User Account IAM Policy configured for bucket access.
- Kafka clusters support only service accounts for Kafka authentication.
- The connector guarantees that records are delivered at least once to the Kafka topic.
- The connector supports multiple tasks.
- The AWS region that the SQS queue belongs to will be inferred from the SQS URL if
  left empty.
- The AWS Lambda function can be invoked by this connector either synchronously or
  asynchronously.
- AWS Lambda automatically retries up to two times in asynchronous mode.
- If no schema is defined, values are encoded as plain strings.
- AWS Lambda function results are stored in success and error topics.
- Kafka Authentication mode. It can be one of KAFKA_API_KEY or SERVICE_ACCOUNT. It
  defaults to KAFKA_API_KEY mode.
- This Quick Start is for the fully-managed Confluent Cloud connector.
- Input format JSON to output format AVRO does not work for the connector.
- Using the Confluent CLI requires additional setup steps.
- Authorized access to a Confluent Cloud cluster on Microsoft Azure is required.
- The Confluent CLI must be installed and configured for the cluster.
- An Azure Blob Storage Container must be created in the same region as your Confluent
  Cloud cluster.
- The Connection type of the network needs to be 'Private Link Access'.
- Resource alias is not supported.
- This Quick Start is for the fully-managed Confluent Cloud connector. If you are
  installing the connector locally for Confluent Platform, see Azure Blob Storage
  Source connector for Confluent Platform.
- A list of topics along with a regex expression of the files which are to be sent
  to that topic.
- Add a schema context name.
- An Azure RBAC service principal is required to run the connector.
- The Azure Cosmos DB requires an id field in every record.
- The connector supports Upsert based on id.
- The connector does not support Delete for tombstone records.
- Kafka Authentication mode defaults to KAFKA_API_KEY
- Expected to provide kafka.api.key and kafka.api.secret for KAFKA_API_KEY mode
- Configuration properties that are not shown in the Cloud Console use the default
  values.
- The Azure Cosmos DB Source connector allows reading from multiple containers using
  a single connector.
- By default it is false, means SDK uses direct mode.
- Default value is 5 minutes
- Some API calls may require additional permissions.
- Rate limiting is applied to all API requests.
- The connector supports WORM-enabled Azure Data Lake Storage Gen2 containers.
- The properties rotate.schedule.interval.ms and rotate.interval.ms can be used with
  flush.size.
- The connector fetches records from Azure Event Hubs through a subscription.
- If you plan to use one or more Single Message Transforms (SMTs), see SMT Limitations.
- For connector limitations, see Azure Event Hubs Source Connector limitations.
- Ensure that you have appropriate permissions to access the API
- Rate limiting may apply to your account
- Uses Azure Log Analytics workspace ID and shared keys for configuration
- Requires setup of Schema Registry for schema-based formats
- Uses Kafka Authentication mode.
- The Azure Service Bus Source connector supports multiple tasks.
- Valid values for producer.override.compression.type are none, gzip, snappy, lz4,
  and zstd.
- Auto creation of tables and limited auto-evolution are also supported.
- Ensure you have all your prerequisites completed.
- Uses password authentication.
- Ensure Confluent Cloud Schema Registry is configured if using schema-based formats.
- Client-side field level encryption (CSFLE) support
- Supports multiple tasks
- Input data format with or without a schema
- Requires Confluent Cloud Schema Registry configured if using a schema-based message
  format like AVRO, JSON_SR, and PROTOBUF.
- Ensure correct permissions for API access.
- The Connection type of the network needs to be 'PrivateLink Access'.
- Endpoints deployed with high availability have network interfaces deployed in multiple
  availability zones.
- 'In Confluent Cloud, one of the following cluster types is set up with the specified
  network resource: A Dedicated cluster with a Confluent Cloud network or A Enterprise
  cluster with a network gateway.'
- A source topic is created to sink data into the ClickHouse database.
- ClickHouse instance is created to sink data into and is running within the same
  region and cloud as the Confluent Cloud cluster.
- A database and a schema are created in ClickHouse to sink data into.
- Uses OAuth2 with refresh token  requires setup of connected app in Flink
- Uses password authentication for Couchbase database.
- Requires an API key and secret for authentication
- The default page size is 100
- Ensure that the Connection type of the network is set to 'PrivateLink Access'.
- Create a separate Amazon S3 bucket where data can be staged before delivery into
  Databricks Delta Lake.
- Be sure to create the Databricks Delta Lake workspace resources in the same region
  where your Kafka cluster is running.
- The Databricks dialog box does not close automatically. You may need to press Cancel
  to close it and refresh your browser.
- The connector requires DeleteObject so it can delete files in the staging S3 bucket
  once they are copied to the Delta Lake table.
- Requires OAuth2 setup for client authentication.
- To support exactly-once semantics, you must create a separate Amazon S3 bucket where
  data can be staged before delivery into Databricks Delta Lake.
errors:
- 'REQUEST_LIMIT_EXCEEDED: Throttle API calls or reduce frequency'
- '401 Unauthorized: Recheck OAuth scopes or token expiration'
- 'QUERY_TIMEOUT: Break down filters or add selectivity'
- '401 Unauthorized: Check your credentials and scopes'
- '429 Too Many Requests: Reduce your request rate'
- '500 Internal Server Error: Try again later'
- '401 Unauthorized: Recheck API key and secret'
- '404 Not Found: Confirm topic and cluster IDs are correct'
- '401 Unauthorized: Check OAuth token and permissions'
- '403 Forbidden: Insufficient permissions for this action'
- '401 Unauthorized: Invalid credentials or token expired'
- '429 Too Many Requests: Rate limit exceeded'
- Verify that all Confluent Cloud resources are destroyed to avoid unexpected charges.
- '403 Forbidden: Check API key permissions'
- '404 Not Found: Verify endpoint and resource existence'
- '500 Internal Server Error: Retry after some time'
- 'INVALID_CREDENTIALS: Check the provided client ID and secret.'
- 'ACCESS_DENIED: Ensure the user has permissions to access the resource.'
- '401 Unauthorized: Check your API key and secret.'
- '403 Forbidden: Check your permissions.'
- '404 Not Found: Verify the endpoint URL.'
- '403 Forbidden: Check if the API key has sufficient permissions.'
- '404 Not Found: Verify the endpoint path.'
- '404 Not Found: Ensure the resource exists'
- '202 ACCEPTED: Successful request to create a cluster.'
- '204 No Content: Successful deletion'
- '200 OK: Successful update'
- '400 Bad Request: Check the request parameters.'
- '401 Unauthorized: Verify authentication token.'
- '404 Not Found: Ensure the cluster ID is correct.'
- '204 No Content: Successful deletion of cluster.'
- '429 Too Many Requests: Rate limit exceeded.'
- '401 Unauthorized: Check your authentication credentials.'
- 'SOURCE_UNAVAILABLE: The cluster link cannot reach its source cluster.'
- '401 Unauthorized: Check OAuth scopes or token expiration'
- '403 Forbidden: Ensure proper permissions for the requested resources'
- '401 Unauthorized: Check client credentials and scopes'
- '404 Not Found: Verify the resource path'
- 'REQUEST_LIMIT_EXCEEDED: Throttle API calls or reduce frequency.'
- '401 Unauthorized: Recheck API key and secret.'
- '403 Forbidden: Check your API key and permissions'
- '404 Not Found: Verify the cluster ID'
- '400 Bad Request: Review your request parameters'
- 'PENDING_STOPPED: Mirror topic is still in pending state.'
- 'consumer.offset.sync.ms: Default is 30 seconds.'
- '401 Unauthorized: Recheck OAuth scopes or token expiration.'
- '403 Forbidden: Check permissions for the requested resource.'
- '404 Not Found: Verify the endpoint path and parameters.'
- '401 Unauthorized: Check API key and permissions'
- 'invalid configuration: consumer.group.prefix.enable cannot be set on a bidirectional
  cluster link.'
- '401 Unauthorized: Check API key and permissions.'
- '404 Not Found: Cluster ID not found.'
- '403 Forbidden: Check permissions for the API key'
- '404 Not Found: Verify the endpoint path is correct'
- 'invalid configuration: consumer.group.prefix.enable cannot be set to true for bidirectional
  cluster links'
- 'REMOTE_LINK_NOT_FOUND_ERROR: Failed to get remote link config due to link not being
  found on the remote cluster.'
- 'INVALID_CONFIGURATION: Check for conflicting settings.'
- 'AUTHENTICATION_ERROR: Failed to describe topic configs due to authentication issues.'
- 'Access denied: Ensure your service account has the required permissions on the
  source and destination clusters.'
- 'UNRESOLVABLE_BOOTSTRAP_ERROR: The destination cluster could not resolve the provided
  bootstrap server to an IP address.'
- 'BOOTSTRAP_TCP_CONNECTION_FAILED_ERROR: The destination cluster cannot reach a Kafka
  cluster at the provided source bootstrap server.'
- 'AUTHENTICATION_ERROR: The source cluster security credential provided to the cluster
  link was not able to authenticate with the source cluster.'
- 'INVALID_BOOTSTRAP_INTERNAL_ENDPOINT_ERROR: Your source cluster bootstrap server
  was to a private internal endpoint or port that Cluster Linking is not allowed to
  access in Confluent Cloud.'
- 'TIMEOUT_ERROR: The operation to create the cluster link timed out.'
- 'UNKNOWN: An unexpected error has occurred.'
- 'UNKNOWN: Error cause cannot be determined.'
- 'INTERNAL_ERROR: System error caused by Confluent software.'
- 'AUTHORIZATION_ERROR: Authorization credentials are not properly configured.'
- 'BROKER_AUTHENTICATION_ERROR: Authentication credentials on the broker are not properly
  configured.'
- 'BROKER_AUTHORIZATION_ERROR: Authorization credentials on the broker are not properly
  configured.'
- 'MISCONFIGURATION_ERROR: A misconfiguration is causing errors.'
- 'REMOTE_LINK_NOT_FOUND_ERROR: The remote link was unexpectedly not found.'
- 'LINK_NOT_FOUND_ERROR: The cluster link cannot be found.'
- 'CONSUMER_GROUP_IN_USE_ERROR: The consumer group is active on the destination, causing
  offsets to not be synced.'
- 'SECURITY_DISABLED_ERROR: No authorizer is configured on the source cluster.'
- 'TOPIC_EXISTS_ERROR: A topic exists on the destination unexpectedly.'
- 'POLICY_VIOLATION_ERROR: The topic transition violates a policy.'
- 'LINK_COORDINATOR_NOT_ENABLED_ERROR: Cluster link is not enabled.'
- 'ACL_LIMIT_EXCEEDED: ACLs limit on the link has been exceeded.'
- 'REMOTE_MIRROR_NOT_FOUND_ERROR: Remote mirror topic is not available.'
- 'UNKNOWN_TOPIC_OR_PARTITION_ERROR: Either a topic or partition was unexpectedly
  not found.'
- 'INVALID_TOPIC: An InvalidTopicException was encountered from the destination cluster.'
- 'SUPPRESSED_ERRORS: This means some errors were suppressed because too many were
  encountered.'
- 'INVAILD_REQUEST_ERROR: An InvalidRequestException was encountered.'
- If the shrink operation fails, the cluster will expand to its original capacity.
- '403 Forbidden: Check your permissions for the requested resource'
- '404 Not Found: Ensure the endpoint is correct and exists'
- '401 Unauthorized: Check OAuth credentials and token status.'
- Control Center Cannot Connect to Confluent Cloud
- '401 Unauthorized: Check your client credentials.'
- '403 Forbidden: Ensure you have the right permissions.'
- 'UNKNOWN_TOPIC_OR_PARTITION: Manually create the topics in Confluent Cloud for Basic,
  Standard, Enterprise, and Freight clusters or enable automatic topic creation for
  Dedicated clusters.'
- '401 Unauthorized: Verify token validity.'
- 'Invalid Credentials: Check your API key and secret.'
- 'Cluster not found: Check API key scope and cluster binding.'
- 'Authentication failures: Verify API key and secret and security protocol configuration.'
- 'Network connectivity: Ensure proper networking setup for private clusters.'
- '404 Not Found: Resource does not exist.'
- '500 Internal Server Error: Try again later.'
- '401 Unauthorized: Check client ID and secret.'
- '401 Unauthorized: Recheck API key permissions'
- 'QUERY_TIMEOUT: Break down filters or add selectivity.'
- '401 Unauthorized: Check your credentials and permissions'
- 'read_uncommitted: The share group consumes all non-transactional and transactional
  records, bounded by the high-water mark.'
- 'read_committed: The share group consumes only non-transactional records and committed
  transactional records. This level is bounded by the last stable offset, meaning
  an open transaction can block the share groups progress.'
- 'UNKNOWN_TOPIC_OR_PARTITION: This server does not host this topic-partition.'
- 'LEADER_NOT_AVAILABLE: There is no leader for this topic-partition as we are in
  the middle of a leadership election.'
- 'NOT_COORDINATOR: This is not the correct coordinator.'
- 'NOT_ENOUGH_REPLICAS: Messages are rejected since there are fewer in-sync replicas
  than required.'
- 'NOT_ENOUGH_REPLICAS_AFTER_APPEND: Messages are written to the log, but to fewer
  in-sync replicas than required.'
- 'NOT_LEADER_OR_FOLLOWER: This server is not the leader for the given partition.'
- '408: Request timeout'
- '425: Too early'
- '429: Too many requests'
- '500: Internal server error'
- '502: Bad gateway'
- '503: Service unavailable'
- '504: Gateway timeout'
- '403 Forbidden: Ensure you have the required permissions.'
- '404 Not Found: Check the endpoint URL.'
- '404 Not Found: Verify the resource path.'
- '500 Internal Server Error: Retry after a brief wait.'
- '429 Too Many Requests: Reduce request rate'
- '401 Unauthorized: Check OAuth token'
- '401 Unauthorized: Verify client ID and secret'
- '404 Not Found: Ensure the endpoint is correct.'
- '404 Not Found: The requested resource does not exist.'
- '429 Too Many Requests: Reduce request frequency'
- '401 Unauthorized: Check OAuth token validity'
- 'KafkaException: Operation failed locally or on broker.'
- 'TypeException: Invalid input.'
- 'ValueException: Invalid input.'
- 'TypeError: Invalid input type.'
- 'ValueError: Invalid input value.'
- '_BAD_MSG: Local: Bad message format'
- '_BAD_COMPRESSION: Local: Invalid compressed data'
- '_DESTROY: Local: Broker handle destroyed for termination'
- '_FAIL: Local: Communication failure with broker'
- '_TRANSPORT: Local: Broker transport failure'
- '_CRIT_SYS_RESOURCE: Local: Critical system resource failure'
- '_RESOLVE: Local: Host resolution failure'
- '_MSG_TIMED_OUT: Local: Message timed out'
- '_PARTITION_EOF: Broker: No more messages'
- '_UNKNOWN_PARTITION: Local: Unknown partition'
- '_FS: Local: File or filesystem error'
- '_UNKNOWN_TOPIC: Local: Unknown topic'
- '_ALL_BROKERS_DOWN: Local: All broker connections are down'
- '_INVALID_ARG: Local: Invalid argument or configuration'
- '_TIMED_OUT: Local: Timed out'
- '_QUEUE_FULL: Local: Queue full'
- '_ISR_INSUFF: Local: ISR count insufficient'
- '_NODE_UPDATE: Local: Broker node update'
- '_SSL: Local: SSL error'
- '_WAIT_COORD: Local: Waiting for coordinator'
- '_UNKNOWN_GROUP: Local: Unknown group'
- '_IN_PROGRESS: Local: Operation in progress'
- '_PREV_IN_PROGRESS: Local: Previous operation in progress'
- '_EXISTING_SUBSCRIPTION: Local: Existing subscription'
- '_ASSIGN_PARTITIONS: Local: Assign partitions'
- '_REVOKE_PARTITIONS: Local: Revoke partitions'
- '_CONFLICT: Local: Conflicting use'
- '_STATE: Local: Erroneous state'
- '_UNKNOWN_PROTOCOL: Local: Unknown protocol'
- '_NOT_IMPLEMENTED: Local: Not implemented'
- '_AUTHENTICATION: Local: Authentication failure'
- '_NO_OFFSET: Local: No offset stored'
- '_OUTDATED: Local: Outdated'
- '_TIMED_OUT_QUEUE: Local: Timed out in queue'
- '_UNSUPPORTED_FEATURE: Local: Required feature not supported by broker'
- '_WAIT_CACHE: Local: Awaiting cache update'
- '_INTR: Local: Operation interrupted'
- '_KEY_SERIALIZATION: Local: Key serialization error'
- '_VALUE_SERIALIZATION: Local: Value serialization error'
- '_KEY_DESERIALIZATION: Local: Key deserialization error'
- '_VALUE_DESERIALIZATION: Local: Value deserialization error'
- '_PARTIAL: Local: Partial response'
- '_READ_ONLY: Local: Read-only object'
- '_NOENT: Local: No such entry'
- '_UNDERFLOW: Local: Read underflow'
- '_INVALID_TYPE: Local: Invalid type'
- '_RETRY: Local: Retry operation'
- '_PURGE_QUEUE: Local: Purged in queue'
- '_PURGE_INFLIGHT: Local: Purged in flight'
- '_FATAL: Local: Fatal error'
- '_INCONSISTENT: Local: Inconsistent state'
- '_GAPLESS_GUARANTEE: Local: Gap-less ordering would not be guaranteed if proceeding'
- '_MAX_POLL_EXCEEDED: Local: Maximum application poll interval (max.poll.interval.ms)
  exceeded'
- '_UNKNOWN_BROKER: Local: Unknown broker'
- '_NOT_CONFIGURED: Local: Functionality not configured'
- '_FENCED: Local: This instance has been fenced by a newer instance'
- '_APPLICATION: Local: Application generated error'
- '_ASSIGNMENT_LOST: Local: Group partition assignment lost'
- '_NOOP: Local: No operation performed'
- '_AUTO_OFFSET_RESET: Local: No offset to automatically reset to'
- '_LOG_TRUNCATION: Local: Partition log truncation detected'
- '_INVALID_DIFFERENT_RECORD: Local: an invalid record in the same batch caused the
  failure of this message too'
- '_DESTROY_BROKER: Local: Broker handle destroyed without termination'
- 'UNKNOWN: Unknown broker error'
- 'NO_ERROR: Success'
- 'OFFSET_OUT_OF_RANGE: Broker: Offset out of range'
- 'INVALID_MSG: Broker: Invalid message'
- 'UNKNOWN_TOPIC_OR_PART: Broker: Unknown topic or partition'
- 'INVALID_MSG_SIZE: Broker: Invalid message size'
- 'LEADER_NOT_AVAILABLE: Broker: Leader not available'
- 'NOT_LEADER_FOR_PARTITION: Broker: Not leader for partition'
- 'REQUEST_TIMED_OUT: Broker: Request timed out'
- 'BROKER_NOT_AVAILABLE: Broker: Broker not available'
- 'REPLICA_NOT_AVAILABLE: Broker: Replica not available'
- 'MSG_SIZE_TOO_LARGE: Broker: Message size too large'
- 'STALE_CTRL_EPOCH: Broker: StaleControllerEpochCode'
- 'OFFSET_METADATA_TOO_LARGE: Broker: Offset metadata string too large'
- 'NETWORK_EXCEPTION: Broker: Broker disconnected before response received'
- 'COORDINATOR_LOAD_IN_PROGRESS: Broker: Coordinator load in progress'
- 'COORDINATOR_NOT_AVAILABLE: Broker: Coordinator not available'
- 'NOT_COORDINATOR: Broker: Not coordinator'
- 'TOPIC_EXCEPTION: Broker: Invalid topic'
- 'RECORD_LIST_TOO_LARGE: Broker: Message batch larger than configured server segment
  size'
- 'NOT_ENOUGH_REPLICAS: Broker: Not enough in-sync replicas'
- 'NOT_ENOUGH_REPLICAS_AFTER_APPEND: Broker: Message(s) written to insufficient number
  of in-sync replicas'
- 'INVALID_REQUIRED_ACKS: Broker: Invalid required acks value'
- 'ILLEGAL_GENERATION: Broker: Specified group generation id is not valid'
- 'INCONSISTENT_GROUP_PROTOCOL: Broker: Inconsistent group protocol'
- 'INVALID_GROUP_ID: Broker: Invalid group.id'
- 'UNKNOWN_MEMBER_ID: Broker: Unknown member'
- 'INVALID_SESSION_TIMEOUT: Broker: Invalid session timeout'
- 'REBALANCE_IN_PROGRESS: Broker: Group rebalance in progress'
- 'INVALID_COMMIT_OFFSET_SIZE: Broker: Commit offset data size is not valid'
- 'TOPIC_AUTHORIZATION_FAILED: Broker: Topic authorization failed'
- 'GROUP_AUTHORIZATION_FAILED: Broker: Group authorization failed'
- 'CLUSTER_AUTHORIZATION_FAILED: Broker: Cluster authorization failed'
- 'INVALID_TIMESTAMP: Broker: Invalid timestamp'
- 'UNSUPPORTED_SASL_MECHANISM: Broker: Unsupported SASL mechanism'
- 'ILLEGAL_SASL_STATE: Broker: Request not valid in current SASL state'
- 'UNSUPPORTED_VERSION: Broker: API version not supported'
- 'TOPIC_ALREADY_EXISTS: Broker: Topic already exists'
- 'INVALID_PARTITIONS: Broker: Invalid number of partitions'
- 'INVALID_REPLICATION_FACTOR: Broker: Invalid replication factor'
- 'INVALID_REPLICA_ASSIGNMENT: Broker: Invalid replica assignment'
- 'INVALID_CONFIG: Broker: Configuration is invalid'
- 'NOT_CONTROLLER: Broker: Not controller for cluster'
- 'INVALID_REQUEST: Broker: Invalid request'
- 'UNSUPPORTED_FOR_MESSAGE_FORMAT: Broker: Message format on broker does not support
  request'
- 'POLICY_VIOLATION: Broker: Policy violation'
- 'OUT_OF_ORDER_SEQUENCE_NUMBER: Broker: Broker received an out of order sequence
  number'
- 'DUPLICATE_SEQUENCE_NUMBER: Broker: Broker received a duplicate sequence number'
- 'INVALID_PRODUCER_EPOCH: Broker: Producer attempted to operate with an old epoch'
- 'INVALID_TXN_STATE: Broker: Producer attempted a transactional operation in an invalid
  state'
- 'INVALID_PRODUCER_ID_MAPPING: Broker: Producer attempted to use a producer id which
  is not currently assigned'
- 'INVALID_TRANSACTION_TIMEOUT: Broker: Transaction timeout is larger than the maximum
  value allowed'
- 'CONCURRENT_TRANSACTIONS: Broker: Producer attempted to update a transaction while
  another operation is in progress'
- 'TRANSACTION_COORDINATOR_FENCED: Broker: Indicates that the transaction coordinator
  is no longer current'
- 'TRANSACTIONAL_ID_AUTHORIZATION_FAILED: Broker: Transactional Id authorization failed'
- 'SECURITY_DISABLED: Broker: Security features are disabled'
- 'OPERATION_NOT_ATTEMPTED: Broker: Operation not attempted'
- 'KAFKA_STORAGE_ERROR: Broker: Disk error accessing log file'
- 'LOG_DIR_NOT_FOUND: Broker: Specified log directory not found'
- 'SASL_AUTHENTICATION_FAILED: Broker: SASL Authentication failed'
- 'UNKNOWN_PRODUCER_ID: Broker: Unknown Producer Id'
- 'REASSIGNMENT_IN_PROGRESS: Broker: Partition reassignment in progress'
- 'DELEGATION_TOKEN_AUTH_DISABLED: Broker: Delegation Token feature not enabled'
- 'DELEGATION_TOKEN_NOT_FOUND: Broker: Delegation Token not found'
- 'DELEGATION_TOKEN_OWNER_MISMATCH: Broker: Specified Principal not valid Owner/Renewer'
- 'DELEGATION_TOKEN_REQUEST_NOT_ALLOWED: Broker: Delegation Token requests not allowed'
- 'DELEGATION_TOKEN_AUTHORIZATION_FAILED: Broker: Delegation Token authorization failed'
- 'DELEGATION_TOKEN_EXPIRED: Broker: Delegation Token expired'
- 'INVALID_PRINCIPAL_TYPE: Broker: Supplied principalType not supported'
- 'NON_EMPTY_GROUP: Broker: The group is not empty'
- 'GROUP_ID_NOT_FOUND: Broker: The group id does not exist'
- 'FETCH_SESSION_ID_NOT_FOUND: Broker: The fetch session ID not found'
- 'INVALID_FETCH_SESSION_EPOCH: Broker: The fetch session epoch is invalid'
- 'LISTENER_NOT_FOUND: Broker: No matching listener'
- 'TOPIC_DELETION_DISABLED: Broker: Topic deletion disabled'
- 'FENCED_LEADER_EPOCH: Broker: Leader epoch older than broker epoch'
- 'UNKNOWN_LEADER_EPOCH: Broker: Leader epoch newer than broker epoch'
- 'UNSUPPORTED_COMPRESSION_TYPE: Broker: Unsupported compression type'
- 'STALE_BROKER_EPOCH: Broker: Broker epoch changed'
- 'OFFSET_NOT_AVAILABLE: Broker: Leader high watermark not caught up'
- 'MEMBER_ID_REQUIRED: Broker: Group member needs valid member ID'
- 'PREFERRED_LEADER_NOT_AVAILABLE: Broker: Preferred leader not available'
- 'GROUP_MAX_SIZE_REACHED: Broker: Consumer group reached maximum size'
- 'FENCED_INSTANCE_ID: Broker: Static consumer fenced by other consumer'
- 'ELIGIBLE_LEADERS_NOT_AVAILABLE: Broker: Eligible partition leaders not available'
- 'ELECTION_NOT_NEEDED: Broker: Leader election not needed'
- 'NO_REASSIGNMENT_IN_PROGRESS: Broker: No partition reassignment in progress'
- 'GROUP_SUBSCRIBED_TO_TOPIC: Broker: Deleting offsets while consumer group subscribed'
- 'INVALID_RECORD: Broker: Broker failed to validate record'
- 'UNSTABLE_OFFSET_COMMIT: Broker: Unstable offsets need to be cleared'
- 'THROTTLING_QUOTA_EXCEEDED: Broker: Throttling quota exceeded'
- 'PRODUCER_FENCED: Broker: Newer producer with same transactionalId fences current'
- 'RESOURCE_NOT_FOUND: Broker: Request illegally referred to non-existing resource'
- 'DUPLICATE_RESOURCE: Broker: Request illegally referred to the same resource twice'
- 'UNACCEPTABLE_CREDENTIAL: Broker: Requested credential not acceptable'
- 'INCONSISTENT_VOTER_SET: Broker: Indicates sender/recipient of voter-only request
  not valid'
- 'INVALID_UPDATE_VERSION: Broker: Invalid update version'
- 'FEATURE_UPDATE_FAILED: Broker: Unable to update finalized features due to server
  error'
- 'PRINCIPAL_DESERIALIZATION_FAILURE: Broker: Request principal deserialization failed'
- 'UNKNOWN_TOPIC_ID: Broker: Unknown topic id'
- 'FENCED_MEMBER_EPOCH: Broker: Member epoch fenced by group coordinator'
- 'UNRELEASED_INSTANCE_ID: Broker: Instance ID still used by another member'
- 'UNSUPPORTED_ASSIGNOR: Broker: Assignor or version range not supported'
- 'STALE_MEMBER_EPOCH: Broker: Member epoch stale'
- 'UNKNOWN_SUBSCRIPTION_ID: Broker: Client sent push telemetry request with invalid
  subscription ID'
- 'TELEMETRY_TOO_LARGE: Broker: Client sent push telemetry request larger than maximum
  size'
- 'REBOOTSTRAP_REQUIRED: Broker: Client metadata stale, should rebootstrap'
- 'UNKNOWN_TOPIC_OR_PART: No longer returned if a topic is missing in the local cache
  when subscribing; the subscription proceeds.'
- 'TOPIC_AUTHORIZATION_FAILED: Reported once per heartbeat or subscription change,
  even if only one topic is unauthorized.'
- KafkaException
- RuntimeError if called on a closed consumer
- 'BufferError: if the internal producer message queue is full.'
- 'KeySerializationError: If an error occurs during key serialization.'
- 'ValueSerializationError: If an error occurs during value serialization.'
- 'KafkaException: For all other errors'
- _BAD_MSG
- _BAD_COMPRESSION
- _DESTROY
- _FAIL
- _TRANSPORT
- _CRIT_SYS_RESOURCE
- _RESOLVE
- _MSG_TIMED_OUT
- _PARTITION_EOF
- _UNKNOWN_PARTITION
- _FS
- _UNKNOWN_TOPIC
- _ALL_BROKERS_DOWN
- _INVALID_ARG
- _TIMED_OUT
- _QUEUE_FULL
- _ISR_INSUFF
- _NODE_UPDATE
- _SSL
- _WAIT_COORD
- _UNKNOWN_GROUP
- _IN_PROGRESS
- _PREV_IN_PROGRESS
- _EXISTING_SUBSCRIPTION
- _ASSIGN_PARTITIONS
- _REVOKE_PARTITIONS
- _CONFLICT
- _STATE
- _UNKNOWN_PROTOCOL
- _NOT_IMPLEMENTED
- _AUTHENTICATION
- _NO_OFFSET
- _OUTDATED
- _TIMED_OUT_QUEUE
- _UNSUPPORTED_FEATURE
- _WAIT_CACHE
- _INTR
- _KEY_SERIALIZATION
- _VALUE_SERIALIZATION
- _KEY_DESERIALIZATION
- _VALUE_DESERIALIZATION
- _PARTIAL
- _READ_ONLY
- _NOENT
- _UNDERFLOW
- _INVALID_TYPE
- _RETRY
- _PURGE_QUEUE
- _PURGE_INFLIGHT
- _FATAL
- _INCONSISTENT
- _GAPLESS_GUARANTEE
- _MAX_POLL_EXCEEDED
- _UNKNOWN_BROKER
- _NOT_CONFIGURED
- _FENCED
- _APPLICATION
- _ASSIGNMENT_LOST
- _NOOP
- _AUTO_OFFSET_RESET
- _LOG_TRUNCATION
- _INVALID_DIFFERENT_RECORD
- _DESTROY_BROKER
- UNKNOWN
- NO_ERROR
- OFFSET_OUT_OF_RANGE
- INVALID_MSG
- UNKNOWN_TOPIC_OR_PART
- INVALID_MSG_SIZE
- LEADER_NOT_AVAILABLE
- NOT_LEADER_FOR_PARTITION
- REQUEST_TIMED_OUT
- BROKER_NOT_AVAILABLE
- REPLICA_NOT_AVAILABLE
- MSG_SIZE_TOO_LARGE
- STALE_CTRL_EPOCH
- OFFSET_METADATA_TOO_LARGE
- NETWORK_EXCEPTION
- COORDINATOR_LOAD_IN_PROGRESS
- COORDINATOR_NOT_AVAILABLE
- NOT_COORDINATOR
- TOPIC_EXCEPTION
- RECORD_LIST_TOO_LARGE
- NOT_ENOUGH_REPLICAS
- NOT_ENOUGH_REPLICAS_AFTER_APPEND
- INVALID_REQUIRED_ACKS
- ILLEGAL_GENERATION
- INCONSISTENT_GROUP_PROTOCOL
- INVALID_GROUP_ID
- UNKNOWN_MEMBER_ID
- INVALID_SESSION_TIMEOUT
- REBALANCE_IN_PROGRESS
- INVALID_COMMIT_OFFSET_SIZE
- TOPIC_AUTHORIZATION_FAILED
- GROUP_AUTHORIZATION_FAILED
- CLUSTER_AUTHORIZATION_FAILED
- INVALID_TIMESTAMP
- UNSUPPORTED_SASL_MECHANISM
- ILLEGAL_SASL_STATE
- UNSUPPORTED_VERSION
- TOPIC_ALREADY_EXISTS
- INVALID_PARTITIONS
- INVALID_REPLICATION_FACTOR
- INVALID_REPLICA_ASSIGNMENT
- INVALID_CONFIG
- NOT_CONTROLLER
- INVALID_REQUEST
- UNSUPPORTED_FOR_MESSAGE_FORMAT
- POLICY_VIOLATION
- OUT_OF_ORDER_SEQUENCE_NUMBER
- DUPLICATE_SEQUENCE_NUMBER
- INVALID_PRODUCER_EPOCH
- INVALID_TXN_STATE
- INVALID_PRODUCER_ID_MAPPING
- INVALID_TRANSACTION_TIMEOUT
- CONCURRENT_TRANSACTIONS
- TRANSACTION_COORDINATOR_FENCED
- TRANSACTIONAL_ID_AUTHORIZATION_FAILED
- SECURITY_DISABLED
- OPERATION_NOT_ATTEMPTED
- KAFKA_STORAGE_ERROR
- LOG_DIR_NOT_FOUND
- SASL_AUTHENTICATION_FAILED
- UNKNOWN_PRODUCER_ID
- REASSIGNMENT_IN_PROGRESS
- DELEGATION_TOKEN_AUTH_DISABLED
- DELEGATION_TOKEN_NOT_FOUND
- DELEGATION_TOKEN_OWNER_MISMATCH
- DELEGATION_TOKEN_REQUEST_NOT_ALLOWED
- DELEGATION_TOKEN_AUTHORIZATION_FAILED
- DELEGATION_TOKEN_EXPIRED
- INVALID_PRINCIPAL_TYPE
- NON_EMPTY_GROUP
- GROUP_ID_NOT_FOUND
- FETCH_SESSION_ID_NOT_FOUND
- INVALID_FETCH_SESSION_EPOCH
- LISTENER_NOT_FOUND
- TOPIC_DELETION_DISABLED
- FENCED_LEADER_EPOCH
- UNKNOWN_LEADER_EPOCH
- UNSUPPORTED_COMPRESSION_TYPE
- STALE_BROKER_EPOCH
- OFFSET_NOT_AVAILABLE
- MEMBER_ID_REQUIRED
- PREFERRED_LEADER_NOT_AVAILABLE
- GROUP_MAX_SIZE_REACHED
- FENCED_INSTANCE_ID
- ELIGIBLE_LEADERS_NOT_AVAILABLE
- ELECTION_NOT_NEEDED
- NO_REASSIGNMENT_IN_PROGRESS
- GROUP_SUBSCRIBED_TO_TOPIC
- INVALID_RECORD
- UNSTABLE_OFFSET_COMMIT
- THROTTLING_QUOTA_EXCEEDED
- PRODUCER_FENCED
- RESOURCE_NOT_FOUND
- DUPLICATE_RESOURCE
- UNACCEPTABLE_CREDENTIAL
- INCONSISTENT_VOTER_SET
- INVALID_UPDATE_VERSION
- FEATURE_UPDATE_FAILED
- PRINCIPAL_DESERIALIZATION_FAILURE
- UNKNOWN_TOPIC_ID
- FENCED_MEMBER_EPOCH
- UNRELEASED_INSTANCE_ID
- UNSUPPORTED_ASSIGNOR
- STALE_MEMBER_EPOCH
- UNKNOWN_SUBSCRIPTION_ID
- TELEMETRY_TOO_LARGE
- REBOOTSTRAP_REQUIRED
- KafkaJS.KafkaJSConnectionError
- KafkaJS.KafkaJSNoBrokerAvailableError
- KafkaJS.KafkaJSError
- client level errors
- 'ErrBadMsg: Bad message format'
- 'ErrBadCompression: Invalid compressed data'
- 'ErrDestroy: Broker handle destroyed for termination'
- 'ErrFail: Communication failure with broker'
- 'ErrTransport: Broker transport failure'
- 'ErrCritSysResource: Critical system resource failure'
- 'ErrResolve: Host resolution failure'
- 'ErrMsgTimedOut: Message timed out'
- 'ErrPartitionEOF: No more messages'
- 'ErrUnknownPartition: Unknown partition'
- 'ErrFs: File or filesystem error'
- 'ErrUnknownTopic: Unknown topic'
- 'ErrAllBrokersDown: All broker connections are down'
- 'ErrInvalidArg: Invalid argument or configuration'
- 'ErrTimedOut: Timed out'
- 'ErrQueueFull: Queue full'
- 'ErrIsrInsuff: ISR count insufficient'
- 'ErrNodeUpdate: Broker node update'
- 'ErrSsl: SSL error'
- 'ErrWaitCoord: Waiting for coordinator'
- 'ErrUnknownGroup: Unknown group'
- 'ErrInProgress: Operation in progress'
- 'ErrPrevInProgress: Previous operation in progress'
- 'ErrExistingSubscription: Existing subscription'
- 'ErrAssignPartitions: Assign partitions'
- 'ErrRevokePartitions: Revoke partitions'
- 'ErrConflict: Conflicting use'
- 'ErrState: Erroneous state'
- 'ErrUnknownProtocol: Unknown protocol'
- 'ErrNotImplemented: Not implemented'
- 'ErrAuthentication: Authentication failure'
- 'ErrNoOffset: No offset stored'
- 'ErrOutdated: Outdated'
- 'ErrTimedOutQueue: Timed out in queue'
- 'ErrUnsupportedFeature: Required feature not supported by broker'
- 'ErrWaitCache: Awaiting cache update'
- 'ErrIntr: Operation interrupted'
- 'ErrKeySerialization: Key serialization error'
- 'ErrValueSerialization: Value serialization error'
- 'ErrKeyDeserialization: Key deserialization error'
- 'ErrValueDeserialization: Value deserialization error'
- 'ErrPartial: Partial response'
- 'ErrReadOnly: Read-only object'
- 'ErrNoent: No such entry'
- 'ErrUnderflow: Read underflow'
- 'ErrInvalidType: Invalid type'
- 'ErrRetry: Retry operation'
- 'ErrPurgeQueue: Purged in queue'
- 'ErrPurgeInflight: Purged in flight'
- 'ErrFatal: Fatal error'
- 'ErrInconsistent: Inconsistent state'
- 'ErrGaplessGuarantee: Gap-less ordering would not be guaranteed if proceeding'
- 'ErrMaxPollExceeded: Maximum application poll interval (max.poll.interval.ms) exceeded'
- 'ErrUnknownBroker: Unknown broker'
- 'ErrNotConfigured: Functionality not configured'
- 'ErrFenced: This instance has been fenced by a newer instance'
- 'ErrApplication: Application generated error'
- 'ErrAssignmentLost: Group partition assignment lost'
- 'ErrNoop: No operation performed'
- 'ErrAutoOffsetReset: No offset to automatically reset to'
- 'ErrLogTruncation: Partition log truncation detected'
- 'ErrInvalidDifferentRecord: An invalid record in the same batch caused the failure
  of this message too'
- 'ErrDestroyBroker: Broker handle destroyed without termination'
- 'ErrUnknown: Unknown broker error'
- 'ErrNoError: Success'
- 'ErrOffsetOutOfRange: Offset out of range'
- 'ErrInvalidMsg: Invalid message'
- 'ErrUnknownTopicOrPart: Unknown topic or partition'
- 'ErrInvalidMsgSize: Invalid message size'
- 'ErrLeaderNotAvailable: Leader not available'
- 'ErrNotLeaderForPartition: Not leader for partition'
- 'ErrRequestTimedOut: Request timed out'
- 'ErrBrokerNotAvailable: Broker not available'
- 'ErrReplicaNotAvailable: Replica not available'
- 'ErrMsgSizeTooLarge: Message size too large'
- 'ErrStaleCtrlEpoch: StaleControllerEpochCode'
- 'ErrOffsetMetadataTooLarge: Offset metadata string too large'
- 'ErrNetworkException: Broker disconnected before response received'
- 'ErrCoordinatorLoadInProgress: Coordinator load in progress'
- 'ErrCoordinatorNotAvailable: Coordinator not available'
- 'ErrNotCoordinator: Not coordinator'
- 'ErrTopicException: Invalid topic'
- 'ErrRecordListTooLarge: Message batch larger than configured server segment size'
- 'ErrNotEnoughReplicas: Not enough in-sync replicas'
- 'ErrNotEnoughReplicasAfterAppend: Message(s) written to insufficient number of in-sync
  replicas'
- 'ErrInvalidRequiredAcks: Invalid required acks value'
- 'ErrIllegalGeneration: Specified group generation id is not valid'
- 'ErrInconsistentGroupProtocol: Inconsistent group protocol'
- 'ErrInvalidGroupID: Invalid group.id'
- 'ErrUnknownMemberID: Unknown member'
- 'ErrInvalidSessionTimeout: Invalid session timeout'
- 'ErrRebalanceInProgress: Group rebalance in progress'
- 'ErrInvalidCommitOffsetSize: Commit offset data size is not valid'
- 'ErrTopicAuthorizationFailed: Topic authorization failed'
- 'ErrGroupAuthorizationFailed: Group authorization failed'
- 'ErrClusterAuthorizationFailed: Cluster authorization failed'
- 'ErrInvalidTimestamp: Invalid timestamp'
- 'ErrUnsupportedSaslMechanism: Unsupported SASL mechanism'
- 'ErrIllegalSaslState: Request not valid in current SASL state'
- 'ErrUnsupportedVersion: API version not supported'
- 'ErrTopicAlreadyExists: Topic already exists'
- 'ErrInvalidPartitions: Invalid number of partitions'
- 'ErrInvalidReplicationFactor: Invalid replication factor'
- 'ErrInvalidReplicaAssignment: Invalid replica assignment'
- 'ErrInvalidConfig: Configuration is invalid'
- 'ErrNotController: Not controller for cluster'
- 'ErrInvalidRequest: Invalid request'
- 'ErrUnsupportedForMessageFormat: Message format on broker does not support request'
- 'ErrPolicyViolation: Policy violation'
- 'ErrOutOfOrderSequenceNumber: Broker received an out of order sequence number'
- 'ErrDuplicateSequenceNumber: Broker received a duplicate sequence number'
- 'ErrInvalidProducerEpoch: Producer attempted an operation with an old epoch'
- 'ErrInvalidTxnState: Producer attempted a transactional operation in an invalid
  state'
- 'ErrInvalidProducerIDMapping: Producer attempted to use a producer id which is not
  currently assigned to its transactional id'
- 'ErrInvalidTransactionTimeout: Transaction timeout is larger than the maximum value
  allowed by the broker''s max.transaction.timeout.ms'
- 'ErrConcurrentTransactions: Producer attempted to update a transaction while another
  concurrent operation on the same transaction was ongoing'
- 'ErrTransactionCoordinatorFenced: Indicates that the transaction coordinator sending
  a WriteTxnMarker is no longer the current coordinator for a given producer'
- 'ErrTransactionalIDAuthorizationFailed: Transactional Id authorization failed'
- 'ErrSecurityDisabled: Security features are disabled'
- 'ErrOperationNotAttempted: Operation not attempted'
- 'ErrKafkaStorageError: Disk error when trying to access log file on disk'
- 'ErrLogDirNotFound: The user-specified log directory is not found in the broker
  config'
- 'ErrSaslAuthenticationFailed: SASL Authentication failed'
- 'ErrUnknownProducerID: Unknown Producer Id'
- 'ErrReassignmentInProgress: Partition reassignment is in progress'
- 'ErrDelegationTokenAuthDisabled: Delegation Token feature is not enabled'
- 'ErrDelegationTokenNotFound: Delegation Token is not found on server'
- 'ErrDelegationTokenOwnerMismatch: Specified Principal is not valid Owner/Renewer'
- 'ErrDelegationTokenRequestNotAllowed: Delegation Token requests are not allowed
  on this connection'
- 'ErrDelegationTokenAuthorizationFailed: Delegation Token authorization failed'
- 'ErrDelegationTokenExpired: Delegation Token is expired'
- C.RD_KAFKA_RESP_ERR_INVALID_PRINCIPAL_TYPE
- C.RD_KAFKA_RESP_ERR_NON_EMPTY_GROUP
- C.RD_KAFKA_RESP_ERR_GROUP_ID_NOT_FOUND
- C.RD_KAFKA_RESP_ERR_FETCH_SESSION_ID_NOT_FOUND
- C.RD_KAFKA_RESP_ERR_INVALID_FETCH_SESSION_EPOCH
- C.RD_KAFKA_RESP_ERR_LISTENER_NOT_FOUND
- C.RD_KAFKA_RESP_ERR_TOPIC_DELETION_DISABLED
- C.RD_KAFKA_RESP_ERR_FENCED_LEADER_EPOCH
- C.RD_KAFKA_RESP_ERR_UNKNOWN_LEADER_EPOCH
- C.RD_KAFKA_RESP_ERR_UNSUPPORTED_COMPRESSION_TYPE
- C.RD_KAFKA_RESP_ERR_STALE_BROKER_EPOCH
- C.RD_KAFKA_RESP_ERR_OFFSET_NOT_AVAILABLE
- C.RD_KAFKA_RESP_ERR_MEMBER_ID_REQUIRED
- C.RD_KAFKA_RESP_ERR_PREFERRED_LEADER_NOT_AVAILABLE
- C.RD_KAFKA_RESP_ERR_GROUP_MAX_SIZE_REACHED
- C.RD_KAFKA_RESP_ERR_FENCED_INSTANCE_ID
- C.RD_KAFKA_RESP_ERR_ELIGIBLE_LEADERS_NOT_AVAILABLE
- C.RD_KAFKA_RESP_ERR_ELECTION_NOT_NEEDED
- C.RD_KAFKA_RESP_ERR_NO_REASSIGNMENT_IN_PROGRESS
- C.RD_KAFKA_RESP_ERR_GROUP_SUBSCRIBED_TO_TOPIC
- C.RD_KAFKA_RESP_ERR_INVALID_RECORD
- C.RD_KAFKA_RESP_ERR_UNSTABLE_OFFSET_COMMIT
- C.RD_KAFKA_RESP_ERR_THROTTLING_QUOTA_EXCEEDED
- C.RD_KAFKA_RESP_ERR_PRODUCER_FENCED
- C.RD_KAFKA_RESP_ERR_RESOURCE_NOT_FOUND
- C.RD_KAFKA_RESP_ERR_DUPLICATE_RESOURCE
- C.RD_KAFKA_RESP_ERR_UNACCEPTABLE_CREDENTIAL
- C.RD_KAFKA_RESP_ERR_INCONSISTENT_VOTER_SET
- C.RD_KAFKA_RESP_ERR_INVALID_UPDATE_VERSION
- C.RD_KAFKA_RESP_ERR_FEATURE_UPDATE_FAILED
- C.RD_KAFKA_RESP_ERR_PRINCIPAL_DESERIALIZATION_FAILURE
- C.RD_KAFKA_RESP_ERR_UNKNOWN_TOPIC_ID
- C.RD_KAFKA_RESP_ERR_FENCED_MEMBER_EPOCH
- C.RD_KAFKA_RESP_ERR_UNRELEASED_INSTANCE_ID
- C.RD_KAFKA_RESP_ERR_UNSUPPORTED_ASSIGNOR
- C.RD_KAFKA_RESP_ERR_STALE_MEMBER_EPOCH
- C.RD_KAFKA_RESP_ERR_UNKNOWN_SUBSCRIPTION_ID
- C.RD_KAFKA_RESP_ERR_TELEMETRY_TOO_LARGE
- C.RD_KAFKA_RESP_ERR_REBOOTSTRAP_REQUIRED
- '401 Unauthorized: Verify your authentication credentials.'
- '403 Forbidden: Ensure you have access to the requested resource.'
- '403 Forbidden: Check API permissions.'
- '404 Not Found: Verify endpoint URL.'
- '429 Too Many Requests: Reduce request rate.'
- '401 Unauthorized: Check API key and OAuth token'
- '404 Not Found: Verify endpoint and resource path'
- '401 Unauthorized: Recheck API key or secret'
- '403 Forbidden: Check your API key permissions.'
- '404 Not Found: Resource may not exist.'
- '403 Forbidden: Insufficient permissions for the requested operation'
- '403 Forbidden: Check if the API key has the necessary permissions'
- '404 Not Found: Verify the resource path and parameters'
- '404 Not Found: Verify the endpoint URL'
- '429 Too Many Requests: Reduce API call frequency'
- '401 Unauthorized: Check credentials and permissions'
- '401 Unauthorized: Check token validity'
- '404 Not Found: Verify resource identifiers'
- '401 Unauthorized: Check your API key or OAuth token'
- '403 Forbidden: Insufficient permissions for this operation'
- 'Limit exceeded: You cant create more than 100 push queries.'
- 'Limit exceeded: You can have a maximum of 40 persistent queries per cluster.'
- 'Limit exceeded: You can have a maximum of 15 ksqlDB clusters per environment.'
- '400 Bad Request: Malformed or missing parameter.'
- '401 Unauthorized: Invalid or missing authentication credentials.'
- '403 Forbidden: Invalid credentials for the resource.'
- '404 Not Found: Resource could not be found.'
- '429 Rate Limit Exceeded: Too many requests.'
- '500 Oops something went wrong: An issue not covered by other errors.'
- 'Processing Errors: Inspect the processing log to get more details about the errors.'
- 'Query Restarts: Check the ksqlDB EXPLAIN statement for details about the underlying
  failures.'
- 'High Storage Utilization: Provision a cluster with more CSUs if running out of
  storage.'
- '403 Forbidden: Check API permissions'
- '404 Not Found: Verify endpoint URL and parameters'
- '403 Forbidden Access: Check with your admin to ensure proper authorization'
- '403 Forbidden: Check permissions for accessing the resource'
- '404 Not Found: Verify the endpoint path and parameters'
- Throttle API calls or reduce frequency.
- Break down filters or add selectivity.
- 'REQUEST_TIMEOUT: Adjust request timeout settings.'
- 'INVALID_INPUT: Check input format and parameters.'
- 'AGENT_NOT_RESPONDING: Check model configuration and API keys.'
- 'TOOL_CALLS_FAILING: Verify tool definitions are correct.'
- 'PERFORMANCE_ISSUES: Use function-based tools for frequent operations.'
- '401 Unauthorized: Check your credentials and OAuth token.'
- '403 Forbidden: Verify your access permissions.'
- '403 Forbidden: Check permissions or roles'
- '404 Not Found: Verify the endpoint and resource'
- '500 Internal Server Error: Retry the request later'
- '401 Unauthorized: Check your credentials and permissions.'
- '403 Forbidden: You do not have permission to access this resource.'
- '401 Unauthorized: Check client credentials and permissions'
- '404 Not Found: Verify the requested resource exists'
- 'TIMEOUT: Request to the model endpoint has timed out.'
- 'INVALID_MODEL: The specified model does not exist or is not registered.'
- 'REQUEST_FAILED: The request to the model endpoint failed.'
- '403 Forbidden: Check if the API key has the necessary permissions.'
- '403 Forbidden: Check permissions and roles assigned to your user.'
- '404 Not Found: Verify the requested resource exists.'
- '500 Internal Server Error: Try the request again later.'
- '429 Too Many Requests: Throttle API calls or reduce frequency'
- '401 Unauthorized: Check your OAuth token'
- '429 Too Many Requests: You are being rate limited'
- '204 No Content: Call succeeded in deletion of share.'
- '401 Unauthorized: Check API key and secret.'
- 'INVALID_REQUEST: Check the request parameters and format.'
- 'NOT_FOUND: Verify the requested resource exists.'
- Existing objects in the bucket may cause Tableflow to fail to start or may be lost
  entirely during initialization.
- Do not directly modify or delete objects from this bucket. Doing so may lead to
  table corruption.
- '401 Unauthorized: Check access token validity'
- '404 Not Found: Verify endpoint path'
- '401 Unauthorized: Check your client credentials and token expiration.'
- '403 Forbidden: Check permissions and roles'
- '429 Too Many Requests: Throttle API calls'
- '500 Internal Server Error: Retry after a delay'
- '401 Unauthorized: Invalid credentials provided.'
- '401 Unauthorized: Check token validity.'
- '403 Forbidden: Insufficient permissions.'
- '404 Not Found: Verify endpoint URL'
- 'INVALID_API_KEY: Check if the API key is valid.'
- 'UNAUTHORIZED: Confirm that the provided credentials have access.'
- 'lakeformation:GetDataAccess: Grant the Lake Formation pass-through permission.'
- '400 Bad Request: Check request parameters.'
- '404 Not Found: Check resource path.'
- '401 Unauthorized: Check client ID and secret or token expiration.'
- '404 Not Found: Endpoint may be incorrect.'
- '400 Bad Request: Check query parameters.'
- '401 Unauthorized: Check client credentials and token validity'
- '403 Forbidden: Check your API permissions.'
- '404 Not Found: Ensure the resource exists.'
- Failures that occur for reasons that are not record-specific always cause Tableflow
  to enter the Pause state.
- '401 Unauthorized: Check your credentials and token validity'
- 'Config Issue: There was a problem with the specified configurations.'
- 'Degraded: There is an internal issue with Tableflow.'
- '401 Unauthorized: Check your credentials and token.'
- '403 Forbidden: Ensure you have the necessary permissions.'
- '403 Forbidden: Check permissions for the requested resource'
- '404 Not Found: Verify the endpoint and resource ID'
- You may not create more than the maximum number of partitions
- '403 Forbidden: Ensure your service account has appropriate READ and DESCRIBE permissions'
- 'unknown topic or partition: Check if the topic exists and review your ACLS'
- '404 Not Found: Check the resource path or ID'
- '429 Too Many Requests: Reduce the frequency of requests.'
- '401 Unauthorized: Check token validity and permissions.'
- '404 Not Found: Verify the endpoint path'
- '429 Too Many Requests: Rate limit exceeded, try again later'
- '404 Not Found: Incorrect endpoint or resource ID'
- '401 Unauthorized: Verify authentication credentials.'
- '403 Forbidden: Check your permissions or access roles.'
- '404 Not Found: Ensure the endpoint path is correct.'
- '429 Too Many Requests: Reduce the rate of requests.'
- '401 Unauthorized: Verify client credentials.'
- '403 Forbidden: Check your permissions'
- '401 Unauthorized: Verify OAuth token and scopes'
- '403 Forbidden: Check your API key permissions'
- '404 Not Found: Resource does not exist'
- 'HTTP 401 unauthorized: Verify the API key and secret in your USM Agent configuration
  file.'
- 'HTTP 503 service unavailable: Verify the Confluent Cloud endpoint URL in the USM
  Agents configuration file.'
- '400: Ensure that the USM Agent and its corresponding Confluent Platform cluster
  are configured for the same Confluent Cloud environment.'
- '403 forbidden: The agents API key is valid, but its service account lacks permissions.'
- 'HTTP 401 unauthorized: Verify API key and secret'
- 'HTTP 503 service unavailable: Verify endpoint URL and network connectivity'
- '400: Ensure Confluent Platform cluster is registered in the same environment'
- '403 Forbidden: Grant USMAgent role to service account'
- '429 Too Many Requests: Rate limits on API requests to search the Catalog API.'
- '401 Unauthorized: Check client credentials and token validity.'
- '403 Forbidden: Ensure the user has sufficient permissions.'
- Rate Limits on searches of the Stream Governance cluster are capped at 25 Write
  requests per second and 75 Read requests.
- '4000151: Business-metadata attribute already exists in entity'
- 'Query complexity limit: maximum query complexity is 200.'
- 'Query depth limit: maximum query depth is 20.'
- Maximum time limit for any GraphQL query is 30 seconds.
- Maximum rate limit is 25 requests per second.
- '400 Bad Request: Check that messages are valid JSON.'
- '403 Forbidden: Ensure proper RBAC permissions are assigned.'
- Rate limits on number of API requests is 25 Write requests per second or 75 Read
  requests across all API keys pointing to a particular LSRC.
- '403 Forbidden: Ensure your API key has the right permissions.'
- '429 Too Many Requests: Throttle your requests.'
- '401 Unauthorized: Check your credentials.'
- 'HTTP/1.1 422 Unprocessable Entity: Schema Limit Exceeded'
- '401 Unauthorized: Check client credentials'
- 'INVALID_RECORD: Message does not contain a valid schema ID.'
- 'PAUSED: Check for DNS resolution issues for the proxy host'
- 'CONNECTION_ERROR: Review logs for specific error messages'
- Unable to authenticate with OAuth provider
- Access denied to Schema Registry resources
- Token expired
- 'Error: Unable to authenticate with OAuth provider'
- '400 Bad Request: Check the request parameters'
- '401 Unauthorized: Verify token validity'
- '401 Unauthorized: Invalid credentials or token expired.'
- Schema being registered is incompatible with an earlier schema
- '401 Unauthorized: Check your credentials and token validity.'
- '429 Too Many Requests: You have exceeded your API rate limit.'
- '500 Internal Server Error: Unexpected error, try again later.'
- Modifying a field type from `Number` to `String` requires either upgrading all producers
  and consumers to the new schema version at the same time or creating a brand-new
  topic.
- 'Schema not found: This can occur when minor differences exist between client and
  registered schemas.'
- error serializing Avro message
- 'java.lang.ClassCastException: class java.time.Instant cannot be cast to class java.lang.Number'
- 'Caused by: org.apache.avro.AvroRuntimeException: Unknown datum type java.time.Instant'
- '{"error_code":40801,"message":"Error serializing Avro message"}'
- '429 Too Many Requests: Exceeded rate limit, try again later.'
- '40801: Error serializing Avro message'
- 'SerializationException: Ensure data is well formed'
- '400 Bad Request: Check your request parameters and payload.'
- '404 Not Found: Ensure the endpoint exists and is correctly specified.'
- '401 Unauthorized: Verify API key and permissions.'
- 'json.fail.unknown.properties: Fails if unknown properties are encountered.'
- 'json.write.dates.iso8601: Allows dates to be written as ISO-8601 strings.'
- 'Error serializing JSON message: JSON does not match schema'
- the JSON document is invalid
- '401 Unauthorized: Recheck API Key or Secret.'
- '400 Bad Request: Check request parameters'
- '401 Unauthorized: Review OAuth token'
- '429 Too Many Requests: Slow down API calls'
- '401 Unauthorized: Check client credentials and permissions.'
- '401 Unauthorized: Recheck OAuth credentials or token expiration.'
- Error occurs if row already exists in the table.
- User-actionable errors may require manual restart of the connector if auto-restart
  is disabled.
- '401 Unauthorized: Check API key and secret'
- '500 Internal Server Error: Check AWS permissions'
- 'REQUEST_LIMIT_EXCEEDED: Contact Amazon to increase this transaction limit for your
  account.'
- 'FAIL: Fail the connector on malformed records.'
- '401 Unauthorized: Recheck IAM user permissions.'
- Hit provisioning capacity, will retry indefinitely.. Increase your throughput capacity
- 'Invalid credentials: Check your AWS and Kafka credentials.'
- 'Connector not found: Ensure that the connector name is correct.'
- 'Task failed: Check the logs for errors.'
- If you see a large number of small files in the S3 bucket, it may be that consecutive
  records in a partition have incompatible schemas.
- '404 Not Found: Verify the endpoint and resource exists.'
- If you set this property to all, the connector will not fail on errant records,
  but will instead log them (and send to DLQ for Sink Connectors) and continue processing.
- If you set this property to none, the connector task will fail on errant records.
- 'AccessDenied: To avoid AccessDenied errors in your CloudTrail logs, you can add
  the equivalent permission to the connector.'
- '401 Unauthorized: Recheck IAM role or access permissions'
- 'InvalidRequestContentException: The entire batch containing the failed record is
  sent to the DLQ.'
- 'Use this property if you would like to configure the connectors error handling
  behavior. WARNING: This property should be used with CAUTION for SOURCE CONNECTORS
  as it may lead to dataloss.'
- If you set this property to all, the connector will not fail on errant records.
- '404 Not Found: Check the endpoint path.'
- '403 Forbidden: Ensure the API key has the necessary permissions.'
- Exceeding quota may result in throttling or errors
- 'Invalid Credentials: Check your Kafka API key and secret.'
- 'Unauthorized: Ensure that the shared access policy has the correct permissions.'
- Use this property if you would like to configure the connectors error handling
  behavior.
- 'Unauthorized: Check API key and secret.'
- 'Invalid configuration: Review connector properties.'
- '401 Unauthorized: Recheck API key or service account permissions'
- '403 Forbidden: Check if you have the right permissions'
- '400 Bad Request: Ensure the request payload is correct'
- '429 Too Many Requests: Limit your requests to avoid hitting rate limits'
- '401 Unauthorized: Check your API key and secret'
- '401 Unauthorized: Check credentials or token expiration.'
- '403 Forbidden: Insufficient permissions for this action.'
auth_info:
  mentioned_objects:
  - OauthToken
  - AuthProvider
  - NamedCredential
  - Authorization
  - OAuth
  - service account
  - API key
  - secret
  - ApiKey
  - ServiceAccount
  - OAuth2
  - ClientCredentials
  - OAuthToken
  - IdentityProvider
  - Service Account
  - API Key
  - Bearer Token
  - Access Token
  - Client ID
  - Client Credential
  - Client Secret
  - AccessToken
  - RefreshToken
  - KafkaAvroSerializer
  - KafkaAvroDeserializer
  - OAuth2Client
  - OAuth2Token
  - confluentBroker
  - confluentSchemaRegistry
  - APIKey
  - OAuthProvider
  - Azure RBAC service principal
  - Azure Cognitive Search API key
  - OAuthClient
client:
  base_url: https://api.confluent.cloud
  auth:
    type: oauth2
    flow: refresh_token
    token_url: https://login.confluent.cloud/oauth2/token
    client_id: '{{ dlt.secrets[''confluent_client_id''] }}'
    client_secret: '{{ dlt.secrets[''confluent_client_secret''] }}'
    refresh_token: '{{ dlt.secrets[''confluent_refresh_token''] }}'
    location: header
    header_name: Authorization
  headers:
    Accept: application/json
source_metadata: null
