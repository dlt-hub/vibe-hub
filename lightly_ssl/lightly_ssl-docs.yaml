resources:
- name: dataset
  endpoint:
    path: /api/datasets
    method: GET
    data_selector: datasets
    params: {}
- name: tags
  endpoint:
    path: /api/tags
    method: GET
    data_selector: tags
    params: {}
- name: dataset
  endpoint:
    path: /datasets
    method: GET
    data_selector: datasets
- name: tag
  endpoint:
    path: /tags
    method: GET
    data_selector: tags
- name: crop_images
  endpoint:
    path: /lightly/crop
    method: POST
    data_selector: results
- name: train_model
  endpoint:
    path: /lightly/train
    method: POST
    data_selector: results
- name: embed_images
  endpoint:
    path: /lightly/embed
    method: POST
    data_selector: results
- name: download_data
  endpoint:
    path: /lightly/download
    method: GET
    data_selector: results
- name: dataset
  endpoint:
    path: /datasets
    method: GET
    data_selector: records
    params: {}
- name: tags
  endpoint:
    path: /tags
    method: GET
    data_selector: records
    params: {}
- name: dataset
  endpoint:
    path: /datasets
    method: GET
    data_selector: records
- name: tag
  endpoint:
    path: /tags
    method: GET
    data_selector: records
- name: LightlyDataset
  endpoint:
    path: ./my/cute/cats/dataset/
    method: GET
- name: dataset
  endpoint:
    path: /api/v1/dataset
    method: GET
    data_selector: datasets
- name: tags
  endpoint:
    path: /api/v1/tags
    method: GET
    data_selector: tags
- name: SimCLRTransform
  endpoint:
    path: /lightly/transforms/SimCLRTransform
    method: GET
    data_selector: records
- name: MultiViewTransform
  endpoint:
    path: /lightly/transforms/multi_view_transform
    method: GET
    data_selector: records
- name: NTXentLoss
  endpoint:
    path: /lightly/loss/NTXentLoss
    method: GET
    data_selector: records
- name: datasets
  endpoint:
    path: /api/v1/datasets
    method: GET
    data_selector: data
    params: {}
- name: tags
  endpoint:
    path: /api/v1/tags
    method: GET
    data_selector: data
    params: {}
- name: ApiWorkflowClient
  endpoint:
    path: /services/data/vXX.X/ApiWorkflowClient
    method: GET
    data_selector: records
    params: {}
- name: ImageNet1k
  endpoint:
    path: /imagenet1k
    method: GET
    data_selector: benchmarks
    params: {}
- name: ImageNet100
  endpoint:
    path: /imagenet100
    method: GET
    data_selector: benchmarks
    params: {}
- name: Imagenette
  endpoint:
    path: /imagenette
    method: GET
    data_selector: benchmarks
    params: {}
- name: ApiWorkflowClient
  endpoint:
    path: /api/workflow
    method: GET
    data_selector: records
    params: {}
- name: dataset
  endpoint:
    path: /api/v1/dataset
    method: GET
    data_selector: datasets
- name: compute_worker_run
  endpoint:
    path: /api/v1/compute_worker/run
    method: GET
    data_selector: runs
- name: LightlyDataset
  endpoint:
    path: /self-supervised-learning/lightly.data.html
    method: GET
    data_selector: dataset
    params: {}
- name: video_dataset
  endpoint:
    path: /video_dir/
    method: GET
    data_selector: videos
- name: cifar10_dataset
  endpoint:
    path: /datasets/cifar10
    method: GET
    data_selector: images
- name: compute_worker_run_info
  endpoint:
    path: /api/workflow/compute_worker_run_info
    method: GET
    data_selector: records
- name: dataset
  endpoint:
    path: /api/workflow/dataset
    method: GET
    data_selector: records
- name: dataset
  endpoint:
    path: /datasets
    method: GET
    data_selector: datasets
    params: {}
- name: tag
  endpoint:
    path: /tags
    method: GET
    data_selector: tags
    params: {}
- name: dataset
  endpoint:
    path: /datasets/pascal_voc
    method: GET
    data_selector: records
    params:
      download: 'true'
- name: ApiWorkflowClient
  endpoint:
    path: /api/workflow
    method: GET
    data_selector: records
    params: {}
- name: cifar10
  endpoint:
    path: /datasets/cifar10
    method: GET
    data_selector: records
    params: {}
- name: dataset
  endpoint:
    path: /datasets
    method: GET
    data_selector: records
- name: tags
  endpoint:
    path: /tags
    method: GET
    data_selector: records
- name: cifar10
  endpoint:
    path: /datasets/cifar10
    method: GET
- name: dataset
  endpoint:
    path: /datasets
    method: GET
    data_selector: datasets
- name: tags
  endpoint:
    path: /tags
    method: GET
    data_selector: tags
- name: dataset
  endpoint:
    path: /datasets/pascal_voc
    method: GET
    data_selector: records
    params:
      download: true
- name: VOCDetection
  endpoint:
    path: /datasets/pascal_voc
    method: GET
    data_selector: records
    params: {}
- name: VOCDetection
  endpoint:
    path: /datasets/pascal_voc
    method: GET
    data_selector: records
    params:
      download: 'true'
- name: dataset
  endpoint:
    path: /api/dataset
    method: GET
    data_selector: records
    params: {}
- name: tag
  endpoint:
    path: /api/tag
    method: GET
    data_selector: records
    params: {}
- name: cifar10
  endpoint:
    path: datasets/cifar10
    method: GET
    data_selector: records
    params: {}
- name: datasets
  endpoint:
    path: /api/v1/datasets
    method: GET
    data_selector: datasets
- name: tags
  endpoint:
    path: /api/v1/tags
    method: GET
    data_selector: tags
- name: dataset
  endpoint:
    path: /datasets
    method: GET
    data_selector: datasets
- name: tag
  endpoint:
    path: /tags
    method: GET
    data_selector: tags
- name: VOCDetection
  endpoint:
    path: /datasets/VOCDetection
    method: GET
- name: cifar10
  endpoint:
    path: /datasets/cifar10
    method: GET
    data_selector: records
    params: {}
- name: CIFAR10
  endpoint:
    path: datasets/cifar10
    method: GET
    data_selector: records
    params: {}
- name: pmsn_example
  endpoint:
    path: /examples/pytorch/pmsn.py
    method: GET
    data_selector: records
- name: cifar10
  endpoint:
    path: /datasets/cifar10
    method: GET
    data_selector: records
    params: {}
- name: dataset
  endpoint:
    path: /api/v1/datasets
    method: GET
    data_selector: datasets
- name: tags
  endpoint:
    path: /api/v1/tags
    method: GET
    data_selector: tags
- name: VOCDetection
  endpoint:
    path: /datasets/VOCDetection
    method: GET
    data_selector: records
    params:
      download: true
- name: dataset
  endpoint:
    path: /api/datasets
    method: GET
    data_selector: datasets
- name: tags
  endpoint:
    path: /api/tags
    method: GET
    data_selector: tags
- name: ApiWorkflowClient
  endpoint:
    path: /api/workflow/client
    method: GET
    data_selector: records
- name: dataloader
  endpoint:
    path: /datasets/pascal_voc
    method: GET
    data_selector: records
    params:
      download: true
- name: dataset
  endpoint:
    path: /datasets/pascal_voc
    method: GET
    data_selector: records
    params: {}
- name: dataset
  endpoint:
    path: /datasets
    method: GET
    data_selector: datasets
    params: {}
- name: tags
  endpoint:
    path: /tags
    method: GET
    data_selector: tags
    params: {}
- name: dataset
  endpoint:
    path: /api/v1/datasets
    method: GET
    data_selector: datasets
- name: tags
  endpoint:
    path: /api/v1/tags
    method: GET
    data_selector: tags
- name: dataset
  endpoint:
    path: /datasets/pascal_voc
    method: GET
    data_selector: records
    params: {}
- name: dataset
  endpoint:
    path: /datasets
    method: GET
    data_selector: records
- name: tag
  endpoint:
    path: /tags
    method: GET
    data_selector: records
- name: compute_worker_run
  endpoint:
    path: /compute_worker_runs
    method: GET
    data_selector: records
- name: ApiWorkflowClient
  endpoint:
    path: /api/workflow/client
    method: GET
- name: lightly-magic
  endpoint:
    path: /lightly/magic
    method: POST
- name: lightly-ssl-train
  endpoint:
    path: /lightly/ssl/train
    method: POST
- name: lightly-embed
  endpoint:
    path: /lightly/embed
    method: POST
- name: lightly-download
  endpoint:
    path: /lightly/download
    method: POST
- name: lightly-crop
  endpoint:
    path: /lightly/crop
    method: POST
- name: train_cli
  endpoint:
    path: /train_cli
    method: GET
    data_selector: records
    params: {}
- name: embed_cli
  endpoint:
    path: /embed_cli
    method: GET
    data_selector: records
    params: {}
- name: download_cli
  endpoint:
    path: /download_cli
    method: GET
    data_selector: records
    params: {}
- name: dataset
  endpoint:
    path: /datasets
    method: GET
    data_selector: records
- name: tag
  endpoint:
    path: /tags
    method: GET
    data_selector: records
- name: lightly-magic
  endpoint:
    path: lightly-magic
    method: CLI
    data_selector: cfg
    params:
      input_dir: Path to the input directory where images are stored.
- name: lightly-ssl-train
  endpoint:
    path: lightly-ssl-train
    method: CLI
    data_selector: cfg
    params:
      input_dir: Path to the input directory where images are stored.
- name: lightly-embed
  endpoint:
    path: lightly-embed
    method: CLI
    data_selector: cfg
    params:
      input_dir: Path to the input directory where images are stored.
      checkpoint: Path to the checkpoint of a pretrained model.
- name: lightly-download
  endpoint:
    path: lightly-download
    method: CLI
    data_selector: cfg
    params:
      tag_name: Download all images from the requested tag.
      token: User access token to the Lightly platform.
      dataset_id: Identifier of the dataset on the Lightly platform.
      input_dir: If input_dir and output_dir are specified, lightly will copy all
        images.
      output_dir: If input_dir and output_dir are specified, lightly will copy all
        images.
- name: lightly-crop
  endpoint:
    path: lightly-crop
    method: CLI
    data_selector: cfg
    params:
      input_dir: Path to the input directory where images are stored.
      labels_dir: Path to the directory where the labels are stored.
      output_dir: Path to the directory where the cropped images are stored.
      crop_padding: Optional additional padding about the bounding box.
      label_names_file: Optional a yaml file including the names of the classes.
- name: download
  endpoint:
    path: /download
    method: POST
    data_selector: files
    params: {}
- name: LightlyDataset
  endpoint:
    path: /dataset
    method: GET
    data_selector: records
- name: MultiViewCollate
  endpoint:
    path: /multi_view_collate
    method: GET
    data_selector: records
- name: SwaVCollateFunction
  endpoint:
    path: /lightly/data/collate/SwaVCollateFunction
    method: GET
    data_selector: records
    params: {}
- name: VICRegCollateFunction
  endpoint:
    path: /lightly/data/collate/VICRegCollateFunction
    method: GET
    data_selector: records
    params: {}
- name: VICRegLCollateFunction
  endpoint:
    path: /lightly/data/collate/VICRegLCollateFunction
    method: GET
    data_selector: records
    params: {}
- name: barlow_twins_loss
  endpoint:
    path: /lightly/loss/barlow_twins_loss
    method: GET
    data_selector: records
    params: {}
- name: dcl_loss
  endpoint:
    path: /lightly/loss/dcl_loss
    method: GET
    data_selector: records
    params: {}
- name: dcl_w_loss
  endpoint:
    path: /lightly/loss/dcl_w_loss
    method: GET
    data_selector: records
    params: {}
- name: detcon_b_loss
  endpoint:
    path: /lightly/loss/detcon_b_loss
    method: GET
    data_selector: records
    params: {}
- name: detcon_s_loss
  endpoint:
    path: /lightly/loss/detcon_s_loss
    method: GET
    data_selector: records
    params: {}
- name: dino_loss
  endpoint:
    path: /lightly/loss/dino_loss
    method: GET
    data_selector: records
    params: {}
- name: hypersphere_loss
  endpoint:
    path: /lightly/loss/hypersphere_loss
    method: GET
    data_selector: records
    params: {}
- name: PMSNCustomLoss
  endpoint:
    path: /lightly/loss/pmsn_loss
    method: GET
    data_selector: parameters
    params: {}
- name: CO2Regularizer
  endpoint:
    path: /lightly/loss/regularizer/co2
    method: GET
    data_selector: parameters
    params: {}
- name: SwaVLoss
  endpoint:
    path: /lightly/loss/swav_loss
    method: GET
    data_selector: parameters
    params: {}
- name: SymNegCosineSimilarityLoss
  endpoint:
    path: /lightly/loss/sym_neg_cos_sim_loss
    method: GET
    data_selector: parameters
    params: {}
- name: TiCoLoss
  endpoint:
    path: /lightly/loss/tico_loss
    method: GET
    data_selector: parameters
    params: {}
- name: VICRegLoss
  endpoint:
    path: /lightly/loss/vicreg_loss
    method: GET
    data_selector: parameters
    params: {}
- name: VICRegLLoss
  endpoint:
    path: /lightly/loss/vicregl_loss
    method: GET
    data_selector: parameters
    params: {}
- name: BYOLPredictionHead
  endpoint:
    path: /models/modules/heads/BYOLPredictionHead
    method: GET
    data_selector: prediction_info
    params: {}
- name: BYOLProjectionHead
  endpoint:
    path: /models/modules/heads/BYOLProjectionHead
    method: GET
    data_selector: projection_info
    params: {}
- name: BarlowTwinsProjectionHead
  endpoint:
    path: /models/modules/heads/BarlowTwinsProjectionHead
    method: GET
    data_selector: projection_info
    params: {}
- name: DINOProjectionHead
  endpoint:
    path: /models/modules/heads/DINOProjectionHead
    method: GET
    data_selector: projection_info
    params: {}
- name: DINOv2ProjectionHead
  endpoint:
    path: /models/modules/heads/DINOv2ProjectionHead
    method: GET
    data_selector: projection_info
    params: {}
- name: DenseCLProjectionHead
  endpoint:
    path: /models/modules/heads/DenseCLProjectionHead
    method: GET
    data_selector: projection_info
    params: {}
- name: MMCRProjectionHead
  endpoint:
    path: /models/modules/heads/MMCRProjectionHead
    method: GET
    data_selector: projection_info
    params: {}
- name: MSNProjectionHead
  endpoint:
    path: /models/modules/heads/MSNProjectionHead
    method: GET
    data_selector: projection_info
    params: {}
- name: MoCoProjectionHead
  endpoint:
    path: /models/modules/heads/MoCoProjectionHead
    method: GET
    data_selector: projection_info
    params: {}
- name: NNCLRPredictionHead
  endpoint:
    path: /models/modules/heads/NNCLRPredictionHead
    method: GET
    data_selector: prediction_info
    params: {}
- name: NNCLRProjectionHead
  endpoint:
    path: /models/modules/heads/NNCLRProjectionHead
    method: GET
    data_selector: projection_info
    params: {}
- name: ProjectionHead
  endpoint:
    path: /models/modules/heads/ProjectionHead
    method: GET
    data_selector: projection_info
    params: {}
- name: SMoGPredictionHead
  endpoint:
    path: /models/modules/heads/SMoGPredictionHead
    method: GET
    data_selector: prediction_info
    params: {}
- name: SMoGProjectionHead
  endpoint:
    path: /models/modules/heads/SMoGProjectionHead
    method: GET
    data_selector: projection_info
    params: {}
- name: SwaVProjectionHead
  endpoint:
    path: /models/modules/heads/SwaVProjectionHead
    method: GET
    data_selector: projection_info
    params: {}
- name: SimCLRProjectionHead
  endpoint:
    path: /models/modules/heads/SimCLRProjectionHead
    method: GET
    data_selector: projection_info
    params: {}
- name: SimSiamPredictionHead
  endpoint:
    path: /models/modules/heads/SimSiamPredictionHead
    method: GET
    data_selector: prediction_info
    params: {}
- name: SimSiamProjectionHead
  endpoint:
    path: /models/modules/heads/SimSiamProjectionHead
    method: GET
    data_selector: projection_info
    params: {}
- name: TiCoProjectionHead
  endpoint:
    path: /models/modules/heads/TiCoProjectionHead
    method: GET
    data_selector: projection_info
    params: {}
- name: VICRegTransform
  endpoint:
    path: /lightly/transforms/vicreg_transform
    method: GET
    data_selector: records
    params: {}
- name: VICRegLTransform
  endpoint:
    path: /lightly/transforms/vicregl_transform
    method: GET
    data_selector: records
    params: {}
- name: ImageGridTransform
  endpoint:
    path: /lightly/transforms/image_grid_transform
    method: GET
    data_selector: transforms
    params: {}
- name: Jigsaw
  endpoint:
    path: /lightly/transforms/jigsaw
    method: GET
    data_selector: n_grid
    params: {}
- name: MAETransform
  endpoint:
    path: /lightly/transforms/mae_transform
    method: GET
    data_selector: input_size
    params: {}
- name: MMCRTransform
  endpoint:
    path: /lightly/transforms/mmcr_transform
    method: GET
    data_selector: k
    params: {}
- name: MoCoV1Transform
  endpoint:
    path: /lightly/transforms/moco_transform/v1
    method: GET
    data_selector: input_size
    params: {}
- name: MoCoV2Transform
  endpoint:
    path: /lightly/transforms/moco_transform/v2
    method: GET
    data_selector: input_size
    params: {}
- name: MSNTransform
  endpoint:
    path: /lightly/transforms/msn_transform
    method: GET
    data_selector: random_size
    params: {}
- name: SimCLRTransform
  endpoint:
    path: /lightly/transforms/simclr_transform
    method: GET
    data_selector: records
- name: SimSiamTransform
  endpoint:
    path: /lightly/transforms/simsiam_transform
    method: GET
    data_selector: records
- name: SMoGTransform
  endpoint:
    path: /lightly/transforms/smog_transform
    method: GET
    data_selector: records
- name: RandomSolarization
  endpoint:
    path: /lightly/transforms/solarize
    method: GET
    data_selector: records
- name: SwaVTransform
  endpoint:
    path: /lightly/transforms/swav_transform
    method: GET
    data_selector: records
- name: selection
  endpoint:
    path: /schedule_compute_worker_run
    method: POST
    data_selector: selection_config
- name: ApiWorkflowClient
  endpoint:
    path: /api/workflow
    method: GET
- name: input
  endpoint:
    path: /obs/bucket/input/project_A/
    method: SET
    data_selector: input
    params: {}
- name: lightly
  endpoint:
    path: /obs/bucket/lightly/project_A/
    method: SET
    data_selector: lightly
    params: {}
- name: compute_worker_run_info
  endpoint:
    path: /compute/worker/run/info
    method: GET
    data_selector: run_info
- name: export_filenames
  endpoint:
    path: /api/export_filenames
    method: POST
    data_selector: filenames
- name: get_all_tags
  endpoint:
    path: /api/get_all_tags
    method: GET
    data_selector: tags
- name: download_dataset
  endpoint:
    path: /api/download_dataset
    method: POST
    data_selector: download_info
- name: export_filenames
  endpoint:
    path: /api/export_filenames
    method: POST
    data_selector: filenames
    params:
      tag_name: initial-tag
- name: lightly_project_A
  endpoint:
    path: obs://bucket/lightly/project_A/
    method: SET
    data_selector: null
    params: {}
- name: lightly_project_B
  endpoint:
    path: obs://bucket/lightly/project_B/
    method: SET
    data_selector: null
    params: {}
- name: input_bucket
  endpoint:
    path: /datalake
    method: GET
    data_selector: list
    params: {}
- name: predictions_bucket
  endpoint:
    path: /datalake/projects/farm-animals
    method: GET
    data_selector: list
    params: {}
- name: Azure Blob Storage
  endpoint:
    path: /security/networking/shared_access_signature
    method: POST
    data_selector: access rights
    params:
      access:
      - read
      - list
      - write
      - update
- name: lightly-datalake
  endpoint:
    path: /projects/wild-animals
    method: GET
    data_selector: objects
    params: {}
- name: dataset
  endpoint:
    path: /api/v1/dataset
    method: POST
    data_selector: dataset
    params: {}
- name: metadata
  endpoint:
    path: /lightly/metadata
    method: GET
    data_selector: records
- name: predictions
  endpoint:
    path: /predictions
    method: POST
    data_selector: predictions
- name: keypoint_detection
  endpoint:
    path: /lightly/predictions/keypoint_detection
    method: GET
    data_selector: predictions
- name: instance_segmentation
  endpoint:
    path: /lightly/predictions/instance_segmentation
    method: GET
    data_selector: predictions
- name: semantic_segmentation
  endpoint:
    path: /lightly/predictions/semantic_segmentation
    method: GET
    data_selector: predictions
- name: classification
  endpoint:
    path: /lightly/predictions/classification
    method: GET
    data_selector: predictions
- name: object_detection
  endpoint:
    path: /lightly/predictions/object_detection
    method: GET
    data_selector: predictions
- name: tiling_task
  endpoint:
    path: /auto-tasks/tiling
    method: POST
    data_selector: tasks
    params: {}
- name: predictions
  endpoint:
    path: /predictions
    method: POST
    data_selector: predictions
- name: predictions
  endpoint:
    path: /predictions
    method: POST
    data_selector: predictions
    params: {}
- name: tasks
  endpoint:
    path: tasks.json
    method: POST
    data_selector: tasks
- name: schema
  endpoint:
    path: object_detection_comma10k/schema.json
    method: POST
    data_selector: schema
- name: dataset
  endpoint:
    path: /api/dataset
    method: POST
    data_selector: filenames_and_read_urls
    params:
      tag_name: initial-tag
- name: predictions
  endpoint:
    path: /api/predictions
    method: POST
    data_selector: predictions
- name: scheduled_run
  endpoint:
    path: /compute/worker/run
    method: POST
    data_selector: results
    params:
      enable_training: true
      n_samples: 500
- name: dataset
  endpoint:
    path: /api/datasets
    method: POST
    data_selector: dataset_id
- name: dataset
  endpoint:
    path: /dataset
    method: POST
    data_selector: dataset_id
    params: {}
- name: filenames
  endpoint:
    path: /export/filenames
    method: GET
    data_selector: filenames
    params:
      tag_name: initial-tag
- name: zero_waste_dataset
  endpoint:
    path: /api/v1/datasets
    method: POST
    data_selector: dataset_id
    params: {}
- name: training_config
  endpoint:
    path: yolov7/cfg/training/yolov7_zerowaste.yaml
    method: GET
    data_selector: parameters
    params: {}
- name: data_config
  endpoint:
    path: yolov7/data/zerowaste_random_0.yaml
    method: GET
    data_selector: data
    params: {}
- name: metadata
  endpoint:
    path: metadata/
    method: POST
    data_selector: metadata
    params: {}
- name: predictions
  endpoint:
    path: /api/predictions
    method: POST
    data_selector: predictions
- name: metadata
  endpoint:
    path: /api/metadata
    method: GET
    data_selector: metadata
- name: transactions
  endpoint:
    path: /transactions
    method: GET
    data_selector: records
- name: dataset
  endpoint:
    path: /datasets
    method: POST
    data_selector: dataset_id
    params:
      dataset_name: DrivingStereo
      dataset_type: IMAGES
- name: s3_delegated_access
  endpoint:
    path: /s3/delegated_access
    method: POST
    data_selector: resource_path
    params:
      resource_path: s3://bucket/input/DrivingStereo/transactions/
      region: eu-central-1
      role_arn: S3-ROLE-ARN
      external_id: S3-EXTERNAL-ID
      purpose: INPUT
- name: scheduled_run
  endpoint:
    path: /schedule_compute_worker_run
    method: POST
    data_selector: scheduled_run_id
    params:
      datasource:
        process_all: true
      selection_config:
        n_samples: 500
        strategies:
        - input:
            type: EMBEDDINGS
            task: transactions
          strategy:
            type: DIVERSITY
- name: dataset
  endpoint:
    path: /create_dataset
    method: POST
    data_selector: dataset_id
- name: input_datasource
  endpoint:
    path: /set_s3_delegated_access_config
    method: POST
    data_selector: resource_path
    params:
      purpose: INPUT
- name: lightly_datasource
  endpoint:
    path: /set_s3_delegated_access_config
    method: POST
    data_selector: resource_path
    params:
      purpose: LIGHTLY
- name: transactions
  endpoint:
    path: /api/v1/transactions
    method: GET
    data_selector: data
    params: {}
- name: dataset
  endpoint:
    path: /datasets
    method: POST
    data_selector: dataset_id
- name: datasource
  endpoint:
    path: /datasources
    method: POST
    data_selector: resource_path
- name: input_data
  endpoint:
    path: s3://bucket/input/pedestrians/
    method: GET
    data_selector: data
- name: lightly_data
  endpoint:
    path: s3://bucket/lightly/pedestrians/
    method: GET
    data_selector: data
- name: predictions
  endpoint:
    path: /predictions
    method: POST
    data_selector: predictions
    params: {}
- name: metadata
  endpoint:
    path: /metadata
    method: POST
    data_selector: metadata
    params: {}
- name: flickering
  endpoint:
    path: /flickering
    method: POST
    data_selector: flickering
    params: {}
- name: dataset
  endpoint:
    path: /datasets
    method: POST
    data_selector: dataset_id
- name: export_filenames
  endpoint:
    path: /export_filenames
    method: GET
    data_selector: filenames_and_read_urls
- name: predictions
  endpoint:
    path: /api/v1/predictions
    method: POST
    data_selector: predictions
    params: {}
- name: metadata
  endpoint:
    path: /api/v1/metadata
    method: POST
    data_selector: metadata
    params: {}
- name: similarity_search
  endpoint:
    path: /compute/similarity_search
    method: POST
    data_selector: results
    params: {}
- name: video_dataset
  endpoint:
    path: /datasets
    method: POST
    data_selector: dataset
    params: {}
- name: compute_worker_run
  endpoint:
    path: /compute/runs
    method: GET
    data_selector: runs
    params: {}
- name: compute_worker_run
  endpoint:
    path: /compute/worker/runs
    method: POST
    data_selector: run_id
- name: compute_worker_run
  endpoint:
    path: /compute/worker/runs
    method: POST
    data_selector: run_id
- name: relevant_filenames
  endpoint:
    path: .lightly/relevant_filenames.txt
    method: POST
    data_selector: files
- name: datapool
  endpoint:
    path: /datapool
    method: POST
- name: videos-datapool
  endpoint:
    path: /api/v1/datasets
    method: POST
    data_selector: dataset
    params: {}
- name: pedestrian-videos-datapool
  endpoint:
    path: /api/v1/datasets
    method: POST
    data_selector: dataset
    params: {}
- name: datapool
  endpoint:
    path: /datapool
    method: POST
    data_selector: datapool
    params:
      use_datapool: 'True'
- name: dataset
  endpoint:
    path: /create_dataset
    method: POST
    data_selector: dataset_name
- name: input_datasource
  endpoint:
    path: /set_s3_delegated_access_config
    method: POST
    data_selector: resource_path
- name: lightly_datasource
  endpoint:
    path: /set_s3_delegated_access_config
    method: POST
    data_selector: resource_path
- name: datapool
  endpoint:
    path: /api/v1/datapool
    method: POST
    data_selector: dataset
    params:
      process_all: true
      use_datapool: true
      enable_training: false
- name: datapool
  endpoint:
    path: /datapool
    method: POST
    data_selector: data
    params: {}
- name: corruption_check
  endpoint:
    path: /corruptness-check
    method: GET
    data_selector: ''
    params: {}
- name: input
  endpoint:
    path: my-container/input/project_A/
    method: SET
    data_selector: datasource
    params:
      purpose: INPUT
- name: lightly
  endpoint:
    path: my-container/lightly/project_A/
    method: SET
    data_selector: datasource
    params:
      purpose: LIGHTLY
- name: dataset
  endpoint:
    path: /datasets
    method: POST
    data_selector: dataset
    params: {}
- name: compute_worker_run
  endpoint:
    path: /compute_worker_run
    method: POST
    data_selector: run
    params: {}
- name: sequence_information
  endpoint:
    path: /sequence_information.json
    method: GET
    data_selector: sequences
- name: custom_embeddings
  endpoint:
    path: /lightly/embeddings
    method: POST
    data_selector: embeddings
    params: {}
- name: dataset
  endpoint:
    path: /api/datasets
    method: GET
    data_selector: datasets
    params: {}
- name: runs
  endpoint:
    path: /api/runs
    method: GET
    data_selector: runs
    params: {}
- name: input_mount
  endpoint:
    path: /input_mount
    method: POST
- name: lightly_mount
  endpoint:
    path: /lightly_mount
    method: POST
- name: output_dir
  endpoint:
    path: /output_dir
    method: POST
- name: artifacts
  endpoint:
    path: /api/artifacts
    method: GET
    data_selector: artifacts
- name: report
  endpoint:
    path: /compute/runs
    method: GET
    data_selector: runs
- name: embedding_analysis
  endpoint:
    path: /report/embedding_analysis
    method: GET
    data_selector: report
    params: {}
- name: selection_results_dashboard
  endpoint:
    path: /report/selection-results
    method: GET
    data_selector: metrics
    params: {}
- name: embeddings
  endpoint:
    path: /embeddings
    method: GET
    data_selector: embeddings
- name: dataset
  endpoint:
    path: /datasets
    method: POST
    data_selector: dataset
    params: {}
- name: s3_config
  endpoint:
    path: /s3/config
    method: POST
    data_selector: s3_config
    params: {}
- name: scheduled_run
  endpoint:
    path: /compute/schedule
    method: POST
    data_selector: scheduled_run
    params: {}
- name: compute_worker_run
  endpoint:
    path: /compute/run
    method: POST
    data_selector: compute_worker_run
    params: {}
- name: artifacts
  endpoint:
    path: /compute/artifacts
    method: GET
    data_selector: artifacts
    params: {}
- name: dataset
  endpoint:
    path: /api/dataset
    method: POST
    data_selector: dataset_id
    params: {}
- name: s3_config
  endpoint:
    path: /api/s3_config
    method: POST
    data_selector: s3_config_id
    params: {}
- name: compute_worker_run
  endpoint:
    path: /api/compute_worker_run
    method: POST
    data_selector: scheduled_run_id
    params: {}
- name: compute_worker_run_info
  endpoint:
    path: /api/compute_worker_run_info
    method: GET
    data_selector: run_info
    params: {}
- name: download_random_video_from_pexels
  endpoint:
    path: /pexels/api/video
    method: GET
    data_selector: video
    params: {}
- name: upload_video_to_s3
  endpoint:
    path: /s3/upload
    method: POST
    data_selector: upload_status
    params: {}
- name: run_lightly_onprem
  endpoint:
    path: /lightly/run
    method: POST
    data_selector: run_status
    params: {}
- name: shutdown_instance
  endpoint:
    path: /ec2/shutdown
    method: POST
    data_selector: shutdown_status
    params: {}
- name: LightlyOne Worker
  endpoint:
    path: /api/worker
    method: POST
- name: AWS Batch Job
  endpoint:
    path: /batch/job
    method: POST
- name: datasets
  endpoint:
    path: /datasets
    method: GET
- name: runs
  endpoint:
    path: /compute/runs
    method: GET
    data_selector: scheduled_runs
    params: {}
- name: crop_datasets
  endpoint:
    path: /crop_datasets
    method: GET
    data_selector: datasets
- name: metadata
  endpoint:
    path: /metadata
    method: GET
    data_selector: histograms
- name: label_box_data_rows
  endpoint:
    path: /v1/datasets/{dataset_id}/export_label_box_v4_data_rows_by_tag_name
    method: POST
    data_selector: label_box_data_rows
    params:
      tag_name: initial-tag
- name: worker
  endpoint:
    path: /api/v1/worker
    method: POST
    data_selector: data
- name: datasets
  endpoint:
    path: /api/datasets
    method: GET
    data_selector: datasets
- name: runs
  endpoint:
    path: /api/runs
    method: GET
    data_selector: runs
- name: SwaVPrototypes
  endpoint:
    path: /SwaVPrototypes
    method: GET
    data_selector: records
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: Input Datasource
  endpoint:
    path: /input_mount
    method: GET
- name: Lightly Datasource
  endpoint:
    path: /lightly_mount
    method: GET
notes:
- The token of the user is read from the environment variable LIGHTLY_TOKEN if not
  passed during initialization.
- Uses OAuth2 with refresh token — requires setup of connected app in api
- Lightly provides a CLI for various self-supervised learning tasks.
- OAuth2 with refresh token is required.
- Ensure you have the correct permissions set up in your account.
- Uses custom backbones for self-supervised learning.
- A large batch size helps with learning.
- Shuffling is important!
- You can also use a custom PyTorch Dataset instead of the LightlyDataset.
- Learn more about how to use custom backbones in our colab playground.
- Self-supervised learning does not require labels for a model to be trained on.
- Picking the right augmentation method seems crucial for the outcome of training
  models using contrastive learning.
- Since solarization and random rotations by 90 degrees are not supported in Torchvision,
  we added them to the transforms module.
- 4 gpus are 2-3x faster than 1 gpu
- With 4 gpus a single epoch takes <40 sec which means that a lot of time is spent
  between epochs (starting workers, doing evaluation). The benefit from using more
  gpus could therefore be even greater with a larger dataset.
- The slowdown from Sync BatchNorm is pretty low
- Self-Supervised models benefit from larger batch sizes and longer training.
- Training time is roughly the same for all methods (three to four hours for 200 epochs).
- Memory consumption is roughly the same for all methods.
- Internally each image will get assigned a default label of 0
- Requires setup of connected app in api
- Each image will get assigned a default label of 0
- Dataset class will assign each image its subdirectory as label
- To use video-specific features of LightlySSL download the necessary extra dependencies
  pip install 'lightly[video]'.
- Randomly accessing video frames is slower compared to accessing the extracted frames
  on disk.
- API requires proper authentication setup to access resources
- 'This example requires the following dependencies to be installed: pip install "lightly[timm]"'
- The model and training settings do not follow the reference settings from the paper.
  The settings are chosen such that the example can easily be run on a small dataset
  with a single GPU.
- 'This example requires the following dependencies to be installed: pip install lightly'
- 'Note: The model and training settings do not follow the reference settings from
  the paper.'
- Requires setup of connected app in API
- The model and training settings do not follow the reference settings from the paper.
- Uses PyTorch Lightning for training
- Dataset is downloaded from VOCDetection
- Requires authentication via OAuth2
- Some endpoints may have rate limits
- MAE requires TIMM to be installed
- 'Optimized for CNNs: NNCLR is specifically designed for convolutional neural networks
  (CNNs), particularly ResNet. It is not recommended for transformer-based architectures.'
- 'Augmentation Robustness: Compared to SimCLR, NNCLR is less dependent on strong
  augmentations since nearest neighbor sampling introduces natural semantic variation.
  However, performance still benefits from well-chosen augmentations and larger batch
  sizes.'
- 'Requires the following dependencies to be installed: pip install lightly'
- Requires OAuth2 authentication for access to API
- Some API endpoints may have rate limits
- Some objects like Contact may return nulls in deeply nested fields
- 'Note: The model and training settings do not follow the reference settings from
  the paper. The settings are chosen such that the example can easily be run on a
  small dataset with a single GPU.'
- The settings are chosen such that the example can easily be run on a small dataset
  with a single GPU.
- Requires user access token to download images from the Lightly platform.
- Applies multiple transformations including random resized crop and color jitter.
- ImageNet normalization is applied.
- Lightly One allows automated data curation processes and supports large datasets.
- In order to use the selection feature, you need to start the LightlyOne Worker in
  worker mode.
- You can specify that the images in the subset should be visually diverse, be images
  the model struggles with, should only be sharp images, or have a certain distribution
  of classes.
- Uses OAuth2 with refresh token.
- Uses OAuth2 with token — requires setup of connected app in LightlyOne
- Treat the API token like a password
- Lightly Python Client supports Python versions from 3.6 to 3.11
- The credentials passed above need to provide LightlyOne with list and read access
  to the input bucket and with list, read, and write access to the Lightly bucket.
- Data processed by the LightlyOne Worker must be available during the whole run duration.
- If using a cloud bucket datasource with a retention or lifecycle policy, data might
  get deleted during a run.
- After a run successfully terminates, the LightlyOne Worker will have created a tag
  with the name `initial-tag` in your dataset.
- Some strategies require specific worker versions.
- The selection algorithm selects samples greedily, enabling scaling to millions of
  samples.
- LightlyOne requires input data to persist over the whole run duration.
- LightlyOne needs read, list, write and delete permissions on your bucket.
- Using Delegated Access is recommended for security and compliance.
- Recommended to set access control to uniform.
- Requires LightlyOne Worker 2.9 or higher and Lightly Python Client 1.4.16 or higher.
- 'The LightlyOne Worker needs the following permissions for the mounted directories:
  Input mount: read and conditional execute permissions (rX), Lightly mount: read,
  write, and execute permissions (rwx).'
- If the mount directories on the host have strict access permissions, it can happen
  that the files are not accessible to the LightlyOne Worker. In that case, you can
  run the LightlyOne Worker with a specific user and group by setting the LIGHTLY_UID
  and LIGHTLY_GID environment variables when starting the docker container.
- Make sure to also use a new Lightly datasource whenever you use a new Input datasource.
- It is discouraged to use another library than PyAV for loading videos with Python
  as the order and number of loaded frames might differ.
- Ensure to add a tasks.json file to the .lightly/predictions directory.
- Each prediction task needs a schema.json file to define the format.
- Using a pre-trained model does not resolve the need for high-quality human annotations.
- Tiling auto tasks generate tiles out of each image.
- Tiling tasks are treated like regular predictions in the LightlyOne Platform.
- Uses YOLOv7 model for predictions
- 'Important classes include: person, bicycle, car, motorcycle, bus, train, truck'
- Active learning reduces the amount of data required for fine-tuning.
- Users need to upload predictions to LightlyOne for active learning.
- Uses YOLOv7 for predictions
- Output format is [x_min, y_min, x_max, y_max, conf, class_index]
- Make sure you don't forget to replace the placeholders s3://bucket/input and s3://bucket/lightly
  with the name of your AWS S3 bucket paths.
- Requires a connected app setup for authentication.
- Ensure to use the correct format for predictions.
- LightlyOne Worker may crash due to out-of-memory (OOM) issue.
- Requires setup of connected app in LightlyOne.
- Use LightlyOne token for authentication.
- Replace the placeholder s3://bucket/input with the name of your AWS S3 bucket path.
- Replace the placeholder 's3://bucket/input' with the name of your AWS S3 bucket
  path.
- Don't forget to replace the '{MY_LIGHTLY_TOKEN}' placeholder with your own token.
- Train using the command line with specified parameters
- Update data configuration for new splits
- The folder hierarchy within the metadata matches the structure of the input bucket.
- Requires installation of LightlyOne and setup of cloud bucket.
- Requires access to a cloud bucket for datasets.
- Requires access to a cloud bucket for dataset uploads
- Uses Python 3.7 or newer
- Monitor the run using the LightlyOne Platform user interface.
- Make sure to replace the placeholders in the S3 paths with actual bucket names.
- Requires setup of connected app in Lightly
- We recommend using Python 3.7 or newer
- Requires setup of connected app in LightlyOne
- Ensure correct video formats are used
- Some objects like predictions may return nulls in deeply nested fields
- Requires setup of Lightly token for authentication
- Use tags to identify query images for similarity search.
- It is not recommended to use MOV videos with H.265 codec or videos captured by iPhone
  cameras due to slow processing speeds.
- The model is trained for 100 epochs by default.
- You can adjust the training settings using the lightly_config argument.
- LightlyOne uses a specific logic for parsing relevant filenames.
- The relevant_filenames_file is expected to be in the Lightly datasource and must
  always be located in a subdirectory called .lightly.
- Only file paths relative to the input datasource are supported, and relative paths
  cannot include dot notations './' or '../'.
- Datapool is deactivated by default but can be enabled in your worker_config when
  scheduling a job by setting use_datapool:True.
- Datapool is deactivated by default but can be enabled in your worker_config when
  scheduling a job.
- If datapool is disabled, the input dataset must be completely empty.
- Datapool is deactivated by default but can be enabled in your worker_config by setting
  use_datapool:True.
- LightlyOne Worker provides a simple way to remove broken frames using lightly.uniformRowRatio.
- Schedule the LightlyOne Worker run with 'pretagging' set to True.
- Requires LightlyOne Worker v2.2 for crop selection features.
- Sequence selection only works with Videos as Input.
- n_samples must be a multiple of selected_sequence_length.
- The embedding CSV file must be UTF-8 encoded and stored in the .lightly/embeddings/
  directory.
- Ensure to provide valid API key in the Authorization header.
- worker.force_start can be set to True to allow multiple workers with the same ID
- sanity_check can be set to True to verify installation of the worker
- You can download the `log.txt` file which contains detailed information to debug
  the error.
- Each scheduled run creates several artifacts upon execution.
- The old report.json file will soon be deprecated in favor of report_v2.json.
- Access the generated files by mounting a local volume to the docker container when
  starting the LightlyOne Worker.
- Workers without labels will pick up all runs, including those that have a runs_on
  specified.
- Runs without the runs_on specified will be picked up by all workers.
- Important to set shutdown_when_job_finished=True in worker config when scheduling
  the job.
- Uses API key for authentication, requires setup of LightlyOne account.
- Don’t forget to set the PEXELS_API_KEY.
- Don’t forget to set the S3_INPUT_BUCKET and the S3_REGION.
- Don’t forget to set the EC2_INSTANCE_ID and the EC2_REGION.
- Requires setting up AWS Batch with a compute environment.
- The platform helps you analyze your unlabeled data, keep track of your dataset and,
  by using various methods, pick the relevant samples for your task.
- Each dataset has at least one tag, typically called and referenced as initial-tag.
- Currently, it's only possible to share a dataset as a writer role.
- Crop datasets only support a single prediction task. When multiple selection strategies
  with different prediction tasks are used, the crops shown on the LightlyOne Platform
  might be incorrect.
- The LightlyOne Worker automatically computes basic metadata of your samples.
- To export images in the old Labelbox v3 format, use the export_label_box_data_rows_by_tag_name
  method.
- Export selected images effortlessly to the Label Studio format
- LightlyOne Worker should run on dedicated hardware to guarantee quick and stable
  data processing.
- For training self-supervised models or improved inference speed we recommend a V100,
  a A10 GPU, or better.
- Requesting GPU resources in the cloud on AWS, GCP or Azure the process can take
  up to 72 hours. We recommend increasing quota early even if the resource will only
  be used later.
- If you want to set more restrictive permissions for security reasons, we recommend
  mounting more specific directories.
- Running the LightlyOne Worker with a custom user and group is recommended.
- When a LightlyOne Worker picks up a scheduled run, it is removed from the list of
  scheduled runs.
- The LightlyOne Worker polls for new jobs every 20s.
- Requires access to mounted directories of local storage.
- If the datapool feature is misconfigured, the LightlyOne Worker run is aborted.
- Make sure to schedule datapool runs with new samples compared to the runs preceding
  them.
- If you use a Mac with an Apple silicon chip, make sure to enable Rosetta emulation
  in Docker Desktop for fast processing.
- Uses OAuth2 with refresh token — requires setup of connected app in Lightly
- Some objects may return nulls in deeply nested fields
- use_datapool is disabled by default to safeguard your dataset from accidental datapool
  usage
- The worker now errors when all predictions are missing or erroneous
- Please update your Lightly Python Client package version to v1.4.21 to be able to
  work with this artifact programmatically.
- Crops from a crop dataset are now stored in a prediction task specific directory.
  This allows using multiple prediction tasks for the same dataset.
- The change is backwards incompatible and crop datasets created with LightlyOne Worker
  version 2.8 or lower cannot be used with version 2.9 or higher.
- Please create a new dataset to use LightlyOne Worker version 2.9.
- Custom metadata paths are no longer allowed to start with lightly, this namespace
  has been reserved for lightly specific metadata.
- Worker 2.8 will now abort instead of silently succeeding in the case when no samples
  are processed or no new samples are selected.
- Worker 2.6 removes the option to use 'Object Level' workflow, which has been deprecated
  since Worker v2.4.
- It is no longer possible to process data from a local disk, which has been deprecated
  since Worker v2.4.
- Configuration options names are checked. E.g. specifying 'enableeeee_training' raises
  an Error.
- 'Configuration types are checked. E.g. specifying ''enable_training'': ''string
  instead of bool'' raises an error.'
- Mount paths must be absolute when starting the docker.
- Volume mounting folders to a Docker container can change file permissions.
errors:
- '400: Missing or invalid parameters'
- '402: Insufficient plan'
- '403: Not authorized for this resource or invalid token'
- '404: Resource (dataset or config) not found'
- '422: Missing or invalid file in datasource'
- '401 Unauthorized: Recheck OAuth scopes or token expiration'
- 'REQUEST_LIMIT_EXCEEDED: Throttle API calls or reduce frequency'
- '401 Unauthorized: Check your OAuth2 token.'
- '404 Not Found: Verify the endpoint path.'
- '401 Unauthorized: Check API key or token validity'
- '404 Not Found: Ensure the endpoint URL is correct'
- '404 Not Found: Verify the endpoint path'
- '500 Internal Server Error: Try again later'
- '401 Unauthorized: Check your token'
- '401 Unauthorized: Check your authentication credentials'
- '404 Not Found: Verify the requested resource path'
- '429 Too Many Requests: Reduce request frequency'
- '401 Unauthorized: Check access token'
- '404 Not Found: Confirm dataset_id and tag_name'
- 'QUERY_TIMEOUT: Break down filters or add selectivity'
- Setting both n_samples and proportion_samples will cause an error.
- Common Errors That Abort the LightlyOne Worker
- Run may fail if scheduled run is not picked up by a LightlyOne Worker.
- '400 Bad Request: Check the request format and required fields.'
- '401 Unauthorized: Verify credentials and token validity.'
- '404 Not Found: Ensure the endpoint is correct.'
- 'Access Denied: Check your permissions.'
- 'Invalid Access Key ID or Secret Access Key: Verify your credentials.'
- Error when tasks.json does not contain valid prediction folders.
- Error when schema.json file is missing for a listed folder in tasks.json.
- '401 Unauthorized: Check your OAuth token or scopes.'
- '400 Bad Request: Ensure your request body matches the expected format.'
- '401 Unauthorized: Recheck API key or token expiration'
- 'Unauthorized: Recheck OAuth scopes or token expiration.'
- '401 Unauthorized: Check your OAuth token.'
- '401 Unauthorized: Check OAuth token'
- '404 Not Found: Verify endpoint path'
- '429 Too Many Requests: Rate limit exceeded'
- '400 Bad Request: Ensure the request format is correct'
- '401 Unauthorized: Check your API token'
- '403 Forbidden: Ensure you have the right permissions'
- '401 Unauthorized: Check your OAuth token'
- '400 Bad Request: Check your request payload'
- 'INVALID_TOKEN: Verify your API token.'
- 'DATASET_NOT_FOUND: Check if the dataset ID is correct.'
- '401 Unauthorized: Recheck API token validity'
- '400 Bad Request: Check your input parameters.'
- '401 Unauthorized: Recheck API key validity.'
- '404 Not Found: Ensure the resource exists.'
- If datapool is disabled (the default), the input dataset must be completely empty.
  Otherwise, the LightlyOne Worker will abort the run with an error.
- If the LightlyOne Worker does not find new samples in your datasource or there are
  no new samples to be added to the datapool after selection, the LightlyOne Worker
  will abort the run.
- Worker run aborted if datapool is disabled and the input dataset is not empty.
- Worker aborts if no new samples are found in the datasource.
- The LightlyOne Worker will abort the run if no new samples are found in the datasource.
- 'Worker aborted: No new samples found in datasource.'
- 'Worker aborted: Input dataset must be empty if datapool is disabled.'
- The LightlyOne Worker will abort the run if it does not find new samples in your
  datasource.
- '401 Unauthorized: Check API key and permissions.'
- '400 Bad Request: Check request parameters for correctness.'
- 'Invalid API key: Check your credentials.'
- 'Not Found: The requested resource does not exist.'
- '401 Unauthorized: Check if the API key is valid.'
- '429 Too Many Requests: Rate limit exceeded.'
- '401 Unauthorized: Check your API key or token.'
- '[Errno 13] Permission Denied: Check directory permissions for mounted directories.'
- All 100 images have been flagged as corrupt.
- Invalid JSON format
- Metadata attribute 'filename' is of type int instead of str.
- No new images to process in input datasource.
- No new samples selected.
- worker errors if it has not been configured how it should handle expiring files
- 'ApiError: Invalid configuration specified'
auth_info:
  mentioned_objects:
  - ApiWorkflowClient
  - ComputeWorkerRunInfo
  - InvalidConfigurationError
  - OauthToken
  - AuthProvider
  - NamedCredential
client:
  base_url: https://app.lightly.ai
source_metadata: null
