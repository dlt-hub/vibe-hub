resources:
- name: quickstart
  endpoint:
    path: /endpoint/quickstart
    method: POST
    data_selector: result
- name: quickstart
  endpoint:
    path: /endpoint/quickstart
    method: POST
    data_selector: result
- name: functions
  endpoint:
    path: /v2/function/running-functions
    method: GET
    data_selector: functions
    params: {}
- name: endpoints
  endpoint:
    path: /v2/endpoint/overview
    method: GET
    data_selector: endpoints
    params: {}
- name: task_queues
  endpoint:
    path: /v2/task-queue/running-tasks
    method: GET
    data_selector: task_queues
    params: {}
- name: pods
  endpoint:
    path: /v2/pod/web-service
    method: GET
    data_selector: pods
    params: {}
- name: functions
  endpoint:
    path: /v2/function
    method: POST
    data_selector: function
    params: {}
- name: endpoints
  endpoint:
    path: /v2/endpoint
    method: POST
    data_selector: endpoint
    params: {}
- name: task_queues
  endpoint:
    path: /v2/task-queue
    method: POST
    data_selector: task_queue
    params: {}
- name: container_image
  endpoint:
    path: /v2/environment/custom-images
    method: GET
    data_selector: records
    params: {}
- name: public_docker_registries
  endpoint:
    path: /v2/environment/custom-registries
    method: GET
- name: private_docker_registries
  endpoint:
    path: /v2/environment/custom-registries
    method: GET
- name: gpu_availability
  endpoint:
    path: /v2/environment/gpu
    method: GET
    data_selector: available_gpus
- name: Image
  endpoint:
    path: /v2/environment/custom-registries
    method: GET
- name: LLM_Parameters_Guidelines
  endpoint:
    path: /v2/environment/resources
    method: GET
    data_selector: recommendations
    params: {}
- name: available_gpus
  endpoint:
    path: /v2/environment/gpu
    method: GET
    data_selector: available_gpus
    params: {}
- name: Recommended CPU and Memory for LLM Parameters
  endpoint:
    data_selector: Recommended Resources
    params: {}
- name: CloudBucket
  endpoint:
    path: /v2/data/external-storage
    method: POST
    data_selector: buckets
    params:
      incremental: region
- name: weights
  endpoint:
    path: ./weights
    method: POST
    data_selector: file
    params: {}
- name: model_weights
  endpoint:
    path: ./model_weights
    method: WRITE
    data_selector: files
    params: {}
- name: output
  endpoint:
    path: /tmp/my_output.txt
    method: POST
    data_selector: output_url
- name: weights
  endpoint:
    path: ./weights
    method: POST
    data_selector: file
    params:
      access_key: S3_KEY
      secret_key: S3_SECRET
      region: us-east-1
- name: weights
  endpoint:
    path: ./weights
    method: MOUNT
    data_selector: bucket_data
- name: autoscaling
  endpoint:
    path: /v2/scaling
    method: GET
    data_selector: scaling_options
- name: output
  endpoint:
    path: /tmp
    method: POST
    data_selector: output_url
- name: weights
  endpoint:
    path: /v2/endpoint
    method: POST
    data_selector: model
    params:
      cpu: 1
      memory: 16Gi
      gpu: T4
- name: handler
  endpoint:
    path: /task_queue
    method: POST
    data_selector: result
    params:
      cpu: 4
      workers: 4
      image:
        python_version: python3.8
        python_packages:
        - pandas
        - csaps
      autoscaler:
        max_containers: 5
        tasks_per_container: 1
- name: autoscaling_config
  endpoint:
    path: /scaling/horizontally/adding-more-containers
    method: GET
    data_selector: autoscaling
    params:
      max_containers: 5
      tasks_per_container: 30
- name: always_on_containers
  endpoint:
    path: /setting/always-on/containers
    method: GET
    data_selector: always_on
    params:
      min_containers: 1
      max_containers: 3
      tasks_per_container: 1
- name: task_queue
  endpoint:
    path: /v2/task-queue/running-tasks
    method: GET
    data_selector: records
- name: sandbox
  endpoint:
    path: /v2/sandbox/configuration
    method: POST
- name: filesystem_snapshot
  endpoint:
    path: /v2/sandbox/snapshots/filesystem
    method: POST
    data_selector: image_id
    params: {}
- name: memory_snapshot
  endpoint:
    path: /v2/sandbox/snapshots/memory
    method: POST
    data_selector: snapshot_id
    params: {}
- name: sandbox
  endpoint:
    path: /v2/sandbox
    method: POST
    data_selector: sandbox
    params: {}
- name: process
  endpoint:
    path: /v2/sandbox/processes
    method: POST
    data_selector: process
    params: {}
- name: process_management
  endpoint:
    path: /v2/sandbox/processes
    method: GET
    data_selector: processes
    params: {}
- name: filesystem_snapshot
  endpoint:
    path: /v2/sandbox/snapshots/filesystem
    method: POST
    data_selector: snapshot_id
    params: {}
- name: memory_snapshot
  endpoint:
    path: /v2/sandbox/snapshots/memory
    method: POST
    data_selector: snapshot_id
    params: {}
- name: process_management
  endpoint:
    path: /v2/sandbox/processes
    method: GET
    data_selector: process
- name: dynamic_preview_urls
  endpoint:
    path: /v2/sandbox/networking
    method: GET
    data_selector: urls
    params: {}
- name: expose_port
  endpoint:
    path: /v2/sandbox/networking/expose_port
    method: POST
    data_selector: url
    params: {}
- name: list_exposed_ports
  endpoint:
    path: /v2/sandbox/networking/list_urls
    method: GET
    data_selector: urls
    params: {}
- name: process
  endpoint:
    path: /v2/sandbox/processes
    method: GET
    data_selector: processList
- name: file_upload
  endpoint:
    path: /v2/sandbox/filesystem/upload
    method: POST
    data_selector: files
    params: {}
- name: file_download
  endpoint:
    path: /v2/sandbox/filesystem/download
    method: GET
    data_selector: files
    params: {}
- name: upload_file
  endpoint:
    path: /upload_file
    method: POST
    data_selector: result
    params: {}
- name: download_file
  endpoint:
    path: /download_file
    method: GET
    data_selector: result
    params: {}
- name: list_files
  endpoint:
    path: /list_files
    method: GET
    data_selector: files
    params: {}
- name: stat_file
  endpoint:
    path: /stat_file
    method: GET
    data_selector: file_info
    params: {}
- name: dynamic_preview_urls
  endpoint:
    path: /v2/sandbox/networking
    method: GET
- name: expose_port
  endpoint:
    path: /v2/sandbox/networking/expose-port
    method: POST
- name: list_exposed_ports
  endpoint:
    path: /v2/sandbox/networking/list-urls
    method: GET
- name: multiply
  endpoint:
    path: /
    method: POST
    data_selector: result
- name: upload_files
  endpoint:
    path: /upload
    method: POST
    data_selector: files
    params: {}
- name: download_files
  endpoint:
    path: /download
    method: GET
    data_selector: files
    params: {}
- name: list_files
  endpoint:
    path: /workspace
    method: GET
    data_selector: files
- name: upload_file
  endpoint:
    path: /fs/upload_file
    method: POST
    data_selector: upload_response
- name: download_file
  endpoint:
    path: /fs/download_file
    method: GET
    data_selector: download_response
- name: sentiment
  endpoint:
    path: /sentiment
    method: POST
    data_selector: result
- name: generate
  endpoint:
    path: /generate
    method: POST
    data_selector: result
- name: warmup
  endpoint:
    path: /warmup
    method: POST
    data_selector: status
- name: model
  endpoint:
    path: /model
    method: GET
    data_selector: model
- name: realtime
  endpoint:
    path: /realtime
    method: POST
    data_selector: response
    params: {}
- name: multiply
  endpoint:
    path: /
    method: POST
    data_selector: result
    params: {}
- name: keep_warm
  endpoint:
    path: /keep_warm
    method: POST
    data_selector: success
    params:
      keep_warm_seconds: 300
- name: min_containers
  endpoint:
    path: /min_containers
    method: POST
    data_selector: success
    params:
      min_containers: 1
- name: sentiment
  endpoint:
    path: /sentiment
    method: POST
    data_selector: ''
    params: {}
- name: generate
  endpoint:
    path: /generate
    method: POST
    data_selector: ''
    params: {}
- name: warmup
  endpoint:
    path: /warmup
    method: POST
    data_selector: ''
    params: {}
- name: model
  endpoint:
    path: /model
    method: GET
    data_selector: ''
    params: {}
- name: realtime_app
  endpoint:
    path: /v2/endpoint/realtime
    method: POST
    data_selector: response
- name: image_endpoint
  endpoint:
    path: /
    method: POST
    data_selector: message
- name: task_queue
  endpoint:
    path: /
    method: POST
    data_selector: task_id
- name: keep_warm
  endpoint:
    path: /warmup
    method: POST
    data_selector: success
    params:
      keep_warm_seconds: 300
- name: always_on
  endpoint:
    path: /
    method: POST
    data_selector: success
    params:
      min_containers: 1
- name: task_queue
  endpoint:
    path: /v2/task
    method: POST
    data_selector: task_id
- name: image_endpoint
  endpoint:
    path: /image-endpoint
    method: POST
    data_selector: message
- name: task_status
  endpoint:
    path: /v2/task/{TASK_ID}/
    method: GET
    data_selector: outputs
- name: cancel_task
  endpoint:
    path: /v2/task/cancel/
    method: DELETE
    data_selector: '{}'
- name: task_queue
  endpoint:
    path: /v2/task-queue/running-tasks
    method: POST
    data_selector: task_id
- name: scheduled_jobs
  endpoint:
    path: /v2/function/scheduled-job
    method: POST
- name: task_queue
  endpoint:
    path: /v2/task
    method: POST
- name: queues
  endpoint:
    path: /v2/function/queues
    method: GET
    data_selector: records
- name: task_status
  endpoint:
    path: /v2/task/{TASK_ID}/
    method: GET
    data_selector: ''
    params: {}
- name: cancel_task
  endpoint:
    path: /v2/task/cancel/
    method: DELETE
    data_selector: ''
    params: {}
- name: pod
  endpoint:
    path: /v2/pod/web-service
    method: POST
    data_selector: pod
    params: {}
- name: exposing_ports
  endpoint:
    path: /v2/pod/web-service
    method: POST
    data_selector: ports
    params: {}
- name: static_ips
  endpoint:
    path: /v2/pod/web-service
    method: GET
    data_selector: static_ip_range
    params: {}
- name: scheduled_jobs
  endpoint:
    path: /v2/function/scheduled-job
    method: GET
- name: deploy
  endpoint:
    path: /deploy
    method: POST
    data_selector: result
- name: queues
  endpoint:
    path: /v2/function/queues
    method: GET
    data_selector: records
- name: public_endpoint
  endpoint:
    path: /endpoint/public/[STUB-ID]
    method: POST
    data_selector: success
- name: distributed_map_example
  endpoint:
    path: /v2/function/maps
    method: GET
    data_selector: records
    params: {}
- name: pod
  endpoint:
    path: /v2/pod/web-service
    method: POST
    data_selector: container
    params: {}
- name: trainer
  endpoint:
    path: /v2/topics/signal
    method: POST
    data_selector: signal
    params: {}
- name: inference
  endpoint:
    path: /v2/endpoint
    method: POST
    data_selector: predict
    params: {}
- name: runtime_variables
  endpoint:
    path: /v2/topics/context
    method: GET
    data_selector: context
- name: public_endpoint
  endpoint:
    path: /endpoint/public/[STUB-ID]
    method: POST
    data_selector: success
- name: callback
  endpoint:
    path: /v2/topics/callbacks
    method: POST
    data_selector: data
    params: {}
- name: beta9
  endpoint:
    path: /v2/self-hosting/aws
    method: GET
    data_selector: data
    params: {}
- name: trainer
  endpoint:
    path: /v2/topics/signal
    method: POST
    data_selector: event
    params: {}
- name: inference
  endpoint:
    path: /v2/topics/signal
    method: POST
    data_selector: event
    params: {}
- name: runtime_variables
  endpoint:
    path: /v2/topics/context
    method: GET
    data_selector: context
    params: {}
- name: localstack
  endpoint:
    path: /services/data/vXX.X/sobjects/Localstack
    method: GET
    data_selector: records
    params: {}
- name: inference-quickstart
  endpoint:
    path: /endpoint/id/bc55068e-b648-4dbc-9cb7-183e1789e011
    method: POST
- name: inference-quickstart
  endpoint:
    path: /inference-quickstart
    method: POST
- name: sandbox_instance
  endpoint:
    path: /sandbox
    method: POST
    data_selector: instance
    params: {}
- name: sandbox
  endpoint:
    path: /sandbox
    method: POST
    data_selector: sandbox_id
- name: sandbox_instance
  endpoint:
    path: /sandbox_instance
    method: POST
    data_selector: sandbox_id
- name: inference-quickstart
  endpoint:
    path: /endpoint/id/bc55068e-b648-4dbc-9cb7-183e1789e011
    method: POST
    data_selector: prediction
    params: {}
- name: get_process
  endpoint:
    path: /get_process
    method: POST
    data_selector: process
    params:
      pid: pid
- name: run_code
  endpoint:
    path: /run_code
    method: POST
    data_selector: result
    params:
      code: code
      blocking: 'True'
      cwd: None
      env: None
- name: process
  endpoint:
    path: /process
    method: GET
    data_selector: processes
    params: {}
- name: sandbox_instance
  endpoint:
    path: /sandbox/instance
    method: POST
- name: sandbox_instance
  endpoint:
    path: /sandbox-instance
    method: POST
- name: process
  endpoint:
    path: /process
    method: GET
    data_selector: process
    params: {}
- name: download_file
  endpoint:
    path: /download_file
    method: POST
    data_selector: result
    params:
      sandbox_path: path/to/file/in/sandbox
      local_path: destination/path/on/local/filesystem
- name: sandbox
  endpoint:
    path: /sandbox
    method: POST
    data_selector: sandbox_id
- name: process
  endpoint:
    path: /sandbox/process
    method: GET
    data_selector: processes
    params: {}
- name: filesystem
  endpoint:
    path: /sandbox/filesystem
    method: GET
    data_selector: files
    params: {}
- name: get_process
  endpoint:
    path: /get_process
    method: GET
    data_selector: process
    params:
      pid: int
- name: run_code
  endpoint:
    path: /run_code
    method: POST
    data_selector: result
    params:
      code: str
      blocking: bool
      cwd: Optional[str]
      env: Optional[Dict[str, str]]
- name: sandbox_file_system
  endpoint:
    path: /find_in_files
    method: GET
    data_selector: files
    params:
      sandbox_path: /workspace
      pattern: '*.py'
- name: SandboxProcess
  endpoint:
    path: /sandbox/process
    method: GET
    data_selector: process
- name: SandboxFileSystem
  endpoint:
    path: /sandbox/filesystem
    method: GET
    data_selector: filesystem
- name: list_files
  endpoint:
    path: /list_files
    method: GET
    data_selector: files
    params:
      sandbox_path: /
- name: process
  endpoint:
    path: /process
    method: GET
    data_selector: processes
    params: {}
- name: sandbox_file
  endpoint:
    path: /sandbox/file
    method: DELETE
    data_selector: file_info
    params: {}
- name: process
  endpoint:
    path: /sandbox/process
    method: GET
    data_selector: processes
    params: {}
- name: file
  endpoint:
    path: /sandbox/file
    method: GET
    data_selector: files
    params: {}
- name: sandbox_file_download
  endpoint:
    path: /sandbox/files/download
    method: GET
    data_selector: file
    params: {}
- name: SandboxFileSystem
  endpoint:
    path: /sandboxfilesystem
    method: POST
    data_selector: response
    params: {}
- name: process
  endpoint:
    path: /processes
    method: GET
    data_selector: processes
- name: sandbox_file
  endpoint:
    path: /sandbox/files
    method: GET
    data_selector: files
- name: sandbox_file_system
  endpoint:
    path: /sandbox/find_in_files
    method: GET
    data_selector: files
    params:
      sandbox_path: /workspace
      pattern: '*.py'
- name: process
  endpoint:
    path: /process
    method: GET
    data_selector: process
    params: {}
- name: sandbox_process
  endpoint:
    path: /sandbox/process
    method: POST
    data_selector: sandbox_process_response
    params: {}
- name: sandbox_file_system
  endpoint:
    path: /sandbox/file_system
    method: GET
    data_selector: file_system_info
    params: {}
- name: stat_file
  endpoint:
    path: /sandbox/stat_file
    method: GET
- name: upload_file
  endpoint:
    path: /sandbox/upload_file
    method: POST
- name: process
  endpoint:
    path: /sandbox/process
    method: GET
    data_selector: processes
    params: {}
- name: file
  endpoint:
    path: /sandbox/file
    method: GET
    data_selector: files
    params: {}
- name: list_files
  endpoint:
    path: /list_files
    method: GET
    data_selector: files
    params:
      sandbox_path: /
- name: task_queue
  endpoint:
    path: /task_queue
    method: POST
    data_selector: tasks
- name: function
  endpoint:
    path: /function
    method: POST
    data_selector: results
- name: process
  endpoint:
    path: /sandbox/process
    method: GET
    data_selector: processes
    params: {}
- name: file
  endpoint:
    path: /sandbox/file
    method: GET
    data_selector: files
    params: {}
- name: SandboxFileSystem
  endpoint:
    path: /sandbox/filesystem/replace_in_files
    method: POST
    data_selector: result
    params: {}
- name: process
  endpoint:
    path: /process
    method: GET
    data_selector: processes
    params: {}
- name: run_code
  endpoint:
    path: /run_code
    method: POST
    data_selector: result
    params:
      blocking: 'True'
      cwd: None
      env: None
- name: process
  endpoint:
    path: /sandbox/process
    method: GET
    data_selector: processes
- name: files
  endpoint:
    path: /sandbox/files
    method: GET
    data_selector: files
- name: stat_file
  endpoint:
    path: /stat_file
    method: GET
    data_selector: metadata
- name: upload_file
  endpoint:
    path: /upload_file
    method: POST
    data_selector: upload_result
- name: multiply
  endpoint:
    path: /multiply
    method: POST
    data_selector: result
- name: transcribe
  endpoint:
    path: /transcribe
    method: POST
    data_selector: result
- name: web_server
  endpoint:
    path: /web_server
    method: POST
    data_selector: result
- name: handler
  endpoint:
    path: /handler
    method: POST
    data_selector: result
- name: get_product_urls
  endpoint:
    path: /get_product_urls
    method: POST
    data_selector: result
- name: get_product_urls
  endpoint:
    path: /get_product_urls
    method: POST
    data_selector: outputs
    params: {}
- name: pod
  endpoint:
    path: /pod
    method: POST
    data_selector: result
- name: multiply
  endpoint:
    path: /endpoint/multiply
    method: POST
- name: transcribe
  endpoint:
    path: /endpoint/transcribe
    method: POST
- name: web_server
  endpoint:
    path: /endpoint/web_server
    method: POST
- name: handler
  endpoint:
    path: /endpoint/handler
    method: POST
- name: get_product_urls
  endpoint:
    path: /endpoint/get_product_urls
    method: POST
- name: task_queue
  endpoint:
    path: /task_queue
    method: POST
- name: asgi
  endpoint:
    path: /asgi
    method: POST
- name: realtime
  endpoint:
    path: /realtime
    method: POST
- name: function
  endpoint:
    path: /function
    method: POST
- name: bot
  endpoint:
    path: /bot
    method: POST
- name: Image
  endpoint:
    path: /v2/reference/sdk
    method: GET
    data_selector: records
- name: Sandbox
  endpoint:
    path: /v2/reference/sdk
    method: GET
    data_selector: records
- name: process
  endpoint:
    path: /get_process/{process_id}
    method: GET
    data_selector: process
    params: {}
- name: processes
  endpoint:
    path: /list_processes
    method: GET
    data_selector: processes
    params: {}
- name: run_code
  endpoint:
    path: /run_code
    method: POST
    data_selector: result
    params:
      blocking: true
      cwd: null
      env: null
- name: sandbox_process
  endpoint:
    path: /sandbox/process
    method: GET
    data_selector: processes
    params: {}
- name: sandbox_filesystem
  endpoint:
    path: /sandbox/filesystem
    method: GET
    data_selector: files
    params: {}
- name: transcribe
  endpoint:
    method: POST
    params: {}
- name: get_product_urls
  endpoint:
    path: /bot/get_product_urls
    method: POST
    data_selector: outputs
- name: bot
  endpoint:
    path: /api/bot
    method: POST
- name: test
  endpoint: {}
- name: sandbox_process_manager
  endpoint:
    path: /sandbox/processes
    method: GET
    data_selector: processes
    params: {}
- name: sandbox_file_system
  endpoint:
    path: /sandbox/files
    method: GET
    data_selector: files
    params: {}
- name: process
  endpoint:
    path: /sandbox/process
    method: GET
    data_selector: processes
    params: {}
- name: sandbox_file_system
  endpoint:
    path: /sandbox/filesystem
    method: GET
    data_selector: files
    params: {}
- name: multiply
  endpoint:
    path: /endpoint/multiply
    method: POST
    data_selector: result
    params: {}
- name: transcribe
  endpoint:
    path: /endpoint/transcribe
    method: POST
    data_selector: result
    params: {}
- name: web_server
  endpoint:
    path: /endpoint/web_server
    method: POST
    data_selector: result
    params: {}
- name: handler
  endpoint:
    path: /endpoint/handler
    method: POST
    data_selector: result
    params: {}
- name: task
  endpoint:
    params:
      authorized: 'True'
- name: queue
  endpoint:
    path: /queue
    method: POST
- name: map
  endpoint:
    path: /map
    method: POST
- name: test
  endpoint:
    path: /map
    method: POST
    data_selector: items
    params: {}
- name: pod
  endpoint:
    path: /pod
    method: POST
    data_selector: result
- name: process
  endpoint:
    path: /sandbox/process
    method: GET
    data_selector: processes
    params: {}
- name: sandbox_file
  endpoint:
    path: /sandbox/files
    method: GET
    data_selector: files
    params: {}
- name: get_product_urls
  endpoint:
    path: /transition/get_product_urls
    method: POST
    data_selector: outputs
- name: multiply
  endpoint:
    path: /endpoint/multiply
    method: POST
    data_selector: result
- name: transcribe
  endpoint:
    path: /endpoint/transcribe
    method: POST
    data_selector: result
- name: web_server
  endpoint:
    path: /endpoint/web_server
    method: POST
    data_selector: result
- name: handler
  endpoint:
    path: /endpoint/handler
    method: POST
    data_selector: result
- name: list_processes
  endpoint:
    path: /sandbox/processes
    method: GET
    data_selector: processes
- name: run_code
  endpoint:
    path: /sandbox/run
    method: POST
    data_selector: result
- name: queue
  endpoint:
    path: /queue
    method: POST
    data_selector: tasks
    params: {}
- name: map
  endpoint:
    path: /map
    method: POST
    data_selector: items
    params: {}
- name: square
  endpoint:
    path: ./{mount_path}
    method: POST
    data_selector: result
    params: {}
- name: deployments
  endpoint:
    path: /deployments
    method: GET
- name: tasks
  endpoint:
    path: /tasks
    method: GET
- name: container
  endpoint:
    path: /container/list
    method: GET
    data_selector: items
- name: deployment
  endpoint:
    path: /deployment/list
    method: GET
    data_selector: items
- name: context
  endpoint:
    path: /config
    method: POST
    data_selector: context
    params:
      incremental: context_name
- name: container_list
  endpoint:
    path: /container/list
    method: GET
    data_selector: containers
- name: task_list
  endpoint:
    path: /task/list
    method: GET
    data_selector: tasks
- name: volume_list
  endpoint:
    path: /volume/list
    method: GET
    data_selector: volumes
- name: secret_list
  endpoint:
    path: /secret/list
    method: GET
    data_selector: secrets
notes:
- You only pay for the compute you use, by the millisecond of usage.
- Retrieve your API token from the dashboard, on the API Keys page.
- Create a credentials file in ~/.beam/config.ini after installation.
- API keys will be saved to this file when running beam config create.
- No idle costs. No infrastructure to cleanup.
- This function will use ubuntu:22.04 with Python 3.10
- The default Beam image uses ubuntu:22.04 as its base and installs Python 3.10.
- Beam only supports Debian-based images.
- Make sure your image is built for the correct x86 architecture.
- 'In the context of LLMs, here are some approximate guidelines for resources to use
  in your apps:'
- 'Currently available GPU options are: T4 (16Gi), A10G (24Gi), RTX4090 (24Gi), A100-40
  (40Gi), H100 (80Gi).'
- Mountpoint is optimized for reading large files with high throughput and writing
  new files from a single client at a time.
- It does not provide full POSIX compliance.
- Secrets and environment variables can be injected into the containers that run your
  apps.
- It can take up to 60 seconds for any files written to a distributed volume to become
  available to other containers.
- Files can be saved to Beam’s /tmp directory
- Public URLs can be generated for saved outputs
- It does not provide full POSIX compliance. For instance, it does not support appending
  to files.
- You may want to save data produced by your tasks. Beam provides an abstraction called
  Output, which allows you to save files or directories and generate public URLs to
  access them.
- If checkpoint fails, please forward us any errors that appear in logs. It’s likely
  the reason for failure is a missing volume — to resolve that you need to ensure
  the cache path is set properly for the model.
- Checkpoints can take up to 3 minutes to capture, and 5 minutes to distribute among
  our servers.
- Public URLs are automatically deleted after 1 hour
- You can pass an optional expires parameter to control how long to persist the file
  before it is deleted
- Sandboxes are ultra-fast, Python-native environments for running any workload -
  with GPUs, networking, and persistent storage - in seconds.
- If checkpoint fails, the deployment will revert to standard cold boots. To try checkpointing
  again, you will need to redeploy.
- Checkpoints can take up to 3 minutes to capture, and 5 minutes to distribute among
  our servers. To properly benchmark the cold start improvement, you need to call
  the app after it has been spun down for a few minutes. Otherwise it may block as
  the checkpoint is syncing.
- Workers allow you to increase your per container throughput, vertically.
- Autoscaling allows to scale the number of containers and increase throughput horizontally.
- The .map() method can parallelize functions that require multiple parameters.
- Sandboxes are configurable cloud environments. You control CPU, memory, GPU, dependencies,
  environment variables, and storage so each sandbox can be customized exactly to
  your needs.
- Sandboxes are configurable cloud environments.
- You control CPU, memory, GPU, dependencies, environment variables, and storage.
- Start with shorter timeouts and increase as needed.
- The Sandbox provides process management through the process property.
- You can execute Python code, run shell commands, and manage long-running processes
  with real-time output streaming.
- You can customize CPU, memory, GPU, dependencies, environment variables, and storage.
- Execute code and commands with real-time output streaming in your sandbox
- Start with minimal resources and scale up as needed.
- Environment variables are good for keeping sensitive data out of your code.
- The Sandbox provides process management through the `process` property.
- The Sandbox provides some basic network tools. You can run web services and expose
  them to the internet behind SSL-terminated endpoints.
- Endpoints are RESTful APIs, designed for synchronous tasks that can complete in
  180 seconds or less.
- The container handling the endpoint will spin down after 180 seconds of inactivity
  by default.
- The container will spin down after 180 seconds of inactivity by default.
- Beam includes an optional `on_start` lifecycle hook which you can add to your functions.
- The `on_start` function runs once when the container starts.
- Container stays alive for 5 min before shutting down automatically
- When keep_warm_seconds is set in your deployment, it will count as billable usage.
- Serve sessions end automatically after 10 minutes of inactivity.
- This app can be deployed in traditional Beam fashion
- Recommended to use S3 for large payloads (20+ MB).
- Task Queues include a built-in retry system. If a task fails for any reason, such
  as out-of-memory error or an application exception, your task will be retried three
  times before automatically moving to a failed state.
- For endpoints, tasks may not start running before the request timeout (180 seconds).
- By default, Beam will sync all the files in your working directory to the remote
  container.
- If you deploy a new version of your scheduled job, the previous schedule will be
  disabled.
- Task Queues are great for deploying resource-intensive functions on Beam.
- Serialization is done using cloudpickle, so any pickleable object will work.
- The task API allows querying the status of tasks.
- Pods are serverless and automatically scale-to-zero.
- By default, pods will be terminated after 10 minutes without any active connections.
- You can prevent some files from getting uploaded by creating a .beamignore file.
- Ensure BEAM_TOKEN is added to Github Secrets for authentication
- Tasks automatically timeout after 20 minutes if they haven’t started running.
- You can customize the default timeout and retry behavior for your tasks.
- You can configure tasks to automatically retry based on a specific exception in
  your app.
- Callbacks fire for both successful and failed tasks
- To secure your server against replay attacks, a timestamp and signature are included
  in the callback request headers
- BEAM_TOKEN must be set in Github Secrets to authenticate.
- Tasks automatically timeout after 20 minutes if they haven’t started running. This
  default exists to prevent stuck tasks from consuming compute resources and potentially
  blocking other tasks in the queue.
- Beam and Beta9 have similar functionality.
- Callbacks fire for both successful and failed tasks.
- Make sure your ingress supports GRPC and HTTP
- Your IAM permissions need to be set correctly. You will need to create S3 buckets
  manually or in Terraform.
- If you are using Karpenter for your autoscaler, you’ll need to add a label to the
  nodes which you want the Beta9 scheduler to pick up.
- Signals will refresh every 1 second while a container is running, until signal.clear()
  is called.
- The effective date of the agreement shall be the date that you register to use the
  service
- You should regularly back up Your Data while using the Service.
- Beam includes a live-reloading feature that allows you to run your code on the same
  environment you’ll be running in production.
- Beam is serverless, which means your apps will scale-to-zero by default. Billing
  is based on the lifecycle of your containers. You are only charged when your containers
  are running.
- Uses QueueDepthAutoscaler with max_containers=5 and tasks_per_container=1
- All infrastructure and runtime configuration is expressed in Python.
- Beam apps are defined entirely in code — no YAML, no config files.
- Uses OAuth2 with refresh token — requires setup of connected app in api
- Uses custom container images for executing tasks
- Supports creating and managing sandboxes for isolated environments
- Make the sandbox never timeout
- Beam’s Python SDK is the heart of the Beam platform.
- This method is not yet implemented.
- Dynamically expose a port to the internet.
- Expose port 8000 for a web service
- Methods for managing processes include listing, running code, and streaming output.
- The Python code to execute must be provided as a string.
- The default for blocking is True, which waits for process completion.
- The method create_directory is not yet implemented.
- The method delete_directory is not yet implemented.
- Method to create a directory is not yet implemented.
- Method to delete a directory is not yet implemented.
- The create_directory and delete_directory methods are not yet implemented.
- Beam apps are defined entirely in code — no YAML, no config files
- The delete and create directory methods are not yet implemented.
- Sessions end automatically after 10 minutes of inactivity.
- Some methods are not yet implemented.
- This method executes Python code within the sandbox environment.
- Uses OAuth2 for authentication
- Pods can be deployed programmatically via Python or CLI.
- The Open API key used to authenticate requests to Open AI
- The code is executed using the Python interpreter available in the sandbox.
- Supports running Python code in a sandbox environment.
- Pod allows for remote execution of arbitrary services.
- Ensure to specify the entrypoint when creating a Pod.
- This API allows interaction with processes and the file system in a sandbox environment.
- Some objects like Contact may return nulls in deeply nested fields
- The bot requires an auth token passed to invoke it.
- Specifies whether the bot requires an auth token passed to invoke it.
- Bot requires an auth token to invoke.
- You can find your Beam Token in the API Keys section of the dashboard.
- Beam will create a credentials file in ~/.beam/config.ini.
- If you are using the beam.cloud, you can leave Gateway Host and Gateway Port blank.
- API token is required for authentication and can be configured in ~/.beam/config.ini
- Uses Bearer token for authentication
- Uses Bearer token for authorization.
errors:
- 'Unauthorized: Recheck Authorization token'
- Container will spin down after 180 seconds of inactivity by default.
- '401 Unauthorized: Recheck Authorization token'
- 'REQUEST_LIMIT_EXCEEDED: Throttle API calls or reduce frequency'
- 'QUERY_TIMEOUT: Break down filters or add selectivity'
- '200: Successful request'
- 'Timestamp is over 5s old: There is a risk that the callback was not fired from
  Beam.'
- 'concurrency_limit_reached: Ensure payment method is added and appropriate plan
  is selected'
- 'Unable to connect to gateway: Ensure you have the latest version of the beam-client
  CLI'
- 'No space left on device: Check disk space and memory configuration'
- '401 Unauthorized: Recheck OAuth token.'
- 'PROCESS_NOT_FOUND: The specified process ID does not exist.'
- 'SANDBOX_CONNECTION_ERROR: Unable to connect to the sandbox.'
- 'SandboxProcessError: Process not found'
- 'SandboxConnectionError: Connection issues with the sandbox'
- 'SandboxConnectionError: Connection to sandbox failed'
- 'SandboxConnectionError: Connection issue'
- 'SandboxFileError: File operation failed'
- '401 Unauthorized: Check your API key or permissions.'
- 'SandboxConnectionError: Connection issue with the sandbox'
- 'SandboxConnectionError: Connection issues to the sandbox'
- 'PROCESS_NOT_FOUND: Ensure the process ID is correct.'
- 'PERMISSION_DENIED: Check user permissions for this operation.'
- '401 Unauthorized: Recheck API key or authentication settings.'
- '401 Unauthorized: Recheck API key or permissions'
- '404 Not Found: Check if the endpoint path is correct.'
- '400 Bad Request: Validate the request parameters.'
- 'FILE_NOT_FOUND: The specified file does not exist in the sandbox.'
- '401 Unauthorized: Recheck API key or token expiration'
- '401 Unauthorized: Recheck OAuth scopes or token expiration'
- '401 Unauthorized: Recheck API key'
- '401 Unauthorized: Check API key.'
- '401 Unauthorized: Recheck API token.'
- '401 Unauthorized: Recheck API token'
- '401 Unauthorized: Check if the Authorization token is valid.'
auth_info:
  mentioned_objects:
  - EKS IRSA
  - Bot
  - BotContext
  - BotLocation
client:
  base_url: https://platform.beam.cloud
  auth:
    type: apikey
    location: header
    header_name: Authorization
source_metadata: null
