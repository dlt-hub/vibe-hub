resources:
- name: File Level Metadata
  endpoint:
    path: /contributing-data/data-reporting-formats#file-level-metadata
    method: GET
    data_selector: metadata
    params: {}
- name: CSV File Structure
  endpoint:
    path: /contributing-data/data-reporting-formats#csv-file-structure
    method: GET
    data_selector: metadata
    params: {}
- name: Sample ID Metadata
  endpoint:
    path: /contributing-data/data-reporting-formats#sample-id-metadata
    method: GET
    data_selector: metadata
    params: {}
- name: Soil Respiration
  endpoint:
    path: /contributing-data/data-reporting-formats#soil-respiration
    method: GET
    data_selector: metadata
    params: {}
- name: Leaf-level Gas Exchange
  endpoint:
    path: /contributing-data/data-reporting-formats#leaf-level-gas-exchange
    method: GET
    data_selector: metadata
    params: {}
- name: Hydrologic Monitoring
  endpoint:
    path: /contributing-data/data-reporting-formats#hydrologic-monitoring
    method: GET
    data_selector: metadata
    params: {}
- name: Water and Soil Chemistry
  endpoint:
    path: /contributing-data/data-reporting-formats#water-and-soil-chemistry
    method: GET
    data_selector: metadata
    params: {}
- name: 16S Amplicon Sequencing
  endpoint:
    path: /contributing-data/data-reporting-formats#16s-amplicon-sequencing
    method: GET
    data_selector: metadata
    params: {}
- name: Model Data Archiving
  endpoint:
    path: /contributing-data/data-reporting-formats#model-data-archiving
    method: GET
    data_selector: metadata
    params: {}
- name: Location Metadata
  endpoint:
    path: /contributing-data/data-reporting-formats#location-metadata
    method: GET
    data_selector: metadata
    params: {}
- name: Unoccupied Aerial System Data
  endpoint:
    path: /contributing-data/data-reporting-formats#unoccupied-aerial-system-data
    method: GET
    data_selector: metadata
    params: {}
- name: provider
  endpoint:
    path: /
    method: POST
    data_selector: ''
    params: {}
- name: dataset
  endpoint:
    path: /datasets
    method: POST
    data_selector: ''
    params: {}
- name: dataset
  endpoint:
    path: /path/to/dataset
    method: POST
    data_selector: dataset
    params: {}
- name: Assessment Reports
  endpoint:
    path: /publish-data/check-dataset-metadata-quality
    method: GET
    data_selector: records
- name: dataset_status
  endpoint:
    path: /publish-data/dataset-statuses
    method: GET
- name: doi_status
  endpoint:
    path: /publish-data/doi-statuses
    method: GET
- name: dataset_statuses
  endpoint:
    path: /dataset/statuses
    method: GET
    data_selector: statuses
- name: doi_statuses
  endpoint:
    path: /doi/statuses
    method: GET
    data_selector: statuses
- name: reporting_formats
  endpoint:
    path: /contributing-data/data-reporting-formats
    method: GET
    data_selector: checks
    params: {}
- name: Manage Publication
  endpoint:
    path: /publish-data/publish-your-dataset
    method: GET
- name: Request Publication
  endpoint:
    path: /publish-data/publish-your-dataset/request-publication
    method: POST
- name: Reserve DOI Before Publication
  endpoint:
    path: /publish-data/publish-your-dataset/reserve-doi-before-publication
    method: POST
- name: Publish with Existing DOI
  endpoint:
    path: /publish-data/publish-your-dataset/publish-with-existing-doi
    method: POST
- name: Reserve DOI
  endpoint:
    path: /publish-data/publish-your-dataset/reserve-doi-before-publication
    method: GET
- name: Reserve DOI
  endpoint:
    path: /publish-data/publish-your-dataset/reserve-doi-before-publication
    method: GET
    data_selector: records
    params: {}
- name: Update Existing Dataset
  endpoint:
    path: /publish-data/update-your-public-dataset
    method: GET
    data_selector: updates
    params: {}
- name: Publish New Dataset
  endpoint:
    path: /publish-data/publish-a-new-dataset-and-doi
    method: GET
    data_selector: new_dataset
    params: {}
- name: dataset_citations
  endpoint:
    path: /manage-data/register-dataset-citations
    method: POST
    data_selector: citations
- name: portals
  endpoint:
    path: /portals
    method: GET
    data_selector: data
- name: datasets
  endpoint:
    path: /datasets
    method: GET
    data_selector: records
- name: data_portals
  endpoint:
    path: /data-portals
    method: GET
    data_selector: records
- name: datasets
  endpoint:
    path: /datasets
    method: GET
    data_selector: records
- name: data_portals
  endpoint:
    path: /data-portals
    method: GET
    data_selector: records
- name: projects
  endpoint:
    path: /projects
    method: GET
    data_selector: data
- name: project_teams
  endpoint:
    path: /manage-data/manage-project-data/project-teams
    method: GET
    data_selector: teams
    params: {}
- name: project_teams
  endpoint:
    path: /manage-data/manage-project-data/project-teams
    method: GET
    data_selector: teams
    params: {}
- name: Tier 2 (HTTP)
  endpoint:
    path: /searching-and-accessing-data/accessing-data
    method: GET
    data_selector: data
- name: Tier 2 (Globus)
  endpoint:
    path: /searching-and-accessing-data/accessing-data
    method: GET
    data_selector: data
- name: Tier 2 (HTTP)
  endpoint:
    path: /download-data-files
    method: GET
- name: Tier 2 (Globus)
  endpoint:
    path: /download-large-data-on-tier-2
    method: GET
- name: packages
  endpoint:
    path: /packages
    method: GET
- name: dataset
  endpoint:
    path: /dataset
    method: GET
- name: datasets
  endpoint:
    path: /search
    method: GET
    data_selector: results
    params:
      providerName: ''
      keywords: ''
      creator: ''
      text: ''
      datePublished: ''
- name: packages
  endpoint:
    path: /packages
    method: GET
    data_selector: results
    params:
      isPublic: 'true'
- name: datasets
  endpoint:
    path: /packages
    method: GET
    data_selector: result
    params:
      isPublic: 'true'
      rowStart: '0'
      pageSize: '25'
- name: dataset_metadata
  endpoint:
    path: /packages/{id}
    method: GET
    data_selector: dataset
    params: {}
- name: packages
  endpoint:
    path: /packages
    method: GET
    data_selector: result
    params:
      isPublic: 'true'
- name: dataset
  endpoint:
    path: /datasets
    method: GET
    data_selector: dataset
    params: {}
- name: packages
  endpoint:
    path: /packages
    method: GET
    data_selector: records
    params:
      isPublic: 'true'
- name: packages
  endpoint:
    path: /packages
    method: GET
    data_selector: result
    params:
      isPublic: 'true'
      pageSize: 25
- name: packages
  endpoint:
    path: /packages
    method: GET
    data_selector: result
    params:
      isPublic: 'true'
      pageSize: 25
- name: dataset
  endpoint:
    path: /datasets/{id}
    method: GET
    data_selector: dataset
    params:
      isPublic: 'true'
- name: Query-Data
  endpoint:
    path: /deepdive
    method: GET
- name: Get-Dataset-File
  endpoint:
    path: /deepdive/{doi}:{file_path}
    method: GET
- name: Query-Data
  endpoint:
    path: /api/v1/deepdive/query-data
    method: GET
    data_selector: results
    params:
      doi: doi:10.15485/1985922
      fieldName: temp
      recordCountMin: 20
- name: Get-Dataset-File
  endpoint:
    path: /api/v1/deepdive/get-dataset-file
    method: GET
    data_selector: results
    params:
      doi: doi:10.15485/1985922
      file_path: Roley_CR_Metabolism_Data_Package.zip/DO_temp_sensor_data.csv
- name: packages
  endpoint:
    path: /packages
    method: GET
    data_selector: results
    params:
      isPublic: 'true'
- name: dataset
  endpoint:
    path: /datasets/{id}
    method: GET
    data_selector: dataset
    params:
      isPublic: 'true'
- name: Get-Dataset-File
  endpoint:
    path: /Get-Dataset-File
    method: GET
- name: Query-Data
  endpoint:
    path: /deepdive
    method: GET
- name: Get-Dataset-File
  endpoint:
    path: /deepdive/{doi}:{file_path}
    method: GET
- name: query_data
  endpoint:
    path: /api/v1/deepdive/query-data
    method: GET
    data_selector: results
    params:
      doi: doi:10.15485/1985922
      fieldName: temp
      recordCountMin: 20
- name: get_dataset_file
  endpoint:
    path: /api/v1/deepdive/get-dataset-file
    method: GET
    data_selector: file_info
    params:
      doi: doi:10.15485/1985922
      file_path: Roley_CR_Metabolism_Data_Package.zip/DO_temp_sensor_data.csv
- name: Get-Dataset-File
  endpoint:
    path: /searching-and-accessing-data/search-with-deep-dive-api/get-dataset-file
    method: GET
    data_selector: fields
- name: dataset
  endpoint:
    path: /programmatic-tools/ess-dive-dataset-api
    method: POST
    data_selector: datasets
    params: {}
- name: packages
  endpoint:
    path: packages
    method: GET
- name: dataset
  endpoint:
    path: /datasets
    method: GET
    data_selector: records
- name: ESS-DIVE Collection
  endpoint:
    path: /path/to/ess-dive-collection
    method: POST
    data_selector: transfer
    params: {}
- name: dataset
  endpoint:
    path: /datasets
    method: GET
    data_selector: datasets
notes:
- ESS-DIVE is primarily intended to host DOE-sponsored environmental research data
- Contact ess-dive-support@lbl.gov if you are interested in archiving external data
- Sandbox is the testing grounds for data contributors to experiment with ESS-DIVE's
  repository features.
- ESS-DIVE can store datasets with data volumes more than a Terabyte in size.
- Data greater than 500GB in volume will be archived on Tier 2 by default.
- Any data contributor can take advantage of the Tier 2 service even if your data
  is less than 500GB.
- You must login to ESS-DIVE with an ORCID before you submit a data contributor request.
- Uses ORCID credentials for login
- Use ESS-DIVE's test instance, Sandbox (https://api-sandbox.ess-dive.lbl.gov) while
  building scripts and making corrections to JSON_LD dataset submissions.
- Only switch to ESS-DIVE's production instance (https://api.ess-dive.lbl.gov/) after
  your scripts are complete.
- Only switch to ESS-DIVE's production instance (<https://api.ess-dive.lbl.gov/>)
  after your scripts are complete.
- Uses OAuth2 with refresh token — requires setup of connected app in api
- The body argument is a string not a file.
- This data set reports selected ambient environmental monitoring data from the S1
  bog in Minnesota for the period June 2010 through December 2016.
- All externally linked datasets must have complete metadata on ESS-DIVE.
- Assessment reports can take a few minutes, or up to 24 hours, to generate.
- The assessment report becomes available to all users on ESS-DIVE once the dataset
  is published.
- Login is required to view statuses.
- The assessment report is run every time a dataset is submitted.
- Login is required to view dataset and DOI statuses.
- Datasets that do not require revisions and pass the first review will automatically
  be published.
- The publication process can take as much as 3 weeks on average depending on dataset
  quality, complexity, and author responsiveness.
- Remember to review the ESS-DIVE terms of use and ensure there is no Protected Information
  in your dataset.
- ESS-DIVE will not accept any datasets that include controlled and prohibited information
  categories.
- Ensure that your dataset has complete metadata before requesting publication.
- ESS-DIVE’s Reporting Formats are designed to make data and metadata published on
  ESS-DIVE more FAIR (Findable, Accessible, Interoperable, Reusable).
- The Fusion DB provides feedback to the ESS-DIVE Publication Review Team if any requirements
  are not met.
- The contents of public data and metadata files successfully parsed by the FusionDB
  are made searchable by the Deep Dive API.
- After publishing a dataset, the metadata and files cannot be private again.
- Datasets must complete all required metadata fields and pass all required quality
  checks before they can be published on ESS-DIVE.
- This is not required to publish a dataset
- A reserved DOI will not function until you request and complete the publication
  review process
- You will be automatically notified via email within 24 hours that we have received
  your request.
- Buttons are disabled after they have been activated. If your button is inaccessible,
  you've already completed the available steps for that process.
- The dataset submitter & contact will receive an automated email from ESS-DIVE confirming
  that we have received your request for publication review and that you should hear
  from the ESS-DIVE review team shortly.
- Updates to datasets under publication review are welcomed and encouraged.
- A reserved DOI will not function until you request and complete the publication
  review process.
- Datasets with reserved DOIs will have the DOI status 'Reserved'.
- In fact, we encourage small updates after publication that enhance the data quality,
  such as completing related citations for recently published manuscripts, adding
  related identifiers from subsequent research, or expanding the keywords to improve
  discoverability.
- It's important to consider the impact your change will have on the research products
  that have previously used and cited your data.
- Data Publications cannot be deleted.
- As a long-term data repository, ESS-DIVE cannot delete or remove data once it has
  been published.
- Alternatively, if you have not used either button, the 'Reserve DOI' button will
  be grayed out when the Existing Identifiers field is filled out. If you want a DOI,
  remove the content of this field to a more appropriate metadata field.
- Data Publications cannot be deleted
- Obsoleting or retiring a public dataset requires modifying the old dataset metadata
  properly and publishing the latest version as a new dataset
- Only registered data contributors can register citations
- Only registered Data Contributors can create data portals on ESS-DIVE
- Only registered data contributors can register citations.
- new data portals are not immediately made public. Just like ESS-DIVE datasets, portals
  must be approved by The ESS-DIVE Team before they are publicly available.
- This page cannot be edited and cannot be viewed while editing.
- New portals are automatically set to private and only visible to the portal creator.
- The portal will remain private until reviewed and approved by the ESS-DIVE Team.
- New data portals are not immediately made public and must be approved by The ESS-DIVE
  Team before they are publicly available.
- Registered data contributors can share their datasets and data portals.
- Only registered data contributors will be able to edit content or manage permissions.
- You can also share datasets programmatically using ESS-DIVE's Dataset API.
- Only registered data contributors can edit content or manage permissions.
- Concurrent editing is not possible; the latest submission will overwrite previous
  edits.
- Only registered data contributors can create or share portals, make sure you are
  logged in and registered before attempting to share a portal
- Only registered data contributors can create or share portals.
- Project management is not set up by default for any project.
- These features are still in development and will be continually updated until Fall
  2023.
- Project PIs have automatic approval to become a project data manager, but they must
  first register as an ESS-DIVE data contributor and notify ESS-DIVE Support.
- Project PIs, co-PIs, or data managers can update the information on this page at
  any time by contacting ESS-DIVE at ess-dive-support@lbl.gov.
- Only project data managers can create teams.
- Teams cannot be renamed or deleted later.
- You must register to become a data contributor to edit datasets.
- It is not possible to edit a dataset without completing this step, even if a team
  has edit access.
- Creating a team of dataset editors? Your team members will need to register as ESS-DIVE
  data contributors in order to be able to edit datasets.
- Only project data managers can create teams
- Data contributors can share datasets with teams
- It's not possible to edit a dataset without completing this step, even if a team
  has edit access.
- Your team members will need to register as ESS-DIVE data contributors in order to
  be able to edit datasets.
- You can refine the search by using more specific fields - identifier (e.g. DOI),
  location, creator (authors), and year (publication year or date range spanned in
  the dataset).
- Public portals are accessible to anyone via the Portal page.
- At this time, there is no way to search through public portals with keywords.
- Anyone can search for public datasets on ESS-DIVE using the Dataset API.
- ORCID login is required to use the API.
- Must pass isPublic=true to search for public datasets.
- Must pass isPublic=false to search for private datasets.
- Must pass isPublic=true to search for public datasets. This call searches for public
  datasets by default.
- The interactive documentation is recommended for familiarizing with query parameters
  and outputs.
- Check that your token is up-to-date; it expires after a 24 hours
- Globus should be used only when data cannot be uploaded with the web interface or
  the Dataset API.
- Contact the ESS-DIVE Support Team to learn if your data is suitable for Globus upload.
- Globus should be used only when data cannot be uploaded with the web interface or
  the Dataset API
- The documentation includes interactive query parameters for the endpoints.
- Once your large data is made accessible on NERSC via Globus, neither you nor ESS-DIVE
  will be able to edit the files.
- The ESS-DIVE Team will use the temporary collection to stage your data for publication.
- Wait for a reply from the ESS-DIVE Team to proceed.
- Check that your token is up-to-date; it expires after 24 hours
- Once large data is made accessible on NERSC via Globus, neither you nor ESS-DIVE
  will be able to edit the files.
- This is a temporary collection that the ESS-DIVE Team will use to stage your data
  for publication.
- 'A dataset that meets any of the following criteria is considered large data by
  ESS-DIVE: Contains one or more files greater than 500GB, Contains more than 100
  individual files outside of zipped hierarchy.'
- Ensure dataset metadata completeness before publication request.
- Users must sign in with Orcid to obtain the authentication token.
errors:
- 'REQUEST_LIMIT_EXCEEDED: Throttle API calls or reduce frequency'
- '401 Unauthorized: Recheck OAuth scopes or token expiration'
- 'QUERY_TIMEOUT: Break down filters or add selectivity'
- Common upload errors may occur when using the Globus transfer service.
- 'ERROR: Contact support if problems persist'
- '201: Success'
- '400: Bad Request'
- '401: Unauthorized'
- Not all requests are approved.
- 'Error loading assessment report: Contact ESS-DIVE support'
- If you do not receive the confirmation email within 24 hours of initiating your
  request, email ESS-DIVE (ess-dive-support@lbl.gov) for assistance.
- '401 Unauthorized: Ensure you have proper permissions.'
- '403 Forbidden: You do not have the required permissions to access this dataset.'
- '401 Unauthorized: Ensure proper authentication credentials are provided.'
- 'REQUEST_LIMIT_EXCEEDED: Throttle API calls or reduce frequency.'
- '401 Unauthorized: Recheck your credentials or permissions.'
- '400 Bad Request: Check query parameters for correctness.'
- '404 Not Found: Dataset with the specified ID does not exist.'
- '401 Unauthorized: Recheck OAuth scopes or token expiration.'
- You do not have authorized access
- One or more fields raised validation errors.
- 'FileNotFoundError: [Errno 2] No such file or directory'
- '404 Not Found: Check the DOI or file path provided.'
- '400 Bad Request: Ensure all required parameters are filled correctly.'
- 'You do not have authorized access: Your token is either incorrect or expired.'
- 'One or more fields raised validation errors: provider/member ''familyName'' is
  a required property.'
- 'FileNotFoundError: The file entered was not found.'
auth_info:
  mentioned_objects:
  - OauthToken
  - AuthProvider
  - NamedCredential
  - ORCID
client:
  base_url: https://api.ess-dive.lbl.gov
  auth:
    type: oauth2
    location: header
    header_name: Authorization
source_metadata: null
