resources:
- name: CreateBucket
  endpoint:
    path: /create-bucket
    method: POST
- name: PutObject
  endpoint:
    path: /put-object
    method: PUT
- name: GetObject
  endpoint:
    path: /get-object
    method: GET
- name: ListObjectsV2
  endpoint:
    path: /list-objects-v2
    method: GET
- name: DeleteObject
  endpoint:
    path: /delete-object
    method: DELETE
- name: DeleteBucket
  endpoint:
    path: /delete-bucket
    method: DELETE
- name: create_bucket
  endpoint:
    path: /s3api/create-bucket
    method: POST
    data_selector: bucket
    params:
      bucket: <bucket-name>
      endpoint-url: http://127.0.0.1:8080
- name: list_buckets
  endpoint:
    path: /s3api/list-buckets
    method: GET
    data_selector: buckets
    params:
      endpoint-url: http://127.0.0.1:8080
- name: list_objects
  endpoint:
    path: /s3api/list-objects
    method: GET
    data_selector: objects
    params:
      bucket: <bucket-name>
      output: text
      endpoint-url: http://127.0.0.1:8080
- name: ultihash_cluster
  endpoint:
    path: /stable/ultihash-cluster
    method: GET
    data_selector: records
    params: {}
- name: registry_credentials
  endpoint:
    path: /create/secret/docker-registry
    method: POST
    data_selector: secrets
    params:
      docker-server: registry.ultihash.io
      docker-username: <registry_login>
      docker-password: <registry_password>
- name: ultihash_credentials
  endpoint:
    path: /create/secret/generic
    method: POST
    data_selector: secrets
    params:
      customer_id: <customer_id>
      access_token: <access_token>
      monitoring_token: <monitoring_token>
- name: ultihash_cluster
  endpoint:
    path: /stable/ultihash-cluster
    method: GET
    data_selector: services
    params: {}
- name: serverless_cluster_sizes
  endpoint:
    path: /serverless/cluster_sizes
    method: GET
    data_selector: sizes
    params: {}
- name: cluster_sizes
  endpoint:
    path: /serverless/cluster-sizes
    method: GET
    data_selector: sizes
- name: create_delete_bucket
  endpoint:
    path: <endpoint-url>
    method: POST
    data_selector: bucket
- name: S3
  endpoint:
    path: <endpoint-url>
    method: GET
    data_selector: service_config
    params: {}
- name: test_iceberg_table
  endpoint:
    path: /iceberg.ulti/test_iceberg_table
    method: GET
    data_selector: records
- name: s3_storage
  endpoint:
    path: /s3_storage
    method: POST
- name: test_iceberg_table
  endpoint:
    path: /iceberg/ulti/test_iceberg_table
    method: GET
    data_selector: records
    params: {}
- name: icechunk_storage
  endpoint:
    path: /s3_storage
    method: POST
    data_selector: storage
    params:
      bucket: bucket-name
      prefix: prefix-name
      allow_http: true
- name: s3-sink-connector
  endpoint:
    path: /connectors/s3-sink-connector/config
    method: PUT
    data_selector: ''
    params: {}
- name: s3-sink-connector-status
  endpoint:
    path: /connectors/s3-sink-connector/status
    method: GET
    data_selector: ''
    params: {}
- name: query
  endpoint:
    path: /query
    method: POST
    data_selector: results
- name: s3-sink-connector
  endpoint:
    path: /connectors/s3-sink-connector/config
    method: PUT
    data_selector: ''
    params: {}
- name: s3-sink-status
  endpoint:
    path: /connectors/s3-sink-connector/status
    method: GET
    data_selector: ''
    params: {}
- name: query
  endpoint:
    path: /query
    method: POST
    data_selector: results
- name: test-data
  endpoint:
    path: /test-data/
    method: GET
    data_selector: records
    params: {}
- name: bucket
  endpoint:
    path: /bucket/test
    method: GET
    data_selector: CORSRules
    params: {}
- name: image
  endpoint:
    path: /images/upload
    method: POST
    data_selector: files
    params: {}
- name: dataset
  endpoint:
    path: /test-data/
    method: GET
    data_selector: records
    params: {}
- name: checkpoint
  endpoint:
    path: /checkpoints/
    method: POST
    data_selector: records
    params: {}
- name: UltiHash
  endpoint:
    path: /ultihash
    method: GET
- name: test
  endpoint:
    path: /
    method: GET
    data_selector: records
    params: {}
- name: UltiHash
  endpoint:
    path: /catalogue
    method: GET
    data_selector: records
- name: landscape_images
  endpoint:
    path: /get_landscape_images
    method: POST
    data_selector: results
- name: landscape_images
  endpoint:
    path: /get_landscape_images
    method: POST
    data_selector: results
- name: landscapes
  endpoint:
    path: /get_landscape_images
    method: POST
    data_selector: results
- name: landscape_images
  endpoint:
    path: /get_landscape_images
    method: POST
    data_selector: results
- name: pre-signed URL generator
  endpoint:
    path: /operations/set-up-pre-signed-urls
    method: GET
    data_selector: urls
    params: {}
- name: scale_cluster
  endpoint:
    path: /administration/scale-your-cluster
    method: GET
    data_selector: replica counts
    params: {}
- name: rolling_updates
  endpoint:
    path: /operations/rolling-updates
    method: GET
- name: license_updates
  endpoint:
    path: /operations/license-updates
    method: GET
- name: backup
  endpoint:
    path: /backup
    method: POST
    data_selector: backup_process
    params: {}
- name: restore
  endpoint:
    path: /restore
    method: POST
    data_selector: restore_process
    params: {}
- name: backup_cluster
  endpoint:
    path: /backup
    method: POST
    data_selector: backup_info
    params: {}
- name: restore_cluster
  endpoint:
    path: /restore
    method: POST
    data_selector: restore_info
    params: {}
- name: storage_groups_with_erasure_coding
  endpoint:
    path: /storage/groups/erasure_coding
    method: POST
    data_selector: groups
    params:
      storages: 6
      data_shards: 4
      parity_shards: 2
      stripe_size_kib: 256
      storageClass: local-path
      size: 70Gi
- name: storage_groups_without_erasure_coding
  endpoint:
    path: /storage/groups/without_erasure_coding
    method: POST
    data_selector: groups
    params:
      storages: 6
      storageClass: local-path
      size: 70Gi
- name: storage_groups_erasure_coding
  endpoint:
    path: /administration/erasure-coding-for-data-resiliency
    method: POST
    data_selector: groups
    params:
      type: ERASURE_CODING
      storages: 6
      data_shards: 4
      parity_shards: 2
      stripe_size_kib: 256
      storageClass: local-path
      size: 70Gi
- name: storage_groups_round_robin
  endpoint:
    path: /administration/storage-groups-without-erasure-coding
    method: POST
    data_selector: groups
    params:
      type: ROUND_ROBIN
      storages: 6
      storageClass: local-path
      size: 70Gi
- name: storage
  endpoint:
    path: /services/data/vXX.X/sobjects/Storage
    method: GET
    data_selector: records
    params: {}
- name: etcd
  endpoint:
    path: persistence/storageClass
    method: COPY
    data_selector: storageClass
    params: {}
- name: database
  endpoint:
    path: primary/persistence/storageClass
    method: COPY
    data_selector: storageClass
    params: {}
- name: storage
  endpoint:
    path: storageClass
    method: COPY
    data_selector: storageClass
    params: {}
- name: deduplicator
  endpoint:
    path: storageClass
    method: COPY
    data_selector: storageClass
    params: {}
- name: core_docker_image
  endpoint:
    path: /core/docker/image
    method: GET
    data_selector: image_tag
- name: etcd_chart_version
  endpoint:
    path: /etcd/chart/version
    method: GET
    data_selector: version
- name: postgres_chart_version
  endpoint:
    path: /postgres/chart/version
    method: GET
    data_selector: version
- name: opentelemetry_chart_version
  endpoint:
    path: /opentelemetry/chart/version
    method: GET
    data_selector: version
- name: prometheus_node_exporter_chart_version
  endpoint:
    path: /prometheus/node/exporter/chart/version
    method: GET
    data_selector: version
notes:
- UltiHash is designed for modern workloads including AI and advanced analytics.
- For users of the Freemium tier, support is available via email at support@ultihash.io.
- While we aim to respond to all inquiries, no specific response times are guaranteed.
- The UltiHash team provides support for Customers of the Premium tier.
- Support is available via email at support@ultihash.io
- Community support is available via the UltiHash Discord server
- This setup is intended for local testing - not production use.
- UltiHash is only supported on Linux.
- For now, UltiHash is only supported on Linux.
- Uses Kubernetes-native architecture for easy scaling and load balancing
- Minimum of 1 Kubernetes node with NVMe SSDs required
- Ensure you have a Kubernetes cluster running version 1.20 or higher.
- Helm version 3.x is required.
- Minimum of 1 Kubernetes node with NVMe SSDs.
- Resource needs will vary depending on the amount of data being stored and managed.
- UltiHash license is available as pay-as-you-go license with pricing for the number
  of used GiBs per hour or subscription license with pricing for the number of used
  GiBs for the subscription duration available in 1 month, 12 month, 24 month and
  36 month contract variations.
- For best performance, especially with larger datasets, itâ€™s essential to provision
  additional resources accordingly.
- Ensure that image repositories are accessible and secrets for private registries
  are correctly configured in the cluster.
- Whenever interacting with AWS cloud, we strongly encourage you to follow the principle
  of least privilege.
- The IAM user or the role that is used to provision and manage UH cluster in an AWS
  account should have the specified IAM permissions.
- Data stays local, stored securely in Frankfurt am Main, Germany (AWS) or Falkenstein,
  Germany (Hetzner).
- High read throughput optimized for large volumes of data stored in the EU.
- UltiHash cluster is deployed on a single EC2 instance of type r8g.4xlarge with a
  network load balancer that routes traffic to it.
- Authentication parameters will be read from the environment variables AWS_ACCESS_KEY_ID
  and AWS_SECRET_ACCESS_KEY.
- UltiHash Serverless is optimized to provide high and consistent read performance.
- UltiHash offers a powerful S3-compatible API for connecting to a huge range of tools.
- S3 path style access has to be enabled
- AWS access and secret keys could be any, since authentication is not yet supported
  by UltiHash
- Uses API key for authentication
- Make sure your target bucket exists on UltiHash
- Make sure your target bucket exists on UltiHash.
- Include the necessary Iceberg, Hadoop AWS, and AWS SDK packages.
- The UltiHash cluster is running over HTTP and not HTTPS.
- The target bucket in UltiHash needs to exist in your UltiHash Cluster prior to this
  configuration.
- The target bucket in UltiHash needs to exist prior to S3 Sink Connector configuration.
- Uses the S3 Sink Connector to push data to object storage.
- In order to grant Presto access to UltiHash, users need to create and configure
  a catalogue called UltiHash, with the ultihash.properties text file.
- S3A driver config requires setting up access key and secret key.
- Ensure that UltiHash credentials are exported in the working terminal
- Each catalogue points at a UltiHash Cluster, and within a catalogue the user can
  create SQL tables which point at specific buckets in the UltiHash Cluster.
- Before starting a PySpark session with access to data stored in UltiHash, the user
  should make sure that the correct packages were downloaded and configure the S3A
  driver.
- Requires deployment of pre-signed URLs Generator alongside the UltiHash cluster.
- Define S3 region (could be any, since the custom S3 endpoint is used)
- Enforce the path style URLs
- In order to grant Trino access to UltiHash, users need to create and configure a
  catalogue called UltiHash, with the ultihash.properties text file.
- UltiHash cluster must be deployed in a Kubernetes environment and exposed via a
  public HTTPs endpoint.
- CORS configuration is required for the bucket containing the data.
- Connects to Zilliz for vector search.
- Expects a JSON payload with a query key.
- Pre-signed URLs provide a way to grant temporary access to objects stored in S3-compatible
  storage systems like UltiHash.
- A pre-signed URL is a time-limited link to an object in storage.
- UltiHash tackles storage management with byte-level deduplication.
- Ensure API calls include the UltiHash license
- Versioning is bucket-scoped and must be explicitly enabled.
- Each version is automatically assigned a unique versionId after each write operation.
- Every PUT or overwrite generates a new immutable version with its own versionId.
- Ensure the ingress controller is configured for your environment (e.g., Nginx) and
  that TLS is used for secure communication.
- Adjust resources to balance performance with cost.
- Use affinity rules to optimize performance and ensure critical services run on appropriate
  nodes.
- Rotate secrets periodically and implement alerts for expired or compromised secrets.
- UltiHash's deduplication runs continuously and is data-type-agnostic, supporting
  structured, unstructured, and even compressed data.
- Set up monitoring early to ensure you can track system performance and diagnose
  issues as they arise.
- Versioning is bucket-scoped and must be explicitly enabled first.
- Each version is automatically assigned a unique versionId after each write (PUT)
  operation.
- UltiHash is deployed via a Helm chart, which lets you update replica counts for
  each service and roll out changes across the cluster.
- Any access to UltiHash cluster is authenticated using AWS Signature Version 4.
- Updating your UltiHash cluster ensures that you are running the latest version of
  the software and that any license changes are properly applied.
- Updates are performed using Helm, which allows you to replace pods gradually (rolling
  updates) or force an update when required.
- Backup process captures the entire Kubernetes namespace where the cluster is deployed.
- Restores can be performed in-place or in a separate environment.
- Currently, only a single storage group is supported.
- To enable UltiHash cluster using the storage class above, specify it in the helm
  values of the UltiHash helm chart
- In-flight encryption can be configured on Ingress level and external load balancer
  level.
- 'optional: specify the KMS key to encrypt the provisioned EBS volumes. If omitted,
  the AWS-managed KMS key will be used'
- Uses OAuth2 with refresh token â€” requires setup of connected app in api
- Implemented support for global policies
- Implemented automated credentials generation for the UH root user
- Update core Docker image tag to 1.6.0
- Bump etcd to chart version 12.0.10 / app version 3.6.2
- Bump postgresl to chart version 16.7.19 / app version 17.5.0
- Bump opentelemetry-collector to chart version 0.129.0 / app version 0.130.0
- Bump prometheus-node-exporter to chart version 4.47.1 / app version 1.9.1
- These scripts provide a straightforward way to interact with UltiHash storage using
  the S3-compatible API.
errors:
- Helm install or upgrade hangs or returns an error
- Application pods do not start
- Missing or incorrect values in values.yaml
- 'Running On-Demand Standard (A, C, D, H, I, M, R, T, Z) instances limit exceeded:
  Increase quota proactively before scaling out your UltiHash cluster.'
- 'REQUEST_LIMIT_EXCEEDED: Throttle API calls or reduce frequency'
- 'QUERY_TIMEOUT: Break down filters or add selectivity'
- 'Connection error: Check if the endpoint is reachable.'
- Check the status of the S3 Sink Connector, it should be 'RUNNING'
- '404 Not Found: No matching records found.'
- '400 Bad Request: Missing ''query'' in request.'
- '401 Unauthorized: Recheck OAuth scopes or token expiration'
auth_info:
  mentioned_objects:
  - AWS Signature Version 4
client:
  base_url: http://127.0.0.1:8080
source_metadata: null
