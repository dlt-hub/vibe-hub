resources:
- name: WildChat
  endpoint:
    path: /datasets/allenai/WildChat
    method: GET
    data_selector: records
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: recipe
  endpoint:
    path: /generate
    method: POST
    data_selector: data
    params: {}
- name: recipe_generator
  endpoint:
    path: /generate/recipe
    method: POST
    data_selector: recipes
    params:
      max_requests_per_minute: 2000
      max_tokens_per_minute: 4000000
- name: recipe_generator
  endpoint:
    path: /
    method: POST
    data_selector: results
- name: recipe_generator
  endpoint:
    path: /models/meta-llama/Llama-4-Scout-17B-16E-Instruct
    method: POST
    data_selector: results
- name: subject_generator
  endpoint:
    path: /bespoke-curator/data-curation-recipes/generating-a-diverse-qa-dataset
    method: GET
- name: Subject
  endpoint:
    path: /subjects
    method: GET
    data_selector: subjects
- name: Subsubject
  endpoint:
    path: /subsubjects
    method: GET
    data_selector: subsubjects
- name: QAs
  endpoint:
    path: /qas
    method: GET
    data_selector: qas
- name: subjects
  endpoint:
    path: /api/subjects
    method: GET
    data_selector: subjects
- name: subsubjects
  endpoint:
    path: /api/subsubjects
    method: GET
    data_selector: subsubjects
- name: qa_pairs
  endpoint:
    path: /api/qa_pairs
    method: GET
    data_selector: qas
- name: stratified_generator
  endpoint:
    path: /stratified-generator
    method: POST
    data_selector: qa_pairs
    params: {}
- name: function_calls
  endpoint:
    path: /api/v1/function_calls
    method: POST
    data_selector: data
    params: {}
- name: function_call_generator
  endpoint:
    path: /function_call_generator
    method: POST
    data_selector: function_calls
    params: {}
- name: function_call_generator
  endpoint:
    path: /function_call_generator
    method: POST
    data_selector: function_calls
    params: {}
- name: get_weather
  endpoint:
    path: /get_weather
    method: POST
    data_selector: function_call
    params: {}
- name: get_local_time
  endpoint:
    path: /get_local_time
    method: POST
    data_selector: function_call
    params: {}
- name: get_weather
  endpoint:
    path: /get_weather
    method: POST
    data_selector: function
    params:
      location: string
      units: string
- name: get_local_time
  endpoint:
    path: /get_local_time
    method: POST
    data_selector: function
    params:
      location: string
      timezone: string
- name: get_weather
  endpoint:
    path: /get_weather
    method: POST
    data_selector: function
    params:
      location: string
      units: string
- name: get_local_time
  endpoint:
    path: /get_local_time
    method: POST
    data_selector: function
    params:
      location: string
      timezone: string
- name: function_call_generator
  endpoint:
    path: /function_call_generator
    method: POST
    data_selector: function_calls
    params: {}
- name: function_call_generator
  endpoint:
    path: /function_call_generator
    method: POST
    data_selector: function_calls
    params: {}
- name: aspect_based_sentiment_analysis
  endpoint:
    path: /aspect_based_sentiment_analysis
    method: POST
    data_selector: results
- name: aspect_based_sentiment
  endpoint:
    path: /datasets/249dcc5c831f4563b5e7565465252ed8
    method: GET
    data_selector: records
    params: {}
- name: yelp_restaurant_reviews
  endpoint:
    path: /bespokelabs/yelp_restaurant_reviews
    method: GET
    data_selector: records
    params: {}
- name: yelp_restaurant_reviews
  endpoint:
    path: /datasets/bespokelabs/yelp_restaurant_reviews
    method: GET
    data_selector: data
    params: {}
- name: evaluate_sentiment
  endpoint:
    path: /evaluate
    method: POST
    data_selector: dataset
    params: {}
- name: fine_tuning
  endpoint:
    path: /fine-tuning
    method: POST
    data_selector: response
    params: {}
- name: yelp_restaurant_reviews
  endpoint:
    path: /bespokelabs/yelp_restaurant_reviews
    method: GET
    data_selector: records
    params: {}
- name: finetuned_model
  endpoint:
    path: /models
    method: GET
    data_selector: models
    params: {}
- name: aspect_based_sentiment_analysis
  endpoint:
    path: /finetuning
    method: POST
    data_selector: response
    params: {}
- name: model
  endpoint:
    path: /models
    method: GET
    data_selector: models
- name: yelp_restaurant_reviews
  endpoint:
    path: /datasets/bespokelabs/yelp_restaurant_reviews
    method: GET
    data_selector: reviews
    params: {}
- name: models
  endpoint:
    path: /models
    method: GET
    data_selector: ''
- name: yelp_restaurant_reviews
  endpoint:
    path: /bespokelabs/yelp_restaurant_reviews
    method: GET
    data_selector: records
- name: finetuned_model
  endpoint:
    path: /models/together_ai/mahesh_bespoke/Meta-Llama-3.1-8B-Instruct-Reference--aspect-based-sentiment-analysis-lora-xyz
    method: POST
    data_selector: dataset
- name: fine_tuned_model
  endpoint:
    path: /models
    method: GET
    data_selector: models
    params: {}
- name: product_curator
  endpoint:
    path: /generate_product
    method: POST
    data_selector: product
    params: {}
- name: yelp_restaurant_reviews
  endpoint:
    path: /datasets/bespokelabs/yelp_restaurant_reviews
    method: GET
    data_selector: dataset
    params: {}
- name: yelp_restaurant_reviews
  endpoint:
    path: /datasets/bespokelabs/yelp_restaurant_reviews
    method: GET
    data_selector: records
    params: {}
- name: evaluation
  endpoint:
    path: /evaluate
    method: POST
    data_selector: dataset
    params: {}
- name: finetune_model
  endpoint:
    path: /finetune
    method: POST
    data_selector: results
    params: {}
- name: fine_tuning
  endpoint:
    path: /fine-tuning
    method: POST
    data_selector: fine_tune_response
- name: ProductCurator
  endpoint:
    path: /api/v1/products
    method: POST
    data_selector: product
- name: features
  endpoint:
    path: /features
    method: GET
    data_selector: features
    params: {}
- name: yelp_restaurant_reviews
  endpoint:
    path: /datasets/bespokelabs/yelp_restaurant_reviews
    method: GET
    data_selector: data
    params: {}
- name: finetuned_model
  endpoint:
    path: /save_pretrained_gguf
    method: POST
    data_selector: model
    params: {}
- name: ollama_model
  endpoint:
    path: /create
    method: POST
    data_selector: model
    params: {}
- name: evaluation
  endpoint:
    path: /evaluate
    method: POST
    data_selector: results
    params: {}
- name: aspect_based_sentiment_analysis
  endpoint:
    path: /finetuning
    method: POST
    data_selector: data
    params: {}
- name: model
  endpoint:
    path: /models
    method: GET
- name: yelp_restaurant_reviews
  endpoint:
    path: /bespokelabs/yelp_restaurant_reviews
    method: GET
    data_selector: records
    params: {}
- name: overall_accuracy
  endpoint:
    data_selector: overall_accuracy
- name: aspect_accuracies
  endpoint:
    data_selector: aspect_accuracies
- name: ProductCurator
  endpoint:
    path: /curator
    method: POST
    data_selector: product
    params: {}
- name: ProductCurator
  endpoint:
    path: /curator/products
    method: POST
    data_selector: products
- name: features
  endpoint:
    path: /features
    method: GET
    data_selector: features
notes:
- Uses OAuth2 with refresh token â€” requires setup of connected app in api
- To keep your datasets private, associate them with a Bespoke Labs account.
- With authentication enabled, all datasets are streamed to the hosted viewer.
- Curator automatically caches the output generated by the LLM class.
- To disable caching, you can simply set CURATOR_DISABLE_CACHE=1 before generating
  your data.
- By default, all cached datasets are saved to ~/.cache/curator.
- Some objects like Contact may return nulls in deeply nested fields
- Structured output allows for clean data structure.
- Chaining multiple LLM calls enables powerful synthetic data pipelines.
- Providers like OpenAI and Anthropic offer batch mode, which allows you to upload
  a bunch of prompts to be processed asynchronously.
- Python 3.10+ is required
- Curator must be installed via `pip install bespokelabs-curator`
- Environment variable OPENAI_API_KEY must be set
- Anthropic API key is required
- Requires setup of GCP account with Vertex AI enabled.
- Access to Google Cloud Bucket is necessary.
- Mistral API key is required
- Install Curator via `pip install bespokelabs-curator`
- Get your kluster.ai API key from https://www.kluster.ai/
- Uses API key for authorization.
- Rate limits are configurable with backend parameters.
- You can easily run multimodal synthetic data generation using curator.
- 'Full caching and automatic recovery: Similar to Curator.LLM''s caching feature,
  code executor also has inbuilt caching and automatic recovery. Any interrupted runs
  can be fully recovered and no computation is lost.'
- Ensure you have at least one Inference Provider enabled in your Hugging Face account.
- Pipeline generates hierarchical datasets of diverse question-answer pairs.
- The StratifiedGenerator ensures generated dataset avoids biases and provides comprehensive
  representation of input questions.
- 'Model Selection: Larger models (e.g., GPT-4) produce higher quality answers but
  cost more.'
- This API allows for customized function calls using different parameters for each
  row in a dataset.
- The generation_params in Dataset must be a string otherwise the Dataset operation
  automatically expand dictionary keys
- Uses Together's finetuning API to generate a synthetic dataset using curator.
- Uses Yelp restaurant reviews dataset to train a sentiment analysis model.
- Uses OpenAI and Together APIs for sentiment analysis.
- The model ID must be replaced with the actual model ID obtained from the API.
- Model training and fine-tuning operations can be executed via the API.
- Uses Together's finetuning API to finetune sentiment analysis models.
- We use curator viewer to visualize the data fast.
- You can comment it out if you don't want to use it.
- We will use Yelp restaurant reviews dataset to train a sentiment analysis model.
- We use json mode instead of structured outputs since many small models don't support
  that
- Model ID required for fine-tuned model
- Ensure appropriate parameters are set for evaluation
- We will run this curator on yelp restaurant reviews dataset to generate aspect based
  sentiment annotations for each review.
- This example requires a GPU for finetuning.
- You can visualize data using Curator viewer easily.
- The dataset is available at the specified endpoint.
- Uses OpenAI and Together APIs for inference and fine-tuning
- Model ID must be replaced with the correct fine-tuned model ID from the API.
- Supports loading in 4bit and long contexts
- Uses file upload for fine-tuning dataset
- Model training process includes multiple events from job creation to completion
- Uses Yelp restaurant reviews dataset for sentiment analysis.
- Uses Together's API for finetuning models.
- Bespoke MiniCheck is available as a Guardrails validator
- Get your API key at the Bespoke Console
- Use the environment variable BESPOKE_API_KEY for the API key
- Uses JSON mode for responses since many small models don't support structured outputs
- This example requires a GPU for finetuning. If you don't have a machine with GPUs
  handy, you can use the Colab version below with free T4 GPUs.
- Choose any number > 0 ! Suggested 8, 16, 32, 64, 128
- This is not bad for a quick start.
- In some cases, you will see that the LLM doesn't output exact text (which happens
  for even GPT-4o)!
- 'Bespoke MiniCheck is available as a Guardrails validator here: https://hub.guardrailsai.com/validator/bespokelabs/bespoke_minicheck'
- First, get your API key at the Bespoke Console.
errors:
- 'REQUEST_LIMIT_EXCEEDED: Throttle API calls or reduce frequency'
- 'QUERY_TIMEOUT: Break down filters or add selectivity'
- '401 Unauthorized: Recheck OAuth scopes or token expiration'
- '401 Unauthorized: Check API key.'
- '429 Too Many Requests: Exceeding rate limits.'
- '401 Unauthorized: Invalid API key.'
- Try increasing the temperature parameter or the number of clusters.
- Try changing the model or backend params.
- '401 Unauthorized: Recheck API keys or permissions'
- '401 Unauthorized: Check your API key.'
- '400 Bad Request: Invalid request data.'
auth_info:
  mentioned_objects:
  - OauthToken
  - AuthProvider
  - NamedCredential
client:
  base_url: https://api.together.xyz
  auth:
    type: apikey
    location: header
    header_name: Authorization
source_metadata: null
