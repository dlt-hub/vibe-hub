resources:
- name: sparse_tensor
  endpoint:
    path: /sparse_tensor
    method: GET
    data_selector: tensor_data
- name: LCollapseOp
  endpoint:
    path: /path/to/lcollapse
    method: GET
    data_selector: records
- name: LCollapseOp
  endpoint:
    path: ''
    method: ''
    data_selector: ''
    params: {}
notes:
- MatX is a header-only library, using it in your own projects is as simple as including
  only the core matx.h file.
- MatX is a header-only library, using it in your own projects is as simple as including
  only the core `matx.h` file.
- Using MatX with an unsupported compiler may result in compiler and/or runtime errors.
- Enabling NVPL will enable NVPL libraries for FFT, BLAS and LAPACK, and so it cannot
  be used in conjunction with other CPU libraries at this time.
- Building documentation must be done separately from other build options as to minimize
  the requirements needed.
- Prefer runtime arguments on the user-facing function if there is no performance
  penalty, and convert to template arguments when creating the operator object.
- Use static_assert with a helpful string wherever possible. Compile-time errors are
  always better than runtime errors, and many rank and type checks in MatX can be
  done at compile-time.
- Current experimental support provides a few factory methods with the common formats
  COO, CSR, CSC, and DIA.
- Custom operator is defined as a class with a postfix of Op
- Operator class always inherits publicly from BaseOp
- A custom operator is always defined as a class with a postfix of Op.
- The operator class always inherits publicly from BaseOp using a CRTP.
errors: []
auth_info:
  mentioned_objects: []
client:
  base_url: https://nvidia.github.io/MatX/
  headers:
    Accept: application/json
source_metadata: null
