resources:
- name: NetCDFDataset
  endpoint: {}
- name: GMLDataset
  endpoint: {}
- name: GraphMLDataset
  endpoint: {}
- name: JSONDataset
  endpoint: {}
- name: CSVDataset
  endpoint: {}
- name: DeltaTableDataset
  endpoint: {}
- name: ExcelDataset
  endpoint: {}
- name: FeatherDataset
  endpoint: {}
- name: GBQQueryDataset
  endpoint: {}
- name: GBQTableDataset
  endpoint: {}
- name: GenericDataset
  endpoint: {}
- name: HDFDataset
  endpoint: {}
- name: cars
  endpoint:
    path: data/09_tracking/cars.json
    method: save
    data_selector: null
    params: {}
- name: api
  endpoint:
    path: /projects/kedro-datasets/en/kedro-datasets-8.1.0/api/kedro_datasets/api.APIDataset/
    method: GET
    data_selector: data
    params: {}
- name: node
  endpoint:
    path: /kedro/node
    method: GET
    data_selector: records
    params: {}
- name: pipeline
  endpoint:
    path: /kedro/pipeline
    method: GET
    data_selector: records
    params: {}
- name: data_catalog
  endpoint:
    path: /kedro/data_catalog
    method: GET
    data_selector: records
    params: {}
- name: Kedro project
  endpoint:
    path: /get-started/architecture_overview/#kedro-project
    method: GET
    data_selector: contents
    params: {}
- name: Kedro framework
  endpoint:
    path: /get-started/architecture_overview/#kedro-framework
    method: GET
    data_selector: contents
    params: {}
- name: Kedro starter
  endpoint:
    path: /get-started/architecture_overview/#kedro-starter
    method: GET
    data_selector: contents
    params: {}
- name: Kedro library
  endpoint:
    path: /get-started/architecture_overview/#kedro-library
    method: GET
    data_selector: contents
    params: {}
- name: Kedro extension
  endpoint:
    path: /get-started/architecture_overview/#kedro-extension
    method: GET
    data_selector: contents
    params: {}
- name: companies
  endpoint:
    path: /data/01_raw/companies.csv
    method: GET
    data_selector: records
    params: {}
- name: reviews
  endpoint:
    path: /data/01_raw/reviews.csv
    method: GET
    data_selector: records
    params: {}
- name: shuttles
  endpoint:
    path: /data/01_raw/shuttles.xlsx
    method: GET
    data_selector: records
    params: {}
- name: companies
  endpoint:
    path: data/01_raw/companies.csv
    method: GET
    data_selector: records
- name: shuttles
  endpoint:
    path: data/01_raw/shuttles.xlsx
    method: GET
    data_selector: records
    params:
      load_args:
        engine: openpyxl
- name: preprocessed_companies
  endpoint:
    path: data/02_intermediate/preprocessed_companies.parquet
    method: GET
    data_selector: records
    params: {}
- name: preprocessed_shuttles
  endpoint:
    path: data/02_intermediate/preprocessed_shuttles.parquet
    method: GET
    data_selector: records
    params: {}
- name: model_input_table
  endpoint:
    path: data/03_primary/model_input_table.parquet
    method: GET
    data_selector: records
    params: {}
- name: regressor
  endpoint:
    path: data/06_models/regressor.pickle
    method: GET
    data_selector: records
    params:
      versioned: true
- name: ds_pipeline_1
  endpoint:
    path: /pipeline/active_modelling_pipeline
    method: POST
- name: ds_pipeline_2
  endpoint:
    path: /pipeline/candidate_modelling_pipeline
    method: POST
- name: project_metadata
  endpoint:
    path: ''
    method: ''
    data_selector: ''
    params: {}
- name: test_a_project
  endpoint:
    path: /tutorials/test_a_project/
    method: GET
- name: model_input_table
  endpoint:
    path: ''
    method: ''
    data_selector: ''
    params: {}
- name: params:model_options
  endpoint:
    path: ''
    method: ''
    data_selector: ''
    params: {}
- name: dataset_errors
  endpoint:
    path: /tutorials/spaceflights_tutorial_faqs/#dataset-errors
    method: GET
    data_selector: records
- name: pipeline_run
  endpoint:
    path: /tutorials/spaceflights_tutorial_faqs/#pipeline-run
    method: GET
    data_selector: records
- name: catalog
  endpoint:
    path: /catalog
    method: GET
    data_selector: datasets
- name: pipelines
  endpoint:
    path: /pipelines
    method: GET
    data_selector: pipelines
- name: context
  endpoint:
    path: /context
    method: GET
    data_selector: context
- name: session
  endpoint:
    path: /session
    method: GET
    data_selector: session
- name: project_name
  endpoint:
    path: /create/new_project/project_name
    method: GET
    data_selector: project_name
- name: repo_name
  endpoint:
    path: /create/new_project/repo_name
    method: GET
    data_selector: repo_name
- name: python_package
  endpoint:
    path: /create/new_project/python_package
    method: GET
    data_selector: python_package
- name: essential_components
  endpoint:
    path: /create/minimal_kedro_project/#essential-components-of-a-kedro-project
    method: GET
- name: mandatory_files
  endpoint:
    path: /create/minimal_kedro_project/#2-mandatory-files
    method: GET
- name: creating_minimal_kedro_project
  endpoint:
    path: /create/minimal_kedro_project/#creating-a-minimal-kedro-project-step-by-step
    method: GET
- name: pyproject.toml
  endpoint:
    path: pyproject.toml
    method: GET
    data_selector: tool.kedro
    params: {}
- name: settings.py
  endpoint:
    path: settings.py
    method: GET
    data_selector: settings
    params: {}
- name: pipeline_registry.py
  endpoint:
    path: pipeline_registry.py
    method: GET
    data_selector: pipelines
    params: {}
- name: project
  endpoint:
    path: /create/project
    method: POST
    data_selector: project_data
- name: linting
  endpoint:
    path: /create/new_project_tools/#linting
    method: GET
- name: testing
  endpoint:
    path: /create/new_project_tools/#testing
    method: GET
- name: custom_logging
  endpoint:
    path: /create/new_project_tools/#custom-logging
    method: GET
- name: documentation
  endpoint:
    path: /create/new_project_tools/#documentation
    method: GET
- name: data_structure
  endpoint:
    path: /create/new_project_tools/#data-structure
    method: GET
- name: pyspark
  endpoint:
    path: /create/new_project_tools/#pyspark
    method: GET
- name: project_name
  endpoint:
    path: /services/data/vXX.X/sobjects/ProjectName
    method: GET
    data_selector: records
- name: repo_name
  endpoint:
    path: /services/data/vXX.X/sobjects/RepoName
    method: GET
    data_selector: records
- name: python_package
  endpoint:
    path: /services/data/vXX.X/sobjects/PythonPackage
    method: GET
    data_selector: records
- name: tools
  endpoint:
    path: /services/data/vXX.X/sobjects/Tools
    method: GET
    data_selector: records
- name: example_pipeline
  endpoint:
    path: /services/data/vXX.X/sobjects/ExamplePipeline
    method: GET
    data_selector: records
- name: starter_usage
  endpoint:
    path: /create/starters/how-to-use-a-starter
    method: GET
    data_selector: records
    params: {}
- name: starter_aliases
  endpoint:
    path: /create/starters/starter-aliases
    method: GET
    data_selector: records
    params: {}
- name: official_starters
  endpoint:
    path: /create/starters/official-kedro-starters
    method: GET
    data_selector: records
    params: {}
- name: configuration
  endpoint:
    path: /en/stable/configure/config_loader_migration/
    method: GET
    data_selector: content
    params: {}
- name: parameters
  endpoint:
    path: parameters.yml
    method: GET
    data_selector: parameters
    params: {}
- name: catalog
  endpoint:
    path: catalog.yml
    method: GET
    data_selector: catalog
    params: {}
- name: parameters
  endpoint:
    path: /conf/base/parameters.yml
    method: GET
    data_selector: parameters
    params: {}
- name: companies
  endpoint:
    path: data/01_raw/companies.csv
    method: GET
    data_selector: ''
    params: {}
- name: reviews
  endpoint:
    path: data/01_raw/reviews.csv
    method: GET
    data_selector: ''
    params: {}
- name: shuttles
  endpoint:
    path: data/01_raw/shuttles.xlsx
    method: GET
    data_selector: ''
    params: {}
- name: weather
  endpoint:
    path: ''
    method: ''
    data_selector: ''
    params:
      table_name: weather_data
      database: meteorology
      schema: observations
      credentials: snowflake_client
- name: us_corn_yield_data
  endpoint:
    path: https://quickstats.nass.usda.gov
    method: GET
    data_selector: records
    params:
      key: SOME_TOKEN
      format: JSON
      commodity_desc: CORN
      statisticcat_des: YIELD
      agg_level_desc: STATE
      year: 2000
- name: partitioned_datasets
  endpoint:
    path: /catalog-data/partitioned_and_incremental_datasets/
    method: GET
    data_selector: datasets
    params: {}
- name: incremental_datasets
  endpoint:
    path: /catalog-data/partitioned_and_incremental_datasets/incremental/
    method: GET
    data_selector: datasets
    params: {}
- name: partitioned_dataset
  endpoint:
    path: /catalog-data/partitioned_and_incremental_datasets/
    method: GET
    data_selector: records
    params: {}
- name: incremental_dataset
  endpoint:
    path: /catalog-data/partitioned_and_incremental_datasets/
    method: GET
    data_selector: records
    params: {}
- name: my_partitioned_dataset
  endpoint:
    path: s3://my-bucket-name/path/to/folder
    method: ''
    data_selector: ''
    params: {}
- name: new_partitioned_dataset
  endpoint:
    path: /partitions.PartitionedDataset
    method: POST
    data_selector: records
    params:
      path: s3://my-bucket-name
      dataset: pandas.CSVDataset
      filename_suffix: .csv
      save_lazily: false
- name: PartitionedDataset
  endpoint:
    path: /catalog-data/partitioned_and_incremental_datasets
    method: GET
    data_selector: datasets
    params: {}
- name: IncrementalDataset
  endpoint:
    path: /catalog-data/incremental_datasets
    method: GET
    data_selector: datasets
    params: {}
- name: my_partitioned_dataset
  endpoint:
    path: s3://my-bucket-name/path/to/folder
    method: GET
    data_selector: records
    params: {}
- name: my_partitioned_dataset
  endpoint:
    path: s3://my-bucket-name/path/to/folder
    method: GET
    data_selector: records
- name: partitioned_datasets
  endpoint:
    path: /catalog-data/partitioned_and_incremental_datasets/partitioned_datasets
    method: GET
- name: incremental_datasets
  endpoint:
    path: /catalog-data/partitioned_and_incremental_datasets/incremental_datasets
    method: GET
- name: my_partitioned_dataset
  endpoint:
    path: s3://my-bucket-name/path/to/folder
    method: GET
    data_selector: records
    params: {}
- name: new_partitioned_dataset
  endpoint:
    path: s3://my-bucket-name
    method: POST
    data_selector: records
    params: {}
- name: bikes
  endpoint:
    path: ../data/01_raw/bikes.csv
    method: GET
    data_selector: null
    params: {}
- name: cars
  endpoint:
    path: ../data/01_raw/cars.csv
    method: GET
    data_selector: null
    params:
      sep: ','
- name: cars_table
  endpoint:
    path: kedro.db
    method: GET
    data_selector: null
    params:
      table_name: cars
- name: scooters_query
  endpoint:
    path: kedro.db
    method: GET
    data_selector: null
    params:
      sql: select * from cars where gear=4
- name: ranked
  endpoint:
    path: ranked.parquet
    method: GET
    data_selector: null
    params: {}
- name: bikes
  endpoint:
    path: ../data/01_raw/bikes.csv
- name: cars
  endpoint:
    path: ../data/01_raw/cars.csv
- name: cars_table
  endpoint:
    path: sqlite:///kedro.db
- name: scooters_query
  endpoint:
    path: select * from cars where gear=4
- name: ranked
  endpoint:
    path: ranked.parquet
- name: test_dataset
  endpoint:
    path: data/01_raw/test.csv
    method: save
    data_selector: data
    params: {}
- name: nodes
  endpoint:
    path: /build/nodes
    method: GET
    data_selector: nodes
- name: variance_pipeline
  endpoint:
    path: /pipeline/variance
    method: GET
    data_selector: nodes
    params: {}
- name: sequential_runner
  endpoint:
    path: /sequential_runner
    method: GET
    data_selector: info
- name: parallel_runner
  endpoint:
    path: /parallel_runner
    method: GET
    data_selector: info
- name: thread_runner
  endpoint:
    path: /thread_runner
    method: GET
    data_selector: info
- name: Runners
  endpoint:
    path: /build/run_a_pipeline/#runners
    method: GET
    data_selector: runners
    params: {}
- name: SequentialRunner
  endpoint:
    path: /build/run_a_pipeline/runners/sequentialrunner
    method: GET
- name: ParallelRunner
  endpoint:
    path: /build/run_a_pipeline/runners/parallelrunner
    method: GET
- name: SequentialRunner
  endpoint:
    path: /build/run_a_pipeline/#sequentialrunner
    method: GET
- name: ParallelRunner
  endpoint:
    path: /build/run_a_pipeline/#parallelrunner
    method: GET
- name: namespace_reuse
  endpoint:
    path: /build/namespaces/reuse-pipelines
    method: GET
    data_selector: sections
    params: {}
- name: namespace_grouping
  endpoint:
    path: /build/namespaces/group-nodes
    method: GET
    data_selector: sections
    params: {}
- name: base_data_science
  endpoint:
    path: /src/project_name/pipelines/data_science/pipeline.py
    method: GET
    data_selector: records
- name: data_science_2
  endpoint:
    path: /src/project_name/pipelines/data_science_2/pipeline.py
    method: GET
    data_selector: records
- name: data_processing
  endpoint:
    path: /pipeline_registry/data_processing
    method: GET
    data_selector: pipelines
    params: {}
- name: data_science
  endpoint:
    path: /pipeline_registry/data_science
    method: GET
    data_selector: pipelines
    params: {}
- name: pipelines
  endpoint:
    path: /register_pipelines
    method: GET
    data_selector: pipelines
- name: dependencies
  endpoint:
    path: /develop/dependencies
    method: GET
    data_selector: contents
    params: {}
- name: tests
  endpoint:
    path: /tests
    method: GET
    data_selector: records
    params: {}
- name: pre_commit_hooks
  endpoint:
    path: /repos/astral-sh/ruff-pre-commit/hooks
    method: GET
    data_selector: hooks
    params: {}
- name: Airflow
  endpoint:
    path: /en/stable/deploy/supported-platforms/airflow/
    method: GET
- name: Amazon SageMaker
  endpoint:
    path: /en/stable/deploy/supported-platforms/amazon_sagemaker/
    method: GET
- name: Amazon EMR Serverless
  endpoint:
    path: /en/stable/deploy/supported-platforms/amazon_emr_serverless/
    method: GET
- name: AWS Step Functions
  endpoint:
    path: /en/stable/deploy/supported-platforms/aws_step_functions/
    method: GET
- name: Azure
  endpoint:
    path: /en/stable/deploy/supported-platforms/azure/
    method: GET
- name: Dask
  endpoint:
    path: /en/stable/deploy/supported-platforms/dask/
    method: GET
- name: Databricks
  endpoint:
    path: /en/stable/deploy/supported-platforms/databricks/
    method: GET
- name: Kubeflow Pipelines
  endpoint:
    path: /en/stable/deploy/supported-platforms/kubeflow/
    method: GET
- name: Prefect
  endpoint:
    path: /en/stable/deploy/supported-platforms/prefect/
    method: GET
- name: Vertex AI
  endpoint:
    path: /en/stable/deploy/supported-platforms/vertexai/
    method: GET
- name: container_based_deployment
  endpoint:
    path: /deploy/single_machine/#container-based
    method: GET
    data_selector: content
- name: package_based_deployment
  endpoint:
    path: /deploy/single_machine/#package-based
    method: GET
    data_selector: content
- name: cli_based_deployment
  endpoint:
    path: /deploy/single_machine/#cli-based
    method: GET
    data_selector: content
- name: distributed_deployment_steps
  endpoint:
    path: /deploy/distributed/
    method: GET
    data_selector: steps
- name: Kedro pipeline
  endpoint:
    path: /deploy/supported-platforms/airflow/
    method: GET
- name: job_run
  endpoint:
    path: /start-job-run
    method: POST
    data_selector: jobDetails
    params: {}
- name: companies
  endpoint:
    path: s3://<your-bucket>/companies.csv
    method: GET
    data_selector: records
- name: reviews
  endpoint:
    path: s3://<your-bucket>/reviews.csv
    method: GET
    data_selector: records
- name: shuttles
  endpoint:
    path: s3://<your-bucket>/shuttles.xlsx
    method: GET
    data_selector: records
- name: preprocessed_companies
  endpoint:
    path: s3://<your-bucket>/preprocessed_companies.csv
    method: GET
    data_selector: records
- name: preprocessed_shuttles
  endpoint:
    path: s3://<your-bucket>/preprocessed_shuttles.csv
    method: GET
    data_selector: records
- name: model_input_table
  endpoint:
    path: s3://<your-bucket>/model_input_table.csv
    method: GET
    data_selector: records
- name: regressor
  endpoint:
    path: s3://<your-bucket>/regressor.pickle
    method: GET
    data_selector: records
- name: X_train
  endpoint:
    path: s3://<your-bucket>/X_train.pickle
    method: GET
    data_selector: records
- name: X_test
  endpoint:
    path: s3://<your-bucket>/X_test.pickle
    method: GET
    data_selector: records
- name: y_train
  endpoint:
    path: s3://<your-bucket>/y_train.pickle
    method: GET
    data_selector: records
- name: y_test
  endpoint:
    path: s3://<your-bucket>/y_test.pickle
    method: GET
    data_selector: records
- name: Spaceflights Step Functions
  endpoint:
    path: /spaceflights-step-functions
    method: POST
    data_selector: functions
    params: {}
- name: DaskRunner
  endpoint:
    path: /dask_runner
    method: POST
    data_selector: results
- name: dask_client
  endpoint:
    path: /conf/dask/parameters.yml
    method: GET
    data_selector: dask_client
    params: {}
- name: data_copy
  endpoint:
    path: /dbfs/FileStore/iris-databricks/data
    method: POST
    data_selector: contents
    params: {}
- name: requirements
  endpoint:
    path: /Workspace/Repos/<databricks_username>/iris-databricks/requirements.txt
    method: GET
- name: parameters
  endpoint:
    path: /Workspace/Repos/<databricks_username>/iris-databricks/conf/base/parameters.yml
    method: GET
- name: Databricks
  endpoint:
    path: /en/stable/deploy/supported-platforms/databricks/databricks_deployment_workflow/
    method: GET
- name: kedro_project
  endpoint:
    path: /api/2.0/jobs/create
    method: POST
- name: kedro-kubeflow
  endpoint:
    path: /kubeflow
    method: GET
    data_selector: components
    params: {}
- name: work_pool
  endpoint:
    path: /work-pool
    method: POST
- name: work_queue
  endpoint:
    path: /work-queue
    method: POST
- name: argo_workflow_spec
  endpoint:
    path: /build_argo_spec.py
    method: POST
    data_selector: output
- name: AWS Batch job
  endpoint:
    path: /submit-aws-batch-jobs
    method: POST
- name: companies
  endpoint:
    path: s3://<your-bucket>/companies.csv
    method: GET
    data_selector: records
    params: {}
- name: reviews
  endpoint:
    path: s3://<your-bucket>/reviews.csv
    method: GET
    data_selector: records
    params: {}
- name: shuttles
  endpoint:
    path: s3://<your-bucket>/shuttles.xlsx
    method: GET
    data_selector: records
    params: {}
- name: preprocessed_companies
  endpoint:
    path: s3://<your-bucket>/preprocessed_companies.csv
    method: GET
    data_selector: records
    params: {}
- name: preprocessed_shuttles
  endpoint:
    path: s3://<your-bucket>/preprocessed_shuttles.csv
    method: GET
    data_selector: records
    params: {}
- name: model_input_table
  endpoint:
    path: s3://<your-bucket>/model_input_table.csv
    method: GET
    data_selector: records
    params: {}
- name: regressor
  endpoint:
    path: s3://<your-bucket>/regressor.pickle
    method: GET
    data_selector: records
    params:
      versioned: true
- name: X_train
  endpoint:
    path: s3://<your-bucket>/X_train.pickle
    method: GET
    data_selector: records
    params: {}
- name: X_test
  endpoint:
    path: s3://<your-bucket>/X_test.pickle
    method: GET
    data_selector: records
    params: {}
- name: y_train
  endpoint:
    path: s3://<your-bucket>/y_train.pickle
    method: GET
    data_selector: records
    params: {}
- name: y_test
  endpoint:
    path: s3://<your-bucket>/y_test.pickle
    method: GET
    data_selector: records
    params: {}
- name: AWS Batch job
  endpoint:
    path: /deploy/supported-platforms/aws_batch/
    method: GET
- name: job_definition
  endpoint:
    path: /create-aws-batch-job-definition
    method: POST
- name: job_queue
  endpoint:
    path: /create-aws-batch-job-queue
    method: POST
- name: compute_environment
  endpoint:
    path: /create-aws-batch-compute-environment
    method: POST
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: pikachu
  endpoint:
    path: s3://data/01_raw/pokemon-images-and-types/images/images/pikachu.png
    method: GET
    data_selector: data
    params: {}
- name: pikachu
  endpoint:
    path: s3://data/01_raw/pokemon-images-and-types/images/images/pikachu.png
    method: GET
    data_selector: ''
    params: {}
- name: hook_specifications
  endpoint:
    path: /hook/specifications
    method: GET
    data_selector: specifications
    params: {}
- name: cli_hooks
  endpoint:
    path: /cli/hooks
    method: GET
    data_selector: cli_hooks
    params: {}
- name: hook_specifications
  endpoint:
    path: /extend/hooks/introduction/#hook-specifications
    method: GET
    data_selector: specifications
    params: {}
- name: cli_hooks
  endpoint:
    path: /cli/hooks
    method: GET
    data_selector: hooks
    params: {}
- name: hook_implementation
  endpoint:
    path: /hook/implementation
    method: GET
    data_selector: hooks
    params: {}
- name: hooks
  endpoint:
    path: /extend/hooks/common_use_cases/
    method: GET
- name: hooks
  endpoint:
    path: /extend/hooks/common_use_cases/
    method: GET
    data_selector: common_use_cases
- name: hooks
  endpoint:
    path: /extend/hooks/
    method: GET
    data_selector: hooks
    params: {}
- name: memory_consumption_tracking
  endpoint:
    path: /extend/hooks/examples/#add-memory-consumption-tracking
    method: GET
    data_selector: examples
    params: {}
- name: data_validation
  endpoint:
    path: /extend/hooks/examples/#add-data-validation
    method: GET
    data_selector: examples
    params: {}
- name: memory_profiling_hooks
  endpoint:
    path: /extend/hooks/examples/#add-memory-consumption-tracking
    method: GET
    data_selector: examples
    params: {}
- name: data_validation
  endpoint:
    path: /extend/hooks/examples/#add-data-validation
    method: GET
    data_selector: examples
    params: {}
- name: companies
  endpoint:
    path: /raw_companies_dataset_expectation
    method: POST
    data_selector: expectations
    params: {}
- name: preprocessed_companies
  endpoint:
    path: /preprocessed_companies_dataset_expectation
    method: POST
    data_selector: expectations
    params: {}
- name: KedroSession
  endpoint:
    path: /extend/session/KedroSession
    method: GET
- name: project_name
  endpoint:
    path: /prompts.yml
    method: GET
- name: repo_name
  endpoint:
    path: /prompts.yml
    method: GET
- name: python_package
  endpoint:
    path: /prompts.yml
    method: GET
- name: kedro.config
  endpoint:
    path: /en/stable/api/config/kedro.config/
    method: GET
- name: kedro.framework
  endpoint:
    path: /en/stable/api/framework/kedro.framework/
    method: GET
- name: kedro.io
  endpoint:
    path: /en/stable/api/io/kedro.io/
    method: GET
- name: kedro.ipython
  endpoint:
    path: /en/stable/api/ipython/kedro.ipython/
    method: GET
- name: kedro.logging
  endpoint:
    path: /en/stable/api/kedro.logging/
    method: GET
- name: kedro.pipeline
  endpoint:
    path: /en/stable/api/pipeline/kedro.pipeline/
    method: GET
- name: kedro.runner
  endpoint:
    path: /en/stable/api/runner/kedro.runner/
    method: GET
- name: kedro.utils
  endpoint:
    path: /en/stable/api/kedro.utils/
    method: GET
- name: AbstractConfigLoader
  endpoint:
    path: /en/stable/api/config/kedro.config.AbstractConfigLoader/
    method: GET
    data_selector: records
- name: OmegaConfigLoader
  endpoint:
    path: /en/stable/api/config/kedro.config.OmegaConfigLoader/
    method: GET
    data_selector: records
- name: MissingConfigException
  endpoint:
    path: /en/stable/api/config/kedro.config.MissingConfigException/
    method: GET
    data_selector: records
- name: conf_source
  endpoint:
    path: /kedro/config/abstract_config.py
    method: GET
    data_selector: conf_source
    params: {}
- name: env
  endpoint:
    path: /kedro/config/abstract_config.py
    method: GET
    data_selector: env
    params: {}
- name: runtime_params
  endpoint:
    path: /kedro/config/abstract_config.py
    method: GET
    data_selector: runtime_params
    params: {}
- name: _custom_resolvers
  endpoint:
    path: _custom_resolvers
    method: GET
- name: _globals
  endpoint:
    path: _globals
    method: GET
- name: _globals_oc
  endpoint:
    path: _globals_oc
    method: GET
- name: _remote_root_path
  endpoint:
    path: _remote_root_path
    method: GET
- name: _runtime_params_oc
  endpoint:
    path: _runtime_params_oc
    method: GET
- name: base_env
  endpoint:
    path: base_env
    method: GET
- name: config_patterns
  endpoint:
    path: config_patterns
    method: GET
- name: default_run_env
  endpoint:
    path: default_run_env
    method: GET
- name: merge_strategy
  endpoint:
    path: merge_strategy
    method: GET
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: KedroSession
  endpoint:
    path: /kedro.framework.cli.catalog.KedroSession
    method: GET
    data_selector: session_id
    params: {}
- name: KedroSession
  endpoint:
    path: /kedro/session
    method: GET
    data_selector: session_data
- name: jupyter
  endpoint:
    path: /jupyter
    method: GET
    data_selector: kernel
    params: {}
- name: jupyter_lab
  endpoint:
    path: /jupyter/lab
    method: GET
    data_selector: kernel
    params: {}
- name: jupyter_notebook
  endpoint:
    path: /jupyter/notebook
    method: GET
    data_selector: kernel
    params: {}
- name: setup
  endpoint:
    path: /jupyter/setup
    method: POST
    data_selector: kernel
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: jupyter_lab
  endpoint:
    path: /jupyter/lab
    method: GET
    data_selector: metadata
    params: {}
- name: jupyter_notebook
  endpoint:
    path: /jupyter/notebook
    method: GET
    data_selector: metadata
    params: {}
- name: describe_datasets
  endpoint:
    path: /describe-datasets
    method: GET
    data_selector: datasets
    params: {}
- name: list_patterns
  endpoint:
    path: /list-patterns
    method: GET
    data_selector: patterns
    params: {}
- name: resolve_patterns
  endpoint:
    path: /resolve-patterns
    method: GET
    data_selector: resolved_patterns
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: run
  endpoint:
    path: /run
    method: POST
- name: KedroContext
  endpoint:
    path: /api/kedro/framework/context/KedroContext
    method: GET
    data_selector: records
    params: {}
- name: KedroContextError
  endpoint:
    path: /api/kedro/framework/context/KedroContextError
    method: GET
    data_selector: records
    params: {}
- name: CatalogCommandsMixin
  endpoint:
    path: /api/kedro/framework/context/CatalogCommandsMixin
    method: GET
    data_selector: records
    params: {}
- name: KedroContext
  endpoint:
    path: /kedro/framework/context/KedroContext
    method: GET
    data_selector: records
- name: KedroContextError
  endpoint:
    path: /kedro/framework/context/KedroContextError
    method: GET
    data_selector: records
- name: CatalogCommandsMixin
  endpoint:
    path: /kedro/framework/context/CatalogCommandsMixin
    method: GET
    data_selector: records
- name: data_processing
  endpoint:
    path: /data_processing
    method: GET
    data_selector: datasets
    params: {}
- name: after_catalog_created
  endpoint:
    path: /services/data/vXX.X/sobjects/after_catalog_created
    method: GET
    data_selector: records
    params: {}
- name: after_dataset_loaded
  endpoint:
    path: /services/data/vXX.X/sobjects/after_dataset_loaded
    method: GET
    data_selector: records
    params: {}
- name: after_dataset_saved
  endpoint:
    path: /services/data/vXX.X/sobjects/after_dataset_saved
    method: GET
    data_selector: records
    params: {}
- name: before_dataset_loaded
  endpoint:
    path: /services/data/vXX.X/sobjects/before_dataset_loaded
    method: GET
    data_selector: records
    params: {}
- name: before_dataset_saved
  endpoint:
    path: /services/data/vXX.X/sobjects/before_dataset_saved
    method: GET
    data_selector: records
    params: {}
- name: after_context_created
  endpoint:
    path: /services/data/vXX.X/sobjects/after_context_created
    method: GET
    data_selector: records
    params: {}
- name: after_node_run
  endpoint:
    path: /services/data/vXX.X/sobjects/after_node_run
    method: GET
    data_selector: records
    params: {}
- name: before_node_run
  endpoint:
    path: /services/data/vXX.X/sobjects/before_node_run
    method: GET
    data_selector: records
    params: {}
- name: on_node_error
  endpoint:
    path: /services/data/vXX.X/sobjects/on_node_error
    method: GET
    data_selector: records
    params: {}
- name: catalog
  endpoint:
    path: /catalog
    method: GET
    data_selector: catalog
- name: dataset
  endpoint:
    path: /dataset
    method: GET
    data_selector: dataset
- name: Node
  endpoint:
    path: /api/kedro/node
    method: GET
    data_selector: records
    params: {}
- name: after_node_run
  endpoint:
    path: after_node_run
    method: POST
    data_selector: None
    params: {}
- name: before_node_run
  endpoint:
    path: before_node_run
    method: POST
    data_selector: None
    params: {}
- name: on_node_error
  endpoint:
    path: on_node_error
    method: POST
    data_selector: None
    params: {}
- name: Pipeline
  endpoint:
    path: Pipeline
    method: POST
    data_selector: None
    params: {}
- name: pipeline
  endpoint:
    path: /pipeline
    method: GET
    data_selector: nodes
    params: {}
- name: after_catalog_created
  endpoint:
    path: /after_catalog_created
    method: GET
    data_selector: catalog
    params: {}
- name: after_dataset_loaded
  endpoint:
    path: /after_dataset_loaded
    method: GET
    data_selector: dataset_name
    params: {}
- name: after_dataset_saved
  endpoint:
    path: /after_dataset_saved
    method: GET
    data_selector: dataset_name
    params: {}
- name: before_dataset_loaded
  endpoint:
    path: /before_dataset_loaded
    method: GET
    data_selector: dataset_name
    params: {}
- name: before_dataset_saved
  endpoint:
    path: /before_dataset_saved
    method: GET
    data_selector: dataset_name
    params: {}
- name: hook_namespace
  endpoint:
    path: /kedro/framework/hooks/markers
    method: GET
- name: catalog_protocol
  endpoint:
    path: /kedro/framework/hooks/specs/CatalogProtocol
    method: GET
- name: data_catalog_specs
  endpoint:
    path: /kedro/framework/hooks/specs/DataCatalogSpecs
    method: GET
- name: only_nodes_with_inputs
  endpoint:
    path: /only_nodes_with_inputs
    method: GET
    data_selector: Pipeline
    params: {}
- name: only_nodes_with_namespaces
  endpoint:
    path: /only_nodes_with_namespaces
    method: GET
    data_selector: Pipeline
    params: {}
- name: only_nodes_with_outputs
  endpoint:
    path: /only_nodes_with_outputs
    method: GET
    data_selector: Pipeline
    params: {}
- name: only_nodes_with_tags
  endpoint:
    path: /only_nodes_with_tags
    method: GET
    data_selector: Pipeline
    params: {}
- name: outputs
  endpoint:
    path: /outputs
    method: GET
    data_selector: set
    params: {}
- name: tag
  endpoint:
    path: /tag
    method: POST
    data_selector: Pipeline
    params: {}
- name: to_json
  endpoint:
    path: /to_json
    method: GET
    data_selector: string
    params: {}
- name: to_nodes
  endpoint:
    path: /to_nodes
    method: GET
    data_selector: Pipeline
    params: {}
- name: to_outputs
  endpoint:
    path: /to_outputs
    method: GET
    data_selector: Pipeline
    params: {}
- name: after_pipeline_run
  endpoint:
    path: /hook/after_pipeline_run
    method: POST
    data_selector: run_result
    params: {}
- name: before_pipeline_run
  endpoint:
    path: /hook/before_pipeline_run
    method: POST
    data_selector: run_params
    params: {}
- name: on_pipeline_error
  endpoint:
    path: /hook/on_pipeline_error
    method: POST
    data_selector: error
    params: {}
- name: pipelines
  endpoint:
    path: /pipelines
    method: GET
- name: KedroSession
  endpoint:
    path: /kedro/framework/session/KedroSession
    method: GET
    data_selector: session_data
    params: {}
- name: BaseSessionStore
  endpoint:
    path: /kedro/framework/session/BaseSessionStore
    method: GET
    data_selector: session_store_data
    params: {}
- name: session
  endpoint:
    path: /kedro/framework/session
    method: GET
    data_selector: session_data
- name: SharedMemoryDataCatalog
  endpoint:
    path: /kedro/SharedMemoryDataCatalog
    method: GET
    data_selector: datasets
    params: {}
- name: session
  endpoint:
    path: /kedro/framework/session
    method: GET
    data_selector: session
    params: {}
- name: shared_data
  endpoint:
    path: /services/data/vXX.X/sobjects/SharedData
    method: GET
    data_selector: records
    params: {}
- name: BaseSessionStore
  endpoint:
    path: /kedro/framework/session/store/BaseSessionStore
    method: GET
    data_selector: session_data
    params: {}
- name: ProjectMetadata
  endpoint:
    path: /api/framework/kedro.framework.startup/ProjectMetadata
    method: GET
- name: ProjectMetadata
  endpoint:
    path: /kedro/framework/startup/ProjectMetadata
    method: GET
    data_selector: metadata
    params: {}
- name: cars
  endpoint:
    path: cars.csv
    method: GET
    data_selector: data
    params: {}
- name: planes
  endpoint:
    path: MemoryDataset
    method: GET
    data_selector: data
    params: {}
- name: datasets
  endpoint:
    path: /datasets
    method: GET
- name: cars
  endpoint:
    path: cars.csv
    method: LOAD
    data_selector: datasets
    params: {}
- name: planes
  endpoint:
    path: planes
    method: SAVE
    data_selector: datasets
    params: {}
- name: DataCatalog
  endpoint:
    path: /api/data/catalog
    method: GET
- name: datasets
  endpoint:
    path: /api/v1/datasets
    method: GET
    data_selector: records
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: catalog
  endpoint:
    path: /to_config
    method: GET
    data_selector: catalog
    params: {}
- name: credentials
  endpoint:
    path: /to_config
    method: GET
    data_selector: credentials
    params: {}
- name: load_versions
  endpoint:
    path: /to_config
    method: GET
    data_selector: load_versions
    params: {}
- name: save_version
  endpoint:
    path: /to_config
    method: GET
    data_selector: save_version
    params: {}
- name: datasets
  endpoint:
    path: /api/datasets
    method: GET
    data_selector: datasets
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: cars
  endpoint:
    path: cars.csv
    method: GET
    data_selector: null
    params: {}
- name: datasets
  endpoint:
    path: /datasets
    method: GET
    data_selector: datasets
    params: {}
- name: example
  endpoint:
    path: /datasets/example
    method: GET
    data_selector: datasets
    params: {}
- name: example
  endpoint:
    path: /datasets/example
    method: GET
    data_selector: records
    params: {}
- name: datasets
  endpoint:
    path: /datasets
    method: GET
    data_selector: records
- name: cars
  endpoint:
    path: cars.csv
    method: GET
    data_selector: records
    params: {}
- name: datasets
  endpoint:
    path: /datasets
    method: GET
    data_selector: records
- name: example
  endpoint:
    path: /example
    method: GET
    data_selector: records
    params: {}
- name: dataset
  endpoint:
    path: /datasets
    method: GET
    data_selector: datasets
    params: {}
- name: dataset_type
  endpoint:
    path: /get_type
    method: GET
    data_selector: str | None
    params:
      ds_name: str
- name: DataCatalog
  endpoint:
    path: /en/stable/api/io/kedro.io.DataCatalog/
    method: GET
    data_selector: datasets
- name: dataset
  endpoint:
    path: /datasets
    method: GET
    data_selector: datasets
    params: {}
- name: dataset_items
  endpoint:
    path: /items
    method: GET
    data_selector: List[tuple[str, AbstractDataset]]
    params: {}
- name: datasets
  endpoint:
    path: /datasets
    method: GET
    data_selector: datasets
    params: {}
- name: example
  endpoint:
    path: /example
    method: GET
    data_selector: records
    params: {}
- name: cars
  endpoint:
    path: cars.csv
    method: GET
    data_selector: records
    params: {}
- name: datasets
  endpoint:
    path: /datasets
    method: GET
    data_selector: datasets
    params: {}
- name: dataset
  endpoint:
    path: /datasets
    method: GET
    data_selector: datasets
    params: {}
- name: example
  endpoint:
    path: ''
    method: ''
    data_selector: ''
    params: {}
- name: datasets
  endpoint:
    path: /datasets
    method: GET
    data_selector: dataset_names
    params: {}
- name: cars
  endpoint:
    path: cars.csv
    method: LOAD
    data_selector: data
    params: {}
- name: _datasets
  endpoint:
    path: __contains__(ds_name)
    method: GET
- name: __getitem__
  endpoint:
    path: __getitem__(ds_name)
    method: GET
- name: __iter__
  endpoint:
    path: __iter__()
    method: GET
- name: __repr__
  endpoint:
    path: __repr__()
    method: GET
- name: __setitem__
  endpoint:
    path: __setitem__(key, value)
    method: POST
- name: confirm
  endpoint:
    path: confirm(name)
    method: POST
- name: exists
  endpoint:
    path: exists(name)
    method: GET
- name: from_config
  endpoint:
    path: from_config(catalog)
    method: POST
- name: get
  endpoint:
    path: get(key, fallback_to_runtime_pattern=False)
    method: GET
- name: items
  endpoint:
    path: items()
    method: GET
- name: keys
  endpoint:
    path: keys()
    method: GET
- name: load
  endpoint:
    path: load(name, version=None)
    method: GET
- name: release
  endpoint:
    path: release(name)
    method: POST
- name: save
  endpoint:
    path: save(name, data)
    method: POST
- name: values
  endpoint:
    path: values()
    method: GET
- name: shared_data
  endpoint:
    path: /datasets/shared_data
    method: POST
    data_selector: data
    params: {}
- name: shared_data
  endpoint:
    path: /shared_data
    method: GET
    data_selector: data
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: shared_data
  endpoint:
    path: /datasets/shared_data
    method: POST
    data_selector: data
    params: {}
- name: shared_data
  endpoint:
    path: /services/data/vXX.X/sobjects/SharedData
    method: GET
    data_selector: records
    params: {}
- name: shared_data
  endpoint:
    path: /validate_catalog
    method: POST
    data_selector: datasets
    params: {}
- name: set_manager_datasets
  endpoint:
    path: set_manager_datasets
    method: None
    data_selector: None
    params: {}
- name: validate_catalog
  endpoint:
    path: validate_catalog
    method: None
    data_selector: None
    params: {}
- name: dataset_configurations
  endpoint:
    path: /catalog/config
    method: GET
    data_selector: resolved_configs
    params: {}
- name: int_{name}
  endpoint:
    path: '{namespace}.int_{name}'
    method: GET
    data_selector: records
- name: companies
  endpoint:
    path: companies.csv
    method: GET
    data_selector: resolved dataset configurations
    params: {}
- name: '{namespace}.int_{name}'
  endpoint:
    path: ''
    method: ''
    data_selector: ''
    params: {}
- name: companies
  endpoint:
    path: companies.csv
    method: GET
    data_selector: records
    params: {}
- name: companies
  endpoint:
    path: companies.csv
    method: GET
    data_selector: records
    params: {}
- name: companies
  endpoint:
    path: companies.csv
    method: GET
    data_selector: ''
    params: {}
- name: companies
  endpoint:
    path: companies.csv
    method: GET
    data_selector: records
    params: {}
- name: companies
  endpoint:
    path: companies.csv
    method: GET
    data_selector: records
- name: companies
  endpoint:
    path: companies.csv
    method: null
    data_selector: null
    params: {}
- name: companies
  endpoint:
    path: '{name}.csv'
    method: GET
    data_selector: records
- name: '{default_example}'
  endpoint:
    method: GET
- name: example_dataset
  endpoint:
    method: GET
- name: '{namespace}.int_{name}'
  endpoint:
    path: None
    method: None
    data_selector: None
    params: {}
- name: companies
  endpoint:
    path: companies
    method: GET
- name: example
  endpoint:
    path: example
    method: GET
- name: '{default_example}'
  endpoint:
    path: example_dataset
    method: GET
    data_selector: records
    params: {}
- name: '{name}'
  endpoint:
    path: example_dataset
    method: GET
    data_selector: records
    params: {}
- name: dataset
  endpoint:
    path: /data
    method: GET
    data_selector: records
- name: dataset_patterns
  endpoint:
    path: /_sort_patterns
    method: POST
    data_selector: Patterns
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: companies
  endpoint:
    path: '{namespace}.int_{name}'
    method: GET
    data_selector: records
    params: {}
- name: example_dataset
  endpoint:
    path: /example_dataset
    method: GET
- name: customers
  endpoint:
    path: /filepath/customers.csv
    method: GET
    data_selector: records
- name: customers
  endpoint:
    path: /customers.csv
    method: GET
    data_selector: records
    params: {}
- name: companies
  endpoint:
    path: companies.csv
    method: GET
    data_selector: records
    params: {}
- name: data.int_customers
  endpoint:
    path: customers.csv
- name: '{namespace}.int_{name}'
  endpoint:
    path: None
    method: None
    data_selector: None
    params:
      None: None
- name: '{name}'
  endpoint:
    path: None
    method: None
    data_selector: None
    params:
      None: None
- name: companies
  endpoint:
    path: '{name}.csv'
    method: GET
    data_selector: records
    params:
      credentials: db_credentials
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
- name: dataset_patterns
  endpoint:
    path: /list_patterns
    method: GET
    data_selector: patterns
    params: {}
- name: dataset_configurations
  endpoint:
    path: /catalog/configurations
    method: GET
    data_selector: configurations
- name: example
  endpoint:
    path: /example/path
    method: GET
    data_selector: data
    params: {}
- name: companies
  endpoint:
    path: None
    method: None
    data_selector: None
    params: {}
- name: example
  endpoint:
    method: GET
- name: example
  endpoint:
    path: '{name}.csv'
    method: GET
    data_selector: records
- name: dataset_name
  endpoint:
    path: /match_runtime_pattern
    method: GET
    data_selector: runtime_patterns
    params: {}
- name: companies
  endpoint:
    path: companies.csv
    method: GET
    data_selector: records
    params: {}
- name: dataset
  endpoint:
    path: /match_runtime_pattern
    method: GET
    data_selector: runtime_patterns
    params: {}
- name: dataset_name
  endpoint:
    path: match_user_catch_all_pattern
    method: GET
    data_selector: first_matching_pattern
    params:
      ds_name: example_dataset
- name: '{namespace}.int_{name}'
  endpoint:
    path: ''
    method: ''
    data_selector: ''
    params: {}
- name: user_defined_catch_all_pattern
  endpoint:
    path: /match_user_catch_all_pattern
    method: GET
    data_selector: pattern
    params: {}
- name: dataset_configuration
  endpoint:
    path: /resolve_pattern
    method: GET
    data_selector: configuration
    params: {}
- name: user_catch_all_pattern
  endpoint:
    path: /match_user_catch_all_pattern
    method: GET
    data_selector: pattern
    params: {}
- name: '{namespace}.int_{name}'
  endpoint:
    path: '{name}.csv'
- name: dataset
  endpoint:
    path: /catalog/dataset
    method: GET
    data_selector: records
- name: my_dataset
  endpoint:
    path: <path-to-my-own-dataset>.MyOwnDataset
    method: ''
    data_selector: ''
    params:
      filepath: data/01_raw/my_data.csv
      param1: <param1-value>
- name: my_dataset
  endpoint:
    path: <path-to-my-own-dataset>.MyOwnDataset
    method: GET
    data_selector: records
    params: {}
- name: my_dataset
  endpoint:
    path: data/01_raw/my_data.csv
    method: GET
    data_selector: records
    params:
      versioned: true
      param1: <param1-value>
- name: my_dataset
  endpoint:
    path: data/01_raw/my_data.csv
    method: GET
    data_selector: null
    params: {}
- name: test_ds
  endpoint:
    path: cached_dataset
    method: POST
    data_selector: dataset
    params:
      version: 'true'
- name: _EPHEMERAL
  endpoint: {}
- name: _copy_mode
  endpoint: {}
- name: _data
  endpoint: {}
- name: metadata
  endpoint: {}
- name: _describe
  endpoint: {}
- name: _exists
  endpoint: {}
- name: _release
  endpoint: {}
- name: load
  endpoint: {}
- name: save
  endpoint: {}
- name: MemoryDataset
  endpoint:
    path: /kedro/io/memory_dataset
    method: GET
    data_selector: data
    params: {}
- name: DatasetAlreadyExistsError
  endpoint:
    path: /api/io/kedro.io.DatasetAlreadyExistsError
    method: GET
    data_selector: records
- name: load_ipython_extension
  endpoint:
    path: /api/ipython/kedro.ipython/load_ipython_extension
    method: GET
- name: magic_load_node
  endpoint:
    path: /api/ipython/kedro.ipython/magic_load_node
    method: GET
- name: magic_reload_kedro
  endpoint:
    path: /api/ipython/kedro.ipython/magic_reload_kedro
    method: GET
- name: reload_kedro
  endpoint:
    path: /api/ipython/kedro.ipython/reload_kedro
    method: GET
- name: load_ipython_extension
  endpoint:
    path: /kedro/ipython/load_ipython_extension
    method: GET
    data_selector: function
    params: {}
- name: magic_reload_kedro
  endpoint:
    path: /api/ipython/kedro.ipython.magic_reload_kedro
    method: GET
- name: reload_kedro
  endpoint:
    path: /reload_kedro
    method: GET
    data_selector: records
    params:
      path: null
      env: null
      runtime_params: null
      local_namespace: null
      conf_source: null
- name: RichHandler
  endpoint:
    path: /api/kedro.logging/RichHandler
    method: GET
    data_selector: records
- name: node
  endpoint:
    path: /en/stable/api/pipeline/kedro.pipeline.node/
    method: GET
- name: Pipeline
  endpoint:
    path: /en/stable/api/pipeline/kedro.pipeline.Pipeline/
    method: GET
- name: GroupNodes
  endpoint:
    path: /en/stable/api/pipeline/kedro.pipeline.node/#kedro.pipeline.node.GroupedNodes
    method: GET
- name: Node
  endpoint:
    path: /en/stable/api/pipeline/kedro.pipeline.node/#kedro.pipeline.node.Node
    method: GET
- name: Node
  endpoint:
    path: /services/data/vXX.X/nodes
    method: GET
    data_selector: records
- name: GroupedNodes
  endpoint:
    path: /services/data/vXX.X/grouped_nodes
    method: GET
    data_selector: records
- name: node
  endpoint:
    path: /api/pipeline/kedro.pipeline.node
    method: GET
    data_selector: node
    params: {}
- name: Pipeline
  endpoint:
    path: /kedro/pipeline
    method: GET
    data_selector: nodes
    params: {}
- name: Pipeline
  endpoint:
    path: /api/pipeline
    method: GET
    data_selector: nodes
    params: {}
- name: from_nodes
  endpoint:
    path: /kedro/pipeline/from_nodes
    method: GET
    data_selector: nodes
    params: {}
- name: _nodes
  endpoint:
    path: /kedro/pipeline/_nodes
    method: GET
    data_selector: tagged_nodes
    params: {}
- name: _nodes_by_input
  endpoint:
    path: /kedro/pipeline/_nodes_by_input
    method: GET
    data_selector: defaultdict(set)
    params: {}
- name: _nodes_by_name
  endpoint:
    path: /kedro/pipeline/_nodes_by_name
    method: GET
    data_selector: '{(name): nodefor node in tagged_nodes}'
    params: {}
- name: _nodes_by_output
  endpoint:
    path: /kedro/pipeline/_nodes_by_output
    method: GET
    data_selector: '{}'
    params: {}
- name: _toposorted_groups
  endpoint:
    path: /kedro/pipeline/_toposorted_groups
    method: GET
    data_selector: '[]'
    params: {}
- name: _toposorted_nodes
  endpoint:
    path: /kedro/pipeline/_toposorted_nodes
    method: GET
    data_selector: '[]'
    params: {}
- name: _toposorter
  endpoint:
    path: /kedro/pipeline/_toposorter
    method: GET
    data_selector: TopologicalSorter(node_dependencies)
    params: {}
- name: grouped_nodes
  endpoint:
    path: /kedro/pipeline/grouped_nodes
    method: GET
    data_selector: list[list[Node]]
    params: {}
- name: node_dependencies
  endpoint:
    path: /kedro/pipeline/node_dependencies
    method: GET
    data_selector: dict[Node, set[Node]]
    params: {}
- name: nodes
  endpoint:
    path: /kedro/pipeline/nodes
    method: GET
    data_selector: list[Node]
    params: {}
- name: AbstractRunner
  endpoint:
    path: /en/stable/api/runner/kedro.runner.AbstractRunner/
    method: GET
- name: SequentialRunner
  endpoint:
    path: /en/stable/api/runner/kedro.runner.SequentialRunner/
    method: GET
- name: ParallelRunner
  endpoint:
    path: /en/stable/api/runner/kedro.runner.ParallelRunner/
    method: GET
- name: ThreadRunner
  endpoint:
    path: /en/stable/api/runner/kedro.runner.ThreadRunner/
    method: GET
- name: _run
  endpoint:
    path: /_run
    method: POST
    data_selector: None
    params: {}
- name: max_workers
  endpoint:
    path: /runner/thread_runner/max_workers
    method: GET
    data_selector: records
    params: {}
- name: is_async
  endpoint:
    path: /runner/thread_runner/is_async
    method: GET
    data_selector: records
    params: {}
- name: _get_executor
  endpoint:
    path: _get_executor
    method: GET
    data_selector: max_workers
    params: {}
- name: _get_required_workers_count
  endpoint:
    path: _get_required_workers_count
    method: GET
    data_selector: pipeline
    params: {}
- name: _run
  endpoint:
    path: _run
    method: GET
    data_selector: pipeline
    params:
      catalog: CatalogProtocol
      hook_manager: PluginManager | None
      run_id: str | None
- name: load_obj
  endpoint:
    path: /kedro.utils/load_obj
    method: GET
    data_selector: parameters
    params: {}
- name: load_ipython_extension
  endpoint:
    path: /kedro.load_ipython_extension
    method: GET
- name: companies
  endpoint:
    path: data/companies.csv
    method: GET
- name: reviews
  endpoint:
    path: data/reviews.csv
    method: GET
- name: shuttles
  endpoint:
    path: data/shuttles.xlsx
    method: GET
- name: mlflow_runs
  endpoint:
    path: /mlflow_runs
    method: GET
    data_selector: records
    params: {}
- name: mlflow_runs
  endpoint:
    path: mlflow_runs
    method: GET
    data_selector: ''
- name: X_test
  endpoint:
    path: data/05_model_input/X_test.parquet
    method: GET
    data_selector: records
- name: y_test
  endpoint:
    path: data/05_model_input/y_test.csv
    method: GET
    data_selector: records
- name: regressor
  endpoint:
    path: kedro_mlflow.io.models.MlflowModelTrackingDataset
    method: POST
    data_selector: records
    params:
      registered_model_name: spaceflights-regressor
- name: regressor
  endpoint:
    path: data/06_models/regressor.pickle
    method: GET
    data_selector: records
    params:
      registered_model_name: spaceflights-regressor
- name: experiment
  endpoint:
    path: /api/2.0/experiments
    method: GET
    data_selector: experiments
    params: {}
- name: model
  endpoint:
    path: /api/2.0/models
    method: GET
    data_selector: models
    params: {}
- name: model_input_table
  endpoint:
    path: data/03_primary/model_input_table
    method: SAVE
    data_selector: records
    params:
      mode: overwrite
- name: model_input_table
  endpoint:
    path: /tmp/warehouse
    method: GET
    data_selector: datasets
    params: {}
- name: project_migration
  endpoint:
    path: /docs/kedro/migration
    method: GET
    data_selector: migration_guide
    params: {}
- name: Kedro API
  endpoint:
    path: /en/stable/api/
    method: GET
    data_selector: records
    params: {}
- name: node
  endpoint:
    path: /kedro/node
    method: GET
    data_selector: nodes
    params: {}
- name: pipeline
  endpoint:
    path: /kedro/pipeline
    method: GET
    data_selector: pipelines
    params: {}
- name: data_catalog
  endpoint:
    path: /kedro/data_catalog
    method: GET
    data_selector: data_sources
    params: {}
- name: api.APIDataset
  endpoint:
    path: /projects/kedro-datasets/en/kedro-datasets-8.1.0/api/kedro_datasets/api.APIDataset/
    method: GET
- name: biosequence.BioSequenceDataset
  endpoint:
    path: /projects/kedro-datasets/en/kedro-datasets-8.1.0/api/kedro_datasets/biosequence.BioSequenceDataset/
    method: GET
- name: dask.CSVDataset
  endpoint:
    path: /projects/kedro-datasets/en/kedro-datasets-8.1.0/api/kedro_datasets/dask.CSVDataset/
    method: GET
- name: dask.ParquetDataset
  endpoint:
    path: /projects/kedro-datasets/en/kedro-datasets-8.1.0/api/kedro_datasets/dask.ParquetDataset/
    method: GET
- name: databricks.ManagedTableDataset
  endpoint:
    path: /projects/kedro-datasets/en/kedro-datasets-8.1.0/api/kedro_datasets/databricks.ManagedTableDataset/
    method: GET
- name: email.EmailMessageDataset
  endpoint:
    path: /projects/kedro-datasets/en/kedro-datasets-8.1.0/api/kedro_datasets/email.EmailMessageDataset/
    method: GET
- name: geopandas.GenericDataset
  endpoint:
    path: /projects/kedro-datasets/en/kedro-datasets-8.1.0/api/kedro_datasets/geopandas.GenericDataset/
    method: GET
- name: huggingface.HFDataset
  endpoint:
    path: /projects/kedro-datasets/en/kedro-datasets-8.1.0/api/kedro_datasets/huggingface.HFDataset/
    method: GET
- name: huggingface.HFTransformerPipelineDataset
  endpoint:
    path: /projects/kedro-datasets/en/kedro-datasets-8.1.0/api/kedro_datasets/huggingface.HFTransformerPipelineDataset/
    method: GET
- name: ibis.FileDataset
  endpoint:
    path: /projects/kedro-datasets/en/kedro-datasets-8.1.0/api/kedro_datasets/ibis.FileDataset/
    method: GET
- name: json.JSONDataset
  endpoint:
    path: /projects/kedro-datasets/en/kedro-datasets-8.1.0/api/kedro_datasets/json.JSONDataset/
    method: GET
- name: pandas.CSVDataset
  endpoint:
    path: /projects/kedro-datasets/en/kedro-datasets-8.1.0/api/kedro_datasets/pandas.CSVDataset/
    method: GET
- name: pandas.ParquetDataset
  endpoint:
    path: /projects/kedro-datasets/en/kedro-datasets-8.1.0/api/kedro_datasets/pandas.ParquetDataset/
    method: GET
- name: text.TextDataset
  endpoint:
    path: /projects/kedro-datasets/en/kedro-datasets-8.1.0/api/kedro_datasets/text.TextDataset/
    method: GET
- name: yaml.YAMLDataset
  endpoint:
    path: /projects/kedro-datasets/en/kedro-datasets-8.1.0/api/kedro_datasets/yaml.YAMLDataset/
    method: GET
- name: api
  endpoint:
    path: /api
    method: GET
    data_selector: data
    params: {}
- name: usda
  endpoint:
    path: https://quickstats.nass.usda.gov
    method: GET
    data_selector: null
    params:
      key: SOME_TOKEN
      format: JSON
      commodity_desc: CORN
      statisticcat_des: YIELD
      agg_level_desc: STATE
      year: 2000
- name: spaceflight
  endpoint:
    path: https://api.spaceflightnewsapi.net/v4/articles
    method: GET
    data_selector: null
    params:
      news_site: NASA
      launch: 65896761-b6ca-4df3-9699-e077a360c52a
- name: dummyjson
  endpoint:
    path: https://dummyjson.com/products/add
    method: POST
    data_selector: null
    params:
      chunk_size: 1
- name: BioSequenceDataset
  endpoint:
    path: ''
    method: ''
    data_selector: ''
    params: {}
- name: cars
  endpoint:
    path: s3://bucket_name/path/to/folder
    method: GET
    data_selector: records
    params: {}
- name: ParquetDataset
  endpoint:
    path: /projects/kedro-datasets/en/kedro-datasets-8.1.0/api/kedro_datasets/dask.ParquetDataset
    method: GET
- name: parquet_dataset
  endpoint:
    path: s3://bucket_name/path/to/folder
    method: LOAD/SAVE
    data_selector: data
    params: {}
- name: ManagedTableDataset
  endpoint:
    path: /api/kedro_datasets/databricks.ManagedTableDataset/
    method: GET
- name: names_and_ages@spark
  endpoint:
    path: names_and_ages
    method: N/A
    data_selector: N/A
    params: {}
- name: names_and_ages@pandas
  endpoint:
    path: names_and_ages
    method: N/A
    data_selector: N/A
    params: {}
- name: EmailMessageDataset
  endpoint:
    path: /api/kedro_datasets/email.EmailMessageDataset
    method: GET
- name: GenericDataset
  endpoint:
    path: /
    method: GET
    data_selector: data
    params: {}
- name: Holoviews
  endpoint:
    path: /services/data/vXX.X/sobjects/Holoviews
    method: POST
    data_selector: records
- name: yelp_reviews
  endpoint:
    path: /datasets/yelp_review_full
    method: GET
    data_selector: records
    params: {}
- name: openai_humaneval
  endpoint:
    path: /datasets/openai_humaneval
    method: GET
    data_selector: records
    params: {}
- name: summarizer_model
  endpoint:
    path: huggingface.HFTransformerPipelineDataset
    method: GET
    data_selector: records
    params:
      task: summarization
- name: fill_mask_model
  endpoint:
    path: huggingface.HFTransformerPipelineDataset
    method: GET
    data_selector: records
    params:
      task: fill-mask
      model_name: Twitter/twhin-bert-base
- name: text_classification_model
  endpoint:
    path: huggingface.HFTransformerPipelineDataset
    method: GET
    data_selector: records
    params:
      task: text-classification
      model_name: prajjwal1/bert-tiny
- name: cars
  endpoint:
    path: data/01_raw/company/cars.csv
    method: LOAD
    data_selector: data
    params: {}
- name: motorbikes
  endpoint:
    path: s3://your_bucket/data/02_intermediate/company/motorbikes/
    method: LOAD
    data_selector: data
    params: {}
- name: TableDataset
  endpoint:
    path: /api/kedro_datasets/ibis.TableDataset
    method: GET
- name: cars
  endpoint:
    path: /services/data/cars
    method: GET
- name: motorbikes
  endpoint:
    path: /services/data/motorbikes
    method: GET
- name: DEFAULT_FS_ARGS
  endpoint:
    path: /projects/kedro-datasets/en/kedro-datasets-8.1.0/api/kedro_datasets/json.JSONDataset/#kedro_datasets.json.JSONDataset.DEFAULT_FS_ARGS
    method: GET
- name: DEFAULT_SAVE_ARGS
  endpoint:
    path: /projects/kedro-datasets/en/kedro-datasets-8.1.0/api/kedro_datasets/json.JSONDataset/#kedro_datasets.json.JSONDataset.DEFAULT_SAVE_ARGS
    method: GET
- name: _fs
  endpoint:
    path: /projects/kedro-datasets/en/kedro-datasets-8.1.0/api/kedro_datasets/json.JSONDataset/#kedro_datasets.json.JSONDataset._fs
    method: GET
- name: _fs_open_args_load
  endpoint:
    path: /projects/kedro-datasets/en/kedro-datasets-8.1.0/api/kedro_datasets/json.JSONDataset/#kedro_datasets.json.JSONDataset._fs_open_args_load
    method: GET
- name: _fs_open_args_save
  endpoint:
    path: /projects/kedro-datasets/en/kedro-datasets-8.1.0/api/kedro_datasets/json.JSONDataset/#kedro_datasets.json.JSONDataset._fs_open_args_save
    method: GET
- name: _protocol
  endpoint:
    path: /projects/kedro-datasets/en/kedro-datasets-8.1.0/api/kedro_datasets/json.JSONDataset/#kedro_datasets.json.JSONDataset._protocol
    method: GET
- name: _save_args
  endpoint:
    path: /projects/kedro-datasets/en/kedro-datasets-8.1.0/api/kedro_datasets/json.JSONDataset/#kedro_datasets.json.JSONDataset._save_args
    method: GET
- name: metadata
  endpoint:
    path: /projects/kedro-datasets/en/kedro-datasets-8.1.0/api/kedro_datasets/json.JSONDataset/#kedro_datasets.json.JSONDataset.metadata
    method: GET
- name: _describe
  endpoint:
    path: /projects/kedro-datasets/en/kedro-datasets-8.1.0/api/kedro_datasets/json.JSONDataset/#kedro_datasets.json.JSONDataset._describe
    method: GET
- name: _exists
  endpoint:
    path: /projects/kedro-datasets/en/kedro-datasets-8.1.0/api/kedro_datasets/json.JSONDataset/#kedro_datasets.json.JSONDataset._exists
    method: GET
- name: _invalidate_cache
  endpoint:
    path: /projects/kedro-datasets/en/kedro-datasets-8.1.0/api/kedro_datasets/json.JSONDataset/#kedro_datasets.json.JSONDataset._invalidate_cache
    method: GET
- name: _release
  endpoint:
    path: /projects/kedro-datasets/en/kedro-datasets-8.1.0/api/kedro_datasets/json.JSONDataset/#kedro_datasets.json.JSONDataset._release
    method: GET
- name: load
  endpoint:
    path: /projects/kedro-datasets/en/kedro-datasets-8.1.0/api/kedro_datasets/json.JSONDataset/#kedro_datasets.json.JSONDataset.load
    method: GET
- name: preview
  endpoint:
    path: /projects/kedro-datasets/en/kedro-datasets-8.1.0/api/kedro_datasets/json.JSONDataset/#kedro_datasets.json.JSONDataset.preview
    method: GET
- name: save
  endpoint:
    path: /projects/kedro-datasets/en/kedro-datasets-8.1.0/api/kedro_datasets/json.JSONDataset/#kedro_datasets.json.JSONDataset.save
    method: GET
- name: cars
  endpoint:
    path: gcs://your_bucket/cars.json
    method: GET
    data_selector: null
    params: {}
- name: cars
  endpoint:
    path: gcs://your_bucket/cars.mat
    method: save
    data_selector: data
    params: {}
- name: metadata
  endpoint:
    path: /api/kedro_datasets/matplotlib.MatplotlibDataset/metadata
    method: GET
- name: output_plot
  endpoint:
    path: data/08_reporting/output_plot.png
    method: save
    data_selector: records
    params: {}
- name: pdf_plot
  endpoint:
    path: data/08_reporting/output_plot.pdf
    method: save
    data_selector: records
    params:
      save_args:
        format: pdf
- name: dict_plot
  endpoint:
    path: data/08_reporting/plots
    method: save
    data_selector: records
    params: {}
- name: GMLDataset
  endpoint:
    path: /
    method: GET
    data_selector: records
    params: {}
- name: GraphMLDataset
  endpoint:
    path: /api/kedro_datasets/networkx.GraphMLDataset
    method: GET
    data_selector: records
- name: JSONDataset
  endpoint:
    path: /path/to/json
    method: GET
    data_selector: records
    params: {}
- name: docx_file
  endpoint:
    path: null
    method: null
    data_selector: null
    params:
      filepath: soya.docx
- name: cars
  endpoint:
    path: data/01_raw/company/cars.csv
    method: GET
    data_selector: records
    params: {}
- name: motorbikes
  endpoint:
    path: s3://your_bucket/data/02_intermediate/company/motorbikes.csv
    method: GET
    data_selector: records
    params:
      credentials: dev_s3
- name: DeltaTableDataset
  endpoint:
    path: /api/kedro_datasets/pandas.DeltaTableDataset
    method: GET
    data_selector: records
    params: {}
- name: boats_filesystem
  endpoint:
    path: data/01_raw/boats
    method: GET
    data_selector: records
    params:
      load_args:
        version: 7
      save_args:
        mode: overwrite
- name: boats_databricks_unity_catalog
  endpoint:
    path: data/01_raw/boats
    method: GET
    data_selector: records
    params:
      catalog_type: UNITY
      database: simple_database
      table: simple_table
      save_args:
        mode: overwrite
- name: trucks_aws_glue_catalog
  endpoint:
    path: data/01_raw/trucks
    method: GET
    data_selector: records
    params:
      catalog_type: AWS
      catalog_name: main
      database: db_schema
      table: db_table
      save_args:
        mode: overwrite
- name: DeltaTable
  endpoint:
    path: /kedro-datasets/pandas/DeltaTableDataset
    method: save
    data_selector: data
    params: {}
- name: rockets
  endpoint:
    path: gcs://your_bucket/rockets.xlsx
    method: GET
    data_selector: null
    params: {}
- name: shuttles
  endpoint:
    path: data/01_raw/shuttles.xlsx
    method: GET
    data_selector: null
    params: {}
- name: trains
  endpoint:
    path: data/02_intermediate/company/trains.xlsx
    method: GET
    data_selector: null
    params: {}
- name: preview
  endpoint:
    path: /preview
    method: GET
    data_selector: dict
    params:
      nrows: '5'
- name: save
  endpoint:
    path: /save
    method: POST
    data_selector: none
    params: {}
- name: cars
  endpoint:
    path: data/01_raw/company/cars.feather
    method: GET
    data_selector: records
    params:
      load_args:
        columns:
        - col1
        - col2
        - col3
        use_threads: true
- name: motorbikes
  endpoint:
    path: s3://your_bucket/data/02_intermediate/company/motorbikes.feather
    method: GET
    data_selector: records
    params:
      credentials: dev_s3
- name: vehicles
  endpoint:
    path: ''
    method: ''
    data_selector: ''
    params:
      sql: select shuttle, shuttle_id from spaceflights.shuttles;
- name: dataset_1
  endpoint:
    path: ''
    method: ''
    data_selector: ''
    params:
      sql: SELECT * FROM dataset_1.table_a
- name: vehicles
  endpoint:
    path: big_query_dataset/big_query_table
    method: GET
    data_selector: records
    params: {}
- name: DEFAULT_FS_ARGS
  endpoint:
    path: /api/kedro_datasets/pandas.GenericDataset/#kedro_datasets.pandas.GenericDataset.DEFAULT_FS_ARGS
    method: GET
- name: DEFAULT_LOAD_ARGS
  endpoint:
    path: /api/kedro_datasets/pandas.GenericDataset/#kedro_datasets.pandas.GenericDataset.DEFAULT_LOAD_ARGS
    method: GET
- name: DEFAULT_SAVE_ARGS
  endpoint:
    path: /api/kedro_datasets/pandas.GenericDataset/#kedro_datasets.pandas.GenericDataset.DEFAULT_SAVE_ARGS
    method: GET
- name: _file_format
  endpoint:
    path: /api/kedro_datasets/pandas.GenericDataset/#kedro_datasets.pandas.GenericDataset._file_format
    method: GET
- name: _fs
  endpoint:
    path: /api/kedro_datasets/pandas.GenericDataset/#kedro_datasets.pandas.GenericDataset._fs
    method: GET
- name: _fs_open_args_load
  endpoint:
    path: /api/kedro_datasets/pandas.GenericDataset/#kedro_datasets.pandas.GenericDataset._fs_open_args_load
    method: GET
- name: _fs_open_args_save
  endpoint:
    path: /api/kedro_datasets/pandas.GenericDataset/#kedro_datasets.pandas.GenericDataset._fs_open_args_save
    method: GET
- name: _load_args
  endpoint:
    path: /api/kedro_datasets/pandas.GenericDataset/#kedro_datasets.pandas.GenericDataset._load_args
    method: GET
- name: _protocol
  endpoint:
    path: /api/kedro_datasets/pandas.GenericDataset/#kedro_datasets.pandas.GenericDataset._protocol
    method: GET
- name: _save_args
  endpoint:
    path: /api/kedro_datasets/pandas.GenericDataset/#kedro_datasets.pandas.GenericDataset._save_args
    method: GET
- name: metadata
  endpoint:
    path: /api/kedro_datasets/pandas.GenericDataset/#kedro_datasets.pandas.GenericDataset.metadata
    method: GET
- name: _describe
  endpoint:
    path: /api/kedro_datasets/pandas.GenericDataset/#kedro_datasets.pandas.GenericDataset._describe
    method: GET
- name: _ensure_file_system_target
  endpoint:
    path: /api/kedro_datasets/pandas.GenericDataset/#kedro_datasets.pandas.GenericDataset._ensure_file_system_target
    method: GET
- name: _exists
  endpoint:
    path: /api/kedro_datasets/pandas.GenericDataset/#kedro_datasets.pandas.GenericDataset._exists
    method: GET
- name: _invalidate_cache
  endpoint:
    path: /api/kedro_datasets/pandas.GenericDataset/#kedro_datasets.pandas.GenericDataset._invalidate_cache
    method: GET
- name: _release
  endpoint:
    path: /api/kedro_datasets/pandas.GenericDataset/#kedro_datasets.pandas.GenericDataset._release
    method: GET
- name: load
  endpoint:
    path: /api/kedro_datasets/pandas.GenericDataset/#kedro_datasets.pandas.GenericDataset.load
    method: GET
- name: save
  endpoint:
    path: /api/kedro_datasets/pandas.GenericDataset/#kedro_datasets.pandas.GenericDataset.save
    method: GET
- name: cars
  endpoint:
    path: data/01_raw/company/cars.csv
    method: GET
    data_selector: records
    params:
      load_args:
        sep: ','
        na_values:
        - '#NA'
        - NA
      save_args:
        index: false
        date_format: '%Y-%m-%d'
- name: flights
  endpoint:
    path: data/01_raw/airplanes.sas7bdat
    method: GET
    data_selector: records
    params:
      load_args:
        format: sas7bdat
- name: save
  endpoint:
    path: /save
    method: POST
    data_selector: data
    params: {}
- name: hdf_dataset
  endpoint:
    path: null
    method: null
    data_selector: null
    params:
      filepath: s3://my_bucket/raw/sensor_reading.h5
      credentials: aws_s3_creds
      key: data
- name: JSONDataset
  endpoint:
    path: /api/kedro_datasets/pandas.JSONDataset/
    method: GET
- name: clickstream_dataset
  endpoint:
    path: abfs://landing_area/primary/click_stream.json
    method: GET
    data_selector: records
    params: {}
- name: json_dataset
  endpoint:
    path: data/01_raw/Video_Games.json
    method: GET
    data_selector: records
    params: {}
- name: boats
  endpoint:
    path: data/01_raw/boats.parquet
    method: LOAD
    data_selector: data
    params: {}
- name: trucks
  endpoint:
    path: abfs://container/02_intermediate/trucks.parquet
    method: LOAD
    data_selector: data
    params:
      columns:
      - name
      - gear
      - disp
      - wt
      index: name
- name: SQLQueryDataset
  endpoint:
    path: /api/kedro_datasets/pandas.SQLQueryDataset
    method: GET
- name: shuttle_id_dataset
  endpoint:
    path: ''
    method: ''
    data_selector: ''
    params: {}
- name: mssql_dataset
  endpoint:
    path: ''
    method: ''
    data_selector: ''
    params: {}
- name: load
  endpoint:
    path: load
    method: GET
    data_selector: pd.DataFrame
- name: save
  endpoint:
    path: save
    method: POST
    data_selector: None
- name: SQLTableDataset
  endpoint:
    path: /projects/kedro-datasets/en/kedro-datasets-8.1.0/api/kedro_datasets/pandas.SQLTableDataset/
    method: GET
- name: XMLDataset
  endpoint:
    path: /
    method: GET
    data_selector: data
    params: {}
- name: IncrementalDataset
  endpoint:
    path: /api/kedro_datasets/partitions/IncrementalDataset
    method: GET
- name: IncrementalDataset
  endpoint:
    path: /api/kedro_datasets/partitions.IncrementalDataset
    method: GET
    data_selector: records
- name: IncrementalDataset
  endpoint:
    path: /services/data/vXX.X/sobjects/IncrementalDataset
    method: GET
    data_selector: records
    params: {}
- name: station_data
  endpoint:
    path: data/03_primary/station_data
    dataset:
      type: pandas.CSVDataset
      load_args:
        sep: "\t"
      save_args:
        sep: "\t"
        index: true
      filename_suffix: .dat
      save_lazily: true
- name: s3_bucket
  endpoint:
    path: s3://bucket-name/path/to/folder
    dataset:
      type: pandas.CSVDataset
      credentials:
        key1: secret1
        key2: secret2
- name: _invalidate_caches
  endpoint:
    path: _invalidate_caches
    method: GET
- name: _join_protocol
  endpoint:
    path: _join_protocol
    method: GET
- name: _list_partitions
  endpoint:
    path: _list_partitions
    method: GET
- name: _partition_to_path
  endpoint:
    path: _partition_to_path
    method: GET
- name: _path_to_partition
  endpoint:
    path: _path_to_partition
    method: GET
- name: _release
  endpoint:
    path: _release
    method: GET
- name: load
  endpoint:
    path: load
    method: GET
- name: save
  endpoint:
    path: save
    method: POST
- name: DEFAULT_FS_ARGS
  endpoint:
    path: /api/kedro_datasets/pickle.PickleDataset/DEFAULT_FS_ARGS
    method: GET
- name: DEFAULT_LOAD_ARGS
  endpoint:
    path: /api/kedro_datasets/pickle.PickleDataset/DEFAULT_LOAD_ARGS
    method: GET
- name: DEFAULT_SAVE_ARGS
  endpoint:
    path: /api/kedro_datasets/pickle.PickleDataset/DEFAULT_SAVE_ARGS
    method: GET
- name: test_model
  endpoint:
    path: data/07_model_output/test_model.pkl
    method: ''
    data_selector: ''
    params: {}
- name: final_model
  endpoint:
    path: s3://your_bucket/final_model.pkl.lz4
    method: ''
    data_selector: ''
    params:
      credentials: s3_credentials
      save_args:
        compress: lz4
- name: load
  endpoint:
    path: load
    method: GET
    data_selector: Any
- name: save
  endpoint:
    path: save
    method: POST
    data_selector: None
- name: Image
  endpoint:
    path: https://storage.googleapis.com/gtv-videos-bucket/sample/images/ForBiggerBlazes.jpg
    method: GET
    data_selector: image
    params: {}
- name: scatter_plot
  endpoint:
    path: data/08_reporting/scatter_plot.html
    method: SAVE
    data_selector: Figure
    params: {}
- name: plotly.JSONDataset
  endpoint:
    path: /api/kedro_datasets/plotly.JSONDataset
    method: GET
- name: scatter_plot
  endpoint:
    path: data/08_reporting/scatter_plot.json
    method: save
    data_selector: data
    params: {}
- name: test_json
  endpoint:
    path: tmp_path / test.json
    method: load
    data_selector: data
    params: {}
- name: bar_plot
  endpoint:
    path: data/08_reporting/bar_plot.json
    method: POST
    data_selector: plot
    params: {}
- name: scatter_plot
  endpoint:
    path: tmp_path/scatter_plot.json
    method: POST
    data_selector: plot
    params: {}
- name: CSVDataset
  endpoint:
    path: /api/kedro_datasets/polars.CSVDataset
    method: GET
- name: cars
  endpoint:
    path: data/01_raw/company/cars.csv
    method: null
    data_selector: null
    params:
      load_args:
        sep: ','
        parse_dates: false
      save_args:
        has_header: false
        null_value: somenullstring
- name: motorbikes
  endpoint:
    path: s3://your_bucket/data/02_intermediate/company/motorbikes.csv
    method: null
    data_selector: null
    params:
      credentials: dev_s3
- name: EagerPolarsDataset
  endpoint:
    path: /api/kedro_datasets/polars.EagerPolarsDataset
    method: GET
    data_selector: records
- name: cars
  endpoint:
    path: s3://data/01_raw/company/cars.parquet
    method: EagerPolarsDataset
    data_selector: null
    params:
      file_format: parquet
      load_args:
        low_memory: true
      save_args:
        compression: snappy
- name: LazyPolarsDataset
  endpoint:
    path: /projects/kedro-datasets/en/kedro-datasets-8.1.0/api/kedro_datasets/polars.LazyPolarsDataset
    method: GET
- name: LazyPolarsDataset
  endpoint:
    path: /api/kedro_datasets/polars.LazyPolarsDataset
    method: GET
- name: cars
  endpoint:
    path: data/01_raw/company/cars.csv
    method: LOAD
    data_selector: records
    params:
      load_args:
        sep: ','
        parse_dates: false
      save_args:
        has_header: false
        null_value: somenullstring
- name: motorbikes
  endpoint:
    path: s3://your_bucket/data/02_intermediate/company/motorbikes.csv
    method: LOAD
    data_selector: records
    params:
      credentials: dev_s3
- name: LazyPolarsDataset
  endpoint:
    path: /kedro_datasets/polars/LazyPolarsDataset
    method: GET
    data_selector: data
    params: {}
- name: PickleDataset
  endpoint:
    path: /api/kedro_datasets/redis.PickleDataset
    method: GET
- name: PickleDataset
  endpoint:
    path: /projects/kedro-datasets/en/kedro-datasets-8.1.0/api/kedro_datasets/redis.PickleDataset/
    method: GET
    data_selector: metadata
- name: my_python_object
  endpoint:
    path: /
    method: GET
    data_selector: records
    params: {}
- name: final_python_object
  endpoint:
    path: /
    method: GET
    data_selector: records
    params: {}
- name: _connection_parameters
  endpoint:
    path: /api/snowflake/connection_parameters
    method: GET
    data_selector: data
    params: {}
- name: _database
  endpoint:
    path: /api/snowflake/database
    method: GET
    data_selector: data
    params: {}
- name: _schema
  endpoint:
    path: /api/snowflake/schema
    method: GET
    data_selector: data
    params: {}
- name: _table_name
  endpoint:
    path: /api/snowflake/table_name
    method: GET
    data_selector: data
    params: {}
- name: weather
  endpoint:
    path: /services/data/weather_data
    method: GET
    data_selector: records
    params: {}
- name: polygons
  endpoint:
    path: /services/data/geopolygons
    method: GET
    data_selector: records
    params: {}
- name: save
  endpoint:
    path: /save
    method: POST
    data_selector: data
    params: {}
- name: DeltaTable
  endpoint:
    path: /api/kedro_datasets/spark.DeltaTableDataset/
    method: GET
- name: weather
  endpoint:
    path: data/02_intermediate/data.parquet
    method: GET
    data_selector: records
    params: {}
- name: my_gbq_spark_data
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params: {}
- name: weather
  endpoint:
    path: s3a://your_bucket/data/01_raw/weather/*
    method: GET
    data_selector: records
    params: {}
- name: weather_with_schema
  endpoint:
    path: s3a://your_bucket/data/01_raw/weather/*
    method: GET
    data_selector: records
    params: {}
- name: weather_cleaned
  endpoint:
    path: data/02_intermediate/data.parquet
    method: GET
    data_selector: records
    params: {}
- name: DEFAULT_SAVE_ARGS
  endpoint:
    path: /projects/kedro-datasets/en/kedro-datasets-8.1.0/api/kedro_datasets/spark.SparkHiveDataset/#kedro_datasets.spark.SparkHiveDataset.DEFAULT_SAVE_ARGS
- name: _database
  endpoint:
    path: /projects/kedro-datasets/en/kedro-datasets-8.1.0/api/kedro_datasets/spark.SparkHiveDataset/#kedro_datasets.spark.SparkHiveDataset._database
- name: _eager_checkpoint
  endpoint:
    path: /projects/kedro-datasets/en/kedro-datasets-8.1.0/api/kedro_datasets/spark.SparkHiveDataset/#kedro_datasets.spark.SparkHiveDataset._eager_checkpoint
- name: _format
  endpoint:
    path: /projects/kedro-datasets/en/kedro-datasets-8.1.0/api/kedro_datasets/spark.SparkHiveDataset/#kedro_datasets.spark.SparkHiveDataset._format
- name: _full_table_address
  endpoint:
    path: /projects/kedro-datasets/en/kedro-datasets-8.1.0/api/kedro_datasets/spark.SparkHiveDataset/#kedro_datasets.spark.SparkHiveDataset._full_table_address
- name: _save_args
  endpoint:
    path: /projects/kedro-datasets/en/kedro-datasets-8.1.0/api/kedro_datasets/spark.SparkHiveDataset/#kedro_datasets.spark.SparkHiveDataset._save_args
- name: _table
  endpoint:
    path: /projects/kedro-datasets/en/kedro-datasets-8.1.0/api/kedro_datasets/spark.SparkHiveDataset/#kedro_datasets.spark.SparkHiveDataset._table
- name: _table_pk
  endpoint:
    path: /projects/kedro-datasets/en/kedro-datasets-8.1.0/api/kedro_datasets/spark.SparkHiveDataset/#kedro_datasets.spark.SparkHiveDataset._table_pk
- name: _write_mode
  endpoint:
    path: /projects/kedro-datasets/en/kedro-datasets-8.1.0/api/kedro_datasets/spark.SparkHiveDataset/#kedro_datasets.spark.SparkHiveDataset._write_mode
- name: metadata
  endpoint:
    path: /projects/kedro-datasets/en/kedro-datasets-8.1.0/api/kedro_datasets/spark.SparkHiveDataset/#kedro_datasets.spark.SparkHiveDataset.metadata
- name: __getstate__
  endpoint:
    path: /projects/kedro-datasets/en/kedro-datasets-8.1.0/api/kedro_datasets/spark.SparkHiveDataset/#kedro_datasets.spark.SparkHiveDataset.__getstate__
- name: _create_hive_table
  endpoint:
    path: /projects/kedro-datasets/en/kedro-datasets-8.1.0/api/kedro_datasets/spark.SparkHiveDataset/#kedro_datasets.spark.SparkHiveDataset._create_hive_table
- name: _describe
  endpoint:
    path: /projects/kedro-datasets/en/kedro-datasets-8.1.0/api/kedro_datasets/spark.SparkHiveDataset/#kedro_datasets.spark.SparkHiveDataset._describe
- name: _exists
  endpoint:
    path: /projects/kedro-datasets/en/kedro-datasets-8.1.0/api/kedro_datasets/spark.SparkHiveDataset/#kedro_datasets.spark.SparkHiveDataset._exists
- name: _upsert_save
  endpoint:
    path: /projects/kedro-datasets/en/kedro-datasets-8.1.0/api/kedro_datasets/spark.SparkHiveDataset/#kedro_datasets.spark.SparkHiveDataset._upsert_save
- name: _validate_save
  endpoint:
    path: /projects/kedro-datasets/en/kedro-datasets-8.1.0/api/kedro_datasets/spark.SparkHiveDataset/#kedro_datasets.spark.SparkHiveDataset._validate_save
- name: load
  endpoint:
    path: /projects/kedro-datasets/en/kedro-datasets-8.1.0/api/kedro_datasets/spark.SparkHiveDataset/#kedro_datasets.spark.SparkHiveDataset.load
- name: save
  endpoint:
    path: /projects/kedro-datasets/en/kedro-datasets-8.1.0/api/kedro_datasets/spark.SparkHiveDataset/#kedro_datasets.spark.SparkHiveDataset.save
- name: hive_dataset
  endpoint:
    path: /hive/hive_dataset
    method: POST
    data_selector: data
    params:
      database: hive_database
      table: table_name
      write_mode: overwrite
- name: SparkJDBCDataset
  endpoint:
    path: /projects/kedro-datasets/en/kedro-datasets-8.1.0/api/kedro_datasets/spark.SparkJDBCDataset/
    method: GET
- name: DEFAULT_LOAD_ARGS
  endpoint:
    path: /projects/kedro-datasets/en/kedro-datasets-8.1.0/api/kedro_datasets/spark.SparkJDBCDataset/#kedro_datasets.spark.SparkJDBCDataset.DEFAULT_LOAD_ARGS
    method: GET
- name: DEFAULT_SAVE_ARGS
  endpoint:
    path: /projects/kedro-datasets/en/kedro-datasets-8.1.0/api/kedro_datasets/spark.SparkJDBCDataset/#kedro_datasets.spark.SparkJDBCDataset.DEFAULT_SAVE_ARGS
    method: GET
- name: _load_args
  endpoint:
    path: /projects/kedro-datasets/en/kedro-datasets-8.1.0/api/kedro_datasets/spark.SparkJDBCDataset/#kedro_datasets.spark.SparkJDBCDataset._load_args
    method: GET
- name: _save_args
  endpoint:
    path: /projects/kedro-datasets/en/kedro-datasets-8.1.0/api/kedro_datasets/spark.SparkJDBCDataset/#kedro_datasets.spark.SparkJDBCDataset._save_args
    method: GET
- name: _table
  endpoint:
    path: /projects/kedro-datasets/en/kedro-datasets-8.1.0/api/kedro_datasets/spark.SparkJDBCDataset/#kedro_datasets.spark.SparkJDBCDataset._table
    method: GET
- name: _url
  endpoint:
    path: /projects/kedro-datasets/en/kedro-datasets-8.1.0/api/kedro_datasets/spark.SparkJDBCDataset/#kedro_datasets.spark.SparkJDBCDataset._url
    method: GET
- name: metadata
  endpoint:
    path: /projects/kedro-datasets/en/kedro-datasets-8.1.0/api/kedro_datasets/spark.SparkJDBCDataset/#kedro_datasets.spark.SparkJDBCDataset.metadata
    method: GET
- name: _describe
  endpoint:
    path: /projects/kedro-datasets/en/kedro-datasets-8.1.0/api/kedro_datasets/spark.SparkJDBCDataset/#kedro_datasets.spark.SparkJDBCDataset._describe
    method: GET
- name: load
  endpoint:
    path: /projects/kedro-datasets/en/kedro-datasets-8.1.0/api/kedro_datasets/spark.SparkJDBCDataset/#kedro_datasets.spark.SparkJDBCDataset.load
    method: GET
- name: save
  endpoint:
    path: /projects/kedro-datasets/en/kedro-datasets-8.1.0/api/kedro_datasets/spark.SparkJDBCDataset/#kedro_datasets.spark.SparkJDBCDataset.save
    method: GET
- name: weather
  endpoint:
    path: weather_table
    method: LOAD
    data_selector: data
    params: {}
- name: table_a
  endpoint:
    path: table_a
    method: SAVE
    data_selector: data
    params: {}
- name: load_args
  endpoint:
    path: /projects/kedro-datasets/en/kedro-datasets-8.1.0/api/kedro_datasets/spark.SparkStreamingDataset/load
    method: GET
- name: save_args
  endpoint:
    path: /projects/kedro-datasets/en/kedro-datasets-8.1.0/api/kedro_datasets/spark.SparkStreamingDataset/save
    method: GET
- name: new_inventory
  endpoint:
    path: data/01_raw/stream/inventory/
    method: GET
    data_selector: ''
    params: {}
- name: svm_dataset
  endpoint:
    path: data/01_raw/location.svm
    method: GET
    data_selector: records
    params: {}
- name: cars
  endpoint:
    path: gcs://your_bucket/cars.svm
    method: GET
    data_selector: records
    params:
      project: my-project
- name: tensorflow_model
  endpoint:
    path: data/06_models/tensorflow_model.h5
    method: save
    data_selector: null
    params: {}
- name: alice_book
  endpoint:
    path: data/01_raw/alice.txt
    method: null
    data_selector: null
    params: {}
- name: DEFAULT_FS_ARGS
  endpoint:
    path: /projects/kedro-datasets/en/kedro-datasets-8.1.0/api/kedro_datasets/yaml.YAMLDataset/DEFAULT_FS_ARGS
    method: GET
- name: DEFAULT_SAVE_ARGS
  endpoint:
    path: /projects/kedro-datasets/en/kedro-datasets-8.1.0/api/kedro_datasets/yaml.YAMLDataset/DEFAULT_SAVE_ARGS
    method: GET
- name: _fs
  endpoint:
    path: /projects/kedro-datasets/en/kedro-datasets-8.1.0/api/kedro_datasets/yaml.YAMLDataset/_fs
    method: GET
- name: _fs_open_args_load
  endpoint:
    path: /projects/kedro-datasets/en/kedro-datasets-8.1.0/api/kedro_datasets/yaml.YAMLDataset/_fs_open_args_load
    method: GET
- name: _fs_open_args_save
  endpoint:
    path: /projects/kedro-datasets/en/kedro-datasets-8.1.0/api/kedro_datasets/yaml.YAMLDataset/_fs_open_args_save
    method: GET
- name: _protocol
  endpoint:
    path: /projects/kedro-datasets/en/kedro-datasets-8.1.0/api/kedro_datasets/yaml.YAMLDataset/_protocol
    method: GET
- name: _save_args
  endpoint:
    path: /projects/kedro-datasets/en/kedro-datasets-8.1.0/api/kedro_datasets/yaml.YAMLDataset/_save_args
    method: GET
- name: metadata
  endpoint:
    path: /projects/kedro-datasets/en/kedro-datasets-8.1.0/api/kedro_datasets/yaml.YAMLDataset/metadata
    method: GET
- name: _describe
  endpoint:
    path: /projects/kedro-datasets/en/kedro-datasets-8.1.0/api/kedro_datasets/yaml.YAMLDataset/_describe
    method: GET
- name: _exists
  endpoint:
    path: /projects/kedro-datasets/en/kedro-datasets-8.1.0/api/kedro_datasets/yaml.YAMLDataset/_exists
    method: GET
- name: _invalidate_cache
  endpoint:
    path: /projects/kedro-datasets/en/kedro-datasets-8.1.0/api/kedro_datasets/yaml.YAMLDataset/_invalidate_cache
    method: GET
- name: _release
  endpoint:
    path: /projects/kedro-datasets/en/kedro-datasets-8.1.0/api/kedro_datasets/yaml.YAMLDataset/_release
    method: GET
- name: load
  endpoint:
    path: /projects/kedro-datasets/en/kedro-datasets-8.1.0/api/kedro_datasets/yaml.YAMLDataset/load
    method: GET
- name: preview
  endpoint:
    path: /projects/kedro-datasets/en/kedro-datasets-8.1.0/api/kedro_datasets/yaml.YAMLDataset/preview
    method: GET
- name: save
  endpoint:
    path: /projects/kedro-datasets/en/kedro-datasets-8.1.0/api/kedro_datasets/yaml.YAMLDataset/save
    method: GET
- name: cars
  endpoint:
    path: cars.yaml
    method: GET
- name: databricks.ExternalTableDataset
  endpoint: {}
- name: langchain.ChatAnthropicDataset
  endpoint: {}
- name: langchain.ChatCohereDataset
  endpoint: {}
- name: langchain.ChatOpenAIDataset
  endpoint: {}
- name: langchain.OpenAIEmbeddingsDataset
  endpoint: {}
- name: netcdf.NetCDFDataset
  endpoint: {}
- name: polars.PolarsDatabaseDataset
  endpoint: {}
- name: prophet.ProphetModelDataset
  endpoint: {}
- name: pytorch.PyTorchDataset
  endpoint: {}
- name: rioxarray.GeoTIFFDataset
  endpoint: {}
- name: safetensors.SafetensorsDataset
  endpoint: {}
- name: video.VideoDataset
  endpoint: {}
- name: names_and_ages
  endpoint:
    path: /services/data/vXX.X/sobjects/names_and_ages
    method: GET
    data_selector: records
- name: claude_instant_1
  endpoint:
    path: /model
    method: POST
    data_selector: response
    params: {}
- name: claude_instant_1
  endpoint:
    path: /model/claude-instant-1
    method: POST
    data_selector: response
    params: {}
- name: cohere_api_key
  endpoint:
    path: /cohere_api_key
    method: GET
- name: cohere_api_url
  endpoint:
    path: /cohere_api_url
    method: GET
- name: command
  endpoint:
    path: /command
    method: POST
    data_selector: response
    params: {}
- name: cohere_api_key
  endpoint:
    path: /cohere_api_key
    method: GET
- name: cohere_api_url
  endpoint:
    path: /cohere_api_url
    method: GET
- name: command
  endpoint:
    path: /cohere-api/command
    method: POST
    data_selector: response
- name: gpt_3_5_turbo
  endpoint:
    path: /
    method: GET
    data_selector: ''
    params: {}
- name: text_embedding_ada_002
  endpoint:
    path: <openai-api-base>
    method: GET
    data_selector: records
    params: {}
- name: single-file
  endpoint:
    path: s3://bucket_name/path/to/folder/data.nc
    method: GET
    data_selector: records
    params: {}
- name: multi-file
  endpoint:
    path: s3://bucket_name/path/to/folder/data*.nc
    method: GET
    data_selector: records
    params: {}
- name: shuttle_id_dataset
  endpoint:
    path: sql
    method: GET
    data_selector: null
    params:
      sql: select shuttle, shuttle_id from spaceflights.shuttles;
- name: model
  endpoint:
    path: gcs://your_bucket/model.json
    method: save
    data_selector: data
    params: {}
- name: model
  endpoint:
    path: data/06_models/model.pt
    method: save
    data_selector: null
    params: {}
- name: model
  endpoint:
    path: data/06_models/model.pt
    method: SAVE
    data_selector: null
    params: {}
- name: load_args
  endpoint:
    path: ''
    method: ''
    data_selector: ''
    params: {}
- name: save_args
  endpoint:
    path: ''
    method: ''
    data_selector: ''
    params: {}
- name: GeoTIFFDataset
  endpoint:
    path: /api/kedro_datasets_experimental/rioxarray.GeoTIFFDataset
    method: GET
- name: sentinal_data
  endpoint:
    path: sentinal_data.tif
    method: GET
    data_selector: data
    params: {}
- name: safetensors
  endpoint:
    path: data/07_model_output/test_model.safetensors
    method: GET
- name: cars
  endpoint:
    path: data/01_raw/cars.mp4
    method: GET
    data_selector: records
    params: {}
- name: motorbikes
  endpoint:
    path: s3://your_bucket/data/02_intermediate/company/motorbikes.mp4
    method: GET
    data_selector: records
    params:
      credentials: dev_s3
- name: NetCDF
  endpoint:
    path: /datasets/netcdf
    method: GET
    data_selector: records
- name: APIDataset
  endpoint:
    path: kedro_datasets/api/APIDataset
    method: GET
- name: BioSequenceDataset
  endpoint:
    path: kedro_datasets/biosequence/BioSequenceDataset
    method: GET
- name: ParquetDataset
  endpoint:
    path: kedro_datasets/dask/ParquetDataset
    method: GET
- name: ManagedTableDataset
  endpoint:
    path: kedro_datasets/databricks/ManagedTableDataset
    method: GET
- name: EmailMessageDataset
  endpoint:
    path: kedro_datasets/email/EmailMessageDataset
    method: GET
- name: GeoJSONDataset
  endpoint:
    path: kedro_datasets/geopandas/GeoJSONDataset
    method: GET
- name: HoloviewsWriter
  endpoint:
    path: kedro_datasets/holoviews/HoloviewsWriter
    method: GET
- name: HFDataset
  endpoint:
    path: kedro_datasets/huggingface/HFDataset
    method: GET
- name: HFTransformerPipelineDataset
  endpoint:
    path: kedro_datasets/huggingface/HFTransformerPipelineDataset
    method: GET
- name: JSONDataset
  endpoint:
    path: kedro_datasets/json/JSONDataset
    method: GET
- name: MatlabDataset
  endpoint:
    path: kedro_datasets/matlab/MatlabDataset
    method: GET
- name: MatplotlibWriter
  endpoint:
    path: kedro_datasets/matplotlib/MatplotlibWriter
    method: GET
- name: NetCDFDataset
  endpoint:
    path: kedro_datasets/netcdf/NetCDFDataset
    method: GET
- name: GMLDataset
  endpoint:
    path: kedro_datasets/networkx/GMLDataset
    method: GET
- name: GraphMLDataset
  endpoint:
    path: kedro_datasets/networkx/GraphMLDataset
    method: GET
- name: JSONDataset
  endpoint:
    path: kedro_datasets/networkx/JSONDataset
    method: GET
- name: CSVDataset
  endpoint:
    path: kedro_datasets/pandas/CSVDataset
    method: GET
- name: DeltaTableDataset
  endpoint:
    path: kedro_datasets/pandas/DeltaTableDataset
    method: GET
- name: ExcelDataset
  endpoint:
    path: kedro_datasets/pandas/ExcelDataset
    method: GET
- name: FeatherDataset
  endpoint:
    path: kedro_datasets/pandas/FeatherDataset
    method: GET
- name: GBQQueryDataset
  endpoint:
    path: kedro_datasets/pandas/GBQQueryDataset
    method: GET
- name: GBQTableDataset
  endpoint:
    path: kedro_datasets/pandas/GBQTableDataset
    method: GET
- name: GenericDataset
  endpoint:
    path: kedro_datasets/pandas/GenericDataset
    method: GET
- name: HDFDataset
  endpoint:
    path: kedro_datasets/pandas/HDFDataset
    method: GET
- name: JSONDataset
  endpoint:
    path: kedro_datasets/pandas/JSONDataset
    method: GET
- name: ParquetDataset
  endpoint:
    path: kedro_datasets/pandas/ParquetDataset
    method: GET
- name: SQLQueryDataset
  endpoint:
    path: kedro_datasets/pandas/SQLQueryDataset
    method: GET
- name: SQLTableDataset
  endpoint:
    path: kedro_datasets/pandas/SQLTableDataset
    method: GET
- name: XMLDataset
  endpoint:
    path: kedro_datasets/pandas/XMLDataset
    method: GET
- name: IncrementalDataset
  endpoint:
    path: kedro_datasets/partitions/IncrementalDataset
    method: GET
- name: PartitionedDataset
  endpoint:
    path: kedro_datasets/partitions/PartitionedDataset
    method: GET
- name: PickleDataset
  endpoint:
    path: kedro_datasets/pickle/PickleDataset
    method: GET
- name: ImageDataset
  endpoint:
    path: kedro_datasets/pillow/ImageDataset
    method: GET
- name: JSONDataset
  endpoint:
    path: kedro_datasets/plotly/JSONDataset
    method: GET
- name: PlotlyDataset
  endpoint:
    path: kedro_datasets/plotly/PlotlyDataset
    method: GET
- name: CSVDataset
  endpoint:
    path: kedro_datasets/polars/CSVDataset
    method: GET
- name: EagerPolarsDataset
  endpoint:
    path: kedro_datasets/polars/EagerPolarsDataset
    method: GET
- name: LazyPolarsDataset
  endpoint:
    path: kedro_datasets/polars/LazyPolarsDataset
    method: GET
- name: PickleDataset
  endpoint:
    path: kedro_datasets/redis/PickleDataset
    method: GET
- name: SnowparkTableDataset
  endpoint:
    path: kedro_datasets/snowflake/SnowparkTableDataset
    method: GET
- name: DeltaTableDataset
  endpoint:
    path: kedro_datasets/spark/DeltaTableDataset
    method: GET
- name: SparkDataset
  endpoint:
    path: kedro_datasets/spark/SparkDataset
    method: GET
- name: SparkHiveDataset
  endpoint:
    path: kedro_datasets/spark/SparkHiveDataset
    method: GET
- name: SparkJDBCDataset
  endpoint:
    path: kedro_datasets/spark/SparkJDBCDataset
    method: GET
- name: SparkStreamingDataset
  endpoint:
    path: kedro_datasets/spark/SparkStreamingDataset
    method: GET
- name: SVMLightDataset
  endpoint:
    path: kedro_datasets/svmlight/SVMLightDataset
    method: GET
- name: TensorFlowModelDataset
  endpoint:
    path: kedro_datasets/tensorflow/TensorFlowModelDataset
    method: GET
- name: TextDataset
  endpoint:
    path: kedro_datasets/text/TextDataset
    method: GET
- name: JSONDataset
  endpoint:
    path: kedro_datasets/tracking/JSONDataset
    method: GET
- name: MetricsDataset
  endpoint:
    path: kedro_datasets/tracking/MetricsDataset
    method: GET
- name: VideoDataset
  endpoint:
    path: kedro_datasets/video/VideoDataset
    method: GET
- name: YAMLDataset
  endpoint:
    path: kedro_datasets/yaml/YAMLDataset
    method: GET
- name: example_table
  endpoint:
    path: https://httpbin.org/post
    method: POST
- name: GMLDataset
  endpoint:
    path: /GMLDataset
    method: GET
    data_selector: data
    params: {}
- name: BioSequenceDataset
  endpoint:
    path: /kedro_datasets/biosequence/BioSequenceDataset
    method: GET
    data_selector: records
    params: {}
- name: GMLDataset
  endpoint:
    path: kedro_datasets.networkx.GMLDataset
    method: GET
- name: GraphMLDataset
  endpoint:
    path: kedro_datasets.networkx.GraphMLDataset
    method: GET
- name: JSONDataset
  endpoint:
    path: kedro_datasets.networkx.JSONDataset
    method: GET
- name: CSVDataset
  endpoint:
    path: kedro_datasets.pandas.CSVDataset
    method: GET
- name: DeltaTableDataset
  endpoint:
    path: kedro_datasets.pandas.DeltaTableDataset
    method: GET
- name: ExcelDataset
  endpoint:
    path: kedro_datasets.pandas.ExcelDataset
    method: GET
- name: FeatherDataset
  endpoint:
    path: kedro_datasets.pandas.FeatherDataset
    method: GET
- name: GBQQueryDataset
  endpoint:
    path: kedro_datasets.pandas.GBQQueryDataset
    method: GET
- name: GBQTableDataset
  endpoint:
    path: kedro_datasets.pandas.GBQTableDataset
    method: GET
- name: GenericDataset
  endpoint:
    path: kedro_datasets.pandas.GenericDataset
    method: GET
- name: HDFDataset
  endpoint:
    path: kedro_datasets.pandas.HDFDataset
    method: GET
- name: parquet_dataset
  endpoint:
    path: s3://bucket_name/path/to/folder
    method: ''
    data_selector: ''
    params: {}
- name: GMLDataset
  endpoint:
    path: /kedro_datasets/networkx/GMLDataset
    method: GET
- name: GraphMLDataset
  endpoint:
    path: /kedro_datasets/networkx/GraphMLDataset
    method: GET
- name: JSONDataset
  endpoint:
    path: /kedro_datasets/networkx/JSONDataset
    method: GET
- name: CSVDataset
  endpoint:
    path: /kedro_datasets/pandas/CSVDataset
    method: GET
- name: DeltaTableDataset
  endpoint:
    path: /kedro_datasets/pandas/DeltaTableDataset
    method: GET
- name: ExcelDataset
  endpoint:
    path: /kedro_datasets/pandas/ExcelDataset
    method: GET
- name: FeatherDataset
  endpoint:
    path: /kedro_datasets/pandas/FeatherDataset
    method: GET
- name: GBQQueryDataset
  endpoint:
    path: /kedro_datasets/pandas/GBQQueryDataset
    method: GET
- name: GBQTableDataset
  endpoint:
    path: /kedro_datasets/pandas/GBQTableDataset
    method: GET
- name: GenericDataset
  endpoint:
    path: /kedro_datasets/pandas/GenericDataset
    method: GET
- name: HDFDataset
  endpoint:
    path: /kedro_datasets/pandas/HDFDataset
    method: GET
- name: JSONDataset
  endpoint:
    path: /kedro_datasets/pandas/JSONDataset
    method: GET
- name: names_and_ages@spark
  endpoint:
    path: names_and_ages
    method: LOAD
    data_selector: data
    params: {}
- name: names_and_ages@pandas
  endpoint:
    path: names_and_ages
    method: LOAD
    data_selector: data
    params: {}
- name: GMLDataset
  endpoint:
    path: /datasets/networkx/GMLDataset
    method: GET
- name: GraphMLDataset
  endpoint:
    path: /datasets/networkx/GraphMLDataset
    method: GET
- name: JSONDataset
  endpoint:
    path: /datasets/networkx/JSONDataset
    method: GET
- name: CSVDataset
  endpoint:
    path: /datasets/pandas/CSVDataset
    method: GET
- name: DeltaTableDataset
  endpoint:
    path: /datasets/pandas/DeltaTableDataset
    method: GET
- name: ExcelDataset
  endpoint:
    path: /datasets/pandas/ExcelDataset
    method: GET
- name: FeatherDataset
  endpoint:
    path: /datasets/pandas/FeatherDataset
    method: GET
- name: GBQQueryDataset
  endpoint:
    path: /datasets/pandas/GBQQueryDataset
    method: GET
- name: GBQTableDataset
  endpoint:
    path: /datasets/pandas/GBQTableDataset
    method: GET
- name: GenericDataset
  endpoint:
    path: /datasets/pandas/GenericDataset
    method: GET
- name: HDFDataset
  endpoint:
    path: /datasets/pandas/HDFDataset
    method: GET
- name: GMLDataset
  endpoint:
    path: /kedro_datasets/networkx/GMLDataset
    method: GET
- name: GraphMLDataset
  endpoint:
    path: /kedro_datasets/networkx/GraphMLDataset
    method: GET
- name: JSONDataset
  endpoint:
    path: /kedro_datasets/networkx/JSONDataset
    method: GET
- name: CSVDataset
  endpoint:
    path: /kedro_datasets/pandas/CSVDataset
    method: GET
- name: DeltaTableDataset
  endpoint:
    path: /kedro_datasets/pandas/DeltaTableDataset
    method: GET
- name: ExcelDataset
  endpoint:
    path: /kedro_datasets/pandas/ExcelDataset
    method: GET
- name: FeatherDataset
  endpoint:
    path: /kedro_datasets/pandas/FeatherDataset
    method: GET
- name: GBQQueryDataset
  endpoint:
    path: /kedro_datasets/pandas/GBQQueryDataset
    method: GET
- name: GBQTableDataset
  endpoint:
    path: /kedro_datasets/pandas/GBQTableDataset
    method: GET
- name: GenericDataset
  endpoint:
    path: /kedro_datasets/pandas/GenericDataset
    method: GET
- name: HDFDataset
  endpoint:
    path: /kedro_datasets/pandas/HDFDataset
    method: GET
- name: JSONDataset
  endpoint:
    path: /kedro_datasets/pandas/JSONDataset
    method: GET
- name: GeoJSONDataset
  endpoint:
    path: GeoJSONDataset
    method: GET
    data_selector: records
    params: {}
- name: GMLDataset
  endpoint:
    path: /path/to/gml
    method: GET
    data_selector: data
    params: {}
- name: Holoviews
  endpoint:
    path: /holoviews
    method: POST
    data_selector: records
    params: {}
- name: GMLDataset
  endpoint:
    path: kedro_datasets.networkx.GMLDataset
    method: GET
- name: GraphMLDataset
  endpoint:
    path: kedro_datasets.networkx.GraphMLDataset
    method: GET
- name: JSONDataset
  endpoint:
    path: kedro_datasets.networkx.JSONDataset
    method: GET
- name: CSVDataset
  endpoint:
    path: kedro_datasets.pandas.CSVDataset
    method: GET
- name: DeltaTableDataset
  endpoint:
    path: kedro_datasets.pandas.DeltaTableDataset
    method: GET
- name: ExcelDataset
  endpoint:
    path: kedro_datasets.pandas.ExcelDataset
    method: GET
- name: FeatherDataset
  endpoint:
    path: kedro_datasets.pandas.FeatherDataset
    method: GET
- name: GBQQueryDataset
  endpoint:
    path: kedro_datasets.pandas.GBQQueryDataset
    method: GET
- name: GBQTableDataset
  endpoint:
    path: kedro_datasets.pandas.GBQTableDataset
    method: GET
- name: GenericDataset
  endpoint:
    path: kedro_datasets.pandas.GenericDataset
    method: GET
- name: HDFDataset
  endpoint:
    path: kedro_datasets.pandas.HDFDataset
    method: GET
- name: yelp_reviews
  endpoint:
    path: /datasets/yelp_review_full
    method: GET
- name: openai_humaneval
  endpoint:
    path: /datasets/openai_humaneval
    method: GET
- name: GMLDataset
  endpoint:
    path: /datasets/networkx/GMLDataset
    method: GET
- name: GraphMLDataset
  endpoint:
    path: /datasets/networkx/GraphMLDataset
    method: GET
- name: JSONDataset
  endpoint:
    path: /datasets/networkx/JSONDataset
    method: GET
- name: CSVDataset
  endpoint:
    path: /datasets/pandas/CSVDataset
    method: GET
- name: DeltaTableDataset
  endpoint:
    path: /datasets/pandas/DeltaTableDataset
    method: GET
- name: ExcelDataset
  endpoint:
    path: /datasets/pandas/ExcelDataset
    method: GET
- name: FeatherDataset
  endpoint:
    path: /datasets/pandas/FeatherDataset
    method: GET
- name: GBQQueryDataset
  endpoint:
    path: /datasets/pandas/GBQQueryDataset
    method: GET
- name: GBQTableDataset
  endpoint:
    path: /datasets/pandas/GBQTableDataset
    method: GET
- name: GenericDataset
  endpoint:
    path: /datasets/pandas/GenericDataset
    method: GET
- name: HDFDataset
  endpoint:
    path: /datasets/pandas/HDFDataset
    method: GET
- name: JSONDataset
  endpoint:
    path: /datasets/pandas/JSONDataset
    method: GET
- name: summarizer_model
  endpoint:
    path: huggingface.HFTransformerPipelineDataset
    method: POST
    data_selector: model
    params:
      task: summarization
- name: fill_mask_model
  endpoint:
    path: huggingface.HFTransformerPipelineDataset
    method: POST
    data_selector: model
    params:
      task: fill-mask
      model_name: Twitter/twhin-bert-base
- name: text_classification_model
  endpoint:
    path: huggingface.HFTransformerPipelineDataset
    method: POST
    data_selector: model
    params:
      task: text-classification
      model_name: prajjwal1/bert-tiny
- name: GMLDataset
  endpoint: {}
- name: GraphMLDataset
  endpoint: {}
- name: JSONDataset
  endpoint: {}
- name: CSVDataset
  endpoint: {}
- name: DeltaTableDataset
  endpoint: {}
- name: ExcelDataset
  endpoint: {}
- name: FeatherDataset
  endpoint: {}
- name: GBQQueryDataset
  endpoint: {}
- name: GBQTableDataset
  endpoint: {}
- name: GenericDataset
  endpoint: {}
- name: HDFDataset
  endpoint: {}
- name: cars
  endpoint:
    path: gcs://your_bucket/cars.json
    method: GET
    data_selector: records
    params: {}
- name: GMLDataset
  endpoint:
    path: /kedro_datasets/networkx/GMLDataset
    method: GET
- name: GraphMLDataset
  endpoint:
    path: /kedro_datasets/networkx/GraphMLDataset
    method: GET
- name: JSONDataset
  endpoint:
    path: /kedro_datasets/networkx/JSONDataset
    method: GET
- name: CSVDataset
  endpoint:
    path: /kedro_datasets/pandas/CSVDataset
    method: GET
- name: DeltaTableDataset
  endpoint:
    path: /kedro_datasets/pandas/DeltaTableDataset
    method: GET
- name: ExcelDataset
  endpoint:
    path: /kedro_datasets/pandas/ExcelDataset
    method: GET
- name: FeatherDataset
  endpoint:
    path: /kedro_datasets/pandas/FeatherDataset
    method: GET
- name: GBQQueryDataset
  endpoint:
    path: /kedro_datasets/pandas/GBQQueryDataset
    method: GET
- name: GBQTableDataset
  endpoint:
    path: /kedro_datasets/pandas/GBQTableDataset
    method: GET
- name: GenericDataset
  endpoint:
    path: /kedro_datasets/pandas/GenericDataset
    method: GET
- name: HDFDataset
  endpoint:
    path: /kedro_datasets/pandas/HDFDataset
    method: GET
- name: cars
  endpoint:
    path: gcs://your_bucket/cars.mat
    method: GET
    data_selector: null
    params: {}
- name: GMLDataset
  endpoint:
    path: /GMLDataset
    method: GET
- name: output_plot
  endpoint:
    path: data/08_reporting/output_plot.png
    method: save
    data_selector: null
    params:
      format: png
- name: pdf_plot
  endpoint:
    path: data/08_reporting/output_plot.pdf
    method: save
    data_selector: null
    params:
      format: pdf
- name: plots
  endpoint:
    path: data/08_reporting/plots
    method: save
    data_selector: null
    params: {}
- name: NetCDFDataset
  endpoint:
    path: /NetCDFDataset
    method: GET
- name: GMLDataset
  endpoint:
    path: /GMLDataset
    method: GET
- name: GraphMLDataset
  endpoint:
    path: /GraphMLDataset
    method: GET
- name: JSONDataset
  endpoint:
    path: /JSONDataset
    method: GET
- name: CSVDataset
  endpoint:
    path: /CSVDataset
    method: GET
- name: DeltaTableDataset
  endpoint:
    path: /DeltaTableDataset
    method: GET
- name: ExcelDataset
  endpoint:
    path: /ExcelDataset
    method: GET
- name: FeatherDataset
  endpoint:
    path: /FeatherDataset
    method: GET
- name: GBQQueryDataset
  endpoint:
    path: /GBQQueryDataset
    method: GET
- name: GBQTableDataset
  endpoint:
    path: /GBQTableDataset
    method: GET
- name: GenericDataset
  endpoint:
    path: /GenericDataset
    method: GET
- name: HDFDataset
  endpoint:
    path: /HDFDataset
    method: GET
- name: single-file
  endpoint:
    path: s3://bucket_name/path/to/folder/data.nc
    method: GET
    data_selector: data
    params:
      save_args:
        mode: a
      load_args:
        decode_times: false
- name: multi-file
  endpoint:
    path: s3://bucket_name/path/to/folder/data*.nc
    method: GET
    data_selector: data
    params:
      load_args:
        concat_dim: time
        combine: nested
        parallel: true
- name: NetCDFDataset
  endpoint:
    path: /NetCDFDataset
    method: GET
- name: GMLDataset
  endpoint:
    path: /GMLDataset
    method: GET
- name: GraphMLDataset
  endpoint:
    path: /GraphMLDataset
    method: GET
- name: JSONDataset
  endpoint:
    path: /JSONDataset
    method: GET
- name: CSVDataset
  endpoint:
    path: /CSVDataset
    method: GET
- name: DeltaTableDataset
  endpoint:
    path: /DeltaTableDataset
    method: GET
- name: ExcelDataset
  endpoint:
    path: /ExcelDataset
    method: GET
- name: FeatherDataset
  endpoint:
    path: /FeatherDataset
    method: GET
- name: GBQQueryDataset
  endpoint:
    path: /GBQQueryDataset
    method: GET
- name: GBQTableDataset
  endpoint:
    path: /GBQTableDataset
    method: GET
- name: GenericDataset
  endpoint:
    path: /GenericDataset
    method: GET
- name: HDFDataset
  endpoint:
    path: /HDFDataset
    method: GET
- name: GMLDataset
  endpoint:
    path: /path/to/gml/dataset
    method: GET
    data_selector: data
    params: {}
- name: NetCDFDataset
  endpoint:
    path: /kedro_datasets/netcdf/NetCDFDataset
    method: GET
- name: GMLDataset
  endpoint:
    path: /kedro_datasets/networkx/GMLDataset
    method: GET
- name: GraphMLDataset
  endpoint:
    path: /kedro_datasets/networkx/GraphMLDataset
    method: GET
- name: JSONDataset
  endpoint:
    path: /kedro_datasets/networkx/JSONDataset
    method: GET
- name: CSVDataset
  endpoint:
    path: /kedro_datasets/pandas/CSVDataset
    method: GET
- name: DeltaTableDataset
  endpoint:
    path: /kedro_datasets/pandas/DeltaTableDataset
    method: GET
- name: ExcelDataset
  endpoint:
    path: /kedro_datasets/pandas/ExcelDataset
    method: GET
- name: FeatherDataset
  endpoint:
    path: /kedro_datasets/pandas/FeatherDataset
    method: GET
- name: GBQQueryDataset
  endpoint:
    path: /kedro_datasets/pandas/GBQQueryDataset
    method: GET
- name: GBQTableDataset
  endpoint:
    path: /kedro_datasets/pandas/GBQTableDataset
    method: GET
- name: GenericDataset
  endpoint:
    path: /kedro_datasets/pandas/GenericDataset
    method: GET
- name: HDFDataset
  endpoint:
    path: /kedro_datasets/pandas/HDFDataset
    method: GET
- name: GraphMLDataset
  endpoint:
    path: /kedro_datasets/networkx/GraphMLDataset
    method: GET
    data_selector: records
    params: {}
- name: NetCDFDataset
  endpoint:
    path: /NetCDFDataset
    method: GET
- name: GMLDataset
  endpoint:
    path: /GMLDataset
    method: GET
- name: GraphMLDataset
  endpoint:
    path: /GraphMLDataset
    method: GET
- name: JSONDataset
  endpoint:
    path: /JSONDataset
    method: GET
- name: CSVDataset
  endpoint:
    path: /CSVDataset
    method: GET
- name: DeltaTableDataset
  endpoint:
    path: /DeltaTableDataset
    method: GET
- name: ExcelDataset
  endpoint:
    path: /ExcelDataset
    method: GET
- name: FeatherDataset
  endpoint:
    path: /FeatherDataset
    method: GET
- name: GBQQueryDataset
  endpoint:
    path: /GBQQueryDataset
    method: GET
- name: GBQTableDataset
  endpoint:
    path: /GBQTableDataset
    method: GET
- name: GenericDataset
  endpoint:
    path: /GenericDataset
    method: GET
- name: HDFDataset
  endpoint:
    path: /HDFDataset
    method: GET
- name: JSONDataset
  endpoint:
    path: /kedro_datasets/networkx/JSONDataset
    method: GET
    data_selector: records
    params: {}
- name: NetCDFDataset
  endpoint:
    path: /datasets/netcdf
    method: GET
- name: cars
  endpoint:
    path: data/01_raw/company/cars.csv
    method: GET
    data_selector: ''
    params: {}
- name: motorbikes
  endpoint:
    path: s3://your_bucket/data/02_intermediate/company/motorbikes.csv
    method: GET
    data_selector: ''
    params:
      credentials: dev_s3
- name: NetCDFDataset
  endpoint:
    path: /kedro_datasets/netcdf
    method: GET
- name: GMLDataset
  endpoint:
    path: /kedro_datasets/networkx/GMLDataset
    method: GET
- name: GraphMLDataset
  endpoint:
    path: /kedro_datasets/networkx/GraphMLDataset
    method: GET
- name: JSONDataset
  endpoint:
    path: /kedro_datasets/networkx/JSONDataset
    method: GET
- name: CSVDataset
  endpoint:
    path: /kedro_datasets/pandas/CSVDataset
    method: GET
- name: DeltaTableDataset
  endpoint:
    path: /kedro_datasets/pandas/DeltaTableDataset
    method: GET
- name: ExcelDataset
  endpoint:
    path: /kedro_datasets/pandas/ExcelDataset
    method: GET
- name: FeatherDataset
  endpoint:
    path: /kedro_datasets/pandas/FeatherDataset
    method: GET
- name: GBQQueryDataset
  endpoint:
    path: /kedro_datasets/pandas/GBQQueryDataset
    method: GET
- name: GBQTableDataset
  endpoint:
    path: /kedro_datasets/pandas/GBQTableDataset
    method: GET
- name: GenericDataset
  endpoint:
    path: /kedro_datasets/pandas/GenericDataset
    method: GET
- name: HDFDataset
  endpoint:
    path: /kedro_datasets/pandas/HDFDataset
    method: GET
- name: boats_filesystem
  endpoint:
    path: data/01_raw/boats
    method: save
    data_selector: null
    params: {}
- name: boats_databricks_unity_catalog
  endpoint:
    path: null
    method: save
    data_selector: null
    params:
      catalog_type: UNITY
      database: simple_database
      table: simple_table
- name: trucks_aws_glue_catalog
  endpoint:
    path: null
    method: save
    data_selector: null
    params:
      catalog_type: AWS
      catalog_name: main
      database: db_schema
      table: db_table
- name: NetCDFDataset
  endpoint:
    path: /NetCDFDataset
    method: GET
- name: GMLDataset
  endpoint:
    path: /GMLDataset
    method: GET
- name: GraphMLDataset
  endpoint:
    path: /GraphMLDataset
    method: GET
- name: JSONDataset
  endpoint:
    path: /JSONDataset
    method: GET
- name: CSVDataset
  endpoint:
    path: /CSVDataset
    method: GET
- name: DeltaTableDataset
  endpoint:
    path: /DeltaTableDataset
    method: GET
- name: ExcelDataset
  endpoint:
    path: /ExcelDataset
    method: GET
- name: FeatherDataset
  endpoint:
    path: /FeatherDataset
    method: GET
- name: GBQQueryDataset
  endpoint:
    path: /GBQQueryDataset
    method: GET
- name: GBQTableDataset
  endpoint:
    path: /GBQTableDataset
    method: GET
- name: GenericDataset
  endpoint:
    path: /GenericDataset
    method: GET
- name: HDFDataset
  endpoint:
    path: /HDFDataset
    method: GET
- name: rockets
  endpoint:
    path: gcs://your_bucket/rockets.xlsx
    method: null
    data_selector: null
    params: {}
- name: shuttles
  endpoint:
    path: data/01_raw/shuttles.xlsx
    method: null
    data_selector: null
    params: {}
- name: trains
  endpoint:
    path: data/02_intermediate/company/trains.xlsx
    method: null
    data_selector: null
    params: {}
- name: test
  endpoint:
    path: test.xlsx
    method: null
    data_selector: null
    params: {}
- name: NetCDFDataset
  endpoint:
    path: /path/to/netcdf/dataset
    method: GET
    data_selector: records
- name: cars
  endpoint:
    path: data/01_raw/company/cars.feather
    method: LOAD
    data_selector: data
    params:
      load_args:
        columns:
        - col1
        - col2
        - col3
        use_threads: true
- name: motorbikes
  endpoint:
    path: s3://your_bucket/data/02_intermediate/company/motorbikes.feather
    method: LOAD
    data_selector: data
    params:
      credentials: dev_s3
- name: vehicles
  endpoint:
    path: /path-to-vehicles-endpoint
    method: GET
    data_selector: records
    params: {}
- name: NetCDFDataset
  endpoint:
    path: /datasets/netcdf
    method: GET
    data_selector: records
- name: vehicles
  endpoint:
    method: GET
    params: {}
- name: cars
  endpoint:
    path: s3://data/01_raw/company/cars.csv
    method: GET
    data_selector: data
    params:
      file_format: csv
      load_args:
        sep: ','
        na_values:
        - '#NA'
        - NA
      save_args:
        index: false
        date_format: '%Y-%m-%d'
- name: flights
  endpoint:
    path: data/01_raw/airplanes.sas7bdat
    method: GET
    data_selector: data
    params:
      file_format: sas
      load_args:
        format: sas7bdat
- name: hdf_dataset
  endpoint:
    path: s3://my_bucket/raw/sensor_reading.h5
    method: GET
    data_selector: data
    params: {}
- name: NetCDFDataset
  endpoint:
    path: /netcdf/dataset
    method: GET
    data_selector: records
- name: clickstream_dataset
  endpoint:
    path: abfs://landing_area/primary/click_stream.json
    method: GET
    data_selector: ''
    params: {}
- name: json_dataset
  endpoint:
    path: data/01_raw/Video_Games.json
    method: GET
    data_selector: ''
    params:
      lines: true
- name: NetCDF
  endpoint:
    path: /datasets/netcdf
    method: GET
- name: GML
  endpoint:
    path: /datasets/gml
    method: GET
- name: GraphML
  endpoint:
    path: /datasets/graphml
    method: GET
- name: JSON
  endpoint:
    path: /datasets/json
    method: GET
- name: CSV
  endpoint:
    path: /datasets/csv
    method: GET
- name: DeltaTable
  endpoint:
    path: /datasets/delta
    method: GET
- name: Excel
  endpoint:
    path: /datasets/excel
    method: GET
- name: Feather
  endpoint:
    path: /datasets/feather
    method: GET
- name: GBQQuery
  endpoint:
    path: /datasets/gbqquery
    method: GET
- name: GBQTable
  endpoint:
    path: /datasets/gbqtable
    method: GET
- name: Generic
  endpoint:
    path: /datasets/generic
    method: GET
- name: HDF
  endpoint:
    path: /datasets/hdf
    method: GET
- name: boats
  endpoint:
    path: data/01_raw/boats.parquet
    method: LOAD
    data_selector: records
    params:
      load_args:
        engine: pyarrow
        use_nullable_dtypes: true
      save_args:
        file_scheme: hive
        has_nulls: false
        engine: pyarrow
- name: trucks
  endpoint:
    path: abfs://container/02_intermediate/trucks.parquet
    method: LOAD
    data_selector: records
    params:
      credentials: dev_abs
      load_args:
        columns:
        - name
        - gear
        - disp
        - wt
        index: name
      save_args:
        compression: GZIP
        partition_on:
        - name
- name: NetCDFDataset
  endpoint:
    path: /NetCDFDataset
    method: GET
- name: GMLDataset
  endpoint:
    path: /GMLDataset
    method: GET
- name: GraphMLDataset
  endpoint:
    path: /GraphMLDataset
    method: GET
- name: JSONDataset
  endpoint:
    path: /JSONDataset
    method: GET
- name: CSVDataset
  endpoint:
    path: /CSVDataset
    method: GET
- name: DeltaTableDataset
  endpoint:
    path: /DeltaTableDataset
    method: GET
- name: ExcelDataset
  endpoint:
    path: /ExcelDataset
    method: GET
- name: FeatherDataset
  endpoint:
    path: /FeatherDataset
    method: GET
- name: GBQQueryDataset
  endpoint:
    path: /GBQQueryDataset
    method: GET
- name: GBQTableDataset
  endpoint:
    path: /GBQTableDataset
    method: GET
- name: GenericDataset
  endpoint:
    path: /GenericDataset
    method: GET
- name: HDFDataset
  endpoint:
    path: /HDFDataset
    method: GET
- name: shuttle_id_dataset
  endpoint:
    path: sql
    method: GET
    data_selector: records
    params: {}
- name: mssql_dataset
  endpoint:
    path: sql
    method: GET
    data_selector: records
    params: {}
- name: NetCDFDataset
  endpoint:
    path: /kedro_datasets/netcdf/NetCDFDataset
    method: GET
- name: GMLDataset
  endpoint:
    path: /kedro_datasets/networkx/GMLDataset
    method: GET
- name: GraphMLDataset
  endpoint:
    path: /kedro_datasets/networkx/GraphMLDataset
    method: GET
- name: JSONDataset
  endpoint:
    path: /kedro_datasets/networkx/JSONDataset
    method: GET
- name: CSVDataset
  endpoint:
    path: /kedro_datasets/pandas/CSVDataset
    method: GET
- name: DeltaTableDataset
  endpoint:
    path: /kedro_datasets/pandas/DeltaTableDataset
    method: GET
- name: ExcelDataset
  endpoint:
    path: /kedro_datasets/pandas/ExcelDataset
    method: GET
- name: FeatherDataset
  endpoint:
    path: /kedro_datasets/pandas/FeatherDataset
    method: GET
- name: GBQQueryDataset
  endpoint:
    path: /kedro_datasets/pandas/GBQQueryDataset
    method: GET
- name: GBQTableDataset
  endpoint:
    path: /kedro_datasets/pandas/GBQTableDataset
    method: GET
- name: GenericDataset
  endpoint:
    path: /kedro_datasets/pandas/GenericDataset
    method: GET
- name: HDFDataset
  endpoint:
    path: /kedro_datasets/pandas/HDFDataset
    method: GET
- name: shuttles_table_dataset
  endpoint:
    path: /shuttles
    method: GET
    data_selector: records
    params: {}
- name: NetCDFDataset
  endpoint: {}
- name: GMLDataset
  endpoint: {}
- name: GraphMLDataset
  endpoint: {}
- name: JSONDataset
  endpoint: {}
- name: CSVDataset
  endpoint: {}
- name: DeltaTableDataset
  endpoint: {}
- name: ExcelDataset
  endpoint: {}
- name: FeatherDataset
  endpoint: {}
- name: GBQQueryDataset
  endpoint: {}
- name: GBQTableDataset
  endpoint: {}
- name: GenericDataset
  endpoint: {}
- name: HDFDataset
  endpoint: {}
- name: XMLDataset
  endpoint:
    path: /_modules/kedro_datasets/pandas/xml_dataset.html
    method: GET
    data_selector: records
    params: {}
- name: NetCDFDataset
  endpoint:
    path: /datasets/netcdf
    method: GET
    data_selector: records
    params: {}
- name: GMLDataset
  endpoint:
    path: /datasets/gml
    method: GET
    data_selector: records
    params: {}
- name: GraphMLDataset
  endpoint:
    path: /datasets/graphml
    method: GET
    data_selector: records
    params: {}
- name: JSONDataset
  endpoint:
    path: /datasets/json
    method: GET
    data_selector: records
    params: {}
- name: CSVDataset
  endpoint:
    path: /datasets/csv
    method: GET
    data_selector: records
    params: {}
- name: DeltaTableDataset
  endpoint:
    path: /datasets/delta
    method: GET
    data_selector: records
    params: {}
- name: ExcelDataset
  endpoint:
    path: /datasets/excel
    method: GET
    data_selector: records
    params: {}
- name: FeatherDataset
  endpoint:
    path: /datasets/feather
    method: GET
    data_selector: records
    params: {}
- name: GBQQueryDataset
  endpoint:
    path: /datasets/gbq_query
    method: GET
    data_selector: records
    params: {}
- name: GBQTableDataset
  endpoint:
    path: /datasets/gbq_table
    method: GET
    data_selector: records
    params: {}
- name: GenericDataset
  endpoint:
    path: /datasets/generic
    method: GET
    data_selector: records
    params: {}
- name: HDFDataset
  endpoint:
    path: /datasets/hdf
    method: GET
    data_selector: records
    params: {}
- name: checkpoint
  endpoint:
    path: DEFAULT_CHECKPOINT_FILENAME
    method: GET
    data_selector: records
    params: {}
- name: checkpoint_type
  endpoint:
    path: DEFAULT_CHECKPOINT_TYPE
    method: GET
    data_selector: records
    params: {}
- name: NetCDFDataset
  endpoint:
    path: /NetCDFDataset
    method: GET
- name: GMLDataset
  endpoint:
    path: /GMLDataset
    method: GET
- name: GraphMLDataset
  endpoint:
    path: /GraphMLDataset
    method: GET
- name: JSONDataset
  endpoint:
    path: /JSONDataset
    method: GET
- name: CSVDataset
  endpoint:
    path: /CSVDataset
    method: GET
- name: DeltaTableDataset
  endpoint:
    path: /DeltaTableDataset
    method: GET
- name: ExcelDataset
  endpoint:
    path: /ExcelDataset
    method: GET
- name: FeatherDataset
  endpoint:
    path: /FeatherDataset
    method: GET
- name: GBQQueryDataset
  endpoint:
    path: /GBQQueryDataset
    method: GET
- name: GBQTableDataset
  endpoint:
    path: /GBQTableDataset
    method: GET
- name: GenericDataset
  endpoint:
    path: /GenericDataset
    method: GET
- name: HDFDataset
  endpoint:
    path: /HDFDataset
    method: GET
- name: station_data
  endpoint:
    path: data/03_primary/station_data
    method: GET
    data_selector: records
    params: {}
- name: df_with_partition
  endpoint:
    path: s3://bucket-name/path/to/folder
    method: GET
    data_selector: records
    params: {}
- name: NetCDFDataset
  endpoint:
    path: /datasets/netcdf
    method: GET
    data_selector: records
- name: GMLDataset
  endpoint:
    path: /datasets/gml
    method: GET
    data_selector: records
- name: GraphMLDataset
  endpoint:
    path: /datasets/graphml
    method: GET
    data_selector: records
- name: test_model
  endpoint:
    path: data/07_model_output/test_model.pkl
    method: save
    data_selector: null
    params: {}
- name: final_model
  endpoint:
    path: s3://your_bucket/final_model.pkl.lz4
    method: save
    data_selector: null
    params:
      credentials: s3_credentials
      save_args:
        compress: lz4
- name: NetCDFDataset
  endpoint: {}
- name: GMLDataset
  endpoint: {}
- name: GraphMLDataset
  endpoint: {}
- name: JSONDataset
  endpoint: {}
- name: CSVDataset
  endpoint: {}
- name: DeltaTableDataset
  endpoint: {}
- name: ExcelDataset
  endpoint: {}
- name: FeatherDataset
  endpoint: {}
- name: GBQQueryDataset
  endpoint: {}
- name: GBQTableDataset
  endpoint: {}
- name: GenericDataset
  endpoint: {}
- name: HDFDataset
  endpoint: {}
- name: ImageDataset
  endpoint:
    path: ImageDataset
    method: GET
    data_selector: records
    params: {}
- name: NetCDFDataset
  endpoint:
    path: /kedro_datasets/netcdf
    method: GET
- name: GMLDataset
  endpoint:
    path: /kedro_datasets/networkx/gml
    method: GET
- name: GraphMLDataset
  endpoint:
    path: /kedro_datasets/networkx/graphml
    method: GET
- name: JSONDataset
  endpoint:
    path: /kedro_datasets/networkx/json
    method: GET
- name: CSVDataset
  endpoint:
    path: /kedro_datasets/pandas/csv
    method: GET
- name: DeltaTableDataset
  endpoint:
    path: /kedro_datasets/pandas/delta_table
    method: GET
- name: ExcelDataset
  endpoint:
    path: /kedro_datasets/pandas/excel
    method: GET
- name: FeatherDataset
  endpoint:
    path: /kedro_datasets/pandas/feather
    method: GET
- name: GBQQueryDataset
  endpoint:
    path: /kedro_datasets/pandas/gbq_query
    method: GET
- name: GBQTableDataset
  endpoint:
    path: /kedro_datasets/pandas/gbq_table
    method: GET
- name: GenericDataset
  endpoint:
    path: /kedro_datasets/pandas/generic
    method: GET
- name: HDFDataset
  endpoint:
    path: /kedro_datasets/pandas/hdf
    method: GET
- name: scatter_plot
  endpoint:
    path: data/08_reporting/scatter_plot.json
    method: save
    data_selector: Figure
    params: {}
- name: test
  endpoint:
    path: tmp_path/test.json
    method: load
    data_selector: Figure
    params: {}
- name: NetCDFDataset
  endpoint:
    path: /kedro_datasets/netcdf
    method: GET
- name: GMLDataset
  endpoint:
    path: /kedro_datasets/networkx/gml
    method: GET
- name: GraphMLDataset
  endpoint:
    path: /kedro_datasets/networkx/graphml
    method: GET
- name: JSONDataset
  endpoint:
    path: /kedro_datasets/networkx/json
    method: GET
- name: CSVDataset
  endpoint:
    path: /kedro_datasets/pandas/csv
    method: GET
- name: DeltaTableDataset
  endpoint:
    path: /kedro_datasets/pandas/delta
    method: GET
- name: ExcelDataset
  endpoint:
    path: /kedro_datasets/pandas/excel
    method: GET
- name: FeatherDataset
  endpoint:
    path: /kedro_datasets/pandas/feather
    method: GET
- name: GBQQueryDataset
  endpoint:
    path: /kedro_datasets/pandas/gbq_query
    method: GET
- name: GBQTableDataset
  endpoint:
    path: /kedro_datasets/pandas/gbq_table
    method: GET
- name: GenericDataset
  endpoint:
    path: /kedro_datasets/pandas/generic
    method: GET
- name: HDFDataset
  endpoint:
    path: /kedro_datasets/pandas/hdf
    method: GET
- name: bar_plot
  endpoint:
    path: data/08_reporting/bar_plot.json
    method: POST
    data_selector: null
    params: {}
- name: scatter_plot
  endpoint:
    path: scatter_plot.json
    method: POST
    data_selector: null
    params: {}
- name: NetCDFDataset
  endpoint:
    path: /netcdf/dataset
    method: GET
    data_selector: data
- name: cars
  endpoint:
    path: data/01_raw/company/cars.csv
    method: LOAD
    data_selector: null
    params:
      load_args:
        sep: ','
        parse_dates: false
      save_args:
        has_header: false
        null_value: somenullstring
- name: motorbikes
  endpoint:
    path: s3://your_bucket/data/02_intermediate/company/motorbikes.csv
    method: LOAD
    data_selector: null
    params:
      credentials: dev_s3
- name: NetCDFDataset
  endpoint:
    path: /datasets/netcdf
    method: GET
    data_selector: records
- name: GMLDataset
  endpoint:
    path: /datasets/gml
    method: GET
    data_selector: records
- name: GraphMLDataset
  endpoint:
    path: /datasets/graphml
    method: GET
    data_selector: records
- name: JSONDataset
  endpoint:
    path: /datasets/json
    method: GET
    data_selector: records
- name: CSVDataset
  endpoint:
    path: /datasets/csv
    method: GET
    data_selector: records
- name: DeltaTableDataset
  endpoint:
    path: /datasets/delta
    method: GET
    data_selector: records
- name: ExcelDataset
  endpoint:
    path: /datasets/excel
    method: GET
    data_selector: records
- name: FeatherDataset
  endpoint:
    path: /datasets/feather
    method: GET
    data_selector: records
- name: GBQQueryDataset
  endpoint:
    path: /datasets/gbqquery
    method: GET
    data_selector: records
- name: GBQTableDataset
  endpoint:
    path: /datasets/gbqtable
    method: GET
    data_selector: records
- name: GenericDataset
  endpoint:
    path: /datasets/generic
    method: GET
    data_selector: records
- name: HDFDataset
  endpoint:
    path: /datasets/hdf
    method: GET
    data_selector: records
- name: cars
  endpoint:
    path: s3://data/01_raw/company/cars.parquet
    method: LOAD
    data_selector: data
    params: {}
- name: NetCDFDataset
  endpoint:
    path: /kedro_datasets/netcdf
    method: GET
    data_selector: records
- name: GMLDataset
  endpoint:
    path: /kedro_datasets/networkx/gml
    method: GET
    data_selector: records
- name: GraphMLDataset
  endpoint:
    path: /kedro_datasets/networkx/graphml
    method: GET
    data_selector: records
- name: JSONDataset
  endpoint:
    path: /kedro_datasets/networkx/json
    method: GET
    data_selector: records
- name: CSVDataset
  endpoint:
    path: /kedro_datasets/pandas/csv
    method: GET
    data_selector: records
- name: DeltaTableDataset
  endpoint:
    path: /kedro_datasets/pandas/delta
    method: GET
    data_selector: records
- name: ExcelDataset
  endpoint:
    path: /kedro_datasets/pandas/excel
    method: GET
    data_selector: records
- name: FeatherDataset
  endpoint:
    path: /kedro_datasets/pandas/feather
    method: GET
    data_selector: records
- name: GBQQueryDataset
  endpoint:
    path: /kedro_datasets/pandas/gbq_query
    method: GET
    data_selector: records
- name: GBQTableDataset
  endpoint:
    path: /kedro_datasets/pandas/gbq_table
    method: GET
    data_selector: records
- name: GenericDataset
  endpoint:
    path: /kedro_datasets/pandas/generic
    method: GET
    data_selector: records
- name: HDFDataset
  endpoint:
    path: /kedro_datasets/pandas/hdf
    method: GET
    data_selector: records
- name: cars
  endpoint:
    path: data/01_raw/company/cars.csv
    method: GET
    data_selector: records
    params: {}
- name: motorbikes
  endpoint:
    path: s3://your_bucket/data/02_intermediate/company/motorbikes.csv
    method: GET
    data_selector: records
    params:
      credentials: dev_s3
- name: NetCDFDataset
  endpoint: {}
- name: GMLDataset
  endpoint: {}
- name: GraphMLDataset
  endpoint: {}
- name: JSONDataset
  endpoint: {}
- name: CSVDataset
  endpoint: {}
- name: DeltaTableDataset
  endpoint: {}
- name: ExcelDataset
  endpoint: {}
- name: FeatherDataset
  endpoint: {}
- name: GBQQueryDataset
  endpoint: {}
- name: GBQTableDataset
  endpoint: {}
- name: GenericDataset
  endpoint: {}
- name: HDFDataset
  endpoint: {}
- name: my_python_object
  endpoint:
    path: /my_object
    method: GET
    data_selector: records
    params: {}
- name: final_python_object
  endpoint:
    path: /my_final_object
    method: GET
    data_selector: records
    params:
      db: 1
- name: NetCDFDataset
  endpoint:
    path: /datasets
    method: GET
    data_selector: records
    params: {}
- name: weather
  endpoint:
    path: /services/data/vXX.X/sobjects/weather_data
    method: GET
    data_selector: records
    params: {}
- name: polygons
  endpoint:
    path: /services/data/vXX.X/sobjects/geopolygons
    method: GET
    data_selector: records
    params: {}
- name: NetCDFDataset
  endpoint:
    path: kedro_datasets.netcdf.NetCDFDataset
    method: GET
- name: GMLDataset
  endpoint:
    path: kedro_datasets.networkx.GMLDataset
    method: GET
- name: GraphMLDataset
  endpoint:
    path: kedro_datasets.networkx.GraphMLDataset
    method: GET
- name: JSONDataset
  endpoint:
    path: kedro_datasets.networkx.JSONDataset
    method: GET
- name: CSVDataset
  endpoint:
    path: kedro_datasets.pandas.CSVDataset
    method: GET
- name: DeltaTableDataset
  endpoint:
    path: kedro_datasets.pandas.DeltaTableDataset
    method: GET
- name: ExcelDataset
  endpoint:
    path: kedro_datasets.pandas.ExcelDataset
    method: GET
- name: FeatherDataset
  endpoint:
    path: kedro_datasets.pandas.FeatherDataset
    method: GET
- name: GBQQueryDataset
  endpoint:
    path: kedro_datasets.pandas.GBQQueryDataset
    method: GET
- name: GBQTableDataset
  endpoint:
    path: kedro_datasets.pandas.GBQTableDataset
    method: GET
- name: GenericDataset
  endpoint:
    path: kedro_datasets.pandas.GenericDataset
    method: GET
- name: HDFDataset
  endpoint:
    path: kedro_datasets.pandas.HDFDataset
    method: GET
- name: weather
  endpoint:
    path: data/02_intermediate/data.parquet
    method: LOAD
    data_selector: data
    params: {}
- name: NetCDFDataset
  endpoint:
    path: /kedro_datasets/netcdf
    method: GET
- name: GMLDataset
  endpoint:
    path: /kedro_datasets/networkx/gml
    method: GET
- name: GraphMLDataset
  endpoint:
    path: /kedro_datasets/networkx/graphml
    method: GET
- name: JSONDataset
  endpoint:
    path: /kedro_datasets/networkx/json
    method: GET
- name: CSVDataset
  endpoint:
    path: /kedro_datasets/pandas/csv
    method: GET
- name: DeltaTableDataset
  endpoint:
    path: /kedro_datasets/pandas/delta
    method: GET
- name: ExcelDataset
  endpoint:
    path: /kedro_datasets/pandas/excel
    method: GET
- name: FeatherDataset
  endpoint:
    path: /kedro_datasets/pandas/feather
    method: GET
- name: GBQQueryDataset
  endpoint:
    path: /kedro_datasets/pandas/gbq_query
    method: GET
- name: GBQTableDataset
  endpoint:
    path: /kedro_datasets/pandas/gbq_table
    method: GET
- name: GenericDataset
  endpoint:
    path: /kedro_datasets/pandas/generic
    method: GET
- name: HDFDataset
  endpoint:
    path: /kedro_datasets/pandas/hdf
    method: GET
- name: weather
  endpoint:
    path: s3a://your_bucket/data/01_raw/weather/*
    method: GET
    data_selector: records
    params: {}
- name: weather_with_schema
  endpoint:
    path: s3a://your_bucket/data/01_raw/weather/*
    method: GET
    data_selector: records
    params: {}
- name: weather_cleaned
  endpoint:
    path: data/02_intermediate/data.parquet
    method: GET
    data_selector: records
    params: {}
- name: NetCDFDataset
  endpoint:
    path: /kedro_datasets/netcdf
    method: GET
- name: GMLDataset
  endpoint:
    path: /kedro_datasets/networkx/gml
    method: GET
- name: GraphMLDataset
  endpoint:
    path: /kedro_datasets/networkx/graphml
    method: GET
- name: JSONDataset
  endpoint:
    path: /kedro_datasets/networkx/json
    method: GET
- name: CSVDataset
  endpoint:
    path: /kedro_datasets/pandas/csv
    method: GET
- name: DeltaTableDataset
  endpoint:
    path: /kedro_datasets/pandas/delta_table
    method: GET
- name: ExcelDataset
  endpoint:
    path: /kedro_datasets/pandas/excel
    method: GET
- name: FeatherDataset
  endpoint:
    path: /kedro_datasets/pandas/feather
    method: GET
- name: GBQQueryDataset
  endpoint:
    path: /kedro_datasets/pandas/gbq_query
    method: GET
- name: GBQTableDataset
  endpoint:
    path: /kedro_datasets/pandas/gbq_table
    method: GET
- name: GenericDataset
  endpoint:
    path: /kedro_datasets/pandas/generic
    method: GET
- name: HDFDataset
  endpoint:
    path: /kedro_datasets/pandas/hdf
    method: GET
- name: hive_dataset
  endpoint:
    path: /services/data/vXX.X/sobjects/hive_dataset
    method: GET
    data_selector: records
    params: {}
- name: NetCDFDataset
  endpoint:
    path: /api/v1/netcdf
    method: GET
    data_selector: data
    params: {}
- name: weather
  endpoint:
    path: jdbc:postgresql://localhost/test
    method: GET
    data_selector: records
    params: {}
- name: NetCDFDataset
  endpoint:
    path: /netcdf
    method: GET
    data_selector: data
- name: new_inventory
  endpoint:
    path: data/01_raw/stream/inventory/
    method: GET
    data_selector: records
    params:
      file_format: json
      save_args:
        output_mode: append
        checkpoint: data/04_checkpoint/raw_new_inventory
        header: true
      load_args:
        schema: data/01_raw/schema/inventory_schema.json
- name: svm_dataset
  endpoint:
    path: data/01_raw/location.svm
    method: load
    data_selector: data
    params:
      load_args:
        zero_based: false
- name: cars
  endpoint:
    path: gcs://your_bucket/cars.svm
    method: load
    data_selector: data
    params:
      fs_args:
        project: my-project
      load_args:
        zero_based: false
- name: tensorflow_model
  endpoint:
    path: data/06_models/tensorflow_model.h5
    method: LOAD
    data_selector: model
    params: {}
- name: NetCDFDataset
  endpoint:
    path: /netcdf
    method: GET
    data_selector: data
- name: GMLDataset
  endpoint:
    path: /gml
    method: GET
    data_selector: data
- name: GraphMLDataset
  endpoint:
    path: /graphml
    method: GET
    data_selector: data
- name: JSONDataset
  endpoint:
    path: /json
    method: GET
    data_selector: data
- name: CSVDataset
  endpoint:
    path: /csv
    method: GET
    data_selector: data
- name: DeltaTableDataset
  endpoint:
    path: /deltatable
    method: GET
    data_selector: data
- name: ExcelDataset
  endpoint:
    path: /excel
    method: GET
    data_selector: data
- name: FeatherDataset
  endpoint:
    path: /feather
    method: GET
    data_selector: data
- name: GBQQueryDataset
  endpoint:
    path: /gbqquery
    method: GET
    data_selector: data
- name: GBQTableDataset
  endpoint:
    path: /gbqtable
    method: GET
    data_selector: data
- name: GenericDataset
  endpoint:
    path: /generic
    method: GET
    data_selector: data
- name: HDFDataset
  endpoint:
    path: /hdf
    method: GET
    data_selector: data
- name: alice_book
  endpoint:
    path: data/01_raw/alice.txt
    method: GET
    data_selector: records
    params: {}
- name: NetCDFDataset
  endpoint:
    path: /kedro_datasets/netcdf/NetCDFDataset
    method: GET
- name: GMLDataset
  endpoint:
    path: /kedro_datasets/networkx/GMLDataset
    method: GET
- name: GraphMLDataset
  endpoint:
    path: /kedro_datasets/networkx/GraphMLDataset
    method: GET
- name: JSONDataset
  endpoint:
    path: /kedro_datasets/networkx/JSONDataset
    method: GET
- name: CSVDataset
  endpoint:
    path: /kedro_datasets/pandas/CSVDataset
    method: GET
- name: DeltaTableDataset
  endpoint:
    path: /kedro_datasets/pandas/DeltaTableDataset
    method: GET
- name: ExcelDataset
  endpoint:
    path: /kedro_datasets/pandas/ExcelDataset
    method: GET
- name: FeatherDataset
  endpoint:
    path: /kedro_datasets/pandas/FeatherDataset
    method: GET
- name: GBQQueryDataset
  endpoint:
    path: /kedro_datasets/pandas/GBQQueryDataset
    method: GET
- name: GBQTableDataset
  endpoint:
    path: /kedro_datasets/pandas/GBQTableDataset
    method: GET
- name: GenericDataset
  endpoint:
    path: /kedro_datasets/pandas/GenericDataset
    method: GET
- name: HDFDataset
  endpoint:
    path: /kedro_datasets/pandas/HDFDataset
    method: GET
- name: cars
  endpoint:
    path: data/09_tracking/cars.json
    method: null
    data_selector: null
    params: null
- name: NetCDFDataset
  endpoint:
    path: /NetCDFDataset
    method: GET
    data_selector: records
- name: GMLDataset
  endpoint:
    path: /GMLDataset
    method: GET
    data_selector: records
- name: GraphMLDataset
  endpoint:
    path: /GraphMLDataset
    method: GET
    data_selector: records
- name: JSONDataset
  endpoint:
    path: /JSONDataset
    method: GET
    data_selector: records
- name: CSVDataset
  endpoint:
    path: /CSVDataset
    method: GET
    data_selector: records
- name: DeltaTableDataset
  endpoint:
    path: /DeltaTableDataset
    method: GET
    data_selector: records
- name: ExcelDataset
  endpoint:
    path: /ExcelDataset
    method: GET
    data_selector: records
- name: FeatherDataset
  endpoint:
    path: /FeatherDataset
    method: GET
    data_selector: records
- name: GBQQueryDataset
  endpoint:
    path: /GBQQueryDataset
    method: GET
    data_selector: records
- name: GBQTableDataset
  endpoint:
    path: /GBQTableDataset
    method: GET
    data_selector: records
- name: GenericDataset
  endpoint:
    path: /GenericDataset
    method: GET
    data_selector: records
- name: HDFDataset
  endpoint:
    path: /HDFDataset
    method: GET
    data_selector: records
- name: cars
  endpoint:
    path: data/01_raw/cars.mp4
    method: LOAD
    data_selector: sequence
- name: motorbikes
  endpoint:
    path: s3://your_bucket/data/02_intermediate/company/motorbikes.mp4
    method: LOAD
    data_selector: sequence
    params:
      credentials: dev_s3
- name: cars
  endpoint:
    path: cars.yaml
    method: GET
    data_selector: data
    params: {}
- name: APIDataset
  endpoint:
    path: kedro_datasets/api/APIDataset
    method: GET
- name: BioSequenceDataset
  endpoint:
    path: kedro_datasets/biosequence/BioSequenceDataset
    method: GET
- name: ParquetDataset
  endpoint:
    path: kedro_datasets/dask/ParquetDataset
    method: GET
- name: ManagedTableDataset
  endpoint:
    path: kedro_datasets/databricks/ManagedTableDataset
    method: GET
- name: EmailMessageDataset
  endpoint:
    path: kedro_datasets/email/EmailMessageDataset
    method: GET
- name: GeoJSONDataset
  endpoint:
    path: kedro_datasets/geopandas/GeoJSONDataset
    method: GET
- name: HoloviewsWriter
  endpoint:
    path: kedro_datasets/holoviews/HoloviewsWriter
    method: GET
- name: HFDataset
  endpoint:
    path: kedro_datasets/huggingface/HFDataset
    method: GET
- name: HFTransformerPipelineDataset
  endpoint:
    path: kedro_datasets/huggingface/HFTransformerPipelineDataset
    method: GET
- name: JSONDataset
  endpoint:
    path: kedro_datasets/json/JSONDataset
    method: GET
- name: MatplotlibWriter
  endpoint:
    path: kedro_datasets/matplotlib/MatplotlibWriter
    method: GET
- name: GMLDataset
  endpoint:
    path: kedro_datasets/networkx/GMLDataset
    method: GET
- name: GraphMLDataset
  endpoint:
    path: kedro_datasets/networkx/GraphMLDataset
    method: GET
- name: JSONDataset
  endpoint:
    path: kedro_datasets/networkx/JSONDataset
    method: GET
- name: CSVDataset
  endpoint:
    path: kedro_datasets/pandas/CSVDataset
    method: GET
- name: DeltaTableDataset
  endpoint:
    path: kedro_datasets/pandas/DeltaTableDataset
    method: GET
- name: ExcelDataset
  endpoint:
    path: kedro_datasets/pandas/ExcelDataset
    method: GET
- name: FeatherDataset
  endpoint:
    path: kedro_datasets/pandas/FeatherDataset
    method: GET
- name: GBQQueryDataset
  endpoint:
    path: kedro_datasets/pandas/GBQQueryDataset
    method: GET
- name: GBQTableDataset
  endpoint:
    path: kedro_datasets/pandas/GBQTableDataset
    method: GET
- name: GenericDataset
  endpoint:
    path: kedro_datasets/pandas/GenericDataset
    method: GET
- name: HDFDataset
  endpoint:
    path: kedro_datasets/pandas/HDFDataset
    method: GET
- name: JSONDataset
  endpoint:
    path: kedro_datasets/pandas/JSONDataset
    method: GET
- name: ParquetDataset
  endpoint:
    path: kedro_datasets/pandas/ParquetDataset
    method: GET
- name: SQLQueryDataset
  endpoint:
    path: kedro_datasets/pandas/SQLQueryDataset
    method: GET
- name: SQLTableDataset
  endpoint:
    path: kedro_datasets/pandas/SQLTableDataset
    method: GET
- name: XMLDataset
  endpoint:
    path: kedro_datasets/pandas/XMLDataset
    method: GET
- name: IncrementalDataset
  endpoint:
    path: kedro_datasets/partitions/IncrementalDataset
    method: GET
- name: PartitionedDataset
  endpoint:
    path: kedro_datasets/partitions/PartitionedDataset
    method: GET
- name: PickleDataset
  endpoint:
    path: kedro_datasets/pickle/PickleDataset
    method: GET
- name: ImageDataset
  endpoint:
    path: kedro_datasets/pillow/ImageDataset
    method: GET
- name: JSONDataset
  endpoint:
    path: kedro_datasets/plotly/JSONDataset
    method: GET
- name: PlotlyDataset
  endpoint:
    path: kedro_datasets/plotly/PlotlyDataset
    method: GET
- name: CSVDataset
  endpoint:
    path: kedro_datasets/polars/CSVDataset
    method: GET
- name: EagerPolarsDataset
  endpoint:
    path: kedro_datasets/polars/EagerPolarsDataset
    method: GET
- name: LazyPolarsDataset
  endpoint:
    path: kedro_datasets/polars/LazyPolarsDataset
    method: GET
- name: PickleDataset
  endpoint:
    path: kedro_datasets/redis/PickleDataset
    method: GET
- name: SnowparkTableDataset
  endpoint:
    path: kedro_datasets/snowflake/SnowparkTableDataset
    method: GET
- name: DeltaTableDataset
  endpoint:
    path: kedro_datasets/spark/DeltaTableDataset
    method: GET
- name: SparkDataset
  endpoint:
    path: kedro_datasets/spark/SparkDataset
    method: GET
- name: SparkHiveDataset
  endpoint:
    path: kedro_datasets/spark/SparkHiveDataset
    method: GET
- name: SparkJDBCDataset
  endpoint:
    path: kedro_datasets/spark/SparkJDBCDataset
    method: GET
- name: SparkStreamingDataset
  endpoint:
    path: kedro_datasets/spark/SparkStreamingDataset
    method: GET
- name: SVMLightDataset
  endpoint:
    path: kedro_datasets/svmlight/SVMLightDataset
    method: GET
- name: TensorFlowModelDataset
  endpoint:
    path: kedro_datasets/tensorflow/TensorFlowModelDataset
    method: GET
- name: TextDataset
  endpoint:
    path: kedro_datasets/text/TextDataset
    method: GET
- name: JSONDataset
  endpoint:
    path: kedro_datasets/tracking/JSONDataset
    method: GET
- name: MetricsDataset
  endpoint:
    path: kedro_datasets/tracking/MetricsDataset
    method: GET
- name: VideoDataset
  endpoint:
    path: kedro_datasets/video/VideoDataset
    method: GET
- name: YAMLDataset
  endpoint:
    path: kedro_datasets/yaml/YAMLDataset
    method: GET
- name: GMLDataset
  endpoint:
    path: /api/kedro_datasets/networkx/GMLDataset
    method: GET
- name: GraphMLDataset
  endpoint:
    path: /api/kedro_datasets/networkx/GraphMLDataset
    method: GET
- name: JSONDataset
  endpoint:
    path: /api/kedro_datasets/networkx/JSONDataset
    method: GET
- name: CSVDataset
  endpoint:
    path: /api/kedro_datasets/pandas/CSVDataset
    method: GET
- name: DeltaTableDataset
  endpoint:
    path: /api/kedro_datasets/pandas/DeltaTableDataset
    method: GET
- name: ExcelDataset
  endpoint:
    path: /api/kedro_datasets/pandas/ExcelDataset
    method: GET
- name: FeatherDataset
  endpoint:
    path: /api/kedro_datasets/pandas/FeatherDataset
    method: GET
- name: GBQQueryDataset
  endpoint:
    path: /api/kedro_datasets/pandas/GBQQueryDataset
    method: GET
- name: GBQTableDataset
  endpoint:
    path: /api/kedro_datasets/pandas/GBQTableDataset
    method: GET
- name: GenericDataset
  endpoint:
    path: /api/kedro_datasets/pandas/GenericDataset
    method: GET
- name: HDFDataset
  endpoint:
    path: /api/kedro_datasets/pandas/HDFDataset
    method: GET
- name: JSONDataset
  endpoint:
    path: /api/kedro_datasets/pandas/JSONDataset
    method: GET
- name: ParquetDataset
  endpoint:
    path: /api/kedro_datasets/pandas/ParquetDataset
    method: GET
- name: example_table
  endpoint:
    path: /post
    method: POST
    data_selector: null
    params:
      chunk_size: 1
- name: articles
  endpoint:
    path: /v4/articles
    method: GET
    data_selector: null
    params:
      news_site: NASA
      launch: 65896761-b6ca-4df3-9699-e077a360c52a
- name: BioSequenceDataset
  endpoint:
    path: /kedro_datasets/biosequence/BioSequenceDataset
    method: GET
    data_selector: records
    params: {}
- name: cars
  endpoint:
    path: s3://bucket_name/path/to/folder
    method: GET
    data_selector: records
    params: {}
- name: parquet_dataset
  endpoint:
    path: s3://bucket_name/path/to/folder
    method: GET
    data_selector: records
    params: {}
- name: names_and_ages
  endpoint:
    path: /managed_table/names_and_ages
    method: GET
    data_selector: records
    params: {}
- name: email_message
  endpoint:
    path: /kedro_datasets/email/message_dataset
    method: GET
    data_selector: records
    params: {}
- name: GeoJSONDataset
  endpoint:
    path: ''
    method: ''
    data_selector: ''
    params: {}
- name: GraphMLDataset
  endpoint:
    path: /kedro_datasets/networkx/GraphMLDataset
    method: GET
- name: JSONDataset
  endpoint:
    path: /kedro_datasets/networkx/JSONDataset
    method: GET
- name: CSVDataset
  endpoint:
    path: /kedro_datasets/pandas/CSVDataset
    method: GET
- name: DeltaTableDataset
  endpoint:
    path: /kedro_datasets/pandas/DeltaTableDataset
    method: GET
- name: ExcelDataset
  endpoint:
    path: /kedro_datasets/pandas/ExcelDataset
    method: GET
- name: FeatherDataset
  endpoint:
    path: /kedro_datasets/pandas/FeatherDataset
    method: GET
- name: GBQQueryDataset
  endpoint:
    path: /kedro_datasets/pandas/GBQQueryDataset
    method: GET
- name: GBQTableDataset
  endpoint:
    path: /kedro_datasets/pandas/GBQTableDataset
    method: GET
- name: GenericDataset
  endpoint:
    path: /kedro_datasets/pandas/GenericDataset
    method: GET
- name: HDFDataset
  endpoint:
    path: /kedro_datasets/pandas/HDFDataset
    method: GET
- name: JSONDataset
  endpoint:
    path: /kedro_datasets/pandas/JSONDataset
    method: GET
- name: ParquetDataset
  endpoint:
    path: /kedro_datasets/pandas/ParquetDataset
    method: GET
- name: SQLQueryDataset
  endpoint:
    path: /kedro_datasets/pandas/SQLQueryDataset
    method: GET
- name: HoloviewsWriter
  endpoint:
    path: /kedro_datasets/holoviews/HoloviewsWriter
    method: GET
    data_selector: records
    params: {}
- name: yelp_reviews
  endpoint:
    path: /datasets/yelp_review_full
    method: GET
    data_selector: train
    params: {}
- name: summarizer_model
  endpoint:
    path: summarization
    method: POST
    data_selector: output
    params: {}
- name: fill_mask_model
  endpoint:
    path: fill-mask
    method: POST
    data_selector: output
    params:
      model_name: Twitter/twhin-bert-base
- name: text_classification_model
  endpoint:
    path: text-classification
    method: POST
    data_selector: output
    params:
      model_name: papluca/xlm-roberta-base-language-detection
- name: cars
  endpoint:
    path: gcs://your_bucket/cars.json
    method: GET
- name: output_plot
  endpoint:
    path: data/08_reporting/output_plot.png
    method: save
    data_selector: records
- name: pdf_plot
  endpoint:
    path: data/08_reporting/output_plot.pdf
    method: save
    data_selector: records
- name: plots_dict
  endpoint:
    path: data/08_reporting/plots
    method: save
    data_selector: records
- name: plots_list
  endpoint:
    path: data/08_reporting/plots
    method: save
    data_selector: records
- name: GMLDataset
  endpoint:
    path: /load
    method: POST
    data_selector: data
    params: {}
- name: GraphMLDataset
  endpoint:
    path: /kedro_datasets/networkx/GraphMLDataset
    method: GET
    data_selector: records
    params: {}
- name: GraphMLDataset
  endpoint:
    path: /services/data/vXX.X/sobjects/GraphMLDataset
    method: GET
- name: JSONDataset
  endpoint:
    path: /kedro_datasets/networkx/JSONDataset
    method: GET
- name: GraphMLDataset
  endpoint:
    path: /dataset/graphml
    method: GET
    data_selector: data
    params: {}
- name: cars
  endpoint:
    path: data/01_raw/company/cars.csv
    method: GET
    data_selector: records
    params: {}
- name: motorbikes
  endpoint:
    path: s3://your_bucket/data/02_intermediate/company/motorbikes.csv
    method: GET
    data_selector: records
    params:
      credentials: dev_s3
- name: boats_filesystem
  endpoint:
    path: data/01_raw/boats
    method: save
    data_selector: version
    params: {}
- name: boats_databricks_unity_catalog
  endpoint:
    path: simple_database/simple_table
    method: save
    data_selector: version
    params: {}
- name: trucks_aws_glue_catalog
  endpoint:
    path: db_schema/db_table
    method: save
    data_selector: version
    params: {}
- name: GraphMLDataset
  endpoint:
    path: /kedro_datasets/networkx/GraphMLDataset
    method: GET
- name: JSONDataset
  endpoint:
    path: /kedro_datasets/networkx/JSONDataset
    method: GET
- name: CSVDataset
  endpoint:
    path: /kedro_datasets/pandas/CSVDataset
    method: GET
- name: DeltaTableDataset
  endpoint:
    path: /kedro_datasets/pandas/DeltaTableDataset
    method: GET
- name: ExcelDataset
  endpoint:
    path: /kedro_datasets/pandas/ExcelDataset
    method: GET
- name: FeatherDataset
  endpoint:
    path: /kedro_datasets/pandas/FeatherDataset
    method: GET
- name: GBQQueryDataset
  endpoint:
    path: /kedro_datasets/pandas/GBQQueryDataset
    method: GET
- name: GBQTableDataset
  endpoint:
    path: /kedro_datasets/pandas/GBQTableDataset
    method: GET
- name: GenericDataset
  endpoint:
    path: /kedro_datasets/pandas/GenericDataset
    method: GET
- name: HDFDataset
  endpoint:
    path: /kedro_datasets/pandas/HDFDataset
    method: GET
- name: JSONDataset
  endpoint:
    path: /kedro_datasets/pandas/JSONDataset
    method: GET
- name: ParquetDataset
  endpoint:
    path: /kedro_datasets/pandas/ParquetDataset
    method: GET
- name: SQLQueryDataset
  endpoint:
    path: /kedro_datasets/pandas/SQLQueryDataset
    method: GET
- name: rockets
  endpoint:
    path: gcs://your_bucket/rockets.xlsx
    method: GET
    data_selector: records
    params: {}
- name: shuttles
  endpoint:
    path: data/01_raw/shuttles.xlsx
    method: GET
    data_selector: records
    params: {}
- name: trains
  endpoint:
    path: data/02_intermediate/company/trains.xlsx
    method: GET
    data_selector: records
    params: {}
- name: cars
  endpoint:
    path: data/01_raw/company/cars.feather
    method: GET
    data_selector: records
    params: {}
- name: motorbikes
  endpoint:
    path: s3://your_bucket/data/02_intermediate/company/motorbikes.feather
    method: GET
    data_selector: records
    params:
      credentials: dev_s3
- name: GraphMLDataset
  endpoint:
    path: /graphml
    method: GET
- name: JSONDataset
  endpoint:
    path: /json
    method: GET
- name: CSVDataset
  endpoint:
    path: /csv
    method: GET
- name: DeltaTableDataset
  endpoint:
    path: /delta
    method: GET
- name: ExcelDataset
  endpoint:
    path: /excel
    method: GET
- name: FeatherDataset
  endpoint:
    path: /feather
    method: GET
- name: GBQQueryDataset
  endpoint:
    path: /gbq_query
    method: GET
- name: GBQTableDataset
  endpoint:
    path: /gbq_table
    method: GET
- name: GenericDataset
  endpoint:
    path: /generic
    method: GET
- name: HDFDataset
  endpoint:
    path: /hdf
    method: GET
- name: JSONDataset
  endpoint:
    path: /json
    method: GET
- name: ParquetDataset
  endpoint:
    path: /parquet
    method: GET
- name: SQLQueryDataset
  endpoint:
    path: /sql_query
    method: GET
- name: vehicles
  endpoint:
    path: /spaceflights/shuttles
    method: GET
    data_selector: records
    params:
      sql: select shuttle, shuttle_id from spaceflights.shuttles;
- name: dataset_1
  endpoint:
    path: /dataset_1/table_a
    method: GET
    data_selector: records
    params:
      sql: SELECT * FROM dataset_1.table_a
- name: vehicles
  endpoint:
    path: ''
    method: ''
    data_selector: ''
    params: {}
- name: JSONDataset
  endpoint:
    path: /kedro_datasets/networkx/JSONDataset
    method: GET
- name: CSVDataset
  endpoint:
    path: /kedro_datasets/pandas/CSVDataset
    method: GET
- name: DeltaTableDataset
  endpoint:
    path: /kedro_datasets/pandas/DeltaTableDataset
    method: GET
- name: ExcelDataset
  endpoint:
    path: /kedro_datasets/pandas/ExcelDataset
    method: GET
- name: FeatherDataset
  endpoint:
    path: /kedro_datasets/pandas/FeatherDataset
    method: GET
- name: GBQQueryDataset
  endpoint:
    path: /kedro_datasets/pandas/GBQQueryDataset
    method: GET
- name: GBQTableDataset
  endpoint:
    path: /kedro_datasets/pandas/GBQTableDataset
    method: GET
- name: GenericDataset
  endpoint:
    path: /kedro_datasets/pandas/GenericDataset
    method: GET
- name: HDFDataset
  endpoint:
    path: /kedro_datasets/pandas/HDFDataset
    method: GET
- name: JSONDataset
  endpoint:
    path: /kedro_datasets/pandas/JSONDataset
    method: GET
- name: ParquetDataset
  endpoint:
    path: /kedro_datasets/pandas/ParquetDataset
    method: GET
- name: SQLQueryDataset
  endpoint:
    path: /kedro_datasets/pandas/SQLQueryDataset
    method: GET
- name: cars
  endpoint:
    path: s3://data/01_raw/company/cars.csv
    method: GET
    data_selector: records
    params: {}
- name: flights
  endpoint:
    path: data/01_raw/airplanes.sas7bdat
    method: GET
    data_selector: records
    params: {}
- name: hdf_dataset
  endpoint:
    path: s3://my_bucket/raw/sensor_reading.h5
    method: GET
    data_selector: data
    params:
      credentials: aws_s3_creds
- name: GraphMLDataset
  endpoint:
    path: /kedro_datasets/networkx/GraphMLDataset.html
    method: GET
- name: JSONDataset
  endpoint:
    path: /kedro_datasets/networkx/JSONDataset.html
    method: GET
- name: CSVDataset
  endpoint:
    path: /kedro_datasets/pandas/CSVDataset.html
    method: GET
- name: DeltaTableDataset
  endpoint:
    path: /kedro_datasets/pandas/DeltaTableDataset.html
    method: GET
- name: ExcelDataset
  endpoint:
    path: /kedro_datasets/pandas/ExcelDataset.html
    method: GET
- name: FeatherDataset
  endpoint:
    path: /kedro_datasets/pandas/FeatherDataset.html
    method: GET
- name: GBQQueryDataset
  endpoint:
    path: /kedro_datasets/pandas/GBQQueryDataset.html
    method: GET
- name: GBQTableDataset
  endpoint:
    path: /kedro_datasets/pandas/GBQTableDataset.html
    method: GET
- name: GenericDataset
  endpoint:
    path: /kedro_datasets/pandas/GenericDataset.html
    method: GET
- name: HDFDataset
  endpoint:
    path: /kedro_datasets/pandas/HDFDataset.html
    method: GET
- name: JSONDataset
  endpoint:
    path: /kedro_datasets/pandas/JSONDataset.html
    method: GET
- name: ParquetDataset
  endpoint:
    path: /kedro_datasets/pandas/ParquetDataset.html
    method: GET
- name: SQLQueryDataset
  endpoint:
    path: /kedro_datasets/pandas/SQLQueryDataset.html
    method: GET
- name: clickstream_dataset
  endpoint:
    path: abfs://landing_area/primary/click_stream.json
    method: GET
    data_selector: records
    params: {}
- name: json_dataset
  endpoint:
    path: data/01_raw/Video_Games.json
    method: GET
    data_selector: records
    params:
      load_args:
        lines: true
- name: GraphMLDataset
  endpoint:
    path: /GraphMLDataset
    method: GET
- name: boats
  endpoint:
    path: data/01_raw/boats.parquet
    method: LOAD
    data_selector: data
    params: {}
- name: trucks
  endpoint:
    path: abfs://container/02_intermediate/trucks.parquet
    method: LOAD
    data_selector: data
    params:
      credentials: dev_abs
      load_args:
        columns:
        - name
        - gear
        - disp
        - wt
        index: name
      save_args:
        compression: GZIP
        partition_on:
        - name
- name: shuttle_id_dataset
  endpoint:
    path: /services/data/vXX.X/sobjects/shuttle_id_dataset
    method: GET
    data_selector: records
    params: {}
- name: mssql_dataset
  endpoint:
    path: /services/data/vXX.X/sobjects/mssql_dataset
    method: GET
    data_selector: records
    params: {}
- name: shuttles_table_dataset
  endpoint:
    path: /services/data/vXX.X/sobjects/shuttles
    method: GET
    data_selector: records
    params: {}
- name: GraphMLDataset
  endpoint:
    path: /datasets/networkx/GraphMLDataset
    method: GET
- name: JSONDataset
  endpoint:
    path: /datasets/networkx/JSONDataset
    method: GET
- name: CSVDataset
  endpoint:
    path: /datasets/pandas/CSVDataset
    method: GET
- name: DeltaTableDataset
  endpoint:
    path: /datasets/pandas/DeltaTableDataset
    method: GET
- name: ExcelDataset
  endpoint:
    path: /datasets/pandas/ExcelDataset
    method: GET
- name: FeatherDataset
  endpoint:
    path: /datasets/pandas/FeatherDataset
    method: GET
- name: GBQQueryDataset
  endpoint:
    path: /datasets/pandas/GBQQueryDataset
    method: GET
- name: GBQTableDataset
  endpoint:
    path: /datasets/pandas/GBQTableDataset
    method: GET
- name: GenericDataset
  endpoint:
    path: /datasets/pandas/GenericDataset
    method: GET
- name: HDFDataset
  endpoint:
    path: /datasets/pandas/HDFDataset
    method: GET
- name: JSONDataset
  endpoint:
    path: /datasets/pandas/JSONDataset
    method: GET
- name: ParquetDataset
  endpoint:
    path: /datasets/pandas/ParquetDataset
    method: GET
- name: SQLQueryDataset
  endpoint:
    path: /datasets/pandas/SQLQueryDataset
    method: GET
- name: XMLDataset
  endpoint:
    path: /kedro_datasets/pandas/XMLDataset
    method: GET
    data_selector: records
    params: {}
- name: GraphMLDataset
  endpoint:
    path: /kedro_datasets/networkx/GraphMLDataset
    method: GET
- name: JSONDataset
  endpoint:
    path: /kedro_datasets/networkx/JSONDataset
    method: GET
- name: CSVDataset
  endpoint:
    path: /kedro_datasets/pandas/CSVDataset
    method: GET
- name: DeltaTableDataset
  endpoint:
    path: /kedro_datasets/pandas/DeltaTableDataset
    method: GET
- name: ExcelDataset
  endpoint:
    path: /kedro_datasets/pandas/ExcelDataset
    method: GET
- name: FeatherDataset
  endpoint:
    path: /kedro_datasets/pandas/FeatherDataset
    method: GET
- name: GBQQueryDataset
  endpoint:
    path: /kedro_datasets/pandas/GBQQueryDataset
    method: GET
- name: GBQTableDataset
  endpoint:
    path: /kedro_datasets/pandas/GBQTableDataset
    method: GET
- name: GenericDataset
  endpoint:
    path: /kedro_datasets/pandas/GenericDataset
    method: GET
- name: HDFDataset
  endpoint:
    path: /kedro_datasets/pandas/HDFDataset
    method: GET
- name: JSONDataset
  endpoint:
    path: /kedro_datasets/pandas/JSONDataset
    method: GET
- name: ParquetDataset
  endpoint:
    path: /kedro_datasets/pandas/ParquetDataset
    method: GET
- name: SQLQueryDataset
  endpoint:
    path: /kedro_datasets/pandas/SQLQueryDataset
    method: GET
- name: IncrementalDataset
  endpoint:
    path: /kedro_datasets/partitions/incremental_dataset
    method: GET
    data_selector: source
    params: {}
- name: station_data
  endpoint:
    path: data/03_primary/station_data
    method: unknown
    data_selector: unknown
    params: {}
- name: GraphMLDataset
  endpoint:
    path: /kedro_datasets/networkx/GraphMLDataset
    method: GET
- name: JSONDataset
  endpoint:
    path: /kedro_datasets/networkx/JSONDataset
    method: GET
- name: CSVDataset
  endpoint:
    path: /kedro_datasets/pandas/CSVDataset
    method: GET
- name: DeltaTableDataset
  endpoint:
    path: /kedro_datasets/pandas/DeltaTableDataset
    method: GET
- name: ExcelDataset
  endpoint:
    path: /kedro_datasets/pandas/ExcelDataset
    method: GET
- name: FeatherDataset
  endpoint:
    path: /kedro_datasets/pandas/FeatherDataset
    method: GET
- name: GBQQueryDataset
  endpoint:
    path: /kedro_datasets/pandas/GBQQueryDataset
    method: GET
- name: GBQTableDataset
  endpoint:
    path: /kedro_datasets/pandas/GBQTableDataset
    method: GET
- name: GenericDataset
  endpoint:
    path: /kedro_datasets/pandas/GenericDataset
    method: GET
- name: HDFDataset
  endpoint:
    path: /kedro_datasets/pandas/HDFDataset
    method: GET
- name: JSONDataset
  endpoint:
    path: /kedro_datasets/pandas/JSONDataset
    method: GET
- name: ParquetDataset
  endpoint:
    path: /kedro_datasets/pandas/ParquetDataset
    method: GET
- name: SQLQueryDataset
  endpoint:
    path: /kedro_datasets/pandas/SQLQueryDataset
    method: GET
- name: test_model
  endpoint:
    path: data/07_model_output/test_model.pkl
    method: save
    data_selector: data
    params: {}
- name: final_model
  endpoint:
    path: s3://your_bucket/final_model.pkl.lz4
    method: save
    data_selector: data
    params:
      compress: lz4
- name: ImageDataset
  endpoint:
    path: /kedro_datasets/pillow/ImageDataset
    method: GET
    data_selector: data
    params: {}
- name: GraphMLDataset
  endpoint:
    path: /kedro_datasets/networkx/GraphMLDataset
    method: GET
- name: JSONDataset
  endpoint:
    path: /kedro_datasets/networkx/JSONDataset
    method: GET
- name: CSVDataset
  endpoint:
    path: /kedro_datasets/pandas/CSVDataset
    method: GET
- name: DeltaTableDataset
  endpoint:
    path: /kedro_datasets/pandas/DeltaTableDataset
    method: GET
- name: ExcelDataset
  endpoint:
    path: /kedro_datasets/pandas/ExcelDataset
    method: GET
- name: FeatherDataset
  endpoint:
    path: /kedro_datasets/pandas/FeatherDataset
    method: GET
- name: GBQQueryDataset
  endpoint:
    path: /kedro_datasets/pandas/GBQQueryDataset
    method: GET
- name: GBQTableDataset
  endpoint:
    path: /kedro_datasets/pandas/GBQTableDataset
    method: GET
- name: GenericDataset
  endpoint:
    path: /kedro_datasets/pandas/GenericDataset
    method: GET
- name: HDFDataset
  endpoint:
    path: /kedro_datasets/pandas/HDFDataset
    method: GET
- name: JSONDataset
  endpoint:
    path: /kedro_datasets/pandas/JSONDataset
    method: GET
- name: ParquetDataset
  endpoint:
    path: /kedro_datasets/pandas/ParquetDataset
    method: GET
- name: SQLQueryDataset
  endpoint:
    path: /kedro_datasets/pandas/SQLQueryDataset
    method: GET
- name: scatter_plot
  endpoint:
    path: data/08_reporting/scatter_plot.json
    method: save
    data_selector: records
    params: {}
- name: test
  endpoint:
    path: test.json
    method: load
    data_selector: records
    params: {}
- name: GraphMLDataset
  endpoint:
    path: /GraphMLDataset
    method: GET
- name: JSONDataset
  endpoint:
    path: /JSONDataset
    method: GET
- name: CSVDataset
  endpoint:
    path: /CSVDataset
    method: GET
- name: DeltaTableDataset
  endpoint:
    path: /DeltaTableDataset
    method: GET
- name: ExcelDataset
  endpoint:
    path: /ExcelDataset
    method: GET
- name: FeatherDataset
  endpoint:
    path: /FeatherDataset
    method: GET
- name: GBQQueryDataset
  endpoint:
    path: /GBQQueryDataset
    method: GET
- name: GBQTableDataset
  endpoint:
    path: /GBQTableDataset
    method: GET
- name: GenericDataset
  endpoint:
    path: /GenericDataset
    method: GET
- name: HDFDataset
  endpoint:
    path: /HDFDataset
    method: GET
- name: JSONDataset
  endpoint:
    path: /JSONDataset
    method: GET
- name: ParquetDataset
  endpoint:
    path: /ParquetDataset
    method: GET
- name: SQLQueryDataset
  endpoint:
    path: /SQLQueryDataset
    method: GET
- name: bar_plot
  endpoint:
    path: data/08_reporting/bar_plot.json
    method: save
    data_selector: plotly_args
    params: {}
- name: scatter_plot
  endpoint:
    path: scatter_plot.json
    method: save
    data_selector: plotly_args
    params: {}
- name: cars
  endpoint:
    path: data/01_raw/company/cars.csv
    method: GET
    data_selector: records
    params: {}
- name: motorbikes
  endpoint:
    path: s3://your_bucket/data/02_intermediate/company/motorbikes.csv
    method: GET
    data_selector: records
    params:
      credentials: dev_s3
- name: cars
  endpoint:
    path: s3://data/01_raw/company/cars.parquet
    method: LOAD
    data_selector: data
    params:
      load_args:
        low_memory: true
      save_args:
        compression: snappy
notes:
- The dataset is write-only, it is versioned by default and only takes metrics of
  numeric values.
- Kedro can be used on Windows, macOS or Linux.
- Installation prerequisites include a Python 3.9+ and git.
- The tutorial takes approximately 30 minutes to complete.
- You will work in the terminal and by inspecting project files in an IDE or text
  editor. There is no Jupyter notebook for the project.
- We recommend that you use the same version of Kedro that was most recently used
  to test this tutorial (0.19.0).
- Do not commit data to version control.
- Do not commit notebook output cells (data can easily sneak into notebooks when you
  don't delete output cells).
- Do not commit credentials in conf/. Use only the conf/local/ folder for sensitive
  information like access credentials.
- Versioning is enabled for regressor.
- Application settings is distinct from run time configuration, which is stored in
  the conf folder and can vary by configuration environment.
- The package_name should be a valid Python package name and the project_name should
  be a human-readable name. They are both mandatory keys for your project.
- kedro_init_version specifies the version of Kedro the project was created with.
- Pipeline execution completed successfully.
- Kedro projects can be explored using Jupyter notebooks.
- Kedro requires [tool.kedro] section in pyproject.toml to define project metadata.
- An empty settings.py is required, even if no settings are defined.
- The configuration file must contain output_dir, project_name, repo_name, and python_package.
- Do not put private access credentials in the base configuration folder or any other
  configuration environment folder that is stored in version control.
- Do not add any local configuration to version control.
- We do not recommend that you load and manipulate a data catalog directly in a Kedro
  node. Nodes are designed to be pure functions and thus should remain agnostic of
  I/O.
- ConfigLoader and TemplatedConfigLoader have been removed in Kedro 0.19.0.
- If you both specify the KEDRO_ENV environment variable and provide the --env argument
  to a CLI command, the CLI argument takes precedence.
- OmegaConfigLoader supports only yaml and json file formats.
- The CONFIG_LOADER_ARGS variable is no longer needed to find globals.yml.
- By default, Kedro is set up to use the kedro.config.OmegaConfigLoader class.
- You can implement a custom configuration loader by extending the kedro.config.AbstractConfigLoader
  class.
- To use this custom configuration loader, set it as the project configuration loader
  in src/<package_name>/settings.py.
- You can only use the resolver in credentials.yml and not in catalog or parameter
  files.
- This merge strategy setting only applies to configuration files in different environments.
- This is an advanced feature and should be used with caution. We do not recommend
  using environment variables for configurations other than credentials.
- Parameter keys are always treated as strings.
- Parameter values are converted to a float or an integer number if the corresponding
  conversion succeeds; otherwise, they are also treated as string.
- Datasets are not included in the core Kedro package from Kedro version 0.19.0. Import
  them from the kedro-datasets package instead.
- From version 2.0.0 of kedro-datasets, all dataset names have changed to replace
  the capital letter 'S' in 'DataSet' with a lower case 's'. For example, CSVDataSet
  is now CSVDataset.
- From version 2.0.0 of kedro-datasets, all dataset names have changed to replace
  the capital letter "S" in "DataSet" with a lower case "s".
- Distributed systems play an increasingly important role in ETL data pipelines.
- Each individual file inside a given location is called a partition.
- Partitioned and incremental datasets are supported.
- Lazy saving is the default behaviour, meaning that if a Callable type is provided,
  the dataset will be written after the after_node_run hook is executed.
- The checkpoint file is only created after the partitioned dataset is explicitly
  confirmed.
- Writing to an existing partition may result in its data being overwritten, if this
  case is not specifically handled by the underlying dataset implementation.
- Specification of force_checkpoint is also supported via the shorthand notation.
- If you need to force the partitioned dataset to load all available partitions, set
  checkpoint to an empty string.
- Datasets are not included in the core Kedro package from Kedro version 0.19.0.
- Use SQLAlchemy compatible database connection string.
- From version 2.0.0 of kedro-datasets, all dataset names have changed to replace
  the capital letter 'S' in 'DataSet' with a lower case 's'.
- Saving None to a dataset is not allowed!
- Node or tag names must ONLY contain letters, digits, hyphens, underscores and/or
  periods. Other symbols are not permitted.
- Kedro uses SequentialRunner by default.
- ThreadRunner doesn't support asynchronous load-input or save-output operations.
- If you specify kedro run without the --pipeline option, it runs the __default__
  pipeline from the dictionary returned by register_pipelines().
- SequentialRunner is used by default in Kedro.
- ParallelRunner requires SharedMemoryDataCatalog for multiprocessing.
- The Kedro CLI selects the correct catalog automatically.
- When using the Python API, you must explicitly choose the appropriate catalog based
  on the runner you select.
- To see the full list of available CLI options, you can run `kedro pipeline create
  --help`.
- In Kedro, you cannot run pipelines with the same node names.
- You can use `kedro run --namespaces=< namespace1,namespace2 >` to run the specific
  namespaces.
- The mapping returned by find_pipelines() can be modified.
- From kedro-datasets version 3.0.0 onwards, the names of the optional dataset-level
  dependencies have been normalised to follow PEP 685. The '.' character has been
  replaced with a '-' character and the names are in lowercase.
- Uses OAuth2 with refresh token  requires setup of connected app in api
- Some objects like Contact may return nulls in deeply nested fields
- If the KEDRO_LOGGING_CONFIG environment variable is not set, Kedro will use the
  default logging configuration.
- Automated testing allows many tests across the whole code base to be run in seconds.
- Tests should be named as descriptively as possible.
- Code formatting guidelines set a standard for the layout of your code, for stylistic
  elements such as use of line breaks and whitespace.
- Linting tools check your code for errors such as a missing bracket or line indent.
- 'Use the following commands to run lint checks: ruff format --check <project_root>,
  ruff check <project_root>'
- Automate the process of formatting and linting with pre-commit hooks.
- Our debugging documentation has moved. Please see our existing guides.
- If your pipeline is sizeable, you may want to run it across separate machines.
- We also have legacy documentation pages for certain deployment targets, but these
  have not been tested against recent Kedro releases.
- Kedro builds the package into the `dist` folder of the project as a `.whl` file.
- The resulting `.whl` packages only contain the Python source code of the Kedro pipeline.
- Once the packaged project is installed, you will need to add a conf folder
- a data folder if the pipeline loads/saves local data
- Repositories on Docker Hub are set to public visibility by default. You can change
  your project to private on the Docker Hub website.
- The resulting .whl package only contains the Python source code of your Kedro pipeline,
  not any of the conf/ and data/ subfolders nor the pyproject.toml file.
- Once you have copied your Kedro project to the server, you need to follow these
  steps to install all project requirements and run the project.
- Containerise the entire pipeline/project for better dependency management.
- Recommended to use Docker for containerisation.
- Execute each Kedro node in an isolated Kubernetes pod using KubernetesPodOperator
- Uses Kedro with Airflow for orchestrating data pipelines
- All datasets must be registered in the DataCatalog and stored in persistent storage
- By default, this approach runs each node in an isolated Docker container.
- You can choose to run multiple nodes together within the same container.
- Python applications on Amazon Elastic MapReduce (EMR) have traditionally managed
  dependencies using bootstrap actions.
- Some applications may need a different approach, such as Custom Python version.
- With a custom Docker image you can package a specific Python version along with
  all required dependencies into a single immutable container.
- EMR Serverless is typically used for pipelines that are either fully or partially
  dependent on PySpark.
- Some applications may need a different approach, such as custom Python version.
- The documented approach has only been tested with the above options.
- On making changes to the custom image, and rebuilding and pushing to ECR, be sure
  to restart the EMR Serverless application before submitting a job if your application
  is already started.
- Ensure that you have s3fs>=0.3.0,<0.5 defined in your requirements.txt so the data
  can be read from S3.
- Ensure all nodes' inputs and outputs have a persistent location on S3, since MemoryDataset
  can't be shared between AWS Lambda functions.
- AWS Lambda function can now use a container image up to 10 GB in size.
- Each Lambda function has a 15-minute timeout, 10GB maximum memory limit and 10GB
  container image code package size limit.
- Supports distributed training in PyTorch/TensorFlow/MPI
- Works well with Azure ML native MLflow integration
- Dask offers both a default, single-machine scheduler and a more sophisticated, distributed
  scheduler.
- Uses Dask to distribute execution of Nodes in the Pipeline
- To connect to an existing Dask cluster, you'll need to set the Dask-related configuration.
- Choose a workflow that aligns best with your project's requirements, whether that's
  quick development, notebook-based coding, or a production-ready setup.
- Create a GitHub personal access token for authentication. Use this token as the
  password when pushing commits via HTTPS.
- Create a GitHub personal access token for authentication.
- Keep the repository private and don't commit to it yet.
- If your cluster terminates, you must re-run your entire notebook, as libraries installed
  using `%pip install ...` are ephemeral.
- The `dbx` package was deprecated by Databricks, and dbx workflow documentation is
  moved to a new page.
- If you prefer to develop projects in notebooks rather than in an IDE, you should
  follow our guide on how to develop a Kedro project within a Databricks workspace
  instead.
- Your databricks host must include the protocol (`https://`).
- If you are not using the `databricks-iris` starter to create a Kedro project, and
  you are working with a version of Kedro earlier than 0.19.0, then you should disable
  file-based logging to prevent Kedro from attempting to write to the read-only file
  system.
- While it is generally not recommended to utilise all-purpose compute for running
  jobs, it is feasible to configure a Databricks job for testing purposes.
- Your Databricks host must include the protocol (`https://`).
- If you are not using the `databricks-iris` starter to create a Kedro project, then
  you should disable file-based logging to prevent Kedro from attempting to write
  to the read-only file system.
- Requires setup of Databricks CLI for authentication
- dbx is deprecated in 2023, the recommended workflow now is to use Databricks Asset
  Bundles.
- Kedro-Viz can be launched in a new browser tab with the %run_viz line magic
- This deployment has been tested using Kedro 0.18.10 with Prefect version 2.10.17.
- If you want to deploy with Prefect 1.0, we recommend you review earlier versions
  of Kedro's Prefect deployment documentation.
- When running a Kedro project locally, ensure to manually create a .telemetry file.
- When you run a Kedro project locally, you are asked on the first kedro command for
  the project, but in this use case, the project will hang unless you follow these
  instructions.
- Be sure that your Prefect Server is up and running.
- Verify that the deployment script arguments match the work pool and work queue names.
- This page contains outdated documentation that has not been tested against recent
  Kedro releases.
- Each node will run in its own container.
- For the purpose of this walk-through, we will use an AWS S3 bucket for datasets;
  therefore AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY environment variables must
  be set to have an ability to communicate with S3.
- The Argo Workflows is defined as the dependencies between tasks using a directed-acyclic
  graph (DAG).
- AWS Batch requires configuration of IAM roles and job definitions.
- Ensure to create a job queue for AWS Batch jobs.
- Ensure you have the necessary AWS credentials in place before moving on.
- Some prerequisites need to be in place before using AWS Batch.
- Kedro defines Hook specifications for particular execution points where users can
  inject additional behaviour.
- To add Hooks to your Kedro project, you must create or modify the file src/<package_name>/hooks.py
  to define a Hook implementation.
- The name of a module that contains Hooks implementation is arbitrary and is not
  restricted to hooks.py.
- Auto-discovered Hooks will run first, followed by the ones specified in settings.py.
- In general, Hook execution order is not guaranteed and you should not rely on it.
- Uses Hooks to customize dataset load and save methods
- Recommended to use `before_dataset_loaded`/`after_dataset_loaded` and `before_dataset_saved`/`after_dataset_saved`
  Hooks
- Recommended to use `after_context_created` Hook to add credentials to the session's
  config loader instance from any external credentials manager
- Uses Hooks to customise the dataset load and save methods where appropriate.
- DefaultAzureCredential() is Azure's recommended approach to authorise access to
  data in your storage accounts.
- A hook class for creating a post mortem debugging with the PDB debugger whenever
  an error is triggered within a pipeline.
- You can use the before_node_run and after_node_run Hooks to add extra behavior before
  and after a node's execution.
- Uses Hooks to customise the dataset load and save methods
- Recommended to use before_dataset_loaded/after_dataset_loaded and before_dataset_saved/after_dataset_saved
  Hooks
- 'Install dependencies: pip install memory_profiler'
- 'Install dependencies: pip install great-expectations'
- Map expectation to dataset using DATASET_EXPECTATION_MAPPING
- KedroSession decouples Kedro's library components from any session data.
- If your starter is stored on a git repository, Kedro defaults to use a tag or branch
  labelled with your version of Kedro.
- If you prefer not to follow this structure, you should override it with the checkout
  flag.
- When the same top-level key appears in any two config files located in the same
  (sub)directory, a ValueError is raised.
- When the same key appears in any two config files located in different (sub)directories,
  the last processed config path takes precedence and overrides this key and any sub-keys.
- This version of the OmegaConfigLoader does not support any of the built-in OmegaConf
  resolvers.
- Support for resolvers might be added in future versions.
- KedroSession is responsible for managing the lifecycle of a Kedro run.
- Requires installation of dependencies as specified in requirements.txt
- Kernel name is based on the package name derived from pyproject.toml
- This API is primarily for managing Kedro projects via CLI commands.
- Ensure the environment is set before executing commands.
- This function will no longer be necessary from Kedro 0.19.*, in which default node
  names will no longer contain commas
- Cannot use the --checkout flag without a --starter value.
- Cannot use the --directory flag without a --starter value.
- Cannot use the --starter flag with the --example and/or --tools flag.
- 'KedroContextError: If there is a mismatch between Kedro project version and package
  version.'
- Hooks to be invoked after a data catalog is created.
- Hooks to be invoked after a dataset is loaded from the catalog.
- Pipeline can include multiple nodes and parameters.
- Circular dependencies can raise errors.
- Kedro uses hooks for plugin management.
- CatalogProtocol provides methods for managing datasets.
- Hooks are invoked during the lifecycle of a pipeline run.
- Projects created using Kedro 0.18.3 and higher call this function to autoregister
  pipelines upon creation/addition.
- A specialized DataCatalog for managing datasets in a shared memory context.
- Some objects like SharedData may return nulls in deeply nested fields
- This method is only applicable to catalogs that contain datasets initialized with
  static, primitive parameters.
- The DataCatalog provides a unified interface for loading and saving datasets.
- Supports features such as lazy loading, versioning, and dynamic dataset creation.
- If the configuration is invalid, it raises a `DatasetError` with a helpful error
  message.
- A centralized registry for managing datasets in a Kedro project.
- Checks whether registered dataset exists by calling its `exists()` method.
- Raises a warning and returns False if `exists()` is not implemented.
- This class is the core component of Kedro's data management system, allowing datasets
  to be defined, accessed, and manipulated in a consistent and reusable way.
- The catalog combines datasets passed directly via the datasets argument and dynamic
  datasets resolved from config (e.g., from YAML).
- Ensures that datasets are serializable and synchronized across threads or processes.
- Validate the catalog to ensure all datasets are serializable and compatible with
  multiprocessing.
- Non-serializable datasets or datasets that rely on single-process memory cannot
  be used in a multiprocessing context.
- This catalog combines datasets passed directly via the datasets argument and dynamic
  datasets resolved from config.
- This method checks that all datasets in the catalog are serializable and do not
  include non-proxied memory datasets as outputs.
- Supports advanced features like pattern matching and user-set catch-all patterns.
- Resolves dataset configurations based on dataset factory patterns and credentials.
- Supports advanced features like pattern matching, user-set catch-all patterns, and
  runtime patterns.
- This method checks if the given dataset name matches any of the user-defined catch-all
  patterns.
- MemoryDataset's non-persistence is indicated by the _EPHEMERAL attribute set to
  True.
- DatasetError raised by AbstractDataset implementations in case of failure of input/output
  methods.
- AbstractDataset implementations should provide instructive information in case of
  failure.
- Main entry point when %load_ext kedro.ipython is executed, either manually or automatically
  through `kedro ipython` or `kedro jupyter lab/notebook`.
- Currently, this feature is only available for Jupyter Notebook (>7.0), Jupyter Lab,
  IPython, and VSCode Notebook.
- warnings issued by the warnings module are redirected to logging
- pretty printing is enabled on the Python REPL (including IPython and Jupyter)
- all tracebacks are handled by rich when rich_tracebacks=True
- This module provides user-friendly functions for creating nodes as parts of Kedro
  pipelines.
- Must only refer to the pipeline's free inputs.
- Optional set of tags to be applied to all the pipeline nodes.
- Raises ValueError when Pipeline inputs cannot be satisfied.
- Using synchronous mode for loading and saving data. Use the --async flag for potential
  performance gains.
- If not set, calculated automatically based on the pipeline configuration and CPU
  core count.
- On windows machines, the max_workers value cannot be larger than 61 and will be
  set to min(61, max_workers).
- Extract an object from a given path.
- Custom class for warnings about deprecated Kedro features.
- Kedro provides a set of CLI commands, which are automatically grouped and documented
  below using their inline docstrings.
- Project-related CLI commands can be run from any subdirectory within a Kedro project.
- Uses Kedro for project management in Jupyter notebooks.
- If the Kedro variables are not available within your Jupyter notebook, you could
  have a malformed configuration file or missing dependencies.
- The %load_node line magic is currently only available for Jupyter Notebook (>7.0)
  and Jupyter Lab. If you are working within a different interactive environment,
  manually copy over the contents from your project files instead of using %load_node
  to automatically populate your node's contents, and continue from step 2.
- Good software engineering practice suggests that we extract magic numbers into
  named constants.
- Optimal configuration for Spark depends on the setup of your Spark cluster.
- MLflow records metadata and artifacts for each run to a local directory called mlflow_runs.
- Uses kedro-mlflow to track Kedro runs in MLflow
- Artifact tracking capabilities are available with MlflowArtifactDataset
- Notice that MLflow runs are immutable for reproducibility purposes.
- The 'kedro-mlflow' plugin introduces a special artifact, 'MlflowModelTrackingDataset'.
- To register a model, add a 'registered_model_name' parameter.
- Delta Lake is an open-source storage layer that brings reliability to data lakes
  by adding a transactional storage layer on top of the data stored in cloud storage.
- It allows for ACID transactions, data versioning, and rollback capabilities.
- The DeltaTableDataset does not support save() operation. Instead, pick the operation
  you want to perform (DeltaTable.update(), DeltaTable.delete(), DeltaTable.merge())
  and write it in your node code instead.
- If you have defined an implementation for the Kedro before_dataset_saved/after_dataset_saved
  hook, the hook will not be triggered.
- Apache Iceberg is an open table format for analytic datasets.
- Uses SQLCatalog with sqlite database for metadata storage
- Requires the pyiceberg package to interact with Iceberg tables
- Choose Existing environment and navigate your way to find your existing environment.
- Emulate terminal in output console enables PyCharm to show rich terminal output.
- Update your Kedro project to use Kedro 1.0.0 following the migration guide.
- The `layer` attribute at the top level has been moved inside the `metadata` -> `kedro-viz`
  attribute.
- The `session_id` parameter has been renamed to `run_id` in all runner methods and
  hooks.
- Participation in this program is optional, and it is enabled by default.
- Kedro will continue working as normal if you opt-out.
- Kedro uses a default template for project structure.
- Project structure can be customized during project creation.
- Installation prerequisites include a Python 3.9+ and `git`.
- Kedro provides a set of CLI commands, which are automatically grouped and documented.
- Filepath in POSIX format to sequence file prefixed with a protocol like s3://. If
  prefix is not provided, file protocol (local filesystem) will be used.
- Uses Dask remote data services to handle load and save operations.
- Supports all allowed geopandas options for loading and saving files.
- 'Filepath in POSIX format to a text file prefixed with a protocol like `s3://`.
  If prefix is not provided, `file` protocol (local filesystem) will be used. The
  prefix should be any protocol supported by `fsspec`. Note: `http(s)` doesn''t support
  versioning.'
- 'Extra arguments to pass into underlying filesystem class constructor (e.g. `{''project'':
  ''my-project''}` for `GCSFileSystem`), as well as to pass to the filesystem''s `open`
  method through nested key `open_args_save`.'
- Uses native json to handle the JSON file.
- Filepath in POSIX format to a Matlab file prefixed with a protocol like `s3://`.
- This class is deprecated and will be removed in a future release. Please use MatplotlibDataset
  instead.
- GMLDataset loads and saves graph data in GML format using NetworkX.
- Filepath in POSIX format to a .docx file prefixed with a protocol like `s3://`.
  If prefix is not provided, `file` protocol (local filesystem) will be used.
- Filepath in POSIX format to a CSV file prefixed with a protocol like s3://.
- Defaults are preserved, apart from 'index', which is set to False.
- Handles load and save using a pandas dataframe.
- You can overwrite a specific partition by using mode=overwrite together with partition_filters.
- Uses openpyxl for Excel file manipulation
- Supports loading multiple sheets from Excel files
- Uses Pandas to dynamically select the appropriate type of read/write target on a
  best effort basis.
- Filepath should be POSIX format.
- Protocols supported by fsspec can be used.
- Saving to a directory is not supported.
- Does not support save argument 'partition_cols'. Please use 'kedro.io.PartitionedDataset'
  instead.
- It does not support save method so it is a read only dataset.
- Filepath in POSIX format to a XML file prefixed with a protocol like 's3://'.
- If prefix is not provided, 'file' protocol (local filesystem) will be used.
- The prefix should be any protocol supported by 'fsspec'.
- 'Note: ''http(s)'' doesn''t support versioning.'
- All defaults are preserved for loading and saving.
- IncrementalDataset is used to manage datasets that grow incrementally over time.
- It stores the information about the last processed partition in a checkpoint.
- Filepath in POSIX format to a JSON file prefixed with a protocol like s3://.
- The prefix should be any protocol supported by fsspec.
- Uses Redis as the backend for loading and saving data.
- Supports serialization and deserialization using Python's pickle module.
- File format used during load and save operations include parquet, csv, delta.
- TensorFlow options for loading models are preserved.
- TensorFlow options for saving models are preserved, except for 'save_format', which
  is set to 'tf'.
- Filepath in POSIX format to a YAML file prefixed with a protocol like s3://.
- If prefix is not provided, file protocol (local filesystem) will be used.
- http(s) doesn't support versioning.
- Credentials must contain `openai_api_base` and `openai_api_key`.
- NetCDFDataset loads and saves data to a local netcdf (.nc) file.
- Supported dimensions are ('band', 'x', 'y') and ('x', 'y'). xarray DataArray's with
  other dimensions cannot be saved to a GeoTIFF file.
- If you need other formats, consider using NetCDF.
- DEFAULT_SAVE_ARGS includes parameters for saving data on server.
- Creates a new instance of BioSequenceDataset pointing to a concrete filepath.
- ParquetDataset loads and saves data to parquet file(s).
- It uses Dask remote data services to handle the corresponding load and save operations.
- This dataset works best with the databricks kedro starter.
- EmailMessageDataset doesnt handle sending email messages.
- The default_save_arg driver is GeoJSON, all others preserved.
- 'DEFAULT_SAVE_ARGS is {''fmt'': ''png''}'
- Uses native json to handle the JSON file
- GraphMLDataset loads and saves graphs to a GraphML file using an underlying filesystem.
- NetworkX is used to create GraphML data.
- DeltaTableDataset loads/saves delta tables from/to a filesystem.
- Uses pandas to handle the Excel file.
- Supports multi-sheet Excel files.
- It does not support save method so it is a read only data set.
- Uses SQLAlchemy connection string for database access.
- Default save parameters store data with no index.
- Filepath in POSIX format to a XML file prefixed with a protocol like s3://.
- Index is set to False when saving XML files.
- PartitionedDataset loads and saves partitioned file-like data using the underlying
  dataset definition.
- If path starts with the protocol (e.g., s3://) then the corresponding fsspec concrete
  filesystem implementation will be used.
- http(s) doesnt support versioning.
- Uses Polars to handle the CSV file.
- Supports custom backends to serialize/deserialize objects.
- Requires setup of Redis server.
- Creates a new instance of DeltaTableDataset with specified filepath.
- Schemas do not change during the pipeline run (defined PKs must be present for the
  duration of the pipeline).
- Tables are not being externally modified during upserts. The upsert method is NOT
  ATOMIC to external changes to the target table while executing.
- Please note that a schema is mandatory for a streaming DataFrame if `schemaInference`
  is not True.
- The dataset is write-only and it is versioned by default.
- YAMLDataset loads/saves data from/to a YAML file using an underlying filesystem.
- Kedro-Datasets is licensed under the Apache 2.0 License.
- Default HTTP(S) method is POST but PUT is also supported.
- Timeout defines how long our program waits for a response after a request.
- Uses Dask remote data services to handle the corresponding load and save operations.
- GeoJSONDataset loads/saves data to a GeoJSON file using an underlying filesystem
- HoloviewsWriter saves Holoviews objects to image file(s) in an underlying filesystem
- HFDataset loads Hugging Face datasets using the datasets library.
- Uses pandas to handle the CSV file.
- Uses pandas-gbq to read and write from/to BigQuery table.
- Uses pandas to handle the XML file.
- IncrementalDataset inherits from PartitionedDataset, which loads and saves partitioned
  file-like data using the underlying dataset definition.
errors:
- 'DatasetError: Failed while loading data from dataset'
- 'DatasetNotFoundError: Dataset not found in the catalog'
- 'DatasetError: An exception occurred when parsing config for Dataset'
- 'DatasetNotFoundError: Dataset ''companies'' not found in the catalog'
- 'FileNotFoundError: [Errno 2] File b''data/03_primary/model_input_table.csv'' does
  not exist'
- 'MissingConfigException: Configuration paths don''t exist.'
- 'ParserError: Bad syntax in configuration files.'
- 'Deployment error: Ensure all dependencies are included in the Docker image.'
- '401 Unauthorized: Recheck personal access token or Databricks host.'
- Ensure AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY values are stored in Kubernetes
  Secrets.
- 'REQUEST_LIMIT_EXCEEDED: Throttle API calls or reduce frequency'
- 'QUERY_TIMEOUT: Break down filters or add selectivity'
- '401 Unauthorized: Recheck OAuth scopes or token expiration'
- 'KedroCliError: Kernel cannot be setup'
- 'ValueError: Package name not found. Make sure you have configured the project using
  ''bootstrap_project''.'
- 'ValueError: If the named or __default__ pipeline is not defined by register_pipelines.'
- 'KedroSessionError: If more than one run is attempted to be executed during a single
  session.'
- 'Please select from the available tools: lint, test, log, docs, data, pyspark, all,
  none.'
- '''viz'' is automatically included in the project. Please remove ''viz'' from your
  tool selection.'
- Tools options 'all' and 'none' cannot be used with other options.
- 'KedroContextError: Error occurred when loading project and running context pipeline.'
- 'ValueError: Raised when any of the given inputs do not exist in the Pipeline object.'
- 'ValueError: When pipeline contains no nodes with the specified namespaces.'
- 'ValueError: Raised when any of the given outputs do not exist in the Pipeline object.'
- 'ImportError: When a module does not expose a create_pipeline function.'
- 'UserWarning: When a module does not expose a create_pipeline function.'
- 'AttributeError: If any datasets are found to be non-serializable or incompatible
  with multiprocessing.'
- '''type'' is missing from dataset catalog configuration.'
- 'DatasetError: If multiple catch-all patterns are found'
- 'DatasetError: when underlying save method raises error.'
- 'FileNotFoundError: when save method got file instead of dir, on Windows.'
- 'NotADirectoryError: when save method got file instead of dir, on Unix.'
- DatasetNotFoundError raised by DataCatalog class in case of trying to use a non-existing
  dataset.
- 'ValueError: When an empty list of nodes is provided.'
- 'CircularDependencyError: When visiting all the nodes is not possible due to the
  existence of a circular dependency.'
- 'OutputNotUniqueError: When multiple Node instances produce the same output.'
- 'ConfirmNotUniqueError: When multiple Node instances attempt to confirm the same
  dataset.'
- 'PipelineError: When inputs, outputs or parameters are incorrectly specified.'
- 'ValueError: When an empty list of nodes is provided, or when not all nodes have
  unique names.'
- 'PipelineError: When inputs, outputs or parameters are incorrectly specified, or
  they do not exist on the original pipeline.'
- 'ValueError: The filtered Pipeline has no nodes.'
- 'ValueError: Raised when Pipeline inputs cannot be satisfied.'
- 'Exception: in case of any downstream node failure.'
- 'ValueError: bad parameters passed'
- 'AttributeError: When the object does not have the given named attribute.'
- 'Failed while saving data to dataset MlflowMatplotlibWriter: clean up the old data
  directory'
- 'NoSuchTableError: Indicates the specified Iceberg table does not exist'
- Loading not supported for 'HoloviewsWriter'
- 'DatasetError: Invalid configuration supplied (through DeltaTableDataset validation)'
- 'DatasetError: Saving to a directory is not supported.'
- 'DatasetError: does not support save argument ''partition_cols''. Please use ''kedro.io.PartitionedDataset''
  instead.'
- 'DatasetError: When either `sql` or `con` parameters is empty.'
- 'ValueError: If backend does not satisfy the pickle interface.'
- 'ImportError: If the backend module could not be imported.'
- 'DatasetError: when underlying exists method raises error.'
- 'DatasetError: when underlying exists method raises error'
- 'DatasetError: When the function fails to create the data set from its config'
- 'DatasetError: When underlying load method raises error'
- 'DatasetError: when underlying release method raises error'
- 'DatasetError: when underlying save method raises error'
- 'FileNotFoundError: when save method got file instead of dir, on Windows'
- 'NotADirectoryError: when save method got file instead of dir, on Unix'
- 'DatasetError: Invalid configuration supplied.'
- 'ValueError: if both auth and credentials are specified or used unsupported RESTful
  API method.'
auth_info:
  mentioned_objects:
  - usda_credentials
  - OauthToken
  - AuthProvider
  - NamedCredential
  - AbstractConfigLoader
  - OmegaConfigLoader
  - MissingConfigException
  - db_credentials
  - anthropic_api_key
  - anthropic_api_url
client:
  base_url: https://docs.kedro.org/en/stable
  headers:
    Accept: application/json
source_metadata: null
