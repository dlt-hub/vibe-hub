resources:
- name: RedisModule_Alloc
  endpoint:
    path: /RedisModule_Alloc
    method: void
    data_selector: void *
    params: {}
- name: RedisModule_Calloc
  endpoint:
    path: /RedisModule_Calloc
    method: void
    data_selector: void *
    params: {}
- name: RedisModule_Realloc
  endpoint:
    path: /RedisModule_Realloc
    method: void *
    data_selector: void *
    params: {}
- name: RedisModule_Free
  endpoint:
    path: /RedisModule_Free
    method: void
    data_selector: void
    params: {}
- name: RedisModule_Strdup
  endpoint:
    path: /RedisModule_Strdup
    method: char *
    data_selector: char *
    params: {}
- name: RedisModule_PoolAlloc
  endpoint:
    path: /RedisModule_PoolAlloc
    method: void *
    data_selector: void *
    params: {}
- name: RedisModule_GetApi
  endpoint:
    path: /RedisModule_GetApi
    method: int
    data_selector: int
    params: {}
- name: RedisModule_IsKeysPositionRequest
  endpoint:
    path: /RedisModule_IsKeysPositionRequest
    method: int
    data_selector: int
    params: {}
- name: RedisModule_KeyAtPos
  endpoint:
    path: /RedisModule_KeyAtPos
    method: void
    data_selector: void
    params: {}
- name: RedisModule_CreateCommand
  endpoint:
    path: /RedisModule_CreateCommand
    method: int
    data_selector: int
    params: {}
- name: RedisModule_SetModuleAttribs
  endpoint:
    path: /RedisModule_SetModuleAttribs
    method: void
    data_selector: void
    params: {}
- name: RedisModule_IsModuleNameBusy
  endpoint:
    path: /RedisModule_IsModuleNameBusy
    method: int
    data_selector: int
    params: {}
- name: RedisModule_Milliseconds
  endpoint:
    path: /RedisModule_Milliseconds
    method: long long
    data_selector: long long
    params: {}
- name: RedisModule_AutoMemory
  endpoint:
    path: /RedisModule_AutoMemory
    method: void
    data_selector: void
    params: {}
- name: RedisModule_CreateString
  endpoint:
    path: /RedisModule_CreateString
    method: RedisModuleString *
    data_selector: RedisModuleString *
    params: {}
- name: RedisModule_CreateStringPrintf
  endpoint:
    path: /RedisModule_CreateStringPrintf
    method: RedisModuleString *
    data_selector: RedisModuleString *
    params: {}
- name: RedisModule_CreateStringFromLongLong
  endpoint:
    path: /RedisModule_CreateStringFromLongLong
    method: RedisModuleString *
    data_selector: RedisModuleString *
    params: {}
- name: RedisModule_CreateStringFromString
  endpoint:
    path: /RedisModule_CreateStringFromString
    method: RedisModuleString *
    data_selector: RedisModuleString *
    params: {}
- name: RedisModule_FreeString
  endpoint:
    path: /RedisModule_FreeString
    method: void
    data_selector: void
    params: {}
- name: RedisModule_RetainString
  endpoint:
    path: /RedisModule_RetainString
    method: void
    data_selector: void
    params: {}
- name: RedisModule_StringPtrLen
  endpoint:
    path: /RedisModule_StringPtrLen
    method: const char *
    data_selector: const char *
    params: {}
- name: RedisModule_StringToLongLong
  endpoint:
    path: /RedisModule_StringToLongLong
    method: int
    data_selector: int
    params: {}
- name: RedisModule_StringToDouble
  endpoint:
    path: /RedisModule_StringToDouble
    method: int
    data_selector: int
    params: {}
- name: RedisModule_StringCompare
  endpoint:
    path: /RedisModule_StringCompare
    method: int
    data_selector: int
    params: {}
- name: RedisModule_StringAppendBuffer
  endpoint:
    path: /RedisModule_StringAppendBuffer
    method: int
    data_selector: int
    params: {}
- name: RedisModule_WrongArity
  endpoint:
    path: /RedisModule_WrongArity
    method: int
    data_selector: int
    params: {}
- name: RedisModule_ReplyWithLongLong
  endpoint:
    path: /RedisModule_ReplyWithLongLong
    method: int
    data_selector: int
    params: {}
- name: RedisModule_ReplyWithError
  endpoint:
    path: /RedisModule_ReplyWithError
    method: int
    data_selector: int
    params: {}
- name: RedisModule_ReplyWithSimpleString
  endpoint:
    path: /RedisModule_ReplyWithSimpleString
    method: int
    data_selector: int
    params: {}
- name: RedisModule_ReplyWithArray
  endpoint:
    path: /RedisModule_ReplyWithArray
    method: int
    data_selector: int
    params: {}
- name: RedisModule_ReplySetArrayLength
  endpoint:
    path: /RedisModule_ReplySetArrayLength
    method: void
    data_selector: void
    params: {}
- name: RedisModule_ReplyWithStringBuffer
  endpoint:
    path: /RedisModule_ReplyWithStringBuffer
    method: int
    data_selector: int
    params: {}
- name: RedisModule_ReplyWithString
  endpoint:
    path: /RedisModule_ReplyWithString
    method: int
    data_selector: int
    params: {}
- name: RedisModule_ReplyWithNull
  endpoint:
    path: /RedisModule_ReplyWithNull
    method: int
    data_selector: int
    params: {}
- name: RedisModule_ReplyWithCallReply
  endpoint:
    path: /RedisModule_ReplyWithCallReply
    method: int
    data_selector: int
    params: {}
- name: RedisModule_ReplyWithDouble
  endpoint:
    path: /RedisModule_ReplyWithDouble
    method: int
    data_selector: int
    params: {}
- name: RedisModule_Replicate
  endpoint:
    path: /RedisModule_Replicate
    method: int
    data_selector: int
    params: {}
- name: RedisModule_ReplicateVerbatim
  endpoint:
    path: /RedisModule_ReplicateVerbatim
    method: int
    data_selector: int
    params: {}
- name: RedisModule_GetClientId
  endpoint:
    path: /RedisModule_GetClientId
    method: unsigned long long
    data_selector: unsigned long long
    params: {}
- name: RedisModule_GetSelectedDb
  endpoint:
    path: /RedisModule_GetSelectedDb
    method: int
    data_selector: int
    params: {}
- name: SendClusterMessage
  endpoint:
    path: /SendClusterMessage
    method: POST
    data_selector: message
    params: {}
- name: GetClusterNodesList
  endpoint:
    path: /GetClusterNodesList
    method: GET
    data_selector: nodeIDs
    params: {}
- name: FreeClusterNodesList
  endpoint:
    path: /FreeClusterNodesList
    method: POST
    data_selector: result
    params: {}
- name: GetMyClusterID
  endpoint:
    path: /GetMyClusterID
    method: GET
    data_selector: clusterID
    params: {}
- name: GetClusterSize
  endpoint:
    path: /GetClusterSize
    method: GET
    data_selector: clusterSize
    params: {}
- name: SetClusterFlags
  endpoint:
    path: /SetClusterFlags
    method: POST
    data_selector: result
    params: {}
- name: CreateTimer
  endpoint:
    path: /CreateTimer
    method: POST
    data_selector: timerID
    params: {}
- name: StopTimer
  endpoint:
    path: /StopTimer
    method: POST
    data_selector: result
    params: {}
- name: GetTimerInfo
  endpoint:
    path: /GetTimerInfo
    method: GET
    data_selector: timerInfo
    params: {}
- name: CreateDict
  endpoint:
    path: /CreateDict
    method: POST
    data_selector: dict
    params: {}
- name: FreeDict
  endpoint:
    path: /FreeDict
    method: POST
    data_selector: result
    params: {}
- name: DictSize
  endpoint:
    path: /DictSize
    method: GET
    data_selector: size
    params: {}
- name: DictSetC
  endpoint:
    path: /DictSetC
    method: POST
    data_selector: result
    params: {}
- name: DictReplaceC
  endpoint:
    path: /DictReplaceC
    method: POST
    data_selector: result
    params: {}
- name: DictSet
  endpoint:
    path: /DictSet
    method: POST
    data_selector: result
    params: {}
- name: DictReplace
  endpoint:
    path: /DictReplace
    method: POST
    data_selector: result
    params: {}
- name: DictGetC
  endpoint:
    path: /DictGetC
    method: GET
    data_selector: value
    params: {}
- name: DictGet
  endpoint:
    path: /DictGet
    method: GET
    data_selector: value
    params: {}
- name: DictDelC
  endpoint:
    path: /DictDelC
    method: DELETE
    data_selector: result
    params: {}
- name: DictDel
  endpoint:
    path: /DictDel
    method: DELETE
    data_selector: result
    params: {}
- name: DictIteratorStartC
  endpoint:
    path: /DictIteratorStartC
    method: POST
    data_selector: iterator
    params: {}
- name: DictIteratorStart
  endpoint:
    path: /DictIteratorStart
    method: POST
    data_selector: iterator
    params: {}
- name: DictIteratorStop
  endpoint:
    path: /DictIteratorStop
    method: POST
    data_selector: result
    params: {}
- name: DictIteratorReseekC
  endpoint:
    path: /DictIteratorReseekC
    method: POST
    data_selector: result
    params: {}
- name: DictIteratorReseek
  endpoint:
    path: /DictIteratorReseek
    method: POST
    data_selector: result
    params: {}
- name: DictNextC
  endpoint:
    path: /DictNextC
    method: GET
    data_selector: nextItem
    params: {}
- name: DictPrevC
  endpoint:
    path: /DictPrevC
    method: GET
    data_selector: prevItem
    params: {}
- name: DictNext
  endpoint:
    path: /DictNext
    method: GET
    data_selector: nextString
    params: {}
- name: DictPrev
  endpoint:
    path: /DictPrev
    method: GET
    data_selector: prevString
    params: {}
- name: GetRandomBytes
  endpoint:
    path: /GetRandomBytes
    method: GET
    data_selector: randomBytes
    params: {}
- name: GetRandomHexChars
  endpoint:
    path: /GetRandomHexChars
    method: GET
    data_selector: randomHexChars
    params: {}
- name: append
  endpoint:
    path: /commands/append
    method: GET
    data_selector: integer-reply
    params: {}
- name: time_series
  endpoint:
    path: /commands/time_series
    method: GET
    data_selector: examples
    params: {}
- name: bgrewriteaof
  endpoint:
    path: /bgrewriteaof
    method: POST
    data_selector: reply
    params: {}
- name: bgsave
  endpoint:
    path: /bgsave
    method: POST
    data_selector: OK
- name: bitcount
  endpoint:
    path: /bitcount
    method: GET
    data_selector: integer-reply
    params: {}
- name: bitfield
  endpoint:
    path: /bitfield
    method: GET
    data_selector: results
- name: bitop
  endpoint:
    path: /bitop
    method: GET
    data_selector: operations
    params: {}
- name: bitpos
  endpoint:
    path: /bitpos
    method: GET
    data_selector: integer-reply
    params: {}
- name: blpop
  endpoint:
    path: /blpop
    method: POST
    data_selector: response
    params:
      timeout: '0'
- name: brpop
  endpoint:
    path: /brpop
    method: GET
- name: brpoplpush
  endpoint:
    path: /brpoplpush
    method: GET
- name: bzpopmax
  endpoint:
    path: /commands/bzpopmax
    method: GET
    data_selector: '@array-reply'
- name: bzpopmin
  endpoint:
    path: /bzpopmin
    method: GET
    data_selector: array-reply
- name: client_getname
  endpoint:
    path: /client/getname
    method: GET
    data_selector: bulk-string-reply
- name: client_id
  endpoint:
    path: /client/id
    method: GET
    data_selector: client_id
    params: {}
- name: client_list
  endpoint:
    path: /client/list
    method: GET
    data_selector: clients
    params: {}
- name: client_pause
  endpoint:
    path: /client/pause
    method: POST
    data_selector: OK
    params: {}
- name: client_reply
  endpoint:
    path: /client/reply
    method: GET
    data_selector: reply_modes
    params: {}
- name: client_setname
  endpoint:
    path: /CLIENT/SETNAME
    method: POST
    data_selector: simple-string-reply
- name: client_unblock
  endpoint:
    path: /CLIENT/UNBLOCK
    method: POST
    data_selector: response
    params: {}
- name: cluster_addslots
  endpoint:
    path: /cluster/addslots
    method: POST
    data_selector: response
    params: {}
- name: cluster_count_failure_reports
  endpoint:
    path: /cluster/count_failure_reports
    method: GET
    data_selector: active_failure_reports
    params: {}
- name: cluster_countkeysinslot
  endpoint:
    path: /cluster/countkeysinslot
    method: GET
    data_selector: integer-reply
- name: cluster_delslots
  endpoint:
    path: /cluster/delslots
    method: POST
    data_selector: response
    params: {}
- name: cluster_failover
  endpoint:
    path: /cluster/failover
    method: POST
    data_selector: simple-string-reply
- name: cluster_forget
  endpoint:
    path: /cluster/forget
    method: POST
    data_selector: response
    params: {}
- name: getkeysinslot
  endpoint:
    path: /cluster/getkeysinslot
    method: GET
    data_selector: array-reply
    params:
      count: specified via the count argument
- name: cluster_info
  endpoint:
    path: /cluster/info
    method: GET
    data_selector: cluster_info
    params: {}
- name: cluster_keyslot
  endpoint:
    path: /CLUSTER KEYSLOT
    method: GET
    data_selector: integer-reply
- name: cluster_meet
  endpoint:
    path: /cluster/meet
    method: POST
    data_selector: response
    params: {}
- name: cluster_nodes
  endpoint:
    path: /cluster/nodes
    method: GET
    data_selector: nodes
    params: {}
- name: cluster_replicas
  endpoint:
    path: /cluster/replicas
    method: GET
    data_selector: replicas
- name: cluster_replicate
  endpoint:
    path: /cluster/replicate
    method: POST
    data_selector: null
    params: {}
- name: cluster_reset
  endpoint:
    path: /cluster/reset
    method: POST
    data_selector: response
    params: {}
- name: cluster_saveconfig
  endpoint:
    path: /cluster/saveconfig
    method: POST
    data_selector: OK
- name: cluster_set_config_epoch
  endpoint:
    path: /cluster/set_config_epoch
    method: POST
    data_selector: simple-string-reply
- name: cluster_setslot
  endpoint:
    path: /cluster/setslot
    method: POST
    data_selector: response
    params: {}
- name: cluster_replicas
  endpoint:
    path: /CLUSTER/REPLICAS
    method: GET
    data_selector: replica_nodes
- name: cluster_slots
  endpoint:
    path: /cluster/slots
    method: GET
    data_selector: '@array-reply'
- name: command_count
  endpoint:
    path: /command/count
    method: GET
    data_selector: '@integer-reply'
- name: getkeys
  endpoint:
    path: /command/getkeys
    method: GET
    data_selector: '@array-reply'
- name: command_info
  endpoint:
    path: /COMMAND_INFO
    method: GET
    data_selector: '@array-reply'
- name: command
  endpoint:
    path: /COMMAND
    method: GET
    data_selector: '@array-reply'
    params: {}
- name: config_get
  endpoint:
    path: /CONFIG GET
    method: GET
    data_selector: key-value pairs
- name: config_resetstat
  endpoint:
    path: /config/resetstat
    method: POST
    data_selector: simple-string-reply
- name: config_rewrite
  endpoint:
    path: /CONFIG REWRITE
    method: POST
    data_selector: response
    params: {}
- name: config_set
  endpoint:
    path: /config/set
    method: POST
    data_selector: response
    params: {}
- name: dbsize
  endpoint:
    path: /dbsize
    method: GET
    data_selector: integer-reply
- name: debug_object
  endpoint:
    path: /debug/object
    method: GET
- name: debug_segfault
  endpoint:
    path: /debug/segfault
    method: POST
- name: decr
  endpoint:
    path: /decr
    method: GET
    data_selector: integer-reply
    params: {}
- name: decrby
  endpoint:
    path: /decrby
    method: POST
    data_selector: integer-reply
    params: {}
- name: Del
  endpoint:
    path: /del
    method: GET
    data_selector: '@integer-reply'
    params: {}
- name: Discard
  endpoint:
    path: /Discard
    method: POST
    data_selector: '@simple-string-reply'
- name: dump
  endpoint:
    path: /DUMP
    method: GET
    data_selector: '@bulk-string-reply'
    params: {}
- name: echo
  endpoint:
    path: /
    method: GET
    data_selector: message
- name: eval
  endpoint:
    path: /eval
    method: POST
    data_selector: response
    params: {}
- name: evalsha
  endpoint:
    path: /evalsha
    method: POST
    data_selector: response
    params: {}
- name: evalsha
  endpoint:
    path: /evalsha
    method: GET
    data_selector: script
    params: {}
- name: exec
  endpoint:
    path: /exec
    method: POST
    data_selector: array-reply
- name: exists
  endpoint:
    path: /exists
    method: GET
    data_selector: integer-reply
- name: expireat
  endpoint:
    path: /expireat
    method: POST
    data_selector: reply
- name: flushall
  endpoint:
    path: /flushall
    method: POST
    data_selector: simple-string-reply
- name: flushdb
  endpoint:
    path: /flushdb
    method: DELETE
    data_selector: null
    params: {}
- name: geodecode
  endpoint:
    path: /geodecode
    method: GET
- name: geodist
  endpoint:
    path: /geodist
    method: GET
    data_selector: distance
    params: {}
- name: geoencode
  endpoint:
    path: /geoencode
    method: GET
    data_selector: array-reply
- name: Geohash
  endpoint:
    path: /geohash
    method: GET
    data_selector: '@array-reply'
- name: geopos
  endpoint:
    path: /geopos
    method: GET
    data_selector: array-reply
- name: georadius
  endpoint:
    path: /georadius
    method: GET
    data_selector: array-reply
- name: georadius_ro
  endpoint:
    path: /georadius_ro
    method: GET
    data_selector: array-reply
- name: georadiusbymember
  endpoint:
    path: /georadiusbymember
    method: GET
    data_selector: array-reply
- name: georadiusbymember_ro
  endpoint:
    path: /georadiusbymember_ro
    method: GET
    data_selector: array-reply
- name: Georadiusbymember
  endpoint:
    path: /georadiusbymember
    method: GET
- name: Get
  endpoint:
    path: /Get
    method: GET
    data_selector: bulk-string-reply
    params: {}
- name: getbit
  endpoint:
    path: /getbit
    method: GET
    data_selector: integer-reply
- name: getrange
  endpoint:
    path: /getrange
    method: GET
- name: getset
  endpoint:
    path: /getset
    method: GET
    data_selector: bulk-string-reply
- name: hdel
  endpoint:
    path: /Hdel
    method: GET
    data_selector: integer-reply
- name: hexists
  endpoint:
    path: /hexists
    method: GET
    data_selector: integer-reply
- name: Hget
  endpoint:
    path: /Hget
    method: GET
    data_selector: bulk-string-reply
- name: hgetall
  endpoint:
    path: /Hgetall
    method: GET
    data_selector: array-reply
    params: {}
- name: hincrby
  endpoint:
    path: /hincrby
    method: GET
    data_selector: integer-reply
- name: hincrbyfloat
  endpoint:
    path: /hincrbyfloat
    method: POST
    data_selector: bulk-string-reply
- name: hkeys
  endpoint:
    path: /HKEYS
    method: GET
    data_selector: fields
    params: {}
- name: hlen
  endpoint:
    path: /hlen
    method: GET
    data_selector: integer-reply
- name: hmget
  endpoint:
    path: ./
    method: GET
    data_selector: array-reply
- name: Hmset
  endpoint:
    path: /Hmset
    method: POST
    data_selector: fields
    params: {}
- name: Hscan
  endpoint:
    path: /Hscan
    method: GET
- name: hset
  endpoint:
    path: /hset
    method: POST
    data_selector: null
    params: {}
- name: hsetnx
  endpoint:
    path: /hsetnx
    method: POST
    data_selector: result
- name: Hstrlen
  endpoint:
    path: ./
    method: GET
    data_selector: integer-reply
- name: hvals
  endpoint:
    path: /Hvals
    method: GET
    data_selector: array-reply
- name: incr
  endpoint:
    path: /incr
    method: GET
    data_selector: integer-reply
- name: Incrby
  endpoint:
    path: /incrby
    method: GET
- name: incrbyfloat
  endpoint:
    path: /incrbyfloat
    method: POST
    data_selector: bulk-string-reply
    params: {}
- name: INFO
  endpoint:
    path: /INFO
    method: GET
    data_selector: bulk-string-reply
- name: lastsave
  endpoint:
    path: /lastsave
    method: GET
    data_selector: integer-reply
    params: {}
- name: lindex
  endpoint:
    path: /lindex
    method: GET
    data_selector: bulk-string-reply
- name: linsert
  endpoint:
    path: /linsert
    method: GET
    data_selector: integer-reply
- name: llen
  endpoint:
    path: /llen
    method: GET
    data_selector: integer-reply
    params: {}
- name: lpop
  endpoint:
    path: /
    method: GET
    data_selector: bulk-string-reply
- name: lpush
  endpoint:
    path: /lpush
    method: GET
    data_selector: ''
- name: lpushx
  endpoint:
    path: /lpushx
    method: POST
    data_selector: integer-reply
- name: lrange
  endpoint:
    path: /Lrange
    method: GET
    data_selector: array-reply
- name: Lrem
  endpoint:
    path: /Lrem
    method: GET
    data_selector: integer-reply
- name: lset
  endpoint:
    path: /lset
    method: GET
    data_selector: records
    params: {}
- name: Ltrim
  endpoint:
    path: /ltrim
    method: POST
    data_selector: response
    params: {}
- name: memory_doctor
  endpoint:
    path: /
    method: GET
- name: MEMORY HELP
  endpoint:
    path: /memory/help
    method: GET
    data_selector: array-reply
- name: memory_malloc_stats
  endpoint:
    path: /MEMORY/MALLOC-STATS
    method: GET
    data_selector: bulk-string-reply
- name: memory_purge
  endpoint:
    path: /memory/purge
    method: GET
    data_selector: simple-string-reply
- name: memory_stats
  endpoint:
    path: /memory/stats
    method: GET
    data_selector: '@array-reply'
- name: memory_usage
  endpoint:
    path: /memory_usage
    method: GET
    data_selector: '@integer-reply'
- name: Mget
  endpoint:
    path: /MGET
    method: GET
    data_selector: array-reply
    params: {}
- name: migrate
  endpoint:
    path: /migrate
    method: POST
    data_selector: status
    params: {}
- name: MONITOR
  endpoint:
    path: /monitor
    method: GET
    data_selector: commands
    params: {}
- name: move
  endpoint:
    path: /MOVE
    method: GET
    data_selector: integer-reply
    params: {}
- name: Mset
  endpoint:
    path: /MSET
    method: GET
    data_selector: simple-string-reply
- name: MSETNX
  endpoint:
    path: /MSETNX
    method: POST
    data_selector: integer-reply
    params: {}
- name: OBJECT
  endpoint:
    path: /OBJECT
    method: GET
    data_selector: internals
    params: {}
- name: PERSIST
  endpoint:
    path: /PERSIST
    method: GET
    data_selector: integer-reply
    params: {}
- name: pexpire
  endpoint:
    path: /pexpire
    method: GET
    data_selector: integer-reply
    params: {}
- name: pexpireat
  endpoint:
    path: /pexpireat
    method: GET
    data_selector: integer-reply
- name: pfadd
  endpoint:
    path: /pfadd
    method: POST
    data_selector: integer-reply
- name: pfcount
  endpoint:
    path: /pfcount
    method: GET
    data_selector: integer-reply
- name: pfmerge
  endpoint:
    path: /pfmerge
    method: POST
    data_selector: simple-string-reply
- name: Ping
  endpoint:
    path: /PING
    method: GET
    data_selector: PONG
- name: Psubscribe
  endpoint:
    path: /Psubscribe
    method: GET
- name: pttl
  endpoint:
    path: /PTTL
    method: GET
    data_selector: integer-reply
- name: Publish
  endpoint:
    path: /Publish
    method: POST
- name: pubsub_channels
  endpoint:
    path: /pubsub/channels
    method: GET
    data_selector: active_channels
- name: pubsub_numsub
  endpoint:
    path: /pubsub/numsub
    method: GET
    data_selector: subscribers_count
- name: pubsub_numpat
  endpoint:
    path: /pubsub/numpat
    method: GET
    data_selector: patterns_count
- name: Quit
  endpoint:
    path: /Quit
    method: GET
    data_selector: simple-string-reply
- name: random_key
  endpoint:
    path: /randomkey
    method: GET
    data_selector: bulk-string-reply
- name: readonly
  endpoint:
    path: /readonly
    method: GET
- name: Readwrite
  endpoint:
    path: /readwrite
    method: GET
    data_selector: ''
- name: renamenx
  endpoint:
    path: /renamenx
    method: GET
    data_selector: integer-reply
    params: {}
- name: REPLICAOF
  endpoint:
    path: /commands/REPLICAOF
    method: POST
    data_selector: simple-string-reply
- name: restore
  endpoint:
    path: /restore
    method: POST
    data_selector: simple-string-reply
- name: role
  endpoint:
    path: /role
    method: GET
    data_selector: role
    params: {}
- name: rpop
  endpoint:
    path: /
    method: GET
- name: Rpoplpush
  endpoint:
    path: /Rpoplpush
    method: GET
- name: rpush
  endpoint:
    path: /rpush
    method: POST
    data_selector: integer-reply
- name: rpushx
  endpoint:
    path: /rpushx
    method: GET
    data_selector: integer-reply
- name: sadd
  endpoint:
    path: /sadd
    method: POST
    data_selector: integer-reply
    params: {}
- name: save
  endpoint:
    path: /SAVE
    method: POST
    data_selector: simple-string-reply
- name: scan
  endpoint:
    path: /scan
    method: GET
    data_selector: elements
- name: collection_iteration
  endpoint:
    path: /scan
    method: GET
    data_selector: elements
    params:
      MATCH: <pattern>
- name: scard
  endpoint:
    path: /scard
    method: GET
    data_selector: integer-reply
- name: script_exists
  endpoint:
    path: /
    method: GET
    data_selector: array-reply
- name: script_flush
  endpoint:
    path: /script/flush
    method: GET
- name: Script kill
  endpoint:
    path: /script/kill
    method: GET
    data_selector: '@simple-string-reply'
- name: script_load
  endpoint:
    path: /script/load
    method: POST
    data_selector: bulk-string-reply
- name: sdiff
  endpoint:
    path: /sdiff
    method: GET
    data_selector: array-reply
    params: {}
- name: sdiffstore
  endpoint:
    path: /sdiffstore
    method: POST
    data_selector: integer-reply
- name: select
  endpoint:
    path: /select
    method: GET
    data_selector: simple-string-reply
- name: set
  endpoint:
    path: /set
    method: POST
    data_selector: response
    params: {}
- name: setbit
  endpoint:
    path: /setbit
    method: GET
    data_selector: '@integer-reply'
- name: setex
  endpoint:
    path: /setex
    method: POST
    data_selector: simple-string-reply
    params: {}
- name: setnx
  endpoint:
    path: /setnx
    method: POST
    data_selector: integer-reply
    params: {}
- name: shutdown
  endpoint:
    path: /shutdown
    method: POST
    data_selector: response
    params: {}
- name: sinter
  endpoint:
    path: /sinter
    method: GET
    data_selector: array-reply
- name: sinterstore
  endpoint:
    path: /sinterstore
    method: POST
- name: sismember
  endpoint:
    path: /Sismember
    method: GET
    data_selector: integer-reply
- name: slaveof
  endpoint:
    path: /SLAVEOF
    method: POST
    data_selector: simple-string-reply
    params: {}
- name: slowlog
  endpoint:
    path: /slowlog
    method: GET
    data_selector: entries
- name: smembers
  endpoint:
    path: /smembers
    method: GET
    data_selector: array-reply
- name: smove
  endpoint:
    path: /smove
    method: GET
    data_selector: integer-reply
- name: sort
  endpoint:
    path: /SORT
    method: GET
    data_selector: array-reply
    params: {}
- name: spop
  endpoint:
    path: /spop
    method: GET
    data_selector: bulk-string-reply
- name: srandmember
  endpoint:
    path: /Srandmember
    method: GET
    data_selector: array-reply
- name: srem
  endpoint:
    path: /srem
    method: POST
    data_selector: integer-reply
- name: sscan
  endpoint:
    path: /sscan
    method: GET
- name: strlen
  endpoint:
    path: /strlen
    method: GET
    data_selector: integer-reply
- name: subscribe
  endpoint:
    path: /subscribe
    method: SUBSCRIBE
- name: sunion
  endpoint:
    path: /sunion
    method: GET
- name: sunionstore
  endpoint:
    path: /sunionstore
    method: POST
- name: swapdb
  endpoint:
    path: /swapdb
    method: POST
    data_selector: response
    params: {}
- name: time
  endpoint:
    path: /TIME
    method: GET
    data_selector: array-reply
- name: touch
  endpoint:
    path: /touch
    method: GET
    data_selector: integer-reply
    params: {}
- name: ttl
  endpoint:
    path: /ttl
    method: GET
    data_selector: integer-reply
- name: type
  endpoint:
    path: /TYPE
    method: GET
    data_selector: type
- name: unlink
  endpoint:
    path: /unlink
    method: GET
    data_selector: integer-reply
    params: {}
- name: Unsubscribe
  endpoint:
    path: /unsubscribe
    method: GET
- name: Unwatch
  endpoint:
    path: /unwatch
    method: POST
    data_selector: null
    params: {}
- name: xack
  endpoint:
    path: /xack
    method: POST
    data_selector: number_of_acknowledged_messages
    params: {}
- name: XADD
  endpoint:
    path: /XADD
    method: POST
    data_selector: entry
    params: {}
- name: Xclaim
  endpoint:
    path: /Xclaim
    method: POST
    data_selector: array-reply
- name: xdel
  endpoint:
    path: /xdel
    method: POST
    data_selector: integer-reply
- name: XGROUP CREATE
  endpoint:
    path: /XGROUP/CREATE
    method: POST
    data_selector: response
    params: {}
- name: XGROUP DESTROY
  endpoint:
    path: /XGROUP/DESTROY
    method: POST
    data_selector: response
    params: {}
- name: XGROUP DELCONSUMER
  endpoint:
    path: /XGROUP/DELCONSUMER
    method: POST
    data_selector: response
    params: {}
- name: XGROUP SETID
  endpoint:
    path: /XGROUP/SETID
    method: POST
    data_selector: response
    params: {}
- name: XGROUP HELP
  endpoint:
    path: /XGROUP/HELP
    method: GET
    data_selector: response
    params: {}
- name: XINFO_STREAM
  endpoint:
    path: XINFO STREAM <key>
    method: GET
    data_selector: length
- name: XINFO_GROUPS
  endpoint:
    path: XINFO GROUPS <key>
    method: GET
    data_selector: groups
- name: XINFO_CONSUMERS
  endpoint:
    path: XINFO CONSUMERS <key> <group>
    method: GET
    data_selector: consumers
- name: XINFO_HELP
  endpoint:
    path: XINFO HELP
    method: GET
    data_selector: subcommands
- name: xlen
  endpoint:
    path: /xlen
    method: GET
    data_selector: '@integer-reply'
- name: xpending
  endpoint:
    path: /XPENDING
    method: GET
    data_selector: array-reply
- name: xrange
  endpoint:
    path: /xrange
    method: GET
    data_selector: entries
- name: xread
  endpoint:
    path: /xread
    method: GET
    data_selector: records
- name: XREADGROUP
  endpoint:
    path: /XREADGROUP
    method: GET
    data_selector: entries
    params:
      group-name: <group-name>
      consumer-name: <consumer-name>
- name: Xrevrange
  endpoint:
    path: /XREVRANGE
    method: GET
    data_selector: array-reply
- name: xtrim
  endpoint:
    path: /xtrim
    method: POST
    data_selector: entries
- name: ZADD
  endpoint:
    path: /ZADD
    method: POST
    data_selector: result
    params: {}
- name: Zcard
  endpoint:
    path: /zcard
    method: GET
    data_selector: integer-reply
    params: {}
- name: Zcount
  endpoint:
    path: /ZCOUNT
    method: GET
    data_selector: '@integer-reply'
- name: zincrby
  endpoint:
    path: /ZINCRBY
    method: POST
    data_selector: score
    params: {}
- name: Zinterstore
  endpoint:
    path: /Zinterstore
    method: GET
- name: zpopmax
  endpoint:
    path: /ZPOPMAX
    method: POST
    data_selector: array-reply
    params:
      count: 1
- name: zpopmin
  endpoint:
    path: /Zpopmin
    method: GET
    data_selector: array-reply
- name: Zrange
  endpoint:
    path: /Zrange
    method: GET
    data_selector: array-reply
- name: zrangebylex
  endpoint:
    path: /zrangebylex
    method: GET
- name: zrangebyscore
  endpoint:
    path: /zrangebyscore
    method: GET
    data_selector: elements
    params: {}
- name: zrank
  endpoint:
    path: /Zrank
    method: GET
    data_selector: rank
    params: {}
- name: Zrem
  endpoint:
    path: /Zrem
    method: GET
    data_selector: integer-reply
- name: Zremrangebylex
  endpoint:
    path: /Zremrangebylex
    method: GET
    data_selector: integer-reply
- name: zremrangebyrank
  endpoint:
    path: /Zremrangebyrank
    method: GET
    data_selector: integer-reply
- name: Zremrangebyscore
  endpoint:
    path: /Zremrangebyscore
    method: GET
    data_selector: elements_removed
- name: zrevrange
  endpoint:
    path: /zrevrange
    method: GET
    data_selector: array-reply
- name: ZREVRANGEBYLEX
  endpoint:
    path: /ZREVRANGEBYLEX
    method: GET
    data_selector: array-reply
- name: Zrevrangebyscore
  endpoint:
    path: /ZREVRANGEBYSCORE
    method: GET
    data_selector: array-reply
- name: zrevrank
  endpoint:
    path: /zrevrank
    method: GET
- name: Zscan
  endpoint:
    path: /Zscan
    method: GET
- name: Zscore
  endpoint:
    path: /Zscore
    method: GET
    data_selector: score
- name: Zunionstore
  endpoint:
    path: /
    method: ZUNIONSTORE
    data_selector: integer-reply
- name: benchmark
  endpoint:
    path: /redis-benchmark
    method: GET
    data_selector: results
    params:
      clients: 50
      requests: 100000
- name: node_rejoin
  endpoint:
    path: /cluster/node_rejoin
    method: GET
- name: replica_migration
  endpoint:
    path: /cluster/replica_migration
    method: GET
- name: node_reset
  endpoint:
    path: /cluster/node_reset
    method: POST
- name: remove_node
  endpoint:
    path: /cluster/remove_node
    method: POST
- name: publish_subscribe
  endpoint:
    path: /cluster/publish_subscribe
    method: POST
- name: hash_slots
  endpoint:
    path: /cluster/slots
    method: GET
- name: cluster_info
  endpoint:
    path: /cluster/info
    method: GET
- name: cluster_nodes
  endpoint:
    path: /cluster/nodes
    method: GET
    data_selector: nodes
- name: add_node_master
  endpoint:
    path: /cluster/add-node
    method: POST
    data_selector: result
    params:
      address: 127.0.0.1:7006
      existing_node: 127.0.0.1:7000
- name: add_node_replica
  endpoint:
    path: /cluster/add-node
    method: POST
    data_selector: result
    params:
      address: 127.0.0.1:7006
      existing_node: 127.0.0.1:7000
      type: slave
- name: remove_node
  endpoint:
    path: /cluster/del-node
    method: DELETE
    data_selector: result
    params:
      node_id: <node-id>
      existing_node: 127.0.0.1:7000
- name: configuration
  endpoint:
    path: /configuration
    method: GET
    data_selector: directives
- name: data_types
  endpoint:
    path: /data-types
    method: GET
    data_selector: data
- name: hash
  endpoint:
    path: /hash
    method: GET
    data_selector: records
- name: set
  endpoint:
    path: /set
    method: GET
    data_selector: records
- name: sorted_set
  endpoint:
    path: /sorted_set
    method: GET
    data_selector: records
- name: simple_numerical_indexes
  endpoint:
    path: /simple/numerical/indexes
    method: GET
    data_selector: records
- name: user_index
  endpoint:
    path: /user/index
    method: POST
    data_selector: index_data
    params: {}
- name: geo_index
  endpoint:
    path: /geo/index
    method: POST
    data_selector: geo_data
    params: {}
- name: completion_index
  endpoint:
    path: /completion/index
    method: POST
    data_selector: completion_data
    params: {}
- name: composite_index
  endpoint:
    path: /composite/index
    method: POST
    data_selector: composite_data
    params: {}
- name: graph_index
  endpoint:
    path: /graph/index
    method: POST
    data_selector: graph_data
    params: {}
- name: event_loop
  endpoint:
    path: /event_loop
    method: GET
    data_selector: events
    params: {}
- name: sds
  endpoint:
    path: /commands/sds
    method: GET
    data_selector: commands
    params: {}
- name: dynamic_strings
  endpoint:
    path: /topics/internals-sds
    method: GET
- name: virtual_memory
  endpoint:
    path: /topics/internals-vm
    method: GET
- name: event_library
  endpoint:
    path: /topics/internals-eventlib
    method: GET
- name: redis_event_library
  endpoint:
    path: /topics/internals-rediseventlib
    method: GET
- name: latency_monitor
  endpoint:
    path: /latency
    method: CONFIG SET
    data_selector: latency-monitor-threshold
    params:
      threshold: '100'
- name: latency_latest
  endpoint:
    path: /latency/latest
    method: GET
    data_selector: latest_latency_events
    params: {}
- name: latency_history
  endpoint:
    path: /latency/history
    method: GET
    data_selector: raw_data
    params:
      event_name: command
- name: latency_reset
  endpoint:
    path: /latency/reset
    method: POST
    data_selector: reset_events
    params: {}
- name: LATENCY GRAPH
  endpoint:
    path: /latency/graph
    method: GET
    data_selector: event-name
    params: {}
- name: LATENCY DOCTOR
  endpoint:
    path: /latency/doctor
    method: GET
    data_selector: latency analysis
    params: {}
- name: maxmemory
  endpoint:
    path: /config/maxmemory
    method: SET
    data_selector: maxmemory
    params: {}
- name: maxmemory-policy
  endpoint:
    path: /config/maxmemory-policy
    method: SET
    data_selector: maxmemory-policy
    params: {}
- name: lfu_mode
  endpoint:
    params:
      lfu-log-factor: '10'
      lfu-decay-time: '1'
- name: mass_insertion
  endpoint:
    path: /mass_insertion
    method: POST
    data_selector: commands
    params: {}
- name: memory_optimization_config
  endpoint:
    path: /memory/config
    method: GET
    data_selector: config
    params: {}
- name: helloworld
  endpoint:
    path: /helloworld/rand
    method: GET
    data_selector: random_number
- name: module_initialization
  endpoint:
    path: /module/initialization
    method: GET
    data_selector: module_init_data
- name: command_registration
  endpoint:
    path: /command/registration
    method: POST
    data_selector: command_reg_data
- name: key_operations
  endpoint:
    path: /key/operations
    method: PUT
    data_selector: key_ops_data
- name: native_types_support
  endpoint:
    path: /modules/native_types
    method: GET
    data_selector: native_types
    params: {}
- name: MyType-AZ
  endpoint:
    path: /services/data/vXX.X/sobjects/MyType-AZ
    method: POST
    data_selector: records
- name: partitioning
  endpoint:
    path: /partitioning
    method: GET
    data_selector: partitioning_info
- name: Redis Cluster
  endpoint:
    path: /topics/cluster-tutorial
    method: GET
    data_selector: information
    params: {}
- name: Twemproxy
  endpoint:
    path: /github.com/twitter/twemproxy
    method: GET
    data_selector: information
    params: {}
- name: Clients supporting consistent hashing
  endpoint:
    path: /redis.io/clients
    method: GET
    data_selector: information
    params: {}
- name: RDB advantages
  endpoint:
    path: /RDBAdvantages
    method: GET
    data_selector: advantages
- name: RDB disadvantages
  endpoint:
    path: /RDBDisadvantages
    method: GET
    data_selector: disadvantages
- name: AOF advantages
  endpoint:
    path: /AOFAdvantages
    method: GET
    data_selector: advantages
- name: AOF disadvantages
  endpoint:
    path: /AOFDisadvantages
    method: GET
    data_selector: disadvantages
- name: subscribe
  endpoint:
    path: /subscribe
    method: POST
    data_selector: messages
    params: {}
- name: unsubscribe
  endpoint:
    path: /unsubscribe
    method: POST
    data_selector: messages
    params: {}
- name: publish
  endpoint:
    path: /publish
    method: POST
    data_selector: messages
    params: {}
- name: redis_commands
  endpoint:
    path: /commands
    method: GET
- name: info_fields
  endpoint:
    path: /rdb/version7/info_fields
    method: GET
    data_selector: info_fields
- name: commands
  endpoint:
    path: /commands
    method: GET
    data_selector: commands
- name: latency_check
  endpoint:
    path: --latency
    method: GET
    data_selector: stats
    params: {}
- name: latency_history
  endpoint:
    path: --latency-history
    method: GET
    data_selector: stats
    params: {}
- name: intrinsic_latency
  endpoint:
    path: --intrinsic-latency
    method: GET
    data_selector: latency
    params:
      test_time: '5'
- name: rdb_backup
  endpoint:
    path: --rdb
    method: GET
    data_selector: backup
    params:
      dest_filename: /tmp/dump.rdb
- name: slave_mode
  endpoint:
    path: --slave
    method: GET
    data_selector: commands
    params: {}
- name: lru_simulation
  endpoint:
    path: --lru-test
    method: GET
    data_selector: hits_misses
    params:
      keys: '10000000'
- name: replication
  endpoint:
    path: /INFO replication
    method: GET
    data_selector: replication_info
    params: {}
- name: role
  endpoint:
    path: /ROLE
    method: GET
    data_selector: role_info
    params: {}
- name: monitor_mymaster
  endpoint:
    path: /sentinel/monitor/mymaster
    method: POST
    data_selector: ''
    params:
      ip: 127.0.0.1
      port: 6379
      quorum: 2
- name: monitor_resque
  endpoint:
    path: /sentinel/monitor/resque
    method: POST
    data_selector: ''
    params:
      ip: 192.168.1.3
      port: 6380
      quorum: 4
- name: sentinel_commands
  endpoint:
    path: /sentinel/commands
    method: GET
    data_selector: commands
- name: master
  endpoint:
    path: /sentinel/master/mymaster
    method: GET
    data_selector: master
    params: {}
- name: slaves
  endpoint:
    path: /sentinel/slaves/mymaster
    method: GET
    data_selector: slaves
    params: {}
- name: sentinels
  endpoint:
    path: /sentinel/sentinels/mymaster
    method: GET
    data_selector: sentinels
    params: {}
- name: get_master_addr
  endpoint:
    path: /sentinel/get-master-addr-by-name/mymaster
    method: GET
    data_selector: address
    params: {}
- name: masters
  endpoint:
    path: /masters
    method: SENTINEL
    data_selector: masters
- name: master_info
  endpoint:
    path: /master/<master name>
    method: SENTINEL
    data_selector: master_info
- name: slaves
  endpoint:
    path: /slaves/<master name>
    method: SENTINEL
    data_selector: slaves
- name: sentinels
  endpoint:
    path: /sentinels/<master name>
    method: SENTINEL
    data_selector: sentinels
- name: get_master_addr
  endpoint:
    path: /get-master-addr-by-name/<master name>
    method: SENTINEL
    data_selector: master_addr
- name: stream_entry
  endpoint:
    path: /XADD
    method: POST
    data_selector: entry
    params: {}
- name: stream_length
  endpoint:
    path: /XLEN
    method: GET
    data_selector: length
    params: {}
- name: xrange
  endpoint:
    path: /xranges
    method: GET
- name: xrevrange
  endpoint:
    path: /xrevranges
    method: GET
- name: xread
  endpoint:
    path: /xreads
    method: GET
- name: xreadgroup
  endpoint:
    path: /xreadgroups
    method: GET
- name: xgroup
  endpoint:
    path: /xgroups
    method: POST
- name: xack
  endpoint:
    path: /xacks
    method: POST
- name: consumer_group
  endpoint:
    path: /XGROUP
    method: CREATE
    data_selector: OK
    params: {}
- name: read_messages
  endpoint:
    path: /XREADGROUP
    method: GET
    data_selector: messages
    params: {}
- name: pending_messages
  endpoint:
    path: /XPENDING
    method: GET
    data_selector: pending
    params: {}
- name: claim_message
  endpoint:
    path: /XCLAIM
    method: POST
    data_selector: claimed_message
    params: {}
- name: stream_info
  endpoint:
    path: /XINFO
    method: GET
    data_selector: stream_info
    params: {}
- name: key-value operations
  endpoint:
    path: /commands
    method: GET
    data_selector: commands
    params: {}
- name: users
  endpoint:
    path: /users
    method: GET
    data_selector: users
- name: posts
  endpoint:
    path: /posts
    method: GET
    data_selector: posts
notes:
- The module name 'AAAAAAAAA' is reserved and produces an error.
- Make sure to generate a strong and very long password
- If BGREWRITEAOF fails, no data gets lost as the old AOF will be untouched.
- The rewrite will be only triggered by Redis if there is not already a background
  process doing persistence.
- BITOP is a potentially slow command as it runs in O(N) time.
- BLPOP blocks the connection when there are no elements to pop from any of the given
  lists.
- A timeout of zero can be used to block indefinitely.
- Due to the single-threaded nature of Redis, it is not possible to kill a client
  connection while it is executing a command.
- New fields are regularly added for debugging purpose. Some could be removed in the
  future.
- 'The command performs the following actions: It stops processing all the pending
  commands from normal and pub/sub clients.'
- Sometimes it can be useful for clients to completely disable replies from the Redis
  server.
- The CLIENT REPLY command controls whether the server will reply the client's commands.
- Setting names to connections is a good way to debug connection leaks due to bugs
  in the application using Redis.
- The command can unblock a client blocked in a blocking operation.
- The command only works if all the specified slots are currently not assigned.
- The command fails if the same slot is specified multiple times.
- Use this command with care only by applications orchestrating Redis Cluster.
- This command only works in cluster mode and may be useful for debugging and in order
  to manually orchestrate a cluster configuration when a new cluster is created.
- CLUSTER FAILOVER, unless the TAKEOVER option is specified, does not execute a failover
  synchronously, it only schedules a manual failover.
- The command implements a ban-list, preventing the same node from being added again
  for some time.
- Provides INFO style information about Redis Cluster vital parameters.
- Redis Cluster needs to form a full mesh but does not require all `CLUSTER MEET`
  commands to establish connections.
- Each node in a Redis Cluster has its view of the current cluster configuration.
- CLUSTER NODES provides all this information for administrative tasks, debugging,
  and configuration inspections.
- The command provides a list of replica nodes replicating from the specified master
  node.
- The command will fail if the specified node is not known or if it is not a master.
- If the command succeeds the new replica will immediately try to contact its master
  in order to replicate from it.
- Does not work for masters if they hold one or more keys, keys must be removed first.
- Starting with Redis version 5, the word slave is no longer used. Please use the
  new command `CLUSTER REPLICAS`.
- Not all the configuration parameters are supported in Redis 2.4
- CONFIG GET takes a single argument, which is a glob-style pattern
- The CONFIG REWRITE command rewrites the redis.conf file the server was started with,
  applying the minimal changes needed to make it reflect the configuration currently
  used by the server.
- CONFIG REWRITE is also able to rewrite the configuration file from scratch if the
  original one no longer exists for some reason.
- The CONFIG SET command is used to reconfigure the server at run time without the
  need to restart Redis.
- All the supported parameters have the same meaning of the equivalent configuration
  parameter used in the redis.conf file.
- EVAL and EVALSHA are used to evaluate scripts using the Lua interpreter built into
  Redis starting from version 2.6.0.
- Redis scripts are executed in an atomic way.
- Using slow scripts can block other clients.
- The CJSON library provides extremely fast JSON manipulation within Lua.
- The timeout will only be cleared by commands that delete or overwrite the contents
  of the key.
- Keys expiring information is stored as absolute Unix timestamps.
- EXPIREAT has the same effect and semantic as EXPIRE, but instead of specifying the
  number of seconds representing the TTL, it takes an absolute Unix timestamp.
- The command never fails.
- Time-complexity for this operation is O(N), N being the number of keys in all existing
  databases.
- This command never fails.
- The time-complexity for this operation is O(N), N being the number of keys in the
  database.
- There is no GEODEL command because you can use ZREM in order to remove elements.
- The command takes arguments in the standard format x,y so the longitude must be
  specified before the latitude.
- Areas very near to the poles are not indexable.
- The command returns the distance as a double (represented as a string) in the specified
  unit, or NULL if one or both the elements are missing.
- This command was renamed to GETRANGE, it is called SUBSTR in Redis versions <= 2.0.
- The function handles out of range requests by limiting the resulting range to the
  actual length of the string.
- The command is always propagated in the replication link and the Append Only File
  as a HSET operation.
- Returns the number of fields contained in the hash stored at `key`.
- Returns `0` when `key` does not exist.
- This operation is limited to 64 bit signed integers.
- If the key does not exist, it is set to 0 before performing the operation.
- The command is always propagated in the replication link and the Append Only File
  as a SET operation.
- consider KEYS as a command that should only be used in production environments with
  extreme care
- It may ruin performance when it is executed against large databases
- This command is intended for debugging and special operations, such as changing
  your keyspace layout
- Don't use KEYS in your regular application code
- An error is returned for out of range indexes.
- This command is currently implemented only when using jemalloc as an allocator,
  and evaluates to a benign NOOP for all others.
- The MEMORY PURGE command attempts to purge dirty pages so these can be reclaimed
  by the allocator.
- Starting with Redis 5, the word slave is no longer used except in this command due
  to protocol constraints.
- MIGRATE supports a new bulk-migration mode that uses pipelining in order to migrate
  multiple keys between instances.
- MONITOR streams back every command processed by the Redis server.
- Certain special administration commands like CONFIG are not logged into the MONITOR
  output.
- Running a single MONITOR client can reduce throughput by more than 50%.
- When PFCOUNT is called with a single key, performances are excellent.
- When PFCOUNT is called with multiple keys, an on-the-fly merge of the HyperLogLogs
  is performed, which is slow.
- The cardinality of the union can't be cached, so when used with multiple keys PFCOUNT
  may take a time in the order of magnitude of the millisecond.
- Like TTL this command returns the remaining time to live of a key that has an expire
  set, with the sole difference that TTL returns the amount of remaining time in seconds
  while PTTL returns it in milliseconds.
- In Redis 2.6 or older the command returns -1 if the key does not exist or if the
  key exist but has no associated expire.
- 'Starting with Redis 2.8 the return value in case of error changed: The command
  returns -2 if the key does not exist. The command returns -1 if the key exists but
  has no associated expire.'
- Renames `key` to `newkey`.
- It returns an error when `key` does not exist.
- If `newkey` already exists it is overwritten, when this happens `RENAME` executes
  an implicit `DEL` operation, so if the deleted key contains a very big value it
  may cause high latency even if `RENAME` itself is usually a constant-time operation.
- Before Redis 3.2.0, an error is returned if source and destination names are the
  same.
- If ttl is 0 the key is created without any expire, otherwise the specified expire
  time (in milliseconds) is set.
- RESTORE will return a 'Target key name is busy' error when key already exists unless
  you use the REPLACE modifier (Redis 3.0 or greater).
- RESTORE checks the RDB version and data checksum. If they don't match an error is
  returned.
- The SAVE command performs a synchronous save of the dataset producing a point in
  time snapshot of all the data inside the Redis instance.
- You almost never want to call SAVE in production environments where it will block
  all the other clients.
- SCAN is a cursor based iterator.
- The default COUNT value is 10.
- Avoid debugging Lua scripts using your Redis production server. Use a development
  server instead.
- The SET command options can replace SETNX, SETEX, PSETEX, it is possible that in
  future versions of Redis these three commands will be deprecated and finally removed.
- SETNX is short for 'SET if Not eXists'.
- The locking pattern using SETNX is discouraged in favor of the Redlock algorithm.
- When setting the last possible byte and the string value stored at *key* does not
  yet hold a string value, or holds a small string value, Redis needs to allocate
  all intermediate memory which can block the server for some time.
- On a 2010 MacBook Pro, setting byte number 536870911 (512MB allocation) takes ~300ms,
  setting byte number 134217728 (128MB allocation) takes ~80ms, setting bit number
  33554432 (32MB allocation) takes ~30ms and setting bit number 8388608 (8MB allocation)
  takes ~8ms.
- Note that once this first allocation is done, subsequent calls to `SETRANGE` for
  the same *key* will not have the allocation overhead.
- A Redis instance that is configured for not persisting on disk will not dump the
  RDB file on SHUTDOWN.
- Conditions where a SHUTDOWN fails include when AOF is enabled and the system is
  in a state that does not allow immediate persist on disk.
- Starting with Redis version 5, the Redis project no longer uses the word slave.
- The slow log is accumulated in memory, so no file is written with information about
  the slow command executions.
- The number of returned elements can be limited using the !LIMIT modifier.
- 'Using hashes in !BY and !GET is possible with the syntax: key->fieldname.'
- This command is not suitable when you need a guaranteed uniform distribution of
  the returned elements.
- When called with just the key argument, return a random element from the set value
  stored at key.
- When called with the additional count argument, return an array of count distinct
  elements if count is positive.
- Specified members that are not a member of this set are ignored.
- If `key` does not exist, it is treated as an empty set and this command returns
  `0`.
- An error is returned when the value stored at `key` is not a set.
- This command swaps two Redis databases.
- 'Starting with Redis 2.8 the return value in case of error changed: The command
  returns -2 if the key does not exist.'
- 'WAIT does not make Redis a strongly consistent store: while synchronous replication
  is part of a replicated state machine, it is not the only thing needed.'
- XACK removes messages from the pending entries list of a stream consumer group.
- XADD is the only Redis command that can add data to a stream.
- Zero-length streams are possible, check if a key exists using TYPE or EXISTS.
- Fetching data from a stream via a consumer group, and not acknowledging such data,
  has the effect of creating pending entries.
- The XPENDING command is the interface to inspect the list of pending messages.
- The STREAMS option is mandatory and MUST be the final option.
- It is very important to understand that you should use the special `$` ID only for
  the first call to `XREAD`.
- Supports consumer groups for message partitioning.
- ZADD supports options like XX, NX, CH, and INCR
- The command has a complexity of just O(log(N)) because it uses elements ranks
- The score value should be the string representation of a numeric value, and accepts
  double precision floating point numbers.
- The command has a complexity of just O(log(N)) because it uses elements ranks.
- Removes the specified members from the sorted set stored at `key`.
- Non existing members are ignored.
- An error is returned when `key` exists and does not hold a sorted set.
- Redis has a very small memory footprint and CPU requirements.
- Redis can be used as an interprocess communication system between the processes
  running in the device.
- The append only file storage of Redis is well suited for the SSD cards.
- By default Redis does not require any authentication and listens to all the network
  interfaces.
- Make sure to set the Linux kernel overcommit memory setting to 1.
- Make sure to disable Linux kernel feature transparent huge pages.
- Make sure to setup some swap in your system.
- Set an explicit maxmemory option limit in your instance.
- If you are using Redis in a very write-heavy application, while saving an RDB file
  on disk or rewriting the AOF log Redis may use up to 2 times the memory normally
  used.
- Make sure to setup some non trivial replication backlog.
- Even if you have persistence disabled, Redis will need to perform RDB saves if you
  use replication.
- If you are using replication, make sure that either your master has persistence
  enabled, or that it does not automatically restarts on crashes.
- Requires a running Redis instance before launching the benchmark
- Using pipelining can significantly increase performance
- Redis is an in-memory data store with some optional persistence options.
- Redis runs slower on a VM compared to running without virtualization using the same
  hardware.
- Redis accepts clients connections on the configured listening TCP port and on the
  Unix socket if enabled.
- When Redis is configured in order to handle a specific number of clients it is a
  good idea to make sure that the operating system limit to the maximum number of
  file descriptors per process is also set accordingly.
- 'Timeouts are not to be considered very precise: Redis avoids to set timer events
  or to run O(N) algorithms in order to check idle clients, so the check is performed
  incrementally from time to time.'
- Redis Cluster does not support multiple databases like the stand alone version of
  Redis. There is just database 0 and the SELECT command is not allowed.
- Redis Cluster is designed to survive failures of a few nodes in the cluster, but
  it is not a suitable solution for applications that require availability in the
  event of large net splits.
- Redis Cluster supports the ability to add and remove nodes while the cluster is
  running.
- The core of the implementation is the ability to move hash slots around.
- The `ADDSLOTS` command is usually used when a new cluster is created from scratch.
- The `DELSLOTS` is mainly used for manual modification of a cluster configuration
  or for debugging tasks.
- The `SETSLOT` subcommand is used to assign a slot to a specific node ID.
- When a slot is set as MIGRATING, the node will accept all queries that are about
  this hash slot.
- When a slot is set as IMPORTING, the node will accept all queries that are about
  this hash slot.
- Multi-key operations may become unavailable when a resharding of the hash slot the
  keys belong to is in progress.
- Clients can use slaves in order to scale reads using the `READONLY` command.
- Currently Redis Cluster does not support NATted environments and in general environments
  where IP addresses or TCP ports are remapped.
- 'For a Redis Cluster to work properly you need, for each node: The normal client
  communication port (usually 6379) used to communicate with clients to be open to
  all the clients that need to reach the cluster, plus all the other cluster nodes.'
- Redis Cluster does not use consistent hashing.
- At least three master nodes are required for a minimal cluster.
- The startup nodes don't need to be all the nodes of the cluster.
- Normal applications don't need to be so careful with error handling.
- A master node must be empty before removal.
- Use redis-cli to perform all cluster operations.
- Redis can start without a configuration file for testing and development.
- Configuration can be modified on the fly using CONFIG SET and CONFIG GET.
- Redis keys can be binary safe and can have a maximum size of 512 MB.
- Redis strings can store values of every kind, including binary data, and the maximum
  size of a value is 512 MB.
- Redis automatically manages keys for empty lists.
- There is no practical limit to the number of fields in hashes.
- Redis is developed with a great stress on stability.
- When Redis crashes it produces a detailed report of what happened.
- It is better to attach GDB to Redis compiled without optimizations using the make
  noopt command.
- It is important to understand that sending the core file contains all the data that
  was inside the Redis instance at the time of the crash.
- Lock validity time is 30000 milliseconds.
- The algorithm requires multiple Redis instances for distribution.
- Currently, a good solution that may be suitable for many use cases is to use Spiped,
  a utility for creating symmetrically encrypted and authenticated pipes between socket
  addresses.
- Redis is an in-memory but persistent on disk database, so it represents a different
  trade off where very high write and read speed is achieved with the limitation of
  data sets that can't be larger than memory.
- If your real problem is not the total RAM needed, but the fact that you need to
  split your data set into multiple Redis instances, please read the Partitioning
  page in this documentation for more info.
- Using the ZREVRANGEBYSCORE it is possible to query a range in reversed order.
- Keeping the index updated may be challenging, in the course of months or years it
  is possible that inconsistencies are added because of software bugs, network partitions
  or other events.
- Different strategies could be used. If the index data is outside Redis read repair
  can be a solution, where data is fixed in a lazy way when it is requested.
- Redis runs on port 6379 by default.
- In order to enable blocking VM in Redis `server.vm_max_threads` must be set to zero.
- The parameter `server.vm_max_memory` is used in order to trigger swapping.
- Redis is an open source (BSD licensed), in-memory data structure store, used as
  a database, cache and message broker.
- Redis may work in Solaris-derived systems like SmartOS, but the support is best
  effort.
- There is no official support for Windows builds, but Microsoft develops and maintains
  a Win-64 port of Redis.
- By default, monitoring is disabled (threshold set to 0).
- Make sure you are not running slow commands that are blocking the server.
- For EC2 users, make sure you use HVM based modern EC2 instances.
- Transparent huge pages must be disabled from your kernel.
- If you are using a virtual machine, check the minimum latency you can expect from
  your runtime environment.
- Enable and use the Latency monitor feature of Redis for latency events and causes.
- Intrinsic latency is the baseline and cannot be removed.
- The intrinsic latency may change over time depending on the load of the system.
- Using a physical machine over a VM is preferred for hosting Redis.
- Keep connections to the server as long lived as possible.
- Use Unix domain sockets if the client is on the same host as the server.
- Prefer aggregated commands (MSET/MGET) over pipelining if possible.
- Monitor slow commands using the Redis Slow Log feature.
- Disable transparent huge pages to avoid latency penalties.
- Check the amount of Redis memory that is swapped on disk if latency is suspected.
- The AOF can be configured to perform an fsync on disk in three different ways using
  the appendfsync configuration option.
- Most Redis users will use either the no or everysec setting for the appendfsync
  configuration directive.
- The suggestion for minimum latency is to avoid other processes doing I/O in the
  same system.
- Using an SSD disk can help as well, but usually even non SSD disks perform well
  with the append only file if the disk is spare as Redis writes to the append only
  file without performing any seek.
- The software watchdog is an experimental feature. While it is designed to be used
  in production environments care should be taken to backup the database before proceeding
  as it could possibly have unexpected interactions with the normal execution of the
  Redis server.
- Please make sure to avoid debugging Lua scripts using your Redis production server.
  Use a development server instead.
- Using the synchronous debugging mode results into the Redis server blocking for
  all the time the debugging session lasts.
- Uses OAuth2 with refresh token  requires setup of connected app in api
- Redis is open source software released under the terms of the three clause BSD license.
- To pick the right eviction policy is important depending on the access pattern of
  your application.
- Setting an expire to a key costs memory, so using a policy like allkeys-lru is more
  memory efficient since there is no need to set an expire for the key to be evicted
  under memory pressure.
- Redis LRU algorithm is not an exact implementation.
- You are able to tune the precision of the algorithm by changing the number of samples
  to check for every eviction.
- To experiment in production with different values for the sample size by using the
  CONFIG SET maxmemory-samples <count> command, is very simple.
- This page is a work in progress. Currently it is just a list of things you should
  check if you have problems with memory.
- Since Redis 2.2 many data types are optimized to use less space up to a certain
  size.
- If a specially encoded value will overflow the configured max size, Redis will automatically
  convert it into normal encoding.
- Redis compiled with 32 bit target uses a lot less memory per key, since pointers
  are small, but such an instance will be limited to 4 GB of maximum memory usage.
- RDB and AOF files are compatible between 32 bit and 64 bit instances.
- 'For this to work, make sure that in your redis.conf you have something like this:
  hash-max-zipmap-entries 256'
- 'Remember to set the following field accordingly to the maximum size of your keys
  and values: hash-max-zipmap-value 1024'
- This API is currently experimental, so it can only be used if the macro REDISMODULE_EXPERIMENTAL_API
  is defined.
- It is important to stress that the private data is best freed in the free_privdata
  callback because the reply function may not be called if the client disconnects
  or timeout.
- Modules are dynamic libraries that can be loaded into Redis at startup or using
  the MODULE LOAD command.
- The current API version is '1'.
- Modules do not depend on Redis or external libraries.
- Keys opened for writing can be accessed for reading.
- When using higher level APIs, replication happens automatically if you use the "!"
  modifier in the format string of RedisModule_Call()
- Automatic memory management is enabled by calling RedisModule_AutoMemory(ctx) at
  the start of the command implementation
- Redis modules can access Redis built-in data structures.
- The name must be unique for each data type in the Redis ecosystem and must be exactly
  9 chars.
- By default keyspace events notifications are disabled.
- At least K or E should be present in the string to deliver events.
- Every time a key with a time to live associated is removed from the data set because
  it expired, an expired event is generated.
- Every time a key is evicted from the data set in order to free memory as a result
  of the maxmemory policy, an evicted event is generated.
- Operations involving multiple keys are usually not supported.
- Redis transactions involving multiple keys can not be used.
- Redis Cluster is the preferred way to get automatic sharding and high availability.
- Twemproxy is a proxy developed at Twitter for automatic partitioning among multiple
  Redis instances.
- 'Redis provides different persistence options: RDB and AOF.'
- RDB is good for backups and disaster recovery.
- AOF provides higher durability.
- Make Sure to Backup Your Database
- Disaster recovery in the context of Redis is basically the same story as backups,
  plus the ability to transfer those backups in many different external data centers.
- Redis supports pipelining since the very early days.
- If you have latency problems with Redis, that in some way appears to be idle for
  some time, read our Redis latency troubleshooting guide.
- Redis stable releases are usually very reliable, however in the rare event you are
  experiencing crashes the developers can help a lot more if you provide debugging
  information.
- We have a long history of users experiencing crashes with Redis that actually turned
  out to be servers with broken RAM.
- Please test your RAM using redis-server --test-memory in case Redis is not stable
  in your system.
- Redis built-in memory test is fast and reasonably reliable, but if you can you should
  reboot your server and use memtest86.
- The protocol outlined here is only used for client-server communication.
- Redis Cluster uses a different binary protocol in order to exchange messages between
  nodes.
- Redis saves dataset only from time to time unless SAVE command is called manually.
- Interactive mode allows users to type Redis commands.
- Command history is preserved between restarts in .rediscli_history file.
- 'Important: Must be executed on the computer running Redis server.'
- Redis is system software, and a type of system software that holds user data, so
  it is among the most critical pieces of a software stack.
- Our release cycle tries hard to make sure that a stable release is only released
  when it reaches a sufficiently high level of stability.
- Redis uses asynchronous replication, with asynchronous slave-to-master acknowledges
  of the amount of data processed.
- A master can have multiple slaves.
- Replication is also largely non-blocking on the slave side.
- Slaves can automatically reconnect when the master-slave link goes down.
- Writable slaves before version 4.0 were incapable of expiring keys with a time to
  live set.
- Redis is designed to be accessed by trusted clients inside trusted environments.
- Failing to protect the Redis port from the outside can have a big security impact.
- The AUTH command is sent unencrypted.
- Redis does not requires root privileges to run. It is recommended to run it as an
  unprivileged redis user that is only used for this purpose.
- Clients require explicit support for Redis Sentinel.
- Clients can automatically discover the master address via Sentinel.
- Clients may connect to slaves to scale read requests.
- On reconnection of a single connection, the Sentinel should be contacted again.
- Clients should return clear errors if no Sentinel can be contacted or if Sentinels
  do not recognize the master name.
- Redis Sentinel is currently a work in progress.
- Redis Sentinel is compatible with Redis 2.4.16 or greater, and redis 2.6.0-rc6 or
  greater.
- Sentinel does not perform automatic Failback.
- Document correct steps for the failback.
- Redis Sentinel is a high availability solution for automatic failover.
- Sentinels use persistent connections to monitor masters and slaves.
- Sentinel can enter TILT mode under certain conditions.
- Observers follow the leader but do not initiate failover.
- Sentinel provides high availability for Redis.
- It is mandatory to use a configuration file when running Sentinel.
- Sentinel does not guarantee that acknowledged writes are retained during failures.
- Sentinel requires at least three instances for robust deployment.
- Sentinel provides an API to inspect its state and health of monitored masters and
  slaves.
- Sentinel requires explicit client support for failover handling.
- Sentinel is a system where each process will always try to impose the last logical
  configuration to the set of monitored instances.
- Only applicable to Redis version 2.6 or greater
- Streams are an append only data structure.
- Each entry has a unique ID composed of time and sequence number.
- Consumers are auto-created the first time they are mentioned, no need for explicit
  creation.
- XREADGROUP is a write command because it modifies the consumer group as a side effect.
- Redis streams are practically very different from Kafka partitions.
- When using 1 stream -> 1 consumer, messages are processed in order.
- Redis streams can have a capped length using the MAXLEN option.
- All the commands in a transaction are serialized and executed sequentially.
- Either all of the commands or none are processed, making Redis transactions atomic.
- Redis commands can fail during a transaction, but still execute the rest of the
  transaction instead of rolling back.
- WATCH can be used for optimistic locking and check-and-set behavior.
- Retwis does not perform any multi-keys operation.
- On a very slow and loaded server, an Apache benchmark with 100 parallel clients
  issuing 100000 requests measured the average pageview to take 5 milliseconds.
- Redis VM is now deprecated.
- Using VM has several disadvantages and problems.
- The swap file has nothing to do with the durability of data, and can be removed
  when a Redis instance is terminated.
- The swap file should not be moved, deleted, or altered in any other way while Redis
  is running.
- The recommendation is to use Linux ext3 file system, or any other file system with
  good support for sparse files.
- VM is still experimental code, but over the last few weeks it was tested in many
  ways in development environments.
errors:
- 'EINVAL: command non existing, wrong arity, wrong format specifier.'
- 'EPERM: operation in Cluster instance with key in non local slot.'
- 'ERROR: Invalid password'
- 'ERR background process already exists: AOF rewrite is already in progress.'
- 'nil multi-bulk: No element could be popped and the timeout expired.'
- 'Invalid timeout: The command returns an error if the timeout is invalid.'
- 'OK: If the connection name was successfully set.'
- '-UNBLOCKED: client unblocked via CLIENT UNBLOCK'
- ERR Slot 1 is already busy
- The command only works if all the specified slots are already associated with some
  node.
- The command fails if the same slot is specified multiple times.
- Error if the operation cannot be executed, for example if we are talking with a
  node which is already a master.
- ERR specified node ID is not found in the nodes table.
- ERR the node receiving the command is a replica, and the specified node ID identifies
  its current master.
- ERR the node ID identifies the same node we are sending the command to.
- 'Invalid address or port specified: an error is returned.'
- Error returned if the command was not successful.
- 'Error: If the server was started without a configuration file at all, the CONFIG
  REWRITE will just return an error.'
- 'ERR Error running script: Script attempted to create global variable'
- ERR Operation against a key holding the wrong kind of value
- '0: if key does not exist.'
- '1: if the timeout was set.'
- Error when the user attempts to index coordinates outside the specified ranges.
- Returns NULL if one or both the members are missing.
- Returns an error if the field contains a value of the wrong type (not a string).
- Returns an error if the current field content or the specified increment are not
  parsable as a double precision floating point number.
- 'ERROR: too many requests per second'
- An error is returned if the key contains a value of the wrong type or contains a
  string that can not be represented as integer.
- An error is returned if the key contains a value of the wrong type (not a string).
- An error is returned if the current key content or the specified increment are not
  parsable as a double precision floating point number.
- simple-string-reply
- 'IOERR: I/O error during the transfer or if the timeout is reached.'
- 'NOKEY: Returned if there are no keys to migrate in the source instance.'
- 'KEY_NOT_FOUND: Returned when `key` does not exist.'
- ERR source key does not exist
- ERR destination key already exists
- 'Target key name is busy: Use REPLACE modifier if key exists.'
- 'Checksum error: RDB version and data checksum do not match.'
- 0 if the key was not set.
- 1 if the key was set.
- simple-string-reply on error
- 'integer-reply: the number of members that were removed from the set, not including
  non existing members.'
- ERR wrong number of arguments for 'swapdb' command
- '-2: The key does not exist.'
- '-1: The key exists but has no associated expire.'
- Some message IDs may no longer be part of the PEL and will not be counted as successfully
  acknowledged.
- An error is returned when `key` exists but does not hold a sorted set.
- Security issue if Redis is exposed on the internet.
- 'REQUEST_LIMIT_EXCEEDED: Throttle API calls or reduce frequency'
- 'QUERY_TIMEOUT: Break down filters or add selectivity'
- Unable to set the max number of files limit to 100032 (Invalid argument), setting
  the max clients configuration to 10112.
- 'ERR_CLUSTER_NOT_IN_CLUSTER_STATE: The cluster is not in a cluster state.'
- 'ERR_NOT_AUTHORIZED: Authentication required.'
- 'Invalid node ID specified: Ensure the node ID is correct.'
- 'Node not found: The specified node does not exist in the cluster.'
- 'nil: No elements to pop from the list.'
- WRONGTYPE Operation against a key holding the wrong kind of value
- 'N/A: Retry on failure if unable to acquire the lock.'
- Latency spikes exceeding configured threshold not logged.
- If the database has many many keys expiring in the same second, and these make up
  at least 25% of the current population of keys with an expire set, Redis can block
  in order to get the percentage of keys already expired below 25%.
- 'noeviction: return errors when the memory limit was reached'
- 'allkeys-lru: evict keys by trying to remove the less recently used (LRU) keys first'
- 'volatile-lru: evict keys by trying to remove the less recently used (LRU) keys
  first, but only among keys that have an expire set'
- 'REDISMODULE_ERR: Function call failed due to incorrect parameters.'
- 'EINVAL: Command name is invalid or format specifier is not recognized.'
- 'EPERM: Attempted to access non-local hash slots in a cluster.'
- To find a list of critical bugs please refer to the changelogs.
- ERR unknown command 'foobar'
- When persistence is turned off, auto restart of instances should be disabled to
  avoid data loss.
- 'min-slaves-to-write: Minimum number of slaves not met for write operation.'
- 'masterauth: Incorrect password for master authentication.'
- 'Unauthorized: A client can authenticate itself by sending the AUTH command followed
  by the password.'
- Redis Sentinel is unreachable.
- Sentinels don't know this master name.
- '-BUSY: A Lua script is running longer than the configured time limit.'
- 'PONG: Response to PING command.'
- 'MISCONFIG: Redis will reply to all write commands with this error when the RDB
  file creation fails'
- ERR The ID specified in XADD is equal or smaller than the target stream top item
- 'Timeout: The command may take too long to respond.'
- 'Invalid ID: The specified ID is not valid in the context of the command.'
- No bugs were noticed during testing, but more obscure bugs may happen in non-controlled
  environments.
auth_info:
  mentioned_objects: []
client:
  base_url: http://localhost:6379
  headers:
    Accept: application/json
source_metadata: null
