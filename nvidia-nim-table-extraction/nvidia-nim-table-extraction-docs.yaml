resources:
- name: infer
  endpoint:
    path: /v1/infer
    method: POST
    data_selector: input
- name: infer
  endpoint:
    path: /v1/infer
    method: POST
    data_selector: input
- name: infer
  endpoint:
    path: /v1/infer
    method: POST
- name: inference
  endpoint:
    path: /v1/infer
    method: POST
    data_selector: null
    params: {}
- name: text_inference
  endpoint:
    path: /v1/infer
    method: POST
    data_selector: data
    params: {}
- name: health_check
  endpoint:
    path: /v1/health/ready
    method: GET
    data_selector: ready
    params: {}
- name: health_check_live
  endpoint:
    path: /v1/health/live
    method: GET
    data_selector: live
    params: {}
- name: infer
  endpoint:
    path: /v1/infer
    method: POST
    data_selector: data
    params: {}
- name: health_check
  endpoint:
    path: /v1/health/ready
    method: GET
    data_selector: ready
    params: {}
- name: health_live_check
  endpoint:
    path: /v1/health/live
    method: GET
    data_selector: live
    params: {}
- name: infer
  endpoint:
    path: /v1/infer
    method: POST
    data_selector: input
    params: {}
- name: infer
  endpoint:
    path: /v1/infer
    method: POST
    data_selector: input
- name: infer
  endpoint:
    path: /v1/infer
    method: POST
    data_selector: data
    params: {}
- name: health
  endpoint:
    path: /v1/health/ready
    method: GET
    data_selector: ready
    params: {}
- name: live_health
  endpoint:
    path: /v1/health/live
    method: GET
    data_selector: live
    params: {}
- name: infer
  endpoint:
    path: /v1/infer
    method: POST
    data_selector: data
    params: {}
- name: health
  endpoint:
    path: /v1/health/ready
    method: GET
    data_selector: ready
    params: {}
- name: health_live
  endpoint:
    path: /v1/health/live
    method: GET
    data_selector: live
    params: {}
- name: metrics
  endpoint:
    path: /metrics
    method: GET
- name: license
  endpoint:
    path: /license
    method: GET
- name: metadata
  endpoint:
    path: /metadata
    method: GET
- name: manifest
  endpoint:
    path: /manifest
    method: GET
- name: inference
  endpoint:
    path: /infer
    method: POST
- name: health_ready
  endpoint:
    path: /health/ready
    method: GET
- name: health_live
  endpoint:
    path: /health/live
    method: GET
- name: metrics
  endpoint:
    path: /v1/metrics
    method: GET
- name: license
  endpoint:
    path: /v1/license
    method: GET
- name: metadata
  endpoint:
    path: /v1/metadata
    method: GET
- name: manifest
  endpoint:
    path: /v1/manifest
    method: GET
- name: inference
  endpoint:
    path: /v1/infer
    method: POST
- name: health_ready
  endpoint:
    path: /v1/health/ready
    method: GET
- name: health_live
  endpoint:
    path: /v1/health/live
    method: GET
- name: PaddleOCR
  endpoint:
    path: /api/paddleocr
    method: GET
    data_selector: model
    params: {}
- name: paddleocr
  endpoint:
    path: /paddleocr
    method: POST
- name: image-ocr
  endpoint:
    path: /v1/infer
    method: POST
    data_selector: response
    params: {}
- name: image-ocr
  endpoint:
    path: /v1/infer
    method: POST
    data_selector: response
    params: {}
- name: model_profiles
  endpoint:
    path: /list-model-profiles
    method: GET
    data_selector: MODEL PROFILES
    params: {}
- name: performance_benchmark
  endpoint:
    path: /performance
    method: GET
- name: performance_benchmark
  endpoint:
    path: /performance
    method: POST
    data_selector: results
- name: infer
  endpoint:
    path: /v1/infer
    method: POST
    data_selector: input
- name: infer
  endpoint:
    path: /v1/infer
    method: POST
    data_selector: input
- name: infer
  endpoint:
    path: /v1/infer
    method: POST
    data_selector: response
    params: {}
- name: health
  endpoint:
    path: /v1/health/ready
    method: GET
    data_selector: ready
    params: {}
- name: health_live
  endpoint:
    path: /v1/health/live
    method: GET
    data_selector: live
    params: {}
- name: inference
  endpoint:
    path: /v1/infer
    method: POST
    data_selector: input
    params: {}
- name: infer
  endpoint:
    path: /v1/infer
    method: POST
    data_selector: data
    params: {}
- name: health
  endpoint:
    path: /v1/health/ready
    method: GET
    data_selector: ready
    params: {}
- name: health_live
  endpoint:
    path: /v1/health/live
    method: GET
    data_selector: live
    params: {}
- name: infer
  endpoint:
    path: /v1/infer
    method: POST
    data_selector: data
    params: {}
- name: health
  endpoint:
    path: /v1/health/ready
    method: GET
    data_selector: ready
    params: {}
- name: health_live
  endpoint:
    path: /v1/health/live
    method: GET
    data_selector: live
    params: {}
- name: infer
  endpoint:
    path: /v1/infer
    method: POST
    data_selector: input
- name: infer
  endpoint:
    path: /v1/infer
    method: POST
    data_selector: data
- name: health
  endpoint:
    path: /v1/health/ready
    method: GET
- name: health_live
  endpoint:
    path: /v1/health/live
    method: GET
- name: metrics
  endpoint:
    path: /v1/metrics
    method: GET
- name: license
  endpoint:
    path: /v1/license
    method: GET
- name: metadata
  endpoint:
    path: /v1/metadata
    method: GET
- name: manifest
  endpoint:
    path: /v1/manifest
    method: GET
- name: inference
  endpoint:
    path: /v1/infer
    method: POST
- name: health_ready
  endpoint:
    path: /v1/health/ready
    method: GET
- name: health_live
  endpoint:
    path: /v1/health/live
    method: GET
- name: metrics
  endpoint:
    path: /v1/metrics
    method: GET
- name: license
  endpoint:
    path: /v1/license
    method: GET
- name: metadata
  endpoint:
    path: /v1/metadata
    method: GET
- name: manifest
  endpoint:
    path: /v1/manifest
    method: GET
- name: infer
  endpoint:
    path: /v1/infer
    method: POST
- name: health_ready
  endpoint:
    path: /v1/health/ready
    method: GET
- name: health_live
  endpoint:
    path: /v1/health/live
    method: GET
- name: environment_variables
  endpoint:
    path: /environment-variables
    method: GET
    data_selector: variables
    params: {}
- name: livenessProbe
  endpoint:
    path: /v1/health/live
    method: GET
- name: readinessProbe
  endpoint:
    path: /v1/health/ready
    method: GET
- name: startupProbe
  endpoint:
    path: /v1/health/ready
    method: GET
- name: livenessProbe
  endpoint:
    path: /v1/health/live
    method: GET
- name: readinessProbe
  endpoint:
    path: /v1/health/ready
    method: GET
- name: startupProbe
  endpoint:
    path: /v1/health/ready
    method: GET
- name: Image OCR NIM
  endpoint:
    path: /nemo/retriever/image-ocr
    method: GET
- name: Object Detection NIM
  endpoint:
    path: https://docs.nvidia.com/nim/ingestion/object-detection/latest/overview.html
    method: GET
- name: Table Extraction NIM
  endpoint:
    path: https://docs.nvidia.com/nim/ingestion/table-extraction/latest/overview.html
    method: GET
- name: Chart Extraction NIM
  endpoint:
    path: https://docs.nvidia.com/nim/ingestion/table-extraction/latest/overview.html
    method: GET
- name: Text Embedding NIM
  endpoint:
    path: https://docs.nvidia.com/nim/nemo-retriever/text-embedding/latest/overview.html
    method: GET
- name: Text Reranking NIM
  endpoint:
    path: https://docs.nvidia.com/nim/nemo-retriever/text-reranking/latest/overview.html
    method: GET
- name: PaddleOCR
  endpoint:
    path: /models/baidu/paddleocr
    method: GET
- name: paddleocr
  endpoint:
    path: /launch
    method: POST
- name: paddleocr
  endpoint:
    path: /v1/infer
    method: POST
- name: PaddleOCR
  endpoint:
    path: /baidu/paddleocr
    method: GET
- name: model_profiles
  endpoint:
    path: /list-model-profiles
    method: GET
    data_selector: MODEL PROFILES
- name: image_inference
  endpoint:
    path: /v1/infer
    method: POST
    data_selector: input
- name: performance_benchmark
  endpoint:
    path: /performance
    method: GET
    data_selector: data
    params: {}
- name: model_profiles
  endpoint:
    path: /list-model-profiles
    method: GET
    data_selector: MODEL PROFILES
    params: {}
- name: performance_benchmark
  endpoint:
    path: /genai-perf/profile
    method: GET
    data_selector: performance_results
- name: NIM_CACHE_PATH
  endpoint:
    path: /opt/nim/.cache
    method: GET
    data_selector: records
    params: {}
- name: NIM_GRPC_API_PORT
  endpoint:
    path: '50051'
    method: GET
    data_selector: records
    params: {}
- name: NIM_HTTP_API_PORT
  endpoint:
    path: '8000'
    method: GET
    data_selector: records
    params: {}
- name: NIM_HTTP_MAX_WORKERS
  endpoint:
    path: '1'
    method: GET
    data_selector: records
    params: {}
- name: NIM_HTTP_TRITON_PORT
  endpoint:
    path: '8080'
    method: GET
    data_selector: records
    params: {}
- name: NIM_IGNORE_MODEL_DOWNLOAD_FAIL
  endpoint:
    path: 'false'
    method: GET
    data_selector: records
    params: {}
- name: NIM_LOG_LEVEL
  endpoint:
    path: INFO
    method: GET
    data_selector: records
    params: {}
- name: NIM_LOGGING_JSONL
  endpoint:
    path: 'false'
    method: GET
    data_selector: records
    params: {}
- name: NIM_MANIFEST_ALLOW_UNSAFE
  endpoint:
    path: '0'
    method: GET
    data_selector: records
    params: {}
- name: NIM_MANIFEST_PATH
  endpoint:
    path: /opt/nim/etc/default/model_manifest.yaml
    method: GET
    data_selector: records
    params: {}
- name: NIM_TRITON_CUDA_MEMORY_POOL_MB
  endpoint:
    path: '256'
    method: GET
    data_selector: records
    params: {}
- name: NIM_TRITON_DYNAMIC_BATCHING_MAX_QUEUE_DELAY_MICROSECONDS
  endpoint:
    path: 100us (microseconds)
    method: GET
    data_selector: records
    params: {}
- name: NIM_TRITON_ENABLE_MODEL_CONTROL
  endpoint:
    path: 'false'
    method: GET
    data_selector: records
    params: {}
- name: NIM_TRITON_GRPC_PORT
  endpoint:
    path: '8001'
    method: GET
    data_selector: records
    params: {}
- name: NIM_TRITON_LOG_VERBOSE
  endpoint:
    path: '0'
    method: GET
    data_selector: records
    params: {}
- name: NIM_TRITON_MAX_BATCH_SIZE
  endpoint:
    path: None
    method: GET
    data_selector: records
    params: {}
- name: NIM_TRITON_MAX_QUEUE_SIZE
  endpoint:
    path: None
    method: GET
    data_selector: records
    params: {}
- name: NIM_TRITON_OPTIMIZATION_MODE
  endpoint:
    path: default
    method: GET
    data_selector: records
    params: {}
- name: NIM_TRITON_PINNED_MEMORY_POOL_MB
  endpoint:
    path: '256'
    method: GET
    data_selector: records
    params: {}
- name: NIM_CACHE_PATH
  endpoint:
    path: /opt/nim/.cache
    method: GET
    data_selector: records
    params: {}
- name: NIM_GRPC_API_PORT
  endpoint:
    path: '50051'
    method: GET
    data_selector: records
    params: {}
- name: NIM_HTTP_API_PORT
  endpoint:
    path: '8000'
    method: GET
    data_selector: records
    params: {}
- name: NIM_HTTP_MAX_WORKERS
  endpoint:
    path: '1'
    method: GET
    data_selector: records
    params: {}
- name: NIM_HTTP_TRITON_PORT
  endpoint:
    path: '8080'
    method: GET
    data_selector: records
    params: {}
- name: NIM_IGNORE_MODEL_DOWNLOAD_FAIL
  endpoint:
    path: 'false'
    method: GET
    data_selector: records
    params: {}
- name: NIM_LOG_LEVEL
  endpoint:
    path: INFO
    method: GET
    data_selector: records
    params: {}
- name: NIM_LOGGING_JSONL
  endpoint:
    path: 'false'
    method: GET
    data_selector: records
    params: {}
- name: NIM_MANIFEST_ALLOW_UNSAFE
  endpoint:
    path: '0'
    method: GET
    data_selector: records
    params: {}
- name: NIM_MANIFEST_PATH
  endpoint:
    path: /opt/nim/etc/default/model_manifest.yaml
    method: GET
    data_selector: records
    params: {}
- name: NIM_TRITON_LOG_VERBOSE
  endpoint:
    path: '0'
    method: GET
    data_selector: records
    params: {}
- name: NIM_TRITON_MAX_BATCH_SIZE
  endpoint:
    path: None
    method: GET
    data_selector: records
    params: {}
- name: NIM_TRITON_MAX_QUEUE_SIZE
  endpoint:
    path: None
    method: GET
    data_selector: records
    params: {}
- name: NIM_TRITON_ENABLE_MODEL_CONTROL
  endpoint:
    path: None
    method: GET
    data_selector: records
    params: {}
- name: livenessProbe
  endpoint:
    path: /v1/health/live
    method: GET
- name: readinessProbe
  endpoint:
    path: /v1/health/ready
    method: GET
- name: NIM for page elements
  endpoint:
    path: /path/to/nim/page/elements
    method: POST
    data_selector: output
    params: {}
- name: NIM for table structure
  endpoint:
    path: /path/to/nim/table/structure
    method: POST
    data_selector: output
    params: {}
- name: NIM for graphic elements
  endpoint:
    path: /path/to/nim/graphic/elements
    method: POST
    data_selector: output
    params: {}
- name: NIM for page elements
  endpoint:
    path: /path/to/nim/page/elements
    method: POST
    data_selector: output
    params: {}
- name: NIM for table structure
  endpoint:
    path: /path/to/nim/table/structure
    method: POST
    data_selector: output
    params: {}
- name: NIM for graphic elements
  endpoint:
    path: /path/to/nim/graphic/elements
    method: POST
    data_selector: output
    params: {}
- name: infer
  endpoint:
    path: /v1/infer
    method: POST
    data_selector: input
- name: Image OCR NIM
  endpoint:
    path: /api/v1/image-ocr
    method: POST
    data_selector: extracted_text
- name: infer
  endpoint:
    path: /v1/infer
    method: POST
    data_selector: input
- name: inference
  endpoint:
    path: /v1/infer
    method: POST
    data_selector: NIM output
    params: {}
- name: text_extraction
  endpoint:
    path: /v1/infer
    method: POST
    data_selector: data
    params: {}
- name: health_check
  endpoint:
    path: /v1/health/ready
    method: GET
    data_selector: ready
    params: {}
- name: health_check_live
  endpoint:
    path: /v1/health/live
    method: GET
    data_selector: live
    params: {}
- name: infer
  endpoint:
    path: /v1/infer
    method: POST
    data_selector: response
    params: {}
- name: health
  endpoint:
    path: /v1/health/ready
    method: GET
    data_selector: response
    params: {}
- name: live_health
  endpoint:
    path: /v1/health/live
    method: GET
    data_selector: response
    params: {}
- name: infer
  endpoint:
    path: /v1/infer
    method: POST
    data_selector: input
- name: infer
  endpoint:
    path: /v1/infer
    method: POST
    data_selector: input
    params: {}
- name: infer
  endpoint:
    path: /v1/infer
    method: POST
    data_selector: data
    params: {}
- name: infer
  endpoint:
    path: /v1/infer
    method: POST
    data_selector: data
    params: {}
- name: health
  endpoint:
    path: /v1/health/ready
    method: GET
    data_selector: ready
    params: {}
- name: live_health
  endpoint:
    path: /v1/health/live
    method: GET
    data_selector: live
    params: {}
- name: infer
  endpoint:
    path: /v1/infer
    method: POST
    data_selector: input
- name: metrics
  endpoint:
    path: /v1/metrics
    method: GET
- name: license
  endpoint:
    path: /v1/license
    method: GET
- name: metadata
  endpoint:
    path: /v1/metadata
    method: GET
- name: manifest
  endpoint:
    path: /v1/manifest
    method: GET
- name: inference_endpoint
  endpoint:
    path: /v1/infer
    method: POST
- name: health_ready
  endpoint:
    path: /v1/health/ready
    method: GET
- name: health_live
  endpoint:
    path: /v1/health/live
    method: GET
- name: infer
  endpoint:
    path: /v1/infer
    method: POST
    data_selector: NIM output
    params: {}
- name: infer
  endpoint:
    path: /v1/infer
    method: POST
    data_selector: input
    params: {}
- name: infer
  endpoint:
    path: /v1/infer
    method: POST
    data_selector: NIM output
    params: {}
- name: infer
  endpoint:
    path: /v1/infer
    method: POST
    data_selector: response
    params: {}
- name: health_check
  endpoint:
    path: /v1/health/ready
    method: GET
    data_selector: response
    params: {}
- name: health_check_live
  endpoint:
    path: /v1/health/live
    method: GET
    data_selector: response
    params: {}
- name: infer
  endpoint:
    path: /v1/infer
    method: POST
    data_selector: input
- name: text_extraction
  endpoint:
    path: /v1/infer
    method: POST
    data_selector: data
    params: {}
- name: health_check
  endpoint:
    path: /v1/health/ready
    method: GET
    data_selector: ready
    params: {}
- name: infer
  endpoint:
    path: /v1/infer
    method: POST
    data_selector: input
- name: infer
  endpoint:
    path: /v1/infer
    method: POST
    data_selector: data
    params: {}
- name: health
  endpoint:
    path: /v1/health/ready
    method: GET
    data_selector: ready
    params: {}
- name: health_live
  endpoint:
    path: /v1/health/live
    method: GET
    data_selector: live
    params: {}
- name: infer
  endpoint:
    path: /v1/infer
    method: POST
    data_selector: data
- name: health
  endpoint:
    path: /v1/health/ready
    method: GET
- name: live_health
  endpoint:
    path: /v1/health/live
    method: GET
- name: metrics
  endpoint:
    path: /v1/metrics
    method: GET
- name: license
  endpoint:
    path: /v1/license
    method: GET
- name: metadata
  endpoint:
    path: /v1/metadata
    method: GET
- name: manifest
  endpoint:
    path: /v1/manifest
    method: GET
- name: inference
  endpoint:
    path: /v1/infer
    method: POST
- name: health_ready
  endpoint:
    path: /v1/health/ready
    method: GET
- name: health_live
  endpoint:
    path: /v1/health/live
    method: GET
- name: infer
  endpoint:
    path: /v1/infer
    method: POST
    data_selector: input
- name: metrics
  endpoint:
    path: /v1/metrics
    method: GET
- name: license
  endpoint:
    path: /v1/license
    method: GET
- name: metadata
  endpoint:
    path: /v1/metadata
    method: GET
- name: manifest
  endpoint:
    path: /v1/manifest
    method: GET
- name: inference
  endpoint:
    path: /v1/infer
    method: POST
- name: health_ready
  endpoint:
    path: /v1/health/ready
    method: GET
- name: health_live
  endpoint:
    path: /v1/health/live
    method: GET
- name: inference
  endpoint:
    path: /v1/infer
    method: POST
    data_selector: null
    params: {}
- name: infer
  endpoint:
    path: /v1/infer
    method: POST
    data_selector: input
- name: infer
  endpoint:
    path: /v1/infer
    method: POST
    data_selector: NIM output
    params: {}
- name: image_inference
  endpoint:
    path: /v1/infer
    method: POST
    data_selector: data
    params: {}
- name: health_check
  endpoint:
    path: /v1/health/ready
    method: GET
    data_selector: ready
    params: {}
- name: infer
  endpoint:
    path: /v1/infer
    method: POST
    data_selector: input
- name: infer
  endpoint:
    path: /v1/infer
    method: POST
    data_selector: data
    params: {}
- name: health_check
  endpoint:
    path: /v1/health/ready
    method: GET
    data_selector: ready
    params: {}
- name: health_check_live
  endpoint:
    path: /v1/health/live
    method: GET
    data_selector: live
    params: {}
- name: infer
  endpoint:
    path: /v1/infer
    method: POST
    data_selector: output
    params: {}
- name: infer
  endpoint:
    path: /v1/infer
    method: POST
    data_selector: data
    params: {}
- name: health
  endpoint:
    path: /v1/health/ready
    method: GET
    data_selector: ready
    params: {}
- name: live_health
  endpoint:
    path: /v1/health/live
    method: GET
    data_selector: live
    params: {}
- name: metrics
  endpoint:
    path: /v1/metrics
    method: GET
- name: license
  endpoint:
    path: /v1/license
    method: GET
- name: metadata
  endpoint:
    path: /v1/metadata
    method: GET
- name: manifest
  endpoint:
    path: /v1/manifest
    method: GET
- name: inference
  endpoint:
    path: /v1/infer
    method: POST
- name: health_ready
  endpoint:
    path: /v1/health/ready
    method: GET
- name: health_live
  endpoint:
    path: /v1/health/live
    method: GET
- name: infer
  endpoint:
    path: /v1/infer
    method: POST
    data_selector: input
- name: infer
  endpoint:
    path: /v1/infer
    method: POST
    data_selector: NIM output
    params: {}
- name: metrics
  endpoint:
    path: /v1/metrics
    method: GET
- name: license
  endpoint:
    path: /v1/license
    method: GET
- name: metadata
  endpoint:
    path: /v1/metadata
    method: GET
- name: manifest
  endpoint:
    path: /v1/manifest
    method: GET
- name: inference
  endpoint:
    path: /v1/infer
    method: POST
- name: health_ready
  endpoint:
    path: /v1/health/ready
    method: GET
- name: health_live
  endpoint:
    path: /v1/health/live
    method: GET
- name: infer
  endpoint:
    path: /v1/infer
    method: POST
    data_selector: input
    params: {}
- name: infer
  endpoint:
    path: /v1/infer
    method: POST
    data_selector: input
- name: infer
  endpoint:
    path: /v1/infer
    method: POST
    data_selector: NIM output
    params: {}
- name: infer
  endpoint:
    path: /v1/infer
    method: POST
    data_selector: data
    params: {}
- name: health
  endpoint:
    path: /v1/health/ready
    method: GET
    data_selector: ready
    params: {}
- name: live_health
  endpoint:
    path: /v1/health/live
    method: GET
    data_selector: live
    params: {}
- name: infer
  endpoint:
    path: /v1/infer
    method: POST
    data_selector: input
- name: metrics
  endpoint:
    path: /v1/metrics
    method: GET
- name: license
  endpoint:
    path: /v1/license
    method: GET
- name: metadata
  endpoint:
    path: /v1/metadata
    method: GET
- name: manifest
  endpoint:
    path: /v1/manifest
    method: GET
- name: inference
  endpoint:
    path: /v1/infer
    method: POST
- name: health_ready
  endpoint:
    path: /v1/health/ready
    method: GET
- name: health_live
  endpoint:
    path: /v1/health/live
    method: GET
- name: image_inference
  endpoint:
    path: /v1/infer
    method: POST
    data_selector: data
- name: health_check
  endpoint:
    path: /v1/health/ready
    method: GET
    data_selector: ready
- name: live_check
  endpoint:
    path: /v1/health/live
    method: GET
    data_selector: live
- name: infer
  endpoint:
    path: /v1/infer
    method: POST
    data_selector: data
    params: {}
- name: health
  endpoint:
    path: /v1/health/ready
    method: GET
    data_selector: ready
    params: {}
- name: health_live
  endpoint:
    path: /v1/health/live
    method: GET
    data_selector: live
    params: {}
- name: infer
  endpoint:
    path: /v1/infer
    method: POST
    data_selector: data
    params: {}
- name: health
  endpoint:
    path: /v1/health/ready
    method: GET
    data_selector: ready
    params: {}
- name: live_health
  endpoint:
    path: /v1/health/live
    method: GET
    data_selector: live
    params: {}
- name: metrics
  endpoint:
    path: /v1/metrics
    method: GET
- name: license
  endpoint:
    path: /v1/license
    method: GET
- name: metadata
  endpoint:
    path: /v1/metadata
    method: GET
- name: manifest
  endpoint:
    path: /v1/manifest
    method: GET
- name: inference
  endpoint:
    path: /v1/infer
    method: POST
- name: health_ready
  endpoint:
    path: /v1/health/ready
    method: GET
- name: health_live
  endpoint:
    path: /v1/health/live
    method: GET
- name: metrics
  endpoint:
    path: /v1/metrics
    method: GET
- name: license
  endpoint:
    path: /v1/license
    method: GET
- name: metadata
  endpoint:
    path: /v1/metadata
    method: GET
- name: manifest
  endpoint:
    path: /v1/manifest
    method: GET
- name: inference
  endpoint:
    path: /v1/infer
    method: POST
- name: health_ready
  endpoint:
    path: /v1/health/ready
    method: GET
- name: health_live
  endpoint:
    path: /v1/health/live
    method: GET
- name: infer
  endpoint:
    path: /v1/infer
    method: POST
- name: health_live
  endpoint:
    path: /v1/health/live
    method: GET
- name: health_ready
  endpoint:
    path: /v1/health/ready
    method: GET
- name: infer
  endpoint:
    path: /v1/infer
    method: POST
    data_selector: data
    params: {}
- name: health_live
  endpoint:
    path: /v1/health/live
    method: GET
    data_selector: ready
    params: {}
- name: health_ready
  endpoint:
    path: /v1/health/ready
    method: GET
    data_selector: live
    params: {}
- name: infer
  endpoint:
    path: /v1/infer
    method: POST
    data_selector: output
    params: {}
- name: manifest
  endpoint:
    path: /v1/manifest
    method: GET
    data_selector: manifest
    params: {}
- name: list-model-profiles
  endpoint:
    path: /v1/list-model-profiles
    method: GET
    data_selector: profiles
    params: {}
- name: PaddleOCR
  endpoint:
    path: /api/paddleocr
    method: GET
    data_selector: models
    params: {}
- name: PaddleOCR
  endpoint:
    path: /baidu/paddleocr
    method: GET
    data_selector: records
    params: {}
- name: NIM Model
  endpoint:
    path: /ngc/nim/models
    method: GET
- name: models
  endpoint:
    path: /models
    method: GET
    data_selector: models
    params: {}
- name: image_inference
  endpoint:
    path: /v1/infer
    method: POST
    data_selector: response
    params: {}
- name: NIM_CACHE_PATH
  endpoint:
    path: /opt/nim/.cache
    method: GET
    data_selector: records
- name: NIM_GRPC_API_PORT
  endpoint:
    path: /50051
    method: GET
    data_selector: records
- name: NIM_HTTP_API_PORT
  endpoint:
    path: /8000
    method: GET
    data_selector: records
- name: NIM_HTTP_MAX_WORKERS
  endpoint:
    path: /1
    method: GET
    data_selector: records
- name: NIM_HTTP_TRITON_PORT
  endpoint:
    path: /8080
    method: GET
    data_selector: records
- name: NIM_IGNORE_MODEL_DOWNLOAD_FAIL
  endpoint:
    path: /false
    method: GET
    data_selector: records
- name: NIM_LOG_LEVEL
  endpoint:
    path: /INFO
    method: GET
    data_selector: records
- name: NIM_LOGGING_JSONL
  endpoint:
    path: /false
    method: GET
    data_selector: records
- name: NIM_MANIFEST_ALLOW_UNSAFE
  endpoint:
    path: /0
    method: GET
    data_selector: records
- name: NIM_MANIFEST_PATH
  endpoint:
    path: /opt/nim/etc/default/model_manifest.yaml
    method: GET
    data_selector: records
- name: NIM_TRITON_DYNAMIC_BATCHING_MAX_QUEUE_DELAY_MICROSECONDS
  endpoint:
    path: /100us
    method: GET
    data_selector: records
- name: NIM_TRITON_LOG_VERBOSE
  endpoint:
    path: /0
    method: GET
    data_selector: records
- name: NIM_TRITON_MAX_BATCH_SIZE
  endpoint:
    path: /None
    method: GET
    data_selector: records
- name: NIM_TRITON_OPTIMIZATION_MODE
  endpoint:
    path: /default
    method: GET
    data_selector: records
- name: genai-perf
  endpoint:
    path: /genai-perf
    method: POST
    data_selector: results
    params: {}
- name: model_profiles
  endpoint:
    path: /list-model-profiles
    method: GET
    data_selector: MODEL PROFILES
    params: {}
- name: image_ocr
  endpoint:
    path: /v1/infer
    method: POST
    data_selector: output
- name: persistence
  parameters:
    enabled: false
    existingClaimName: ''
    class: ''
    retain: ''
    createPV: false
    accessMode: ReadWriteOnce
    size: 50Gi
- name: list-model-profiles
  endpoint:
    path: /list-model-profiles
    method: GET
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: graph
  endpoint:
    path: /api/v1/graph
    method: GET
    data_selector: data
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: libquadmath
  endpoint:
    path: scipy.libs/libquadmath
    method: GET
- name: libtheoradec
  endpoint:
    path: /libtheoradec
    method: GET
- name: libtheoraenc
  endpoint:
    path: /libtheoraenc
    method: GET
- name: libwebp
  endpoint:
    path: /libwebp
    method: GET
- name: libwebpmux
  endpoint:
    path: /libwebpmux
    method: GET
- name: libvorbis
  endpoint:
    path: /libvorbis
    method: GET
- name: libvorbisenc
  endpoint:
    path: /libvorbisenc
    method: GET
- name: libxcb
  endpoint:
    path: /libxcb
    method: GET
- name: libxcb-image
  endpoint:
    path: /libxcb-image
    method: GET
- name: libxcb-util
  endpoint:
    path: /libxcb-util
    method: GET
- name: libxcb-render-util
  endpoint:
    path: /libxcb-render-util
    method: GET
- name: libxcb-icccm
  endpoint:
    path: /libxcb-icccm
    method: GET
- name: libXau
  endpoint:
    path: /libXau
    method: GET
- name: infer
  endpoint:
    path: /v1/infer
    method: POST
    data_selector: output
    params: {}
- name: manifest
  endpoint:
    path: /v1/manifest
    method: GET
    data_selector: manifest
    params: {}
- name: infer
  endpoint:
    path: /v1/infer
    method: POST
    data_selector: output
    params: {}
- name: manifest
  endpoint:
    path: /v1/manifest
    method: GET
    data_selector: manifest
    params: {}
- name: libquadmath
  endpoint:
    path: scipy.libs/libquadmath*.so
    method: GET
    data_selector: files
    params: {}
- name: manifest
  endpoint:
    path: /v1/manifest
    method: GET
    data_selector: result
- name: PaddleOCR
  endpoint:
    path: /baidu/paddleocr
    method: GET
- name: paddleocr
  endpoint:
    path: /nim/paddleocr
    method: POST
    data_selector: model
    params: {}
- name: paddleocr
  endpoint:
    path: /v1/infer
    method: POST
    data_selector: response
    params: {}
- name: infer
  endpoint:
    path: /v1/infer
    method: POST
- name: manifest
  endpoint:
    path: /v1/manifest
    method: GET
- name: infer
  endpoint:
    path: /v1/infer
    method: GET
    data_selector: output
    params: {}
- name: manifest
  endpoint:
    path: /v1/manifest
    method: GET
    data_selector: manifest
    params: {}
- name: model_profiles
  endpoint:
    path: /list-model-profiles
    method: GET
    data_selector: MODEL PROFILES
- name: infer
  endpoint:
    path: /v1/infer
    method: POST
    data_selector: results
- name: manifest
  endpoint:
    path: /v1/manifest
    method: GET
    data_selector: manifest
- name: manifest
  endpoint:
    path: /v1/manifest
    method: GET
    data_selector: ''
    params: {}
- name: PaddleOCR
  endpoint:
    path: /models/paddleocr
    method: GET
- name: image
  endpoint:
    path: /v1/health/live
    method: GET
- name: image-ocr
  endpoint:
    path: /v1/infer
    method: POST
    data_selector: input
    params: {}
- name: environment_variables
  endpoint:
    path: /environment-variables
    method: GET
    data_selector: variables
    params: {}
- name: livenessProbe
  endpoint:
    path: /v1/health/live
    method: GET
- name: readinessProbe
  endpoint:
    path: /v1/health/ready
    method: GET
- name: startupProbe
  endpoint:
    path: /v1/health/ready
    method: GET
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: libquadmath
  endpoint:
    path: scipy.libs/libquadmath*.so
    method: GET
notes:
- PaddleOCR NIM output provides confidence scores and float [0, 1] bounding boxes
  associated with each text detection.
- The only supported type is image_url.
- Each image must be base64 encoded.
- The persistence.enabled value and all related dependent configuration flags are
  currently non-functional in the NIM helm chart.
- Optimized models are GPU specific and require a minimum GPU memory value as specified
  in the Optimized configuration sections of each model.
- Generic profiles operate with any NVIDIA GPU with sufficient memory capacity.
- NGC API key required to access NGC resources.
- 'If the input image_url does not match the expected format described in the API
  Reference, the runtime returns an error message, such as {"error": "Incorrect padding"},
  indicating what format error occurred.'
- Requires NGC API key for downloading private images.
- NIM can run in modes optimized for VRAM usage or performance when using a TensorRT
  model profile.
- Personal keys allow you to configure an expiration date, revoke or delete the key
  using an action button, and rotate the key as needed.
- Prior to v0.86.0 use `logging` instead of `debug`.
- NIM microservices run on hosts with NVIDIA GPUs.
- Models can be quite large, and you can fill a disk downloading things to emptyDirs
  or other locations around your pod image.
- In the current version of Image OCR NIM (PaddleOCR) the `list-model-profiles` command
  fails to run on hosts that don’t have an NVIDIA GPU, even when `NIM_CPU_ONLY` is
  set.
- Uses docker containers under the hood.
- NIM can run in modes optimized for VRAM usage or performance.
- Uses OAuth2 with refresh token — requires setup of connected app in api
- Each image must be base64 encoded, and should be represented in the JSON format.
- The supported image formats are png and jpeg.
- The API supports PNG and JPEG formats.
- 'The following NIMs do not support NIM_SERVED_MODEL_NAME: nemoretriever-graphic-elements-v1,
  nemoretriever-page-elements-v2, nemoretriever-table-structure-v1, nemoretriever-ocr-v1,
  PaddleOCR'
- 'The following NIMs do not support NIM_SERVED_MODEL_NAME: nemoretriever-graphic-elements-v1,
  nemoretriever-page-elements-v2, nemoretriever-table-structure-v1, nemoretriever-ocr-v1,
  PaddleOCR.'
- If autoscaling is not enabled, these are ignored.
- Values used for autoscaling should be overridden on a per-model basis.
- Enable horizontal pod autoscaler is set to false.
- Minimum replicas for autoscaling is set to 1.
- Maximum replicas for autoscaling is set to 10.
- The list-model-profiles command incorrectly lists compatible model profiles as incompatible.
  Select the profile that matches your hardware configuration. This bug does not impact
  automatic profile selection.
- The list-model-profiles command fails to run on hosts that don’t have an NVIDIA
  GPUs, even when NIM_CPU_ONLY is set.
- Optimized models are GPU specific and require a minimum GPU memory value.
- Generic profiles are chosen automatically when optimized profiles are not available.
- Choose a container name for bookkeeping
- Choose a path on your system to cache the downloaded models
- If you have an issue with permission mismatches when downloading models in your
  local cache directory, add the -u $(id -u) option to the docker run call to run
  under your current identity.
- This helm chart requires that you have a secret with your NGC API key configured
  for downloading private images.
- Some objects like Contact may return nulls in deeply nested fields
- NIM starts up partially, but fails to reach ready state, and then stalls.
- NIM starts up partially, but fails to reach ready state, and then crashes.
- NIM serves a small number of requests, and then fails.
- If you run this model on RTX 40xx or later, you need a minimum of 8GB of VRAM.
- By default, metrics are printed to the container log.
- By default, traces are printed to the container log.
- An NGC API key is required to access NGC resources.
- Personal keys allow you to configure an expiration date, revoke or delete the key.
- The pod should eventually end up in the running state.
- As a Developer, you must secure your own API endpoints. We suggest using a proxy
  as well as HTTPS/TLS 1.2.
- To override automatic profile selection, set a specific profile ID with -e NIM_MODEL_PROFILE=<value>.
- The current version of Image OCR NIM (PaddleOCR) the list-model-profiles command
  fails to run on hosts that don’t have an NVIDIA GPU.
- Text Embedding NIM is built on the NVIDIA software platform, incorporating CUDA,
  TensorRT, and Triton to offer out-of-the-box GPU acceleration.
- Text Embedding NIM comes with enterprise-ready features, such as a high-performance
  inference server, flexible integration, and enterprise-grade security.
- Enable livenessProbe.
- Enable readinessProbe.
- Enable startupProbe.
- Reranking is essential in hybrid retrieval situations, as it helps to combine results
  from different sources of data when there is no easy way to merge them.
- We round up to the closest integer in our naming convention, so you might see mention
  of Mistral4B in other documentation and in URLs and filenames.
- Text Embedding NIM is optimized for high-performance deep learning inference.
- NeMo Text Retriever NIM APIs provide easy access to state-of-the-art models for
  enterprise semantic search applications.
- The `list-model-profiles` command incorrectly lists compatible model profiles as
  incompatible.
- Select the profile that matches your hardware configuration.
- The `list-model-profiles` command incorrectly lists compatible model profiles as
  incompatible. Select the profile that matches your hardware configuration. This
  bug does not impact automatic profile selection.
- Fixed bug where `list-model-profiles` command fails to run on hosts that don’t have
  an NVIDIA GPUs, even when `NIM_CPU_ONLY` is set.
- Added support for B200 GPU.
- Updates the `/v1/infer` endpoint request and response JSON schemas. The new output
  schema provides bounding boxes and confidence scores for each text detection.
- Optimized models require specific GPU memory values.
- Generic profiles are used when optimized profiles are not available.
- Use --gpus all to specify all GPUs.
- Increase shared memory with --shm-size=1g.
- Set PID limit with --pids-limit=-1.
- Use a Kubernetes cluster with GPU nodes.
- Metrics are printed to the container log by default.
- Traces are printed to the container log by default.
- In the current version of Image OCR NIM the list-model-profiles command fails to
  run on hosts that don’t have an NVIDIA GPU, even when NIM_CPU_ONLY is set.
- This NIM uses persistent storage for storing downloaded models.
- NIMs do not impose rate limits.
- As a Developer, you must secure your own API endpoints.
- 'Warning: In the current version of Image OCR NIM the list-model-profiles command
  fails to run on hosts that don’t have an NVIDIA GPU, even when NIM_CPU_ONLY is set.'
- Uses Apache License Version 2.0
- The Software is provided "AS IS", without warranty of any kind.
- The software is provided 'AS IS', without warranty of any kind.
- This software is made available under the terms of either of the licenses found
  in LICENSE.APACHE or LICENSE.BSD. Contributions to cryptography are made under the
  terms of both these licenses.
- Previous versions of geventhttpclient used http_parser.c, which in turn was based
  on src/http/ngx_http_parse.c from NGINX, copyright Igor Sysoev, Joyent, Inc. and
  other Node contributors.
- NVIDIA CORPORATION, its affiliates and licensors retain all intellectual property
  and proprietary rights in and to this material.
- Uses OAuth2 with refresh token — requires setup of connected app in google
- Kiwi is licensed under the terms of the Modified BSD License.
- 'This program is free software: you can redistribute it and/or modify it under the
  terms of the GNU General Public License as published by the Free Software Foundation,
  either version 3 of the License, or (at your option) any later version.'
- This program is distributed in the hope that it will be useful, but WITHOUT ANY
  WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A
  PARTICULAR PURPOSE.
- This license applies to OpenCV binary in the directory cv2/.
- Redistribution and use in source and binary forms, with or without modification,
  are permitted provided that the following conditions are met.
- NetworkX is distributed under the 3-clause BSD license.
- This program is distributed in the hope that it will be useful, but WITHOUT ANY
  WARRANTY.
- Covered Software is provided under this License on an "as is" basis, without warranty
  of any kind.
- Under no circumstances and under no legal theory, whether tort (including negligence),
  contract, or otherwise, shall any Contributor, or anyone who distributes Covered
  Software as permitted above, be liable to You for any direct, indirect, special,
  incidental, or consequential damages of any character.
- This software is provided 'as is' without warranty of any kind.
- This software is provided 'as is' and any express or implied warranties are disclaimed.
- This software is provided 'AS IS' and without any warranty.
- This license applies to OpenCV binary in the directory cv2/
- This license applies to the above binaries in the directory cv2/
- Covered Software is provided under this License on an 'as is' basis, without warranty
  of any kind.
- Apache License Version 2.0, January 2004
- This software is made available under the terms of either of the licenses found
  in LICENSE.APACHE or LICENSE.BSD.
- Contributions to this software is made under the terms of both these licenses.
- This license applies to libvpx binary in the directory cv2/
- This software is provided by the copyright holders and contributors 'AS IS' and
  any express or implied warranties, including, but not limited to, the implied warranties
  of merchantability and fitness for a particular purpose are disclaimed.
- Libquadmath is free software; you can redistribute it and/or modify it under the
  terms of the GNU Library General Public License.
- THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
  OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.
- Uses Apache License, Version 2.0
- No specific API configurations provided.
- This software is provided 'AS IS', without warranty of any kind.
- The `list-model-profiles` command fails to run on hosts that don’t have an NVIDIA
  GPUs, even when `NIM_CPU_ONLY` is set.
- This is a public beta release of the NVIDIA NIM for Table Extraction.
- Updates the /v1/infer endpoint request and response JSON schemas.
- The /v1/manifest API returns an empty result instead of the manifest file.
- 'If the input image_url does not match the expected format, the runtime returns
  an error message, such as {"error": "Incorrect padding"}.'
- Python software and documentation are licensed under the Python Software Foundation
  License Version 2.
- Starting with Python 3.8.6, examples, recipes, and other code in the documentation
  are dual licensed under the PSF License Version 2 and the Zero-Clause BSD license.
- This software is provided 'AS IS' without warranties or conditions of any kind.
- Deploys using Helm chart
- Requires NVIDIA GPU nodes
- The `list-model-profiles` command fails to run on hosts that don’t have NVIDIA GPUs,
  even when `NIM_CPU_ONLY` is set.
- NIM container is GPU-accelerated and uses NVIDIA Container Toolkit for access to
  GPUs on the host.
- You may need to increase the available shared memory given to the microservice container.
- This is a General Access release of the NVIDIA NIM for Image OCR.
- The /v1/infer endpoint request and response JSON schemas have been updated.
- The `list-model-profiles` command fails to run on hosts that don’t have an NVIDIA
  GPU, even when `NIM_CPU_ONLY` is set.
- The `list-model-profiles` command incorrectly includes incompatible model profiles.
- Returns an empty string instead of 'nan' when no text is detected in an image.
- NIMs do not impose rate limits. If you want to restrict access to your application,
  it is your responsibility to implement a strategy.
- The NIM uses multiple ports, but only the HTTP API Port needs to be accessible outside
  of the cluster.
- If the input image_url does not match the expected format, an error message is returned.
- 'The following NIMs do not support NIM_SERVED_MODEL_NAME: nemoretriever-graphic-elements-v1,
  nemoretriever-page-elements-v2, nemoretriever-table-structure-v1, PaddleOCR'
- Enable horizontal pod autoscaler if needed based on quality-of-service metrics.
- Standard metrics of CPU and memory are of limited use in scaling NIM.
- NVIDIA provides an API key for authentication.
- This is documentation for an old version (1.4.0).
- Use a Kubernetes cluster with GPU nodes for deployment.
- Requires setup of secrets for NGC API key for downloading private images.
- NIM uses docker containers under the hood.
- Tokenization uses Triton’s Python backend capabilities that scales with the number
  of CPU cores available.
- Metrics and traces are printed to the container log by default.
- Contributions to cryptography are made under the terms of both these licenses.
- In the current version of ${__product_short_name} the `list-model-profiles` command
  fails to run on hosts that don’t have an NVIDIA GPU, even when `NIM_CPU_ONLY` is
  set.
- 'The following NIMs do not support `NIM_SERVED_MODEL_NAME`: nemoretriever-graphic-elements-v1,
  nemoretriever-page-elements-v2, nemoretriever-table-structure-v1, PaddleOCR.'
- Enable horizontal pod autoscaler is false.
- Uses Apache License Version 2.0 for distribution.
- This license applies to the above library binaries in the directory cv2/
- This software is provided 'as is' without express or implied warranty.
- This license applies to libvpx binary in the directory cv2/.
- This license applies to the above library binaries in the directory cv2/.
- There is no warranty for the program, to the extent permitted by applicable law.
- The program is distributed in the hope that it will be useful, but without any warranty.
- This version of the GNU Lesser General Public License incorporates the terms and
  conditions of version 3 of the GNU General Public License, supplemented by the additional
  permissions listed below.
- This software is provided 'as is', without any express or implied warranty.
- The authors make no representations about the suitability of this software for any
  purpose.
- This software is provided by the copyright holders and contributors 'as is' and
  any express or implied warranties are disclaimed.
- Software is provided 'AS IS', without warranty of any kind.
- The software is provided "AS IS", without warranty of any kind, express or implied.
- Libquadmath is free software; you can redistribute it and/or modify it under the
  terms of the GNU Library General Public License as published by the Free Software
  Foundation; either version 2.1 of the License, or (at your option) any later version.
- The software is provided 'as is', without warranty of any kind.
- You cannot use the name of the IJG or The libjpeg-turbo Project in advertising.
- 'Redistribution and use in source and binary forms, with or without modification,
  are permitted provided that the following conditions are met: 1. Redistributions
  of source code must retain the above copyright notice, this list of conditions and
  the following disclaimer. 2. Redistributions in binary form must reproduce the above
  copyright notice, this list of conditions and the following disclaimer in the documentation
  and/or other materials provided with the distribution.'
- Libquadmath is free software; you can redistribute it and/or modify it under the
  terms of the GNU Library General Public License as published by the Free Software
  Foundation.
- All Python releases are Open Source
- Python software and documentation are licensed under the Python Software Foundation
  License Version 2
- This software is provided by the copyright holders and contributors 'AS IS' and
  any express or implied warranties are disclaimed.
errors:
- '422 (Unprocessable Entity): Invalid image URL format: Ensure all URLs follow the
  pattern: `data:<image-media-type>;base64,<base64-image-data>`'
- '422 (Unprocessable Entity): Invalid base64 content: Verify that your base64 encoding
  process is correct and that the image data is not corrupted'
- '422 (Unprocessable Entity): Malformed request: Verify that your request format
  matches the API specification'
- '429 (Too Many Requests): Request queue full: Reduce the request rate, or increase
  the queue size by using `NIM_TRITON_MAX_QUEUE_SIZE`'
- '500 (Internal Server Error): Server error: Check server logs for details and report
  the issue if persistent'
- '503 (Service Unavailable): Service not ready: Check health endpoints and wait for
  the service to complete initialization'
- '422 (Unprocessable Entity): Invalid image URL format: Ensure all URLs follow the
  pattern: ''data:<image-media-type>;base64,<base64-image-data>'''
- '429 (Too Many Requests): Request queue full: Reduce the request rate, or increase
  the queue size by using ''NIM_TRITON_MAX_QUEUE_SIZE'''
- '422 (Unprocessable Entity): Invalid image URL format: Ensure all URLs follow the
  pattern: data:<image-media-type>;base64,<base64-image-data>'
- '429 (Too Many Requests): Request queue full: Reduce the request rate, or increase
  the queue size by using NIM_TRITON_MAX_QUEUE_SIZE'
- '422 (Unprocessable Entity): Invalid image URL format'
- '422 (Unprocessable Entity): Invalid base64 content'
- '422 (Unprocessable Entity): Malformed request'
- '429 (Too Many Requests): Request queue full'
- '500 (Internal Server Error): Server error'
- '503 (Service Unavailable): Service not ready'
- '{"error": "Incorrect padding"}: If the input image_url does not match the expected
  format described in the API Reference.'
- '401 Unauthorized: Recheck API key or permissions.'
- '422 (Unprocessable Entity): Invalid image URL format - Ensure all URLs follow the
  pattern: data:<image-media-type>;base64,<base64-image-data>'
- '422 (Unprocessable Entity): Invalid base64 content - Verify that your base64 encoding
  process is correct and that the image data is not corrupted'
- '422 (Unprocessable Entity): Malformed request - Verify that your request format
  matches the API specification'
- '429 (Too Many Requests): Request queue full - Reduce the request rate, or increase
  the queue size by using NIM_TRITON_MAX_QUEUE_SIZE'
- '500 (Internal Server Error): Server error - Check server logs for details and report
  the issue if persistent'
- '503 (Service Unavailable): Service not ready - Check health endpoints and wait
  for the service to complete initialization'
- '422 (Unprocessable Entity): Invalid image URL format.'
- '429 (Too Many Requests): Request queue full.'
- '500 (Internal Server Error): Server error.'
- '503 (Service Unavailable): Service not ready.'
- Ensure that the correct number of replicas is set for autoscaling.
- 'If the input image_url does not match the expected format described in the API
  Reference, the runtime returns an error message, such as {"error": "Incorrect padding"},
  indicating what format error occurred.'
- 'REQUEST_LIMIT_EXCEEDED: Throttle API calls or reduce frequency'
- 'QUERY_TIMEOUT: Break down filters or add selectivity'
- '401 Unauthorized: Recheck OAuth scopes or token expiration'
- Ensure correct configurations for liveness and readiness probes.
- In exchange for that improvement, the trade-off is increased cost and latency.
- '422 (Unprocessable Entity): Invalid image URL format - Ensure all URLs follow the
  pattern: `data:<image-media-type>;base64,<base64-image-data>`'
- '429 (Too Many Requests): Request queue full - Reduce the request rate, or increase
  the queue size by using `NIM_TRITON_MAX_QUEUE_SIZE`'
- '422 (Unprocessable Entity): Invalid image URL format - Ensure all URLs follow the
  required data URL format: data:<image-media-type>;base64,<base64-image-data>'
- '422 (Unprocessable Entity): Invalid image URL format. Ensure all URLs follow the
  pattern: data:<image-media-type>;base64,<base64-image-data>'
- '429 (Too Many Requests): Request queue full. Reduce the request rate, or increase
  the queue size by using NIM_TRITON_MAX_QUEUE_SIZE'
- '500 (Internal Server Error): Server error. Check server logs for details'
- '503 (Service Unavailable): Service not ready. Check health endpoints and wait for
  the service to complete initialization'
- '422 (Unprocessable Entity): Invalid image URL format - Ensure all URLs follow the
  pattern: ''data:<image-media-type>;base64,<base64-image-data>'''
- '429 (Too Many Requests): Request queue full - Reduce the request rate, or increase
  the queue size by using ''NIM_TRITON_MAX_QUEUE_SIZE'''
- '422 (Unprocessable Entity): Invalid image URL format: The image URL doesn’t follow
  the required data URL format: Ensure all URLs follow the pattern: data:<image-media-type>;base64,<base64-image-data>'
- '422 (Unprocessable Entity): Invalid base64 content: The base64-encoded data in
  the URL is invalid: Verify that your base64 encoding process is correct and that
  the image data is not corrupted'
- '422 (Unprocessable Entity): Malformed request: The JSON payload structure is incorrect:
  Verify that your request format matches the API specification'
- '429 (Too Many Requests): Request queue full: The number of concurrent requests
  exceeds the configured queue size: Reduce the request rate, or increase the queue
  size by using NIM_TRITON_MAX_QUEUE_SIZE'
- '500 (Internal Server Error): Server error: An unexpected error occurred during
  processing: Check server logs for details and report the issue if persistent'
- '503 (Service Unavailable): Service not ready: The service is still initializing
  or loading models: Check health endpoints and wait for the service to complete initialization'
- '422 (Unprocessable Entity): Invalid image URL format: The image URL doesn’t follow
  the required data URL format'
- '422 (Unprocessable Entity): Invalid base64 content: The base64-encoded data in
  the URL is invalid'
- '422 (Unprocessable Entity): Malformed request: The JSON payload structure is incorrect'
- '429 (Too Many Requests): Request queue full: The number of concurrent requests
  exceeds the configured queue size'
- '500 (Internal Server Error): Server error: An unexpected error occurred during
  processing'
- '503 (Service Unavailable): Service not ready: The service is still initializing
  or loading models'
- 'Incorrect padding: The input `image_url` does not match the expected format.'
- '{"error": "Incorrect padding"}: If the input `image_url` does not match the expected
  format.'
- '400 Bad Request: Check the request parameters.'
- '500 Internal Server Error: Server encountered an unexpected condition.'
- '401 Unauthorized: Check your NGC API key and permissions'
- '404 Not Found: Ensure the requested endpoint exists'
- Redistribution of source code must retain the above copyright notice, this list
  of conditions and the following disclaimer.
- The origin of this software must not be misrepresented; you must not claim that
  you wrote the original software.
- Altered source versions must be plainly marked as such, and must not be misrepresented
  as being the original software.
- The name of the author may not be used to endorse or promote products derived from
  this software without specific prior written permission.
- '404 Not Found: Ensure the endpoint is correct.'
- '500 Internal Server Error: Try again later.'
- No warranty against interference with your enjoyment of the library.
- No use of any Covered Software is authorized under this License except under this
  disclaimer.
- IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT,
  INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES.
- '{"error": "Incorrect padding"}'
- NIM starts up partially, but fails to reach ready state, and then stalls.
- NIM starts up partially, but fails to reach ready state, and then crashes.
- NIM serves a small number of requests, and then fails.
- 'Incorrect padding: Indicates format error with image_url input.'
- 'Incorrect padding: Indicates what format error occurred.'
- Ensure to manage replicas based on autoscaling parameters.
- IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT,
  INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
- No warranty against interference with your enjoyment of the library or against infringement.
- Under no circumstances and under no legal theory shall any Contributor be liable
  to You for any direct, indirect, special, incidental, or consequential damages.
- No warranty or conditions of any kind
- No warranty or liability for any direct, indirect, incidental, special, exemplary,
  or consequential damages.
- THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
  ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES
  OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.
auth_info:
  mentioned_objects:
  - OauthToken
  - AuthProvider
  - NamedCredential
client:
  base_url: http://localhost:8000
source_metadata: null
