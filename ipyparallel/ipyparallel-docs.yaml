resources:
- name: abort
  endpoint:
    path: /abort
    method: GET
    data_selector: jobs
    params: {}
- name: activate
  endpoint:
    path: /activate
    method: GET
    data_selector: suffix
    params: {}
- name: apply
  endpoint:
    path: /apply
    method: GET
    data_selector: args
    params: {}
- name: clear
  endpoint:
    path: /clear
    method: GET
    data_selector: targets
    params: {}
- name: execute
  endpoint:
    path: /execute
    method: POST
    data_selector: code
    params:
      silent: true
- name: gather
  endpoint:
    path: /gather
    method: GET
    data_selector: key
    params: {}
- name: get
  endpoint:
    path: /get
    method: GET
    data_selector: key_s
    params: {}
- name: map
  endpoint:
    path: /map
    method: POST
    data_selector: f
    params: {}
- name: run
  endpoint:
    path: /run
    method: POST
    data_selector: filename
    params: {}
- name: shutdown
  endpoint:
    path: /shutdown
    method: POST
    data_selector: targets
    params: {}
- name: Cluster
  endpoint:
    path: /api/ipyparallel.Cluster
    method: GET
- name: pbs
  endpoint:
    path: /ipython/profile/pbs
    method: create
    data_selector: profile
    params: {}
- name: ssh
  endpoint:
    path: /ipython/profile/ssh
    method: create
    data_selector: profile
    params: {}
- name: Cluster
  endpoint:
    path: /api/ipyparallel.Cluster
    method: GET
    data_selector: Cluster objects
    params: {}
- name: Cluster
  endpoint:
    path: /api/ipyparallel/Cluster
    method: GET
    data_selector: clusters
    params: {}
- name: Cluster
  endpoint:
    path: /api/ipyparallel.Cluster
    method: GET
    data_selector: operations
    params: {}
- name: PBS
  endpoint:
    path: /ipython/parallel
    method: GET
    data_selector: jobs
    params: {}
- name: ipcontroller
  endpoint:
    path: /ipcontroller_config.py
    method: GET
- name: Cluster
  endpoint:
    path: /api/ipyparallel/Cluster
    method: GET
    data_selector: records
- name: cluster
  endpoint:
    path: /api/ipyparallel.Cluster
    method: GET
- name: ipcontroller-client
  endpoint:
    path: /Users/me/.ipython/profile_default/security/ipcontroller-client.json
    method: GET
    data_selector: url
- name: ipcontroller-engine
  endpoint:
    path: /Users/me/.ipython/profile_default/security/ipcontroller-engine.json
    method: GET
    data_selector: exec_key
- name: ipcontroller-client
  endpoint:
    path: ''
    method: ''
    data_selector: ''
    params: {}
- name: MPI
  endpoint:
    path: /path/to/my/startup.py
    method: RUN
    data_selector: default
    params: {}
- name: Cluster
  endpoint:
    path: /api/ipyparallel/Cluster
    method: GET
    data_selector: records
- name: DirectView
  endpoint:
    path: /api/ipyparallel/DirectView
    method: GET
    data_selector: records
- name: ipcontroller-client
  endpoint:
    path: /Users/me/.ipython/profile_default/security/ipcontroller-client.json
    method: GET
    data_selector: url
    params: {}
- name: ipcontroller-engine
  endpoint:
    path: /Users/me/.ipython/profile_default/security/ipcontroller-engine.json
    method: GET
    data_selector: url
    params: {}
- name: DirectView
  endpoint:
    path: /api/ipyparallel/DirectView
    method: GET
- name: DirectView
  endpoint:
    path: /api/ipyparallel/DirectView
    method: GET
    data_selector: records
- name: AsyncResult
  endpoint:
    path: /api/ipyparallel/AsyncResult
    method: GET
    data_selector: records
- name: LoadBalancedView
  endpoint:
    path: /api/ipyparallel/LoadBalancedView
    method: GET
    data_selector: records
    params: {}
- name: AsyncResult
  endpoint:
    path: /api/ipyparallel/AsyncResult
    method: GET
    data_selector: records
    params: {}
- name: TaskScheduler
  endpoint:
    path: /schedulers
    method: GET
    data_selector: schedulers
    params: {}
- name: DirectView
  endpoint:
    path: /api/ipyparallel/directview
    method: GET
    data_selector: records
    params: {}
- name: Client
  endpoint:
    path: /api/ipyparallel/client
    method: GET
    data_selector: records
    params: {}
- name: DirectView
  endpoint:
    path: /api/ipyparallel/DirectView
    method: GET
    data_selector: records
- name: Client
  endpoint:
    path: /api/ipyparallel/Client
    method: GET
    data_selector: records
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: load_balancing_schemes
  endpoint:
    path: /schedulers/load_balancing_schemes
    method: GET
    data_selector: schemes
    params: {}
- name: task_record
  endpoint:
    path: /api/ipyparallel/task_record
    method: GET
    data_selector: TaskRecord
    params: {}
- name: AsyncResult
  endpoint:
    path: /reference/details.html#AsyncResult
    method: GET
    data_selector: results
    params: {}
- name: ipcontroller-engine
  endpoint:
    path: ipcontroller-engine.json
    method: GET
- name: ipcontroller-client
  endpoint:
    path: ipcontroller-client.json
    method: GET
- name: AsyncResult
  endpoint:
    path: /AsyncResult
    method: GET
    data_selector: methods
    params: {}
- name: campaign_member
  endpoint:
    path: /services/data/vXX.X/sobjects/CampaignMember
    method: GET
    data_selector: records
    params:
      incremental: updated_at
- name: contact
  endpoint:
    path: /services/data/vXX.X/sobjects/Contact
    method: GET
    data_selector: records
    params: {}
- name: cluster
  endpoint:
    path: /Cluster
    method: POST
    data_selector: cluster
    params:
      engines: mpi
- name: task_record
  endpoint:
    path: /api/ipyparallel/task_record
    method: GET
    data_selector: records
- name: controller_launcher
  endpoint:
    path: /api/ipyparallel/cluster/ControllerLauncher
    method: GET
- name: engine_launcher
  endpoint:
    path: /api/ipyparallel/cluster/EngineLauncher
    method: GET
- name: HTCondorControllerLauncher
  endpoint:
    params: {}
- name: HTCondorEngineSetLauncher
  endpoint:
    params: {}
- name: HTCondorLauncher
  endpoint:
    params: {}
- name: LSFControllerLauncher
  endpoint:
    params: {}
- name: SSHControllerLauncher
  endpoint:
    path: /c/SSHControllerLauncher
    method: GET
    data_selector: records
- name: SSHEngineLauncher
  endpoint:
    path: /c/SSHEngineLauncher
    method: GET
    data_selector: records
- name: SSHEngineSetLauncher
  endpoint:
    path: /c/SSHEngineSetLauncher
    method: GET
    data_selector: records
- name: SSHLauncher
  endpoint:
    path: /c/SSHLauncher
    method: GET
    data_selector: records
- name: SlurmLauncher
  endpoint:
    path: ''
    method: ''
    data_selector: ''
    params: {}
- name: WindowsHPCControllerLauncher
  endpoint:
    path: ''
    method: ''
    data_selector: ''
    params: {}
- name: WindowsHPCEngineSetLauncher
  endpoint:
    path: ''
    method: ''
    data_selector: ''
    params: {}
- name: WindowsHPCLauncher
  endpoint:
    path: ''
    method: ''
    data_selector: ''
    params: {}
- name: batch_file_name
  endpoint:
    path: /c.SlurmLauncher.batch_file_name
    method: GET
    data_selector: batch_script
    params: {}
- name: batch_template
  endpoint:
    path: /c.SlurmLauncher.batch_template
    method: GET
    data_selector: ''
    params: {}
- name: batch_template_file
  endpoint:
    path: /c.SlurmLauncher.batch_template_file
    method: GET
    data_selector: ''
    params: {}
- name: delete_command
  endpoint:
    path: /c.SlurmLauncher.delete_command
    method: GET
    data_selector: scancel
    params: {}
- name: environment
  endpoint:
    path: /c.SlurmLauncher.environment
    method: GET
    data_selector: ''
    params: {}
- name: job_id_regexp
  endpoint:
    path: /c.SlurmLauncher.job_id_regexp
    method: GET
    data_selector: \d+
    params: {}
- name: job_id_regexp_group
  endpoint:
    path: /c.SlurmLauncher.job_id_regexp_group
    method: GET
    data_selector: '0'
    params: {}
- name: namespace
  endpoint:
    path: /c.SlurmLauncher.namespace
    method: GET
    data_selector: ''
    params: {}
- name: options
  endpoint:
    path: /c.SlurmLauncher.options
    method: GET
    data_selector: ''
    params: {}
- name: output_file
  endpoint:
    path: /c.SlurmLauncher.output_file
    method: GET
    data_selector: ''
    params: {}
- name: output_limit
  endpoint:
    path: /c.SlurmLauncher.output_limit
    method: GET
    data_selector: '100'
    params: {}
- name: qos
  endpoint:
    path: /c.SlurmLauncher.qos
    method: GET
    data_selector: ''
    params: {}
- name: queue
  endpoint:
    path: /c.SlurmLauncher.queue
    method: GET
    data_selector: ''
    params: {}
- name: signal_command
  endpoint:
    path: /c.SlurmLauncher.signal_command
    method: GET
    data_selector:
    - scancel
    - -s
    params: {}
- name: stop_timeout
  endpoint:
    path: /c.SlurmLauncher.stop_timeout
    method: GET
    data_selector: '60'
    params: {}
- name: submit_command
  endpoint:
    path: /c.SlurmLauncher.submit_command
    method: GET
    data_selector:
    - sbatch
    params: {}
- name: timelimit
  endpoint:
    path: /c.SlurmLauncher.timelimit
    method: GET
    data_selector: ''
    params: {}
notes:
- only jobs that have not started yet can be aborted.
- to halt a running job, you must interrupt the engine(s) via the Cluster API.
- BroadcastView does not yet have a fully native map implementation.
- Uses IPython parallel for distributed computing.
- Most Cluster methods are async, and all async cluster methods have a blocking version
  with a _sync suffix.
- Some features are only available when using the Cluster API.
- If you know you won’t need your cluster anymore after you use it, use of these context
  managers is encouraged.
- Most Cluster methods are async, and all async cluster methods have a blocking version
  with a _sync suffix
- IPython supports several batch systems, including PBS, LSF, Slurm, SGE, and HTCondor.
- SSH mode uses ssh to execute ipengine on remote nodes.
- The controller listens only on loopback by default.
- Starting with IPython Parallel 7, some features are only available when using the
  Cluster API.
- allow connections on all interfaces from engines
- engines on the same node will use loopback, while engines from other nodes will
  use an external IP
- Due to the lack of security in ZeroMQ, the controller will only listen for connections
  on localhost by default.
- If you see Timeout errors on engines or clients, then the first thing you should
  check is the ip address the controller is listening on.
- If you see Timeout errors on engines or clients, check the ip address the controller
  is listening on.
- Uses SSH for remote engines — ensure SSH keys are set up for password-less logins
- To reuse the connection file, use the --reuse flag.
- Use 'Cluster' API for advanced features like collective interrupts and improved
  crash handling.
- The DirectView's version of map() does not do dynamic load balancing.
- sync_imports() does not allow import foo as bar syntax, because the assignment represented
  by the as bar part is not available to the import hook.
- For persistent JSON files, use the --reuse flag with ipcontroller.
- The Engine itself also has some amount of configuration. Most of this has to do
  with initializing MPI or connecting to the controller.
- These commands/files will be run again, after each execution.
- Parallel commands can raise Python exceptions, just like serial commands.
- A single parallel command can raise multiple exceptions (one for each engine the
  command was run on).
- The CompositeError class wraps one or more other exceptions.
- Uses Direct interface for working with IPython engines
- sync_imports does not allow import foo as bar syntax
- CompositeError truncates the list of exceptions it will print to CompositeError.tb_limit
  (default is five)
- The task interface allows for dynamic load balancing of tasks.
- The pure ZeroMQ scheduler does not support dependencies.
- The default scheduling scheme is Least Load.
- This scheduler does not support any of the advanced features of the Python Scheduler.
- The DirectView’s version of map() does not do dynamic load balancing.
- Ensure that appropriate modules are imported where the task is run.
- support for local=False has not been implemented, so only packages that can be imported
  locally will work this way.
- the usual renaming of the import handle in the same line like in import matplotlib.pyplot
  as plt does not work on the remote engine
- The DirectView does not do dynamic load balancing.
- You can use the builtin map() with a RemoteFunction.
- Uses OAuth2 with refresh token — requires setup of connected app in api
- Some objects like Contact may return nulls in deeply nested fields
- The task interface allows dynamic load balancing and fault tolerance.
- The default load balancing scheme is leastload.
- Uses various database backends including MongoDB, SQLite, and DictDB.
- The AsyncResult object gives you a way of getting a result at a later time through
  its get() method, but it also collects metadata on execution.
- IPython uses ZeroMQ for networking.
- By default, no IPython connections are encrypted.
- Uses IPython's parallel architecture for computations.
- Uses directed acyclic graphs (DAG) for task dependencies
- There are still many sections to fill out in this doc
- The basic interface of the AsyncResult is exactly that of the AsyncResult in multiprocessing.pool.
- Methods include wait(), ready(), successful(), and get().
- mpi4py package is not a strict requirement, but highly recommended.
- The process must be started using mpiexec or a batch system with MPI support.
- The DB backends (SQLite and MongoDB) are slow and can consume large amounts of resources.
- Launchers are used through the Cluster API, which manages one ControllerLauncher
  and zero to many EngineLaunchers.
- Default connections are not encrypted and only listen on localhost
- Connections can be authenticated and encrypted using CurveZMQ as of version 7.1
- Added in version 8.0.
- DAGs are good for task dependencies as they prevent closed loops in task execution.
- Set environment variables for the launched process
- This can help force the engines to get their ids in order, or limit process flood
  when starting many engines.
- 'To generate a config file, use: ipython profile create --parallel'
- This lets you parameterize additional options, such as wall_time with a custom template.
- The mpi4py package is not a strict requirement. However, you need to have _some_
  way of calling MPI from Python.
- You also need some way of making sure that MPI_Init is called when the IPython engines
  start up.
- You need some way of making sure that MPI_Init is called when the IPython engines
  start up.
errors:
- RemoteError
- CompositeError
- NoEnginesRegistered
- ImpossibleDependency
- InvalidDependency
- 'RemoteError: Error raised elsewhere'
- 'CompositeError: Error for representing possibly multiple errors on engines'
- 'NoEnginesRegistered: Exception for operations that require some engines, but none
  exist'
- 'ImpossibleDependency: Exception for unmet dependencies'
- 'InvalidDependency: Exception for invalid dependencies'
- 'TimeoutError: Result not ready.'
- 'ZeroDivisionError: integer division or modulo by zero'
- 'CompositeError: raised when there are multiple errors'
- 'UnmetDependency: Task failed due to unmet dependency on an engine.'
- 'REQUEST_LIMIT_EXCEEDED: Throttle API calls or reduce frequency.'
- 'ImpossibleDependency: The scheduler discovered that a task can never be run.'
- 'REQUEST_LIMIT_EXCEEDED: Throttle API calls or reduce frequency'
- 'QUERY_TIMEOUT: Break down filters or add selectivity'
- '401 Unauthorized: Recheck OAuth scopes or token expiration'
- 'CompositeError: raised when there are multiple errors.'
- 'Unauthorized clients: Requires access to the controller’s ports.'
- 'Unauthorized engines: Requires authentication key to register.'
- 'TimeoutError: Raised if the result does not arrive within the specified timeout.'
- 'RemoteError: Raised encapsulating the remote exception with some metadata.'
- 'Unauthorized clients: Requires access to the controller''s ports'
- 'Unauthorized engines: Requires authentication key to register the engine'
- 'Unauthorized controllers: Requires correct key to connect'
- 'TimeoutError: The number of seconds to wait for a process to exit before raising
  a TimeoutError in stop'
auth_info:
  mentioned_objects:
  - OauthToken
  - AuthProvider
  - NamedCredential
client:
  base_url: https://github.com/ipython/ipyparallel
  auth:
    type: none
source_metadata: null
