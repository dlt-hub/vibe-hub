resources:
- name: job
  endpoint:
    path: /client/jobs
    method: GET
- name: job_meta
  endpoint:
    path: /client/jobs/meta
    method: GET
- name: jobs
  endpoint:
    path: /client/jobs
    method: GET
- name: jobs
  endpoint:
    path: /jobs
    method: GET
    data_selector: records
    params: {}
- name: logs
  endpoint:
    path: /logs
    method: GET
- name: projects
  endpoint:
    path: /projects
    method: GET
- name: requests
  endpoint:
    path: /requests
    method: GET
    data_selector: requests
    params: {}
- name: samples
  endpoint:
    path: /samples
    method: GET
    data_selector: samples
    params: {}
- name: spiders
  endpoint:
    path: /spiders
    method: GET
    data_selector: spiders
    params: {}
- name: projects
  endpoint:
    path: /projects
    method: GET
    data_selector: projects
- name: spiders
  endpoint:
    path: /projects/{project_id}/spiders
    method: GET
    data_selector: spiders
- name: jobs
  endpoint:
    path: /projects/{project_id}/jobs
    method: GET
    data_selector: jobs
- name: metadata
  endpoint:
    path: /metadata
    method: GET
    data_selector: records
- name: items
  endpoint:
    path: /items
    method: GET
    data_selector: records
- name: logs
  endpoint:
    path: /logs
    method: GET
    data_selector: records
- name: requests
  endpoint:
    path: /requests
    method: GET
    data_selector: records
- name: activity
  endpoint:
    path: /activity
    method: GET
    data_selector: records
- name: collections
  endpoint:
    path: /collections
    method: GET
    data_selector: records
- name: frontiers
  endpoint:
    path: /frontiers
    method: GET
    data_selector: records
- name: settings
  endpoint:
    path: /settings
    method: GET
    data_selector: records
notes:
- Uses OAuth2 with refresh token — requires setup of connected app in api
- If not provided, it will read from `SH_APIKEY` or `SHUB_JOBAUTH` environment variables.
- If you need full access to *Scrapy Cloud* features, you’ll need to provide a Scrapy
  Cloud API key.
- 'Not a public constructor: use Collections instance to get a Collection instance.'
- 'Not a public constructor: use Frontiers instance to get a Frontier instance.'
- Recommended to iterate through logs via iter() method for large amounts of logs.
- Your Scrapy Cloud API key is available at the bottom of https://app.zyte.com/o/settings
  after you sign up.
errors:
- 'REQUEST_LIMIT_EXCEEDED: Throttle API calls or reduce frequency'
- 'QUERY_TIMEOUT: Break down filters or add selectivity'
- '401 Unauthorized: Recheck OAuth scopes or token expiration'
- '400: Bad Request'
- '403: Forbidden'
- '404: Not Found'
- '500: Server Error'
- '401: Unauthorized'
- 'Unauthorized: Check your API key'
- 'NotFound: Check the resource you are trying to access'
- 'BadRequest: Usually raised in case of 400 response from API.'
- 'Unauthorized: Request lacks valid authentication credentials for the target resource.'
- 'NotFound: Entity doesn’t exist (e.g. spider or project).'
- 'ValueTooLarge: Value cannot be written because it exceeds size limits.'
- 'DuplicateJobError: Job for given spider with given arguments is already scheduled
  or running.'
- 'ServerError: Indicates some server error: something unexpected has happened.'
auth_info:
  mentioned_objects:
  - ScrapinghubClient
  - Jobs
  - Job
  - JobMeta
client:
  base_url: https://python-scrapinghub.readthedocs.io
  auth:
    type: oauth2
source_metadata: null
