auth_info:
- information_source; https://portkey.ai/docs/api-reference/authentication:
  - Portkey uses API key authentication sent via the SDK initialization. You provide
    your API key (obtained from the Settings page) to the Portkey SDK constructor
    as the apiKey parameter. Optionally, you can specify a virtualKey for virtual
    key management.
  - Portkey's APIs require authentication for all requests. Use your Portkey API key
    in the Authorization header as a Bearer token, or pass it via the x-portkey-api-key
    header. Alternatively, use JWT-based authentication for token-based access.
- information_source; https://portkey.ai/docs/api-reference/inference-api/headers:
  - 'Authorization requires two headers: the x-portkey-api-key header with your Portkey
    API key (stored in environment variable PORTKEY_API_KEY), and either a virtual
    key via x-portkey-virtual-key header (a pre-saved provider credential reference),
    or an x-portkey-config header containing either a config ID or JSON configuration
    object. The Authorization Bearer header with OPENAI_API_KEY is used when calling
    OpenAI directly, not through Portkey.'
  - Portkey API requires two authentication headers. First, include the x-portkey-api-key
    header with your Portkey API key (stored in the $PORTKEY_API_KEY environment variable).
    Second, include the Authorization header with a Bearer token (stored in the $TOKEN
    environment variable). Additional optional headers like x-portkey-trace-id, x-portkey-provider,
    and x-portkey-custom-host can be used for routing and observability but are not
    required for authentication.
  - Portkey API requires two authentication layers. First, the Portkey API key must
    be provided via the x-portkey-api-key header (or api_key / apiKey parameter),
    which can be obtained from the Portkey dashboard and is also available as the
    PORTKEY_API_KEY environment variable. Second, provider authentication is required
    but the documentation excerpt does not specify the details for provider authentication.
pagination_info:
- information_source; https://portkey.ai/docs/llms-full.txt:
  - 'Pagination is controlled via the optional limit query parameter (default: 20)
    which specifies the number of jobs to retrieve per request. The response structure
    and fields for navigating to subsequent pages are not documented in the provided
    excerpt.'
  - Use the `page_size` query parameter to control results per response. The documentation
    references pagination capability but does not explicitly describe response fields
    for navigating pages, stopping conditions, or how to construct subsequent requests.
  - Use the `page_size` query parameter to control the number of results per response.
    The documentation references paginated data endpoints but does not explicitly
    specify response fields for pagination navigation, stopping conditions, or how
    to construct subsequent requests.
  - 'Use the optional query parameter limit (default: 20) to control the number of
    fine-tuning jobs retrieved per request. The documentation does not specify response
    fields for pagination, next page tokens, or mechanisms to retrieve additional
    pages beyond the limit parameter.'
possible_base_urls:
- information_source; https://portkey.ai/docs/api-reference/inference-api/headers:
  - https://api.portkey.ai/v1
  - https://api.portkey.ai/v1/chat/completions
possible_endpoints:
- information_source; https://portkey.ai/docs/api-reference/authentication:
  - DELETE /files/{id}
  - GET /files
  - GET /files/{id}
  - GET /files/{id}/content
  - POST /files/upload
- information_source; https://portkey.ai/docs/api-reference/inference-api/headers:
  - POST https://api.portkey.ai/v1/chat/completions
- information_source; https://portkey.ai/docs/llms-full.txt:
  - DELETE /admin/users/invites/{inviteId}
  - DELETE /admin/users/{userId}
  - DELETE /admin/workspaces/{workspaceId}
  - DELETE /admin/workspaces/{workspaceId}/users/{userId}
