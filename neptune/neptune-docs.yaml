resources:
- name: runs
  endpoint:
    method: GET
- name: model_metadata
  endpoint:
    method: GET
- name: project_metadata
  endpoint:
    method: GET
- name: init_project
  endpoint:
    method: GET
- name: init_run
  endpoint:
    method: GET
- name: project
  endpoint:
    method: GET
- name: run
  endpoint:
    method: GET
- name: model
  endpoint:
    method: GET
- name: model_version
  endpoint:
    method: GET
- name: project
  endpoint:
    method: GET
- name: run
  endpoint:
    method: GET
- name: model
  endpoint:
    method: GET
- name: model_version
  endpoint:
    method: GET
- name: runs
  endpoint:
    method: GET
- name: projects
  endpoint:
    method: GET
- name: runs
  endpoint:
    path: /api/leaderboard/v1/runs
    method: GET
    data_selector: entries
- name: projects
  endpoint:
    path: /api/leaderboard/v1/projects
    method: GET
    data_selector: entries
- name: runs
  endpoint:
    method: GET
- name: projects
  endpoint:
    method: GET
- name: runs
  endpoint:
    method: GET
- name: projects
  endpoint:
    method: GET
- name: models
  endpoint:
    method: GET
- name: projects
  endpoint:
    path: /api/management/projects
    method: GET
- name: members
  endpoint:
    path: /api/management/members
    method: GET
- name: metadata
  endpoint:
    path: /api/management/metadata
    method: GET
- name: runs
  endpoint:
    method: GET
- name: projects
  endpoint:
    method: GET
- name: model_metadata
  endpoint:
    method: GET
- name: runs
  endpoint:
    method: GET
- name: projects
  endpoint:
    method: GET
- name: models
  endpoint:
    method: GET
- name: runs
  endpoint:
    path: /api/leaderboard/v1/runs
    method: GET
- name: projects
  endpoint:
    path: /api/leaderboard/v1/projects
    method: GET
- name: model_versions
  endpoint:
    path: /api/leaderboard/v1/model-versions
    method: GET
- name: runs
  endpoint:
    method: GET
- name: projects
  endpoint:
    method: GET
- name: workspaces
  endpoint:
    method: GET
- name: model_versions
  endpoint:
    method: GET
- name: runs
  endpoint:
    data_selector: sys
- name: run
  endpoint:
    method: GET
- name: project
  endpoint:
    method: GET
- name: runs_table
  endpoint:
    method: GET
- name: run_structure
  endpoint:
    method: GET
- name: runs
  endpoint:
    path: /api/leaderboard/v1/runs
    method: GET
    data_selector: entries
- name: experiments
  endpoint:
    path: /api/leaderboard/v1/experiments
    method: GET
    data_selector: entries
- name: models
  endpoint:
    path: /api/model-registry/v1/models
    method: GET
    data_selector: entries
- name: run
  endpoint:
    method: GET
- name: runs
  endpoint:
    path: /api/leaderboard/v1/
    method: GET
- name: run
  endpoint:
    path: /api/leaderboard/v1/runs
    method: GET
    data_selector: entries
- name: project
  endpoint:
    path: /api/leaderboard/v1/projects
    method: GET
    data_selector: entries
- name: run
  endpoint:
    method: GET
- name: run
  endpoint:
    method: GET
- name: runs
  endpoint:
    path: /api/runs
    method: GET
    data_selector: runs
- name: model_metadata
  endpoint:
    path: /api/model_metadata
    method: GET
    data_selector: models
- name: project_metadata
  endpoint:
    path: /api/project_metadata
    method: GET
    data_selector: projects
- name: run
  endpoint:
    path: /api/leaderboard/v1/runs
    method: GET
    data_selector: entries
- name: model
  endpoint:
    path: /api/leaderboard/v1/models
    method: GET
    data_selector: entries
- name: project
  endpoint:
    path: /api/leaderboard/v1/projects
    method: GET
    data_selector: entries
- name: runs
  endpoint:
    method: GET
- name: models
  endpoint:
    method: GET
- name: projects
  endpoint:
    method: GET
- name: runs_table
  endpoint:
    method: GET
- name: runs
  endpoint:
    method: GET
- name: runs
  endpoint:
    path: /api/leaderboard/v1/projects/{project}/runs
    method: GET
    data_selector: entries
- name: run_metadata
  endpoint:
    path: /api/leaderboard/v1/projects/{project}/runs/{run_id}
    method: GET
    data_selector: data
- name: models
  endpoint:
    path: /api/leaderboard/v1/projects/{project}/models
    method: GET
    data_selector: entries
- name: run
  endpoint:
    method: init_run
- name: runs
  endpoint:
    path: /api/leaderboard/v1/experiments
    method: GET
    data_selector: entries
- name: projects
  endpoint:
    path: /api/backend/v1/projects
    method: GET
    data_selector: projects
- name: model_versions
  endpoint:
    path: /api/backend/v1/model-versions
    method: GET
    data_selector: entries
- name: runs
  endpoint:
    path: /api/leaderboard/v1/runs
    method: GET
- name: model_metadata
  endpoint:
    path: /api/model_registry/v1/models
    method: GET
- name: project_metadata
  endpoint:
    path: /api/leaderboard/v1/projects
    method: GET
- name: video
  endpoint:
    method: POST
- name: audio
  endpoint:
    method: POST
    data_selector: records
- name: video
  endpoint:
    method: POST
    data_selector: records
- name: artifacts
  endpoint:
    path: /api/artifacts
    method: GET
    data_selector: artifacts
- name: runs
  endpoint:
    path: /api/runs
    method: GET
    data_selector: runs
- name: runs
  endpoint:
    path: /api/leaderboard/v1/runs
    method: GET
    data_selector: entries
- name: experiments
  endpoint:
    path: /api/leaderboard/v1/experiments
    method: GET
    data_selector: entries
- name: models
  endpoint:
    path: /api/leaderboard/v1/models
    method: GET
    data_selector: entries
- name: runs
  endpoint:
    method: GET
- name: projects
  endpoint:
    method: GET
- name: models
  endpoint:
    method: GET
- name: runs
  endpoint:
    path: /api/leaderboard/v1/
    method: GET
- name: model_checkpoints
  endpoint:
    method: POST
- name: datasets
  endpoint:
    method: POST
- name: datasets
  endpoint:
    method: POST
- name: charts_and_plots
  endpoint:
    path: /logging/charts_and_plots/
    method: GET
- name: runs
  endpoint:
    path: /api/runs
    method: GET
- name: projects
  endpoint:
    path: /api/projects
    method: GET
- name: models
  endpoint:
    path: /api/models
    method: GET
- name: files
  endpoint:
    method: POST
- name: runs
  endpoint:
    path: /api/runs
    method: GET
- name: files
  endpoint:
    path: /api/files
    method: GET
- name: files
  endpoint:
    method: POST
    data_selector: upload
- name: requirements
  endpoint:
    path: /source_code/requirements
    method: GET
- name: dependencies
  endpoint:
    path: /api/leaderboard/v1/dependencies
    method: GET
    data_selector: dependencies
- name: html_obj
  endpoint:
    method: POST
- name: html
  endpoint:
    path: /api/leaderboard/v1/experiments/html
    method: POST
- name: source_code_diff
  endpoint:
    path: /source_code/diff
    method: GET
- name: git_info
  endpoint:
    method: GET
- name: git_info
  endpoint:
    method: GET
    data_selector: records
    params:
      repository_path: /path/to/repo
- name: parameters
  endpoint:
    path: /parameters
    method: POST
- name: metrics
  endpoint:
    method: POST
    data_selector: metrics
- name: runs
  endpoint:
    method: GET
    data_selector: runs
- name: runs
  endpoint:
    path: /o/{workspace}/org/{project}/runs
    method: GET
    data_selector: runs
- name: metadata
  endpoint:
    path: /o/{workspace}/org/{project}/runs/details
    method: GET
    data_selector: metadata
- name: train_distribution
  endpoint:
    path: /train/distribution
    method: POST
- name: data_sample
  endpoint:
    path: /data/sample
    method: POST
- name: train_predictions
  endpoint:
    path: /train/predictions
    method: POST
- name: images
  endpoint:
    method: POST
    data_selector: records
- name: runs
  endpoint:
    path: /api/leaderboard/v1/runs
    method: GET
    data_selector: entries
- name: images
  endpoint:
    path: /api/leaderboard/v1/images
    method: GET
    data_selector: entries
- name: metadata
  endpoint:
    path: /api/leaderboard/v1/metadata
    method: GET
    data_selector: entries
- name: execution_command
  endpoint:
    method: GET
    data_selector: String
- name: source_code
  endpoint:
    method: GET
    params:
      source_files: []
- name: tabular_data
  endpoint:
    method: upload
    data_selector: CSV
- name: monitoring
  endpoint:
    method: GET
    data_selector: monitoring
- name: system_metrics
  endpoint:
    path: /monitoring
    method: GET
    data_selector: monitoring
    params:
      capture_hardware_metrics: true
      capture_stdout: true
      capture_stderr: true
      capture_traceback: true
- name: runs
  endpoint:
    path: /runs
    method: POST
    data_selector: run
    params: {}
- name: metadata
  endpoint:
    path: /metadata
    method: GET
    data_selector: metadata
    params: {}
- name: run
  endpoint:
    path: /init_run
    method: POST
    data_selector: run
    params: {}
- name: init_run
  endpoint:
    path: /api/neptune/init_run
    method: POST
- name: resume_run
  endpoint:
    path: /api/runs
    method: POST
    data_selector: run
- name: run_groups
  endpoint:
    path: /run_groups
    method: GET
- name: group_tags
  endpoint:
    path: /sys/group_tags
    method: GET
    data_selector: records
    params: {}
- name: runs
  endpoint:
    path: /runs
    method: GET
    data_selector: records
    params: {}
- name: run
  endpoint:
    path: /api/runs
    method: POST
    data_selector: run
    params: {}
- name: run
  endpoint:
    path: /api/runs
    method: POST
    data_selector: run
    params: {}
- name: tags
  endpoint:
    path: /sys/tags
    method: POST
    data_selector: tags
- name: preprocessing
  endpoint:
    path: /preprocessing
    method: POST
    data_selector: metadata
    params: {}
- name: runs
  endpoint:
    path: /fetch_runs_table
    method: GET
    data_selector: runs
- name: run
  endpoint:
    path: /init_run
    method: POST
    data_selector: run
    params: {}
- name: copy_runs
  endpoint:
    path: /copy_runs
    method: POST
    data_selector: results
    params: {}
- name: run
  endpoint:
    path: /api/run
    method: GET
    data_selector: metadata
- name: string_series
  endpoint:
    path: /api/field_types/stringseries
    method: GET
    data_selector: records
- name: file_series
  endpoint:
    path: /api/field_types/fileseries
    method: GET
    data_selector: records
- name: custom_index_values
  endpoint:
    path: /api/custom_index_values
    method: GET
    data_selector: records
- name: multiple_series_logging
  endpoint:
    path: /api/multiple_series_logging
    method: GET
    data_selector: records
- name: fetch_series_data
  endpoint:
    path: /api/fetch_series_data
    method: GET
    data_selector: records
- name: monitoring
  endpoint:
    path: /monitoring
    method: GET
    data_selector: FloatSeries, StringSeries
    params: {}
- name: single_run_dashboard
  endpoint:
    path: /dashboards/single-run
    method: GET
    data_selector: widgets
- name: multi_run_dashboard
  endpoint:
    path: /dashboards/multi-run
    method: GET
    data_selector: widgets
- name: model_metadata
  endpoint:
    path: /api/model_metadata
    method: POST
    data_selector: metadata
- name: project_metadata
  endpoint:
    path: /api/project_metadata
    method: GET
    data_selector: metadata
- name: runs
  endpoint:
    path: /fetch/runs
    method: GET
    data_selector: runs
    params:
      query: '`sys/group_tags`:stringSet CONTAINS "production"'
- name: model_metadata
  endpoint:
    path: /api/model_metadata
    method: POST
    data_selector: metadata
    params: {}
- name: training
  endpoint:
    path: runs/training/id
    method: POST
    data_selector: id
    params: {}
- name: eval
  endpoint:
    path: runs/eval/id
    method: POST
    data_selector: id
    params: {}
- name: model_metadata
  endpoint:
    path: /model/metadata
    method: GET
    data_selector: metadata
- name: runs
  endpoint:
    path: /fetch_runs_table
    method: POST
    data_selector: runs
    params:
      query: '`model/stage`:string = "production"'
      columns:
      - model/stage
      - model/size
      - test/acc
      sort_by: model/size
- name: model_files
  endpoint:
    path: /model/binary
    method: GET
    data_selector: model_files
    params: {}
- name: project_metadata
  endpoint:
    path: /projects
    method: GET
    data_selector: projects
- name: project_metadata
  endpoint:
    path: /allowed/metrics
    method: GET
    data_selector: value
    params: {}
- name: reports
  endpoint:
    path: /reports
    method: GET
    data_selector: reports
    params: {}
- name: experiments
  endpoint:
    path: /api/experiments
    method: GET
    data_selector: results
    params:
      state: failed
- name: runs
  endpoint:
    path: /fetch_runs_table
    method: GET
    data_selector: runs
    params:
      state: inactive
- name: runs
  endpoint:
    path: /api/v2/runs
    method: GET
    data_selector: records
- name: models
  endpoint:
    path: /api/v2/models
    method: GET
    data_selector: records
- name: runs_table
  endpoint:
    path: /fetch_runs_table
    method: GET
    data_selector: records
- name: experiments
  endpoint:
    path: /v2/experiments
    method: GET
    data_selector: data
- name: runs
  endpoint:
    path: /fetch_runs_table
    method: GET
    data_selector: runs
    params: {}
- name: uploaded_files
  endpoint:
    path: /api/field_types/download
    method: GET
    data_selector: files
    params: {}
- name: experiments
  endpoint:
    path: /api/v2/experiments
    method: GET
    data_selector: experiments
- name: models
  endpoint:
    path: /api/v2/models
    method: GET
    data_selector: models
- name: runs
  endpoint:
    path: /fetch_runs_table
    method: GET
    data_selector: runs
    params: {}
- name: run
  endpoint:
    path: /api/runs
    method: GET
    data_selector: runs
- name: model
  endpoint:
    path: /api/models
    method: GET
    data_selector: models
- name: data_versions
  endpoint:
    path: /api/field_types/artifact
    method: GET
    data_selector: files
    params: {}
- name: project
  endpoint:
    path: /api/projects
    method: GET
    data_selector: records
    params: {}
- name: trials
  endpoint:
    path: /trials
    method: GET
    data_selector: metrics
    params: {}
- name: sweep
  endpoint:
    path: /sweep
    method: POST
    data_selector: params
    params: {}
- name: project
  endpoint:
    path: /api/v1/projects
    method: GET
    data_selector: projects
- name: run
  endpoint:
    path: /init_run
    method: POST
- name: neptune_run
  endpoint:
    path: /init_run
    method: POST
- name: parameters
  endpoint:
    path: /parameters
    method: POST
    data_selector: parameters
- name: dataset
  endpoint:
    path: /dataset
    method: POST
    data_selector: dataset
- name: results
  endpoint:
    path: /results
    method: POST
    data_selector: results
- name: datasets/train
  endpoint:
    path: /datasets/train
    method: POST
- name: datasets/test
  endpoint:
    path: /datasets/test
    method: POST
- name: metrics/test_score
  endpoint:
    path: /metrics/test_score
    method: POST
- name: parameters
  endpoint:
    path: /parameters
    method: POST
- name: datasets/train
  endpoint:
    path: /datasets/train
    method: POST
- name: datasets/test
  endpoint:
    path: /datasets/test
    method: POST
- name: project_metadata
  endpoint:
    path: /init_project
    method: POST
    data_selector: project
    params: {}
- name: train_sampled
  endpoint:
    path: /datasets/train_sampled
    method: POST
    data_selector: datasets
    params: {}
- name: datasets
  endpoint:
    path: /datasets
    method: GET
    data_selector: datasets
    params: {}
- name: train_sampled
  endpoint:
    path: /datasets/train_sampled/latest
    method: GET
    data_selector: datasets
    params: {}
- name: test
  endpoint:
    path: /datasets/test.csv
    method: GET
    data_selector: datasets
    params: {}
- name: neptune_logger
  endpoint:
    path: /neptune_logger
    method: POST
    data_selector: metadata
    params: {}
- name: interactive_img
  endpoint:
    path: /api/run/interaactive_img
    method: POST
    data_selector: result
- name: init_run
  endpoint:
    path: /init_run
    method: POST
- name: project
  endpoint:
    path: /projects
    method: GET
- name: training_records
  endpoint:
    path: /log/training
    method: POST
    data_selector: responses
- name: validation_records
  endpoint:
    path: /log/validation
    method: POST
    data_selector: responses
- name: model
  endpoint:
    path: /model/binary
    method: POST
    data_selector: results
    params: {}
- name: training
  endpoint:
    path: /training/best_score
    method: POST
    data_selector: results
    params: {}
- name: data
  endpoint:
    path: /data/results
    method: POST
    data_selector: results
    params: {}
- name: explainer
  endpoint:
    path: /api/v1/explainer
    method: POST
    data_selector: explainer
- name: model_performance
  endpoint:
    path: /api/v1/model/performance
    method: GET
    data_selector: performance
- name: variable_importance
  endpoint:
    path: /api/v1/variable/importance
    method: GET
    data_selector: importance
- name: NeptuneHook
  endpoint:
    path: /neptunehook
    method: POST
    data_selector: parameters
    params: {}
- name: neptune_run
  endpoint:
    path: /init_run
    method: POST
    data_selector: run
    params: {}
- name: neptune_project
  endpoint:
    path: /
    method: GET
    data_selector: project
    params: {}
- name: metadata
  endpoint:
    path: /api/v1/projects/{project_id}/metadata
    method: GET
    data_selector: data
- name: NeptuneCallback
  endpoint:
    path: /neptune-callback
    method: POST
    data_selector: metadata
- name: run
  endpoint:
    path: /api/runs
    method: POST
    data_selector: run_id
- name: run
  endpoint:
    path: /init_run
    method: POST
    data_selector: run
- name: expectations_reports
  endpoint:
    path: /gx/expectations/reports
    method: POST
    data_selector: reports
    params: {}
- name: validations_reports
  endpoint:
    path: /gx/validations/reports
    method: POST
    data_selector: reports
    params: {}
- name: neptune_project
  endpoint:
    params:
      project: ml-team/classification
- name: neptune_api_token
  endpoint:
    params:
      api_token: h0dHBzOi8aHR0cHM.4kl0jvYh3Kb8...ifQ==
- name: NeptuneCallback
  endpoint:
    path: /api/neptune/callback
    method: POST
    data_selector: callback
    params: {}
- name: run
  endpoint:
    path: /get_run
    method: GET
    data_selector: Run
    params: {}
- name: neptune_project
  endpoint:
    path: /neptune/projects
    method: GET
    data_selector: projects
- name: neptune_logging
  endpoint:
    path: /neptune/logging
    method: POST
    data_selector: metadata
    params:
      project: $NEPTUNE_PROJECT
      base_namespace: kedro
      dependencies: infer
      enabled: 'true'
      upload_source_files:
      - '**/*.py'
      - conf/base/*.yml
- name: NeptuneCallback
  endpoint:
    path: /neptune/callback
    method: POST
    data_selector: metadata
    params: {}
- name: leaflet_map
  endpoint:
    path: /upload
    method: POST
    data_selector: upload
    params: {}
- name: training_metadata
  endpoint:
    path: /api/training/metadata
    method: GET
    data_selector: records
- name: booster_summary
  endpoint:
    path: /api/booster/summary
    method: GET
    data_selector: records
- name: neptune_run
  endpoint:
    path: /api/runs
    method: POST
    data_selector: run
    params: {}
- name: neptune_run
  endpoint:
    path: /init_run
    method: POST
    data_selector: run
    params:
      project: common/lightgbm-integration
- name: NeptuneCallback
  endpoint:
    path: /neptune/integrations/lightgbm/NeptuneCallback
    method: POST
- name: booster_summary
  endpoint:
    path: /create_booster_summary
    method: POST
    data_selector: metadata
    params: {}
- name: neptune_run
  endpoint:
    path: /init_run
    method: POST
    data_selector: run
    params:
      with_id: NLI-7
- name: mlflow_runs
  endpoint:
    path: /mlflow/runs
    method: GET
    data_selector: runs
    params: {}
- name: neptune_tracking_uri
  endpoint:
    path: /create_neptune_tracking_uri
    method: POST
    data_selector: tracking_uri
- name: neptune_mlflow_export
  endpoint:
    path: /neptune_mlflow
    method: POST
    data_selector: export_status
- name: run
  endpoint:
    path: /init_run
    method: POST
    data_selector: run
    params: {}
- name: project
  endpoint:
    path: /api/v1/projects
    method: GET
- name: log_study_metadata
  endpoint:
    path: /log_study_metadata
    method: POST
    data_selector: metadata
    params: {}
- name: load_study_from_run
  endpoint:
    path: /load_study_from_run
    method: GET
    data_selector: study
    params: {}
- name: create_summary
  endpoint:
    path: /create_summary
    method: POST
    data_selector: summary
- name: get_model_config
  endpoint:
    path: /get_model_config
    method: GET
    data_selector: model_config
- name: get_serialized_model
  endpoint:
    path: /get_serialized_model
    method: GET
    data_selector: serialized_model
- name: get_forecast_components
  endpoint:
    path: /get_forecast_components
    method: GET
    data_selector: forecast_components
- name: create_forecast_plots
  endpoint:
    path: /create_forecast_plots
    method: POST
    data_selector: forecast_plots
- name: create_residual_diagnostics_plots
  endpoint:
    path: /create_residual_diagnostics_plots
    method: POST
    data_selector: residual_diagnostics
- name: logs
  endpoint:
    path: /logs
    method: POST
    data_selector: records
- name: training_data
  endpoint:
    path: /data/CIFAR10
    method: GET
    data_selector: records
- name: project
  endpoint:
    path: /api/v1/projects
    method: GET
    data_selector: projects
- name: run
  endpoint:
    path: /api/v1/runs
    method: GET
    data_selector: runs
- name: project
  endpoint:
    path: /api/projects
    method: GET
    data_selector: projects
    params:
      project_name: ml-team/classification
- name: model
  endpoint:
    path: /log_model
    method: POST
    data_selector: logs
    params: {}
- name: NeptuneLogger
  endpoint:
    path: /neptune/logger
    method: POST
    data_selector: metadata
- name: NeptuneLogger
  endpoint:
    path: /api/neptune_logger
    method: POST
    data_selector: logger
- name: checkpoint
  endpoint:
    path: /checkpoints
    method: POST
    data_selector: checkpoints
    params: {}
- name: project
  endpoint:
    path: /api/projects
    method: GET
    data_selector: projects
- name: init_run
  endpoint:
    path: /init_run
    method: POST
- name: log_metrics
  endpoint:
    path: /log_metrics
    method: POST
- name: log_hyperparams
  endpoint:
    path: /log_hyperparams
    method: POST
- name: NeptuneObserver
  endpoint:
    path: /api/neptune/sacred
    method: POST
- name: create_regressor_summary
  endpoint:
    path: /create_regressor_summary
    method: POST
    data_selector: summary
    params: {}
- name: create_classifier_summary
  endpoint:
    path: /create_classifier_summary
    method: POST
    data_selector: summary
    params: {}
- name: create_kmeans_summary
  endpoint:
    path: /create_kmeans_summary
    method: POST
    data_selector: summary
    params: {}
- name: get_estimator_params
  endpoint:
    path: /get_estimator_params
    method: GET
    data_selector: params
    params: {}
- name: get_pickled_model
  endpoint:
    path: /get_pickled_model
    method: GET
    data_selector: pickled_model
    params: {}
- name: get_test_preds
  endpoint:
    path: /get_test_preds
    method: GET
    data_selector: test_preds
    params: {}
- name: get_test_preds_proba
  endpoint:
    path: /get_test_preds_proba
    method: GET
    data_selector: test_preds_proba
    params: {}
- name: get_scores
  endpoint:
    path: /get_scores
    method: GET
    data_selector: scores
    params: {}
- name: create_learning_curve_chart
  endpoint:
    path: /create_learning_curve_chart
    method: POST
    data_selector: learning_curve
    params: {}
- name: create_feature_importance_chart
  endpoint:
    path: /create_feature_importance_chart
    method: POST
    data_selector: feature_importance
    params: {}
- name: create_residuals_chart
  endpoint:
    path: /create_residuals_chart
    method: POST
    data_selector: residuals
    params: {}
- name: create_prediction_error_chart
  endpoint:
    path: /create_prediction_error_chart
    method: POST
    data_selector: prediction_error
    params: {}
- name: create_cooks_distance_chart
  endpoint:
    path: /create_cooks_distance_chart
    method: POST
    data_selector: cooks_distance
    params: {}
- name: create_classification_report_chart
  endpoint:
    path: /create_classification_report_chart
    method: POST
    data_selector: classification_report
    params: {}
- name: create_confusion_matrix_chart
  endpoint:
    path: /create_confusion_matrix_chart
    method: POST
    data_selector: confusion_matrix
    params: {}
- name: create_roc_auc_chart
  endpoint:
    path: /create_roc_auc_chart
    method: POST
    data_selector: roc_auc
    params: {}
- name: create_precision_recall_chart
  endpoint:
    path: /create_precision_recall_chart
    method: POST
    data_selector: precision_recall
    params: {}
- name: create_class_prediction_error_chart
  endpoint:
    path: /create_class_prediction_error_chart
    method: POST
    data_selector: class_prediction_error
    params: {}
- name: get_cluster_labels
  endpoint:
    path: /api/get_cluster_labels
    method: GET
    data_selector: File
    params:
      nrows: 1000
- name: create_kelbow_chart
  endpoint:
    path: /api/create_kelbow_chart
    method: GET
    data_selector: File
    params: {}
- name: create_silhouette_chart
  endpoint:
    path: /api/create_silhouette_chart
    method: GET
    data_selector: File
    params: {}
- name: seaborn_fig
  endpoint:
    path: /api/v2/seaborn_fig
    method: POST
    data_selector: data
    params: {}
- name: neptune_run
  endpoint:
    path: /api/v1/runs
    method: POST
    data_selector: run
- name: tensorboard_logs
  endpoint:
    path: /tensorboard
    method: POST
    data_selector: logs
    params: {}
- name: xgboost_integration
  endpoint:
    path: /common/xgboost-integration
    method: POST
- name: xgboost_integration
  endpoint:
    path: /common/xgboost-integration
    method: POST
    data_selector: metadata
- name: neptune_callback
  endpoint:
    path: /neptune/integrations/xgboost
    method: POST
    data_selector: callback
    params: {}
- name: runs
  endpoint:
    path: /api/v1/runs
    method: GET
    data_selector: runs
- name: NeptuneLogger
  endpoint:
    path: /api/v2/neptune_logger
    method: POST
    data_selector: response
    params: {}
- name: run
  endpoint:
    path: /neptune_init_run
    method: POST
    data_selector: run
    params:
      project: workspace-name/project-name
      api_token: Your Neptune API token
- name: run
  endpoint:
    path: /init_run
    method: POST
    data_selector: run
- name: project
  endpoint:
    path: /api/v2/projects
    method: GET
    data_selector: projects
- name: workspace
  endpoint:
    path: /api/v2/workspaces
    method: GET
    data_selector: workspaces
- name: project_list
  endpoint:
    path: /get_project_list
    method: GET
    data_selector: projects
    params:
      api_token: NEPTUNE_API_TOKEN
- name: create_project
  endpoint:
    path: /create_project
    method: POST
    data_selector: project_name
    params:
      api_token: NEPTUNE_API_TOKEN
- name: delete_project
  endpoint:
    path: /delete_project
    method: DELETE
    data_selector: project_name
    params:
      api_token: NEPTUNE_API_TOKEN
- name: add_project_member
  endpoint:
    path: /add_project_member
    method: POST
    data_selector: member_added
    params:
      api_token: NEPTUNE_API_TOKEN
- name: get_project_member_list
  endpoint:
    path: /get_project_member_list
    method: GET
    data_selector: members
    params:
      api_token: NEPTUNE_API_TOKEN
- name: remove_project_member
  endpoint:
    path: /remove_project_member
    method: DELETE
    data_selector: member_removed
    params:
      api_token: NEPTUNE_API_TOKEN
- name: get_workspace_member_list
  endpoint:
    path: /get_workspace_member_list
    method: GET
    data_selector: workspace_members
    params:
      api_token: NEPTUNE_API_TOKEN
- name: get_workspace_service_account_list
  endpoint:
    path: /get_workspace_service_account_list
    method: GET
    data_selector: service_accounts
    params:
      api_token: NEPTUNE_API_TOKEN
- name: get_project_service_account_list
  endpoint:
    path: /get_project_service_account_list
    method: GET
    data_selector: project_service_accounts
    params:
      api_token: NEPTUNE_API_TOKEN
- name: add_project_service_account
  endpoint:
    path: /add_project_service_account
    method: POST
    data_selector: service_account_added
    params:
      api_token: NEPTUNE_API_TOKEN
- name: remove_project_service_account
  endpoint:
    path: /remove_project_service_account
    method: DELETE
    data_selector: service_account_removed
    params:
      api_token: NEPTUNE_API_TOKEN
- name: invite_to_workspace
  endpoint:
    path: /invite_to_workspace
    method: POST
    data_selector: invite_status
    params:
      api_token: NEPTUNE_API_TOKEN
- name: trash_objects
  endpoint:
    path: /trash_objects
    method: POST
    data_selector: trash_status
    params:
      api_token: NEPTUNE_API_TOKEN
- name: delete_objects_from_trash
  endpoint:
    path: /delete_objects_from_trash
    method: POST
- name: clear_trash
  endpoint:
    path: /clear_trash
    method: POST
- name: get_workspace_status
  endpoint:
    path: /get_workspace_status
    method: GET
- name: run_structure
  endpoint:
    path: /init_run
    method: GET
    data_selector: data
- name: workspace_member_list
  endpoint:
    path: /get_workspace_member_list
    method: GET
- name: workspace_service_account_list
  endpoint:
    path: /get_workspace_service_account_list
    method: GET
- name: workspace_status
  endpoint:
    path: /get_workspace_status
    method: GET
- name: log
  endpoint:
    path: /log
    method: POST
- name: get_structure
  endpoint:
    path: /get_structure
    method: GET
    data_selector: data
    params: {}
- name: get_url
  endpoint:
    path: /get_url
    method: GET
    data_selector: url
    params: {}
- name: get_workspace_member_list
  endpoint:
    path: /get_workspace_member_list
    method: GET
    data_selector: members
    params: {}
- name: get_workspace_service_account_list
  endpoint:
    path: /get_workspace_service_account_list
    method: GET
    data_selector: service_accounts
    params: {}
- name: get_workspace_status
  endpoint:
    path: /get_workspace_status
    method: GET
    data_selector: status
    params: {}
- name: init_run
  endpoint:
    path: /init_run
    method: POST
    data_selector: run
    params: {}
- name: invite_to_workspace
  endpoint:
    path: /invite_to_workspace
    method: POST
    data_selector: invite_status
    params: {}
- name: list_fileset_files
  endpoint:
    path: /list_fileset_files
    method: GET
    data_selector: files
    params: {}
- name: log
  endpoint:
    path: /log
    method: POST
    data_selector: log_status
    params: {}
- name: print_structure
  endpoint:
    path: /print_structure
    method: GET
    data_selector: structure
    params: {}
- name: remove_project_member
  endpoint:
    path: /remove_project_member
    method: DELETE
    data_selector: remove_status
    params: {}
- name: remove_project_service_account
  endpoint:
    path: /remove_project_service_account
    method: DELETE
    data_selector: remove_status
    params: {}
- name: stop
  endpoint:
    path: /stop
    method: POST
    data_selector: stop_status
    params: {}
- name: get_structure
  endpoint:
    path: /get_structure
    method: GET
- name: get_url
  endpoint:
    path: /get_url
    method: GET
- name: get_workspace_member_list
  endpoint:
    path: /get_workspace_member_list
    method: GET
- name: get_workspace_service_account_list
  endpoint:
    path: /get_workspace_service_account_list
    method: GET
- name: get_workspace_status
  endpoint:
    path: /get_workspace_status
    method: GET
- name: init_run
  endpoint:
    path: /init_run
    method: POST
- name: invite_to_workspace
  endpoint:
    path: /invite_to_workspace
    method: POST
- name: list_fileset_files
  endpoint:
    path: /list_fileset_files
    method: GET
- name: log
  endpoint:
    path: /log
    method: POST
- name: print_structure
  endpoint:
    path: /print_structure
    method: GET
- name: remove_project_member
  endpoint:
    path: /remove_project_member
    method: POST
- name: remove_project_service_account
  endpoint:
    path: /remove_project_service_account
    method: POST
- name: stop_synchronization_callback
  endpoint:
    path: /stop_synchronization_callback
    method: POST
- name: stop
  endpoint:
    path: /stop
    method: POST
- name: sync
  endpoint:
    path: /sync
    method: POST
- name: artifact
  endpoint:
    path: /artifacts
    method: GET
    data_selector: records
    params: {}
- name: dataset
  endpoint:
    path: /dataset/data_sample
    method: POST
    data_selector: value
    params: {}
- name: upload_example_data
  endpoint:
    path: /upload/example/data
    method: POST
    data_selector: records
- name: download_file
  endpoint:
    path: /download/file
    method: GET
    data_selector: records
- name: fetch_extension
  endpoint:
    path: /fetch/extension
    method: GET
    data_selector: records
- name: File
  endpoint:
    path: /api/v1/file
    method: POST
    data_selector: file
    params: {}
- name: FileSeries
  endpoint:
    path: /api/v1/file-series
    method: POST
    data_selector: file_series
    params: {}
- name: FileSet
  endpoint:
    path: /api/v1/file-set
    method: POST
    data_selector: file_set
    params: {}
- name: dataset
  endpoint:
    path: /datasets_folder
    method: POST
- name: model
  endpoint:
    path: /model
    method: POST
- name: data
  endpoint:
    path: /data
    method: POST
- name: scripts
  endpoint:
    path: /scripts
    method: POST
- name: files
  endpoint:
    path: /data/files
    method: GET
    data_selector: data
- name: runs
  endpoint:
    path: /fetch_runs_table
    method: GET
    data_selector: runs
- name: sys/id
  endpoint:
    path: /sys/id
    method: GET
- name: sys/custom_run_id
  endpoint:
    path: /sys/custom_run_id
    method: GET
- name: sys/name
  endpoint:
    path: /sys/name
    method: GET
- name: sys/creation_time
  endpoint:
    path: /sys/creation_time
    method: GET
- name: sys/owner
  endpoint:
    path: /sys/owner
    method: GET
- name: sys/state
  endpoint:
    path: /sys/state
    method: GET
- name: sys/failed
  endpoint:
    path: /sys/failed
    method: GET
- name: sys/size
  endpoint:
    path: /sys/size
    method: GET
- name: model
  endpoint:
    path: /models
    method: POST
- name: project
  endpoint:
    path: /init_project
    method: POST
    data_selector: project
    params: {}
- name: fetch_runs_table
  endpoint:
    path: /fetch_runs_table
    method: GET
    data_selector: run
    params: {}
- name: clear
  endpoint:
    path: /clear
    method: CLI
    data_selector: junk_metadata
    params: {}
- name: run
  endpoint:
    path: /init_run
    method: POST
    data_selector: run
    params: {}
- name: max_string_attribute_length_exceeded
  endpoint:
    path: /max_string_attribute_length_exceeded
    method: GET
    data_selector: ''
    params: {}
- name: invite_to_workspace
  endpoint:
    path: /api/management/invite_to_workspace
    method: POST
    data_selector: response
    params:
      username: jackie
      workspace: ml-team
      role: admin
- name: add_project_member
  endpoint:
    path: /management/add_project_member
    method: POST
    data_selector: response
    params:
      project: ml-team/classification
      username: jackie
      role: contributor
- name: add_project_service_account
  endpoint:
    path: /management/add_project_service_account
    method: POST
    data_selector: response
    params:
      project: ml-team/classification
      service_account_name: cicd@ml-team
      role: contributor
- name: delete_metadata
  endpoint:
    path: /deleting_data_from_run
    method: GET
    data_selector: metadata
    params: {}
- name: trash_objects
  endpoint:
    path: /trash_objects
    method: POST
    data_selector: objects
    params: {}
- name: create_project
  endpoint:
    path: /management/create_project
    method: POST
    data_selector: project
    params: {}
- name: get_project_list
  endpoint:
    path: /management/get_project_list
    method: GET
    data_selector: projects
    params: {}
- name: delete_project
  endpoint:
    path: /management/delete_project
    method: POST
    data_selector: ''
    params: {}
- name: public_projects
  endpoint:
    path: /management/public_projects
    method: POST
- name: archive_project
  endpoint:
    path: /archive_project
    method: POST
    data_selector: metadata
- name: azureBlob
  endpoint:
    path: /azureBlob
    method: POST
    data_selector: connectionString
    params: {}
- name: elasticsearch
  endpoint:
    path: /elasticsearch
    method: POST
    data_selector: address
    params: {}
- name: mariadb
  endpoint:
    path: /mariadb
    method: POST
    data_selector: host
    params: {}
- name: admin_console
  endpoint:
    path: /auth/admin/neptune/console
    method: GET
- name: neptune
  endpoint:
    path: /neptune
    method: GET
    data_selector: packages
    params: {}
- name: neptune-client
  endpoint:
    path: /neptune-client
    method: GET
    data_selector: packages
    params: {}
- name: neptune-notebooks
  endpoint:
    path: /neptune-notebooks
    method: GET
    data_selector: packages
    params: {}
- name: parameters
  endpoint:
    path: /parameters
    method: GET
    data_selector: parameters
    params: {}
- name: artifacts
  endpoint:
    path: /artifacts
    method: GET
    data_selector: artifacts
    params: {}
- name: logs
  endpoint:
    path: /logs
    method: GET
    data_selector: logs
    params: {}
- name: model_version
  endpoint:
    path: /model_version
    method: POST
    data_selector: model_version
    params: {}
- name: validation_metrics
  endpoint:
    path: /validation/metrics
    method: GET
    data_selector: metrics
notes:
- Uses environment variables NEPTUNE_PROJECT and NEPTUNE_API_TOKEN for configuration
- 'Supports multiple connection modes: async, sync, read-only, and debug'
- Default async mode with 5 second flush period
- API token should be saved as environment variable for security
- Uses API token authentication via NEPTUNE_API_TOKEN environment variable
- 'Project name format: workspace-name/project-name'
- 'Supports multiple connection modes: async, sync, read-only, debug, offline'
- Anonymous logging available with ANONYMOUS_API_TOKEN
- Save Neptune API token and project name as environment variables for security
- Anonymous logging available to public projects using ANONYMOUS_API_TOKEN
- Projects in the common workspace are public and can be used for testing
- Uses API token for authentication
- Supports logging various data types including metrics, images, artifacts
- Requires TensorFlow for MNIST dataset access
- Version 2.x documentation - new docs available at docs.neptune.ai
- Uses API token for authentication - set via NEPTUNE_API_TOKEN environment variable
- Supports tracking of experiments, model metadata, and project metadata
- Client library version <2.0 for app version 2.x
- Self-hosted Neptune can be deployed on your own infrastructure (on-premises) or
  in a private cloud
- Can be deployed in a Kubernetes cluster or in a virtual machine that runs a Kubernetes
  cluster
- Latest version is Neptune 2.5.0 (Nov 2024)
- Model registry is deprecated and will be removed in a future release
- Out of range float values are not JSON compliant → Downgrade simplejson to 3.18
- 'Connection pool is full, discarding connection: app.neptune.ai → Non-issue unrelated
  to Neptune'
- API token is very long - make sure to copy and paste it in full
- Neptune creates .neptune data directory in CWD by default
- NEPTUNE_DATA_DIRECTORY environment variable can be set to change directory location
- Not officially supported on conda
- Log and query access is controlled with API tokens, which can be associated either
  with regular users or (non-human) service accounts
- Enterprise plans include project-level access control
- To use the SaaS version of Neptune, you need an internet connection from your system
- Neptune has persistent URLs, which means that whenever you change something in the
  Neptune app, the URL updates to reflect the changes
- Functions as a combined database and dashboard for ML metadata
- Supports logging from laptop, cloud environment, or computation cluster to central
  workspace
- Documentation covers Neptune app version 2.x and neptune-client version <2.0
- GPU power consumption is automatically logged in the monitoring namespace
- Dropped support for Python 3.7
- Model registry feature is deprecated and will be removed in April 2025
- Single- and multi-run exploration is now unified
- All messages that Neptune prints to the console are prefixed with [neptune]
- Uses OAuth2 with refresh token support
- Supports tracking of Git information, dependencies, and uncommitted changes
- Image size limit is 32 MB for series logging
- String fields are limited to 1024 characters for search indexing
- Supports various integrations including PyTorch, TensorFlow, Keras, XGBoost, LightGBM,
  Optuna, and others
- Supports artifact tracking with Google Cloud Storage, AWS
- Automatic cleanup of junk metadata when running scripts
- Service accounts are workspace-specific and controlled by admins
- Regular user accounts can belong to multiple workspaces
- 'Projects have three levels of visibility: Workspace, Public, and Private'
- Storage amount is workspace-specific
- Enterprise customers can configure SSO for workspaces
- The sys namespace is always created and contains basic info about the object
- For runs, monitoring and source_code namespaces are created by default
- Fields can be flat (stored at the root of the object) or nested (stored under one
  or more namespaces)
- Run represents a tracked experiment containing model-building metadata
- Project represents a Neptune project for logging and querying project-level metadata
- Supports both cloud and self-hosted deployments
- Has public and private project visibility options
- Automatically logs metadata from various ML frameworks
- SOC compliance available for enterprise customers
- Supports logging various metadata types including metrics, parameters, artifacts,
  and files
- Uses append() method for series data and assignment (=) for single values
- Field types determine storage, display, and interaction methods
- Supports tracking files with track_files() method
- Can upload files, arrays, HTML, and Python objects with specialized methods
- You can create at most 9000 fields in one Neptune run
- Field limit is not about metadata limits per se
- Neptune compares values of fields that have the same data type
- If a field stores different data types across runs, Neptune treats them as different
  fields
- 'Fields can contain values of various types: strings, dictionaries, floats, files,
  or artifacts'
- A field can also contain a series of values
- Namespaces (folders) can contain multiple fields of various types, but a field is
  always fixed to a type
- Fields can be organized under namespaces in a folder-like structure
- Fields can be flat (root level) or nested under one or more namespaces
- Field limits apply to prevent excessive metadata storage
- Library name changed from neptune-client to neptune
- Package import changed from neptune.new to neptune
- System metrics not tracked in interactive sessions by default
- No more implicit casting to String for unsupported types
- Functions require keyword arguments instead of positional arguments
- Run states unified to Active/Inactive everywhere
- To smoothly upgrade to the 1.0 version of the Neptune client library, first uninstall
  the neptune-client library and then install neptune
- Requires Python 3.8+
- Python 3.8+ required
- pip installation required
- To upgrade from neptune-client, first uninstall neptune-client then install neptune
- Save Neptune credentials as environment variables
- Can install from GitHub repository
- Project name must consist of 3 to 50 alphanumerical characters and hyphens
- Project key must consist of 1 to 10 capital letters and cannot be changed after
  creation
- Project names are case-insensitive
- Projects have quota limits that may require subscription upgrade or archiving existing
  projects
- Can be accessed in read-only mode to fetch metadata without modifying
- Supports anonymous access to public projects
- Auto-generates Neptune IDs composed of project key and counter
- Automatically logs monitoring, source_code, and sys namespaces
- Code snapshotting not available in Colab or cloud environments
- Environment variables NEPTUNE_API_TOKEN and NEPTUNE_PROJECT recommended for credentials
- Neptune is primarily a metadata tracking platform rather than a traditional API
- Authentication requires API token setup
- Project name must be set in format workspace-name/project-name
- Make sure you create no more than 9000 fields in a single Neptune object
- Avoid creating more unique fields than necessary
- For collections or sequences of data points, use Neptune's field types for series
  or sets
- 'Consider using a custom monitoring namespace name: monitoring/YourOptionalCustomPart'
- In distributed runs, ensure that each process logs the metrics into its own monitoring
  namespace
- When you're done logging to a Neptune run, stop it with the stop() method in your
  code
- If you fetch metadata that you logged earlier in the same script, call wait() before
  querying
- Neptune client library is thread-safe
- Avoid modifying a variable from multiple threads or processes
- Once a field is created, you can't change its type
- Save Neptune API token and project name as environment variables rather than in
  plain text
- Neptune picks up credentials automatically from environment variables
- Avoid storing credentials in source code of training scripts
- API tokens can belong to user accounts or service accounts
- Save API tokens as environment variables
- Can configure logging mode, logging level, and location of .neptune data folder
- Supports error handling and callbacks for data synchronization lags
- Supports service accounts for team access
- Environment variables can be used for configuration
- Multiple integrations available for ML frameworks
- Storage quota limits may apply
- API tokens obtained from local installation contain the address to self-hosted instance
- Service accounts always need to be explicitly assigned to a project in order to
  access it
- Neptune logs certain metadata by default such as system metrics, source code, and
  Git information
- Trashed items still count toward storage quota until permanently deleted
- Supports sync and read-only connection modes
- Use mode='sync' for synchronous logging
- Use mode='read-only' for querying without logging new data
- 'Supports five connection modes: async (default), debug, offline, read-only, and
  sync'
- Debug mode stores no data locally or remotely
- Offline mode stores data locally but doesn't send to Neptune until manual sync
- Read-only mode only fetches data from existing objects without adding or changing
  data
- Synchronous mode waits for calls to reach server before executing tracking calls
- Connection mode can be set via NEPTUNE_MODE environment variable or mode parameter
  in init function
- Logger can be accessed with logging.getLogger('neptune')
- Logging level can be set to suppress Neptune logs except deprecation warnings using
  logging.CRITICAL
- Uses environment variables NEPTUNE_ENABLE_DEFAULT_ASYNC_LAG_CALLBACK and NEPTUNE_ENABLE_DEFAULT_ASYNC_NO_PROGRESS_CALLBACK
  to enable default callbacks
- Callbacks can be triggered when synchronization is lagging or not progressing
- Default thresholds can be overridden with async_lag_threshold and async_no_progress_threshold
  parameters
- Custom callback functions should take a Neptune object as argument and can use stop()
  method
- Neptune uses API token authentication stored in environment variables or configuration
  files
- Custom init_run() functions can be defined for advanced configuration
- Supports offline logging mode for disconnected environments
- Automatic logging of system metrics, git info, and dependencies
- Uses .neptune directory to store data locally before synchronizing with server
- Can change current working directory inside script before neptune.init call
- Offline mode available for local storage
- Supports logging of various metadata types including parameters, metrics, artifacts,
  files, and system metrics
- Display options depend on data type and logging method used
- Uses track_files() for artifact versioning and upload() for files to view in Neptune
- Supports DVC file integration through source_files parameter
- 'Supports video formats: MP4, OGG, OGV, MOV, M4V, MKV, WEBM'
- Use upload() method to log video files
- Create File preview widget to preview audio/video in dashboard
- Supports MP3, M4A, OGA, WAVE audio formats
- Files can be logged using upload() method and viewed in Neptune app
- Artifacts track file metadata including URL, file path, MD5 hash, size, and last
  modified timestamp
- MD5 hash is calculated based on file contents and metadata including path, size,
  and modification time
- Can track single files or entire folders with nested files
- Supports tracking datasets, models, and any file-based artifacts
- Supports logging NumPy arrays and tensors from TensorFlow and PyTorch
- Arrays can be visualized as images using File.as_image()
- Supports 2D and 3D arrays for image visualization
- API token and project name should be saved as environment variables
- Anonymous logging available to public project common/quickstarts
- Supports multiple machine learning frameworks through integrations
- Model checkpoints appear in the All metadata section
- Uses upload() method to save model weights from any deep learning framework
- Checkpoints are logged under configurable field names in namespaces like model_checkpoints
- Datasets are logged as artifacts using track_files() method
- Supports single files and folders
- Records MD5 hash, size, and last modified metadata
- Supports local and S3 file paths
- Neptune does not track libraries imported in notebook code cells
- To track dependencies from an .ipynb file, a separate dependency file must be present
- Tracks uncommitted changes by generating diff.patch file from difference between
  index and HEAD
- Diff files are overwritten if run is resumed
- Can upload diff manually under separate field to preserve original
- By default, Neptune automatically extracts Git information from the project's .git
  directory
- Git tracking can be disabled by setting git_ref=False
- Repository path can be specified with GitRef(repository_path='/path/to/repo')
- On Windows, backslashes in paths need to be escaped
- Neptune looks for a repository in the execution path and its parent directories
  by default
- Git tracking can be disabled by setting git_ref=False or git_ref=GitRef.DISABLED
- Windows paths need to be escaped with raw strings or double backslashes
- Parameters are stored in a namespace called 'parameters' with a field created for
  each parameter
- Parameters can be displayed in experiments table and custom dashboards
- Logged parameters appear in the 'All metadata' section of the run
- In some cases, logging a large amount of metrics at once may exceed rate limits
- To optimize batching when creating multiple series fields in a single statement,
  iterate through the fields in the outer loop and the values in the inner loop
- Metrics can be logged as single values or series of values
- Custom index values can be set with step argument - must be strictly increasing
  Int or Float values
- All value series are displayed as charts in Neptune UI
- Supports logging interactive charts and visualizations as HTML objects
- Matplotlib figures logged as static images by default, use File.as_html() for interactive
- Custom dashboards support File preview widgets for visualizations
- 'Supports image file formats: PNG, JPEG, JPG, GIF, BMP and WebP'
- Supports Matplotlib, Seaborn, and PIL figures
- Supports NumPy arrays
- Supports TensorFlow and PyTorch tensors
- Interactive visualizations are in HTML format and won't be displayed in Images section
- Use upload() method for single images
- Use append() method for series of images
- When logging figure objects directly, File constructor is not needed
- Supports NumPy arrays and TensorFlow/PyTorch tensors
- Interactive visualizations are in HTML format and displayed in All metadata section
- Use upload() method for single images, append() method for series of images
- By default, Neptune automatically logs the entry-point script and its contents
- Neptune can't snapshot the code you execute in cloud environments, such as Google
  Colab
- Git information will still be logged even when source code logging is disabled
- The source_files argument supports wildcard (glob) patterns
- CSV file is displayed in the All metadata section of the run view
- Preview displays adjustable number of rows via drop-down menu
- Raw data tab available for viewing and copying file contents
- By default, monitoring of system metrics is turned off for interactive Python kernels,
  such as Jupyter notebooks
- Setting all monitoring options to False prevents the creation of a monitoring namespace
  altogether
- Custom monitoring namespace name replaces the monitoring/<hash>/ pattern
- When logging metrics from multiple processes, ensure that your custom name is unique
  for each process
- 'By default, Neptune automatically logs hardware consumption: memory, CPU, GPU (only
  NVIDIA), plus its memory and power usage'
- 'Console logs: stdout, stderr, and traceback reports are logged by default'
- Metrics are stored in the monitoring namespace of each run
- Hash value is calculated based on environment information to ensure uniqueness for
  each process
- You can assign a single string to a field.
- Iteratively log a series of text entries with the append() method.
- Due to a technical limitation, only 1000 characters are indexed in String fields.
- Each run automatically tracks system and environment information.
- Best practice to save Neptune API token and project name as environment variables.
- To keep your token secure, avoid placing it in source code. Instead, save it as
  an environment variable.
- There is no limit to the number of times you can resume a run.
- Git information will still be logged, unless disabled separately.
- To turn off logging of hardware consumption, set capture_hardware_metrics to False
  when starting a run
- By default, monitoring of hardware consumption is turned off for interactive Python
  kernels, such as Jupyter notebooks
- Runs can be grouped by tag, configuration, or other value.
- The ID is stored in the system namespace (`sys/id`).
- Custom run names can be set using the name argument of the init_run() function.
- Uses Neptune API for logging runs
- The maximum length of the ID is 36 characters.
- The custom ID is stored in the system namespace (sys/custom_run_id) field of the
  run.
- It's not possible to use a custom run ID in offline mode.
- If a run belongs to a group with matching turned on, the group color overrides the
  run color.
- If a run belongs to multiple groups with matching turned on, the run color resolves
  to gray.
- You can modify the name, description, and tags of any run object in the Information
  view.
- Most integrations automatically organize the metadata logged by the integration
  framework into a dedicated namespace.
- You can usually customize the name of this namespace with the help of a parameter.
- Entries logged for step must be strictly increasing Int or Float values.
- You can automate adding new fields to existing runs by fetching run IDs programmatically.
- Stopping or aborting a run can be done remotely.
- Overwriting the metadata stored under a namespace or field cannot be undone.
- Using read-only mode ensures that any initialized runs or other Neptune objects
  won't be modified.
- If you don't need to log system metrics or hardware monitoring but need write access
  to the run, you can resume it with auto-logging options disabled.
- You can use a script to export runs from one project to another within the same
  or different workspaces.
- To back up your run data from one or more Neptune projects, you can use a utility
  script available in our examples repo.
- Using del or pop() cannot be undone.
- Fields containing single values are always overwritten with the most recent entry
  that is logged.
- Fields containing a series of values are appended with the most recent entry.
- Pass run object between functions
- A common case for working with multiple simultaneous runs is logging each hyperparameter
  optimization trial as a separate run.
- sync() is useful when parallel processes are logging to the servers
- wait() ensures all queued Neptune logging calls reach the servers before continuing
  execution
- A variable logged by another process may not be immediately visible on the server.
- If the script is not doing model training, you can initialize Neptune in the sync
  connection mode. This makes every method synchronous.
- Neptune automatically displays all numerical series as charts and image series as
  an interactive gallery.
- By default, two automatically logged StringSeries are the stdout and stderr fields,
  which track the standard streams.
- You can later upload the data to the Neptune servers with the neptune sync command.
- If your metadata was stored locally but not synchronized with Neptune servers, you
  can upload the offline data manually with the `neptune sync`.
- Modification timestamps are stored automatically in the sys namespace.
- 'You can sort by the following: sys/ping_time, sys/modification_time.'
- The Charts tab displays any logged numerical series (FloatSeries fields).
- A customizable legend helps analyze runs without leaving the tab.
- The dashboard doesn't dynamically update if new metric names appear and they match
  the originally used filter.
- Combining multiple different metrics in a single chart is currently only supported
  for one run at a time.
- Uses OAuth2 with refresh token — requires setup of connected app in api
- Visualizes system metrics and hardware consumption logged during your run
- The Source code tab displays source code information logged during a run.
- Set API token and project for authentication
- Only metadata of tracked artifacts is uploaded, not the contents.
- A dashboard is a customizable display option for runs in your project.
- You can combine different metadata types, such as charts, parameters, image series,
  and code snapshots.
- Dashboards are autosaved when you make a change.
- Runs come with rich comparison and visualization support.
- Requires setup of API token in Neptune
- Log separately from training metadata
- Use tags to manage model stages and versions
- You can download model metadata from an individual run, or fetch model metadata
  from all runs in the project as a data frame.
- Requires setup of connected app in neptune.ai
- To change model stage, use tags to indicate model stage.
- Requires setup of API token for authentication
- Project metadata helps you maintain a single source of truth for runs and models
  tracked in the project.
- Reports are autosaved when you make a change.
- You can access the version history through the version options.
- When building ML models for research or production, it's important to be able to
  reproduce a run to validate its results and performance.
- If your run status is not actually 'Failed', you can leave out the 'sys/failed']
  == True condition.
- You have neptune installed and your Neptune credentials saved as environment variables.
- Ensure to filter results by state to obtain only inactive runs.
- We're not logging new data, so we can resume the run in read-only mode.
- You can now continue logging metadata to this new run.
- You can download the metadata of your runs and models in bulk, or extract data from
  individual objects.
- Runs can be filtered by owner, ID, state, or tags
- The limit parameter restricts the number of returned entries
- To filter runs, pass a raw NQL string to the query argument.
- Dedicated parameters for filtering by owner, ID, state, or tags cannot be combined
  with the query parameter.
- The API supports bulk downloading of metadata.
- Uses API key for authentication
- Limit parameter restricts number of returned entries
- Requires setup of API token for access
- This feature is experimental.
- Runs and other Neptune objects are automatically assigned an identifier (ID) based
  on the project key.
- You can download or export data through the Neptune web application
- Set API token and project
- Make sure not to publish sensitive data through your code!
- Setup of API token is required.
- Keep track of code, data, environment, and parameters.
- Log results, like evaluation metrics and model files.
- You can log anonymously to a public project with a shared API token
- Make sure not to publish sensitive data through your code
- Neptune integrates directly with Optuna, a hyperparameter optimization framework.
- Set your Neptune API token and full project name to the NEPTUNE_API_TOKEN and NEPTUNE_PROJECT
  environment variables, respectively.
- Your full project name has the form workspace-name/project-name.
- You can pass your credentials in the code when initializing Neptune.
- Sign up at neptune.ai/register.
- Create a project for storing your metadata.
- 'Install Neptune: pip install neptune.'
- If you haven't saved your credentials as environment variables, you can pass them
  as arguments when initializing Neptune.
- Use Neptune to track all the metadata across multiple processes into a single run.
- Uses API token for authentication — requires setup of Neptune project
- Ensure to create and log metadata to a single run from the main process.
- Export the same NEPTUNE_CUSTOM_RUN_ID environment variable in each node.
- To follow this tutorial, have scikit-learn installed.
- Best practice to save Neptune API token and project name as environment variables
- Monitor training live example provided in the documentation.
- You can try Neptune anonymously by logging to a public project with a shared API
  token.
- Use namespaces to organize and visualize cross-validation results.
- Use environment variables NEPTUNE_API_TOKEN and NEPTUNE_PROJECT to set credentials.
- Passing your Neptune credentials as environment variables is recommended.
- Track datasets
- Query the dataset version used in a run
- Assert whether two runs used the same dataset version
- Use neptune.ANONYMOUS_API_TOKEN for authentication.
- We don't need the assertion code anymore, so you can freely to remove it.
- Project-level metadata can be logged under the Project metadata tab in Neptune.
- You can log and query metadata on project level, including dataset and model versions.
- With Neptune, you can log metadata generated from different tasks of Airflow DAG
  runs.
- Save your Neptune credentials as Airflow Variables to ensure that they work for
  all tasks.
- User's Neptune API token should be saved as an environment variable.
- It's a best practice to save your Neptune API token and target project as AWS secrets.
- The Neptune-AWS integration lets you initialize Neptune by reading your credentials
  from AWS Secrets.
- Best practice is to save your Neptune API token and project name as environment
  variables.
- Set your Neptune API token and full project name to the NEPTUNE_API_TOKEN and NEPTUNE_PROJECT
  environment variables.
- Use the run object to log metadata and upload files.
- You can set your credentials with the os and getpass libraries
- These won't persist when the notebook kernel is terminated
- DALEX is an open source tool for exploring and explaining model behavior to understand
  how complex models are working.
- Best practice to save API token and project name as environment variables.
- Set NEPTUNE_API_TOKEN as an environment variable in Deepnote.
- Automatically logs model configuration, training code and Git information, system
  metrics and hardware consumption.
- As a best practice, you should save your Neptune API token and project name as environment
  variables
- Captures model training metadata and logs them to Neptune.
- Pass your token as a Docker environment variable or Docker secret.
- 'How to find your Neptune API token: In the bottom-left corner of the Neptune app,
  open the user menu and select Get your API token.'
- For best practice, save your Neptune API token and project name as environment variables.
- fastai is a deep learning library.
- 'With the Neptune-fastai integration, the following metadata is logged automatically:
  Hyperparameters, Losses and metrics, Training code (Python scripts or Jupyter notebooks),
  Git information, Dataset version, Model configuration, architecture, and weights.'
- You can use the created Neptune callback outside of the learner context, which lets
  you log metadata after the fitting or testing methods are finished.
- Sign up at neptune.ai/register to get started.
- Your full project name has the form 'workspace-name/project-name'.
- It's not recommended to pass your credentials in the code when initializing Neptune.
- Captures metadata generated when training models with fastai.
- Set your Neptune API token as an environment variable by creating an encrypted secret
  for your GitHub repository
- You can also add your Neptune project name (NEPTUNE_PROJECT) and other variables.
- Log GX Core's configurations
- Log validation results and display them in the Neptune app
- Upload GX Core's rich HTML reports and interact with them in the Neptune app
- API token can be found in the Neptune app under user menu.
- Project name follows the format workspace-name/project-name.
- Have Neptune and 🤗 Transformers installed.
- Project name has the form 'workspace-name/project-name'.
- You can leave the api_token argument out if you have saved your token to the NEPTUNE_API_TOKEN
  environment variable.
- Logging additional metadata after training
- It's not recommended to pass your API token directly in code.
- You can replace $NEPTUNE_PROJECT with the full name of your Neptune project.
- You can find your API token in the user menu, in the bottom-left corner of the app.
- You can set the log_model_diagram option to True to save the model visualization.
- It's not recommended to pass your API token in code.
- To use this package, you need to have Keras or TensorFlow 2 installed on your machine.
- Uses API key for authentication.
- Logs training and validation metrics, parameters, feature names, and hardware consumption
  metrics.
- Once you've signed up and created a project, set your Neptune API token and full
  project name to the NEPTUNE_API_TOKEN and NEPTUNE_PROJECT environment variables,
  respectively.
- Neptune-LightGBM integration logs training and validation metrics, parameters, and
  hardware consumption metrics.
- API token should be set as an environment variable.
- Projects in the common workspace are public and can be used for testing.
- The api_token argument is included to enable anonymous logging.
- As a best practice, you should save your Neptune API token and project name as environment
  variables.
- To log a confusion matrix, the predicted labels and ground truth are required.
- Requires setup of API token and project.
- Save your Neptune API token and project name as environment variables
- API token is required for access.
- You should save your Neptune API token and project name as environment variables
- Track training code, environment, and Git information
- Log hyperparameters
- Monitor hardware consumption
- Monitor model training live
- Save model checkpoints
- Log performance charts and images
- Log training, validation, and testing metrics and visualize them in the Neptune
  app
- Ensure to set NEPTUNE_API_TOKEN and NEPTUNE_PROJECT environment variables.
- You can log the model summary, as generated by the ModelSummary utility from PyTorch
  Lightning.
- The NeptuneLogger class captures metadata generated during training.
- To keep your token secure, avoid placing it in the source code. Instead, save it
  as an environment variable.
- Ensure to set the API token for authentication.
- MosaicML Composer is a PyTorch library for efficient neural network training.
- You should save your Neptune API token and project name as environment variables.
- 'Log and monitor the Optuna hyperparameter sweep live: Values and params for each
  trial, Best values and params for the study, Hardware consumption and console logs,
  Interactive Optuna plots, Parameter distributions for each trial, The Study object
  itself.'
- Log and monitor the Optuna hyperparameter sweep live
- Values and params for each trial
- It is not recommended to pass the API token directly in the code.
- To disable logging of all trials, pass log_all_trials=False to the NeptuneCallback
  constructor or the log_study_metadata function.
- API token should be set in NEPTUNE_API_TOKEN environment variable.
- Full project name should be set in NEPTUNE_PROJECT environment variable.
- Create a trial-level Neptune run with a 'trial' tag
- Log the study name as a group tag to group trials of the same study together
- Log parameters and scores to the trial-level run
- Optuna is an open source hyperparameter optimization framework to automate hyperparameter
  search.
- With the Neptune-Optuna integration, you can log and monitor the Optuna hyperparameter
  sweep live.
- 'To find your API token: In the bottom-left corner of the Neptune app, expand the
  user menu and select Get my API token.'
- If your setup allows passing environment variables to worker nodes, you should pass
  the NEPTUNE_CUSTOM_RUN_ID environment variable to the computational node.
- You can log anonymously to the public project.
- Set your Neptune API token and full project name to the environment variables NEPTUNE_API_TOKEN
  and NEPTUNE_PROJECT.
- API token is required for authentication.
- Project name should be in the format 'workspace-name/project-name'.
- You can save the model checkpoint at the end of the training loop.
- API token can be retrieved in the Neptune app under user menu.
- Project name is in the form 'workspace-name/project-name'.
- Keep track of your model training metadata when using PyTorch Ignite, such as training
  metrics, model checkpoints, training code and Git information.
- Checkpoint saving is not supported on Windows
- NeptuneSaver is not supported on Windows
- Some objects may return nulls in deeply nested fields
- Save your Neptune API token and project name as environment variables.
- Tracks training code, environment, and Git information
- Logs hyperparameters
- Monitors hardware consumption
- Monitors model training live
- Saves model checkpoints
- Logs performance charts and images
- Logs training, validation, and testing metrics
- Avoid placing API token in source code, use environment variable.
- Uses API token for authentication — requires setup of project in Neptune
- Sacred is a tool to configure, organize, log, and reproduce computational experiments.
- With the Neptune-Sacred integration, you can log hyperparameters, metrics and losses,
  training code and Git information, dataset version, and model configuration.
- Passing your Neptune API token and full project name to the NEPTUNE_API_TOKEN and
  NEPTUNE_PROJECT environment variables.
- Have scikit-learn installed.
- Passing your Neptune credentials in code is not recommended especially for the API
  token.
- Seaborn figure support was added in version 1.9.0 of the Neptune client library.
- Pass credentials as environment variables NEPTUNE_API_TOKEN and NEPTUNE_PROJECT
- API token can be found in the Neptune app under user menu
- Captures NeuralNetClassifier history and logs the metadata to Neptune.
- Close the run if needed
- With the Neptune-TensorBoard integration, you can track metrics and log metadata
  to both TensorBoard and Neptune at the same time.
- You can also use the CLI utility to export existing TensorBoard logs to Neptune.
- API token and project name should be set as environment variables.
- The command doesn't work together with the Neptune-Jupyter extension (neptune-notebooks).
  To use the command, you must uninstall neptune-notebooks first.
- To migrate from Weights and Biases to Neptune, you can use the wandb_to_neptune.py
  utility script provided in the neptune-ai/examples repo.
- Metrics, Parameters, the pickled model, and other metadata are logged automatically.
- Ensure that you have at least version 1.3.0 of XGBoost installed
- You can use the Neptune integration with XGBoost to capture model training metadata
  with `NeptuneCallback`.
- This callback requires xgboost>=1.3.0.
- The Neptune Experiment Tracker flavor is provided by the Neptune-ZenML integration.
- Uses API token for authentication — set as environment variable NEPTUNE_API_TOKEN
- Project name should be set as environment variable NEPTUNE_PROJECT
- Integrations work independently of each other.
- This integration has not yet been updated for neptune `1.x` and requires using neptune-client
  `<1.0.0`.
- Integration requires using neptune-client <1.0.0
- Legacy integration is not supported in the new Neptune client.
- This integration is not actively maintained and does not work on Windows.
- Deprecated integration
- Requires API token to be set up
- User's API token is used when none is provided in the function calls.
- Deleting objects from trash is irreversible.
- Empties the trash of the specified project permanently.
- Set API token and project before use
- Emptying the trash is a separate action. A trashed item is permanently deleted only
  when the trash is emptied.
- Always call stop() in interactive environments, such as a Python interpreter or
  Jupyter notebook.
- API token is required for accessing the API.
- Some objects like Contact may return nulls in deeply nested fields
- Requires API token for authentication
- Ensure to set the API token for access.
- Currently, the only accepted keyword argument is include_plotlyjs.
- Uses OAuth2 with refresh token — requires setup of connected app in neptune
- A single text log entry is limited to 1000 characters, but there is no limit to
  the number of entries in the series.
- Requires setup of connected app in Neptune
- If the logged text exceeds this character limit, the entry will be truncated to
  match the limit.
- Handler object can become any type once a specific logging method is invoked.
- Always store your Neptune API token as an environment variable rather than passing
  it through your model-training source code.
- We recommend you do the same for the project name.
- 'Available connection modes include: async, debug, offline, read-only, sync.'
- In asynchronous mode, metadata tracking calls do not throw exceptions related to
  connectivity or metadata consistency issues. Such issues are printed to stderr.
- In offline mode, no connection to Neptune servers is established. Instead, all the
  tracked metadata is stored on the local disk, in the .neptune folder of the current
  working directory.
- By default, metadata tracking works asynchronously.
- This can be a handy way to debug or 'switch off' Neptune without modifying your
  code.
- The OS can trigger disk flushing implicitly.
- Debug mode essentially turns off all the Neptune-related logging.
- In offline mode, all tracked metadata is stored on the local disk.
- Requires setup of API token in the environment.
- Default callback function that is called if the synchronization lags too much or
  has not progressed at all.
- The output of this function is lazy-evaluated, as the final type depends on the
  logging method that is called on the stringified object.
- Model registry is deprecated. The feature will be deactivated on 2025-04-01.
- The model registry feature is deprecated.
- Neptune CLI is a command-line utility that helps you synchronize metadata with the
  Neptune servers manually.
- 'You may need to manually sync data if the tracked metadata could not be uploaded
  to Neptune, for example: Due to connectivity issues, If you logged data in offline
  mode, If the logging hours for your workspace were exceeded.'
- 'neptune-notebooks incompatibility: The command doesn''t work together with the
  Neptune-Jupyter extension (neptune-notebooks). To use the command, you must uninstall
  neptune-notebooks first.'
- For runs created in offline mode, you need to specify the project where the data
  should be uploaded.
- Ensure API token is set for authentication
- If you exceed the field limit while logging, Neptune stops the synchronization to
  the server and stores the data locally.
- To continue uploading the metadata, you need to delete some excess fields from the
  object in question, then sync the data manually.
- To avoid extra logging of new metadata, turn off system monitoring and other automatic
  logging options.
- On older versions, you can add a check to filter out Inf and NaN values
- To help locate the problem in your code, try initializing Neptune in synchronous
  mode
- Exception - 'Handler' object has no attribute 'append'
- 'Experiencing connection interruptions. Will try to reestablish communication with
  Neptune. Internal exception was: HTTPTooManyRequests'
- 'NVML Error: NVML Shared Library Not Found - GPU usage metrics may not be reported.'
- 'It means one of the following: There are no NVIDIA GPUs on your machine or your
  NVIDIA NVML library is not installed or configured properly.'
- This issue should generally not cause problems and can be ignored.
- Instead of turning off logging completely, you can filter out this error by adding
  the provided snippet to your scripts.
- In version 1.0, unsupported types must be explicitly logged as a supported type.
- Sometimes your metric may not be calculated correctly, which might result in the
  value `None`. Neptune will skip unsupported values when creating a series with `append()`
  or `extend()`.
- You can also convert this value to for example `0` so that it can be logged to Neptune.
- The object type you're trying to log may not be directly supported by Neptune.
- The syncing is progressing slowly or not at all.
- The remaining operations refer to the queue of synchronization operations Neptune
  needs to complete in order to upload your logged metadata to the servers.
- Writing to an archived project is not allowed.
- X-coordinates (step) must be strictly increasing
- Service accounts are workspace-specific.
- Service accounts can log data to Neptune projects they've been assigned to.
- A service account cannot access projects with 'workspace' visibility. It must be
  explicitly assigned to a project to be able to access it.
- Deactivating a service account makes its API token unusable.
- Customized SSO/LDAP integration is available for the self-hosted version of Neptune.
- Neptune supports SAML 2.0-based identity providers, such as Okta and Google.
- If your team uses SSO, check with your team lead or workspace admin before proceeding.
- Workspace admins can change and manage the plan, view usage statistics per project,
  and manage payment settings.
- Project name is case-insensitive.
- Projects have a configurable storage limit in multiples of 10 GB, with a minimum
  of 10 GB.
- Fetching metadata of an archived project is possible in read-only mode.
- Neptune 2.5 introduces support for Azure Blob Storage for object storage.
- Upgrading to version 2.5 is supported only from the previous version (2.4.x).
- Requires external MySQL, Elasticsearch and Ingress Controller.
- Administrator credentials are found in the neptune.yaml configuration file under
  the neptune.init section.
- You can register new users manually through the Keycloak administration console.
- To integrate Keycloak with your LDAP instance, go to https://<YourNeptuneAddress>/auth/admin/neptune/console/#/create/user-storage/neptune/providers/ldap.
- In early 2023, we released a major version upgrade of the Neptune client library
  and changed the package name from 'neptune-client' to 'neptune'.
- If you're running low on disk space, Neptune may not be able to index new runs.
- To keep connections stable, increase the Nginx keep-alive timeout.
- We strongly recommend using HTTPS (SSL certificates) when exposing Neptune.
- Set API token and project before usage
- Uses HTTPS for secure connections
- Neptune 2.2.x is the last version requiring license key updates via redeployment
- Your Neptune API token is like a password to the application.
- By saving your token as an environment variable, you avoid putting it in your source
  code, which is more convenient and secure.
- Any environment variables declared this way won't persist after the notebook kernel
  shuts down.
- If you start a new kernel, they need to be set again.
- Trash takes up space
- As long as items remain in the trash, they take up storage space
- If there are any runs you no longer need, consider deleting them. To keep your storage
  manageable, make this clean-up a monthly or quarterly activity.
- If you want to keep the old runs, check if there are some individual metadata fields
  that you could delete, such as model checkpoints or large visualizations.
- If you have a large datasets logged, consider storing them in dedicated cloud storage
  and only tracking them in Neptune as artifacts.
- Using Neptune in debug mode
- Using Neptune in synchronous mode
- You can use Neptune as a mock object for testing purposes by initializing a run
  in debug mode.
- Workspace or project is read only mode - you have read-only access to all your metadata
  stored in Neptune.
- The 0.x client is deprecated
- We strongly encourage you to migrate to the new client at your earliest convenience.
- Neptune supports both 0.x and 1.x API structures.
- Model registry is deprecated
- The model registry feature will be deactivated on 2025-04-01
errors:
- 'ChunkedEncodingError: Fixed with retry request mechanism'
- 'REQUEST_LIMIT_EXCEEDED: Performance issues on forking process (Linux) have been
  fixed'
- 'Expired OAuth tokens: Properly handled with automatic refresh'
- 'NeptuneException: Most Neptune errors inherit from this class'
- Connection lost
- Field count limit exceeded
- Float attribute value malformed
- Handler object has no attribute append
- HTTP Too many requests
- Inactive run
- Limit exceeded
- Max string attribute length exceeded
- No module named neptune
- NVML Shared Library Not Found
- Timestamp must be non-decreasing
- Type does not support attribute
- Unsupported type
- Waiting for remaining operations
- Writing to archived project
- X-coordinates must be strictly increasing
- 'HTTP Too many requests: Reduce the frequency of API calls.'
- 'Inactive run: Check if the run has been stopped or aborted.'
- 'Limit exceeded: Ensure you are within your usage limits.'
- Unable to find project name or API token.
- 'HTTP Too many requests: Reduce frequency of requests.'
- 'Inactive run: Check the run status.'
- 'HTTP Too many requests: Reduce frequency of API calls.'
- 'Inactive run: Ensure the run is active before performing actions.'
- 'Field count limit exceeded: Reduce the number of fields you''re trying to log.'
- 'HTTP Too many requests: Throttle your API calls to avoid hitting rate limits.'
- 'HTTP Too many requests: Reduce request frequency'
- 'Inactive run: Ensure the run is active before stopping or aborting'
- 'HTTP Too many requests: Reduce frequency of requests'
- 'Inactive run: Ensure the run is active when logging data'
- 'Limit exceeded: Check the limits for fields and attributes'
- 'Limit exceeded: Review API usage limits.'
- 'HTTP Too many requests: Reduce frequency of API calls'
- 'Inactive run: Check if the run is still active'
- 'Connection lost: Ensure network stability.'
- 'Limit exceeded: Reduce request rate.'
- 'Limit exceeded: Review your usage and adjust accordingly.'
- 'HTTP Too many requests: Reduce request frequency or implement backoff strategy'
- 'Limit exceeded: Check usage limits and adjust accordingly'
- 'HTTP Too many requests: Reduce the frequency of API calls'
- 'Inactive run: Ensure the run is active before logging data'
- 'Limit exceeded: Check the API limits for your account'
- 'HTTP Too many requests: Reduce requests or throttle'
- 'Limit exceeded: Check the limit for your account'
- 'Inactive run: Recheck run status'
- 'Limit exceeded: Check your usage limits'
- 'Limit exceeded: Check the API usage limits.'
- 'HTTP Too many requests: Reduce API call frequency'
- 'Limit exceeded: Check your API usage limits'
- '401 Unauthorized: Recheck OAuth scopes or token expiration'
- 'Limit exceeded: Check API rate limits'
- 'REQUEST_LIMIT_EXCEEDED: Throttle API calls or reduce frequency'
- 'QUERY_TIMEOUT: Break down filters or add selectivity'
- 'HTTP Too many requests: Throttle your API calls.'
- '403 Forbidden: Check API key permissions'
- '404 Not Found: Verify the endpoint or resource exists'
- 'Limit exceeded: Review API usage limits'
- 'Limit exceeded: Throttle API calls or reduce frequency'
- 'Inactive run: Check the run status or start a new run'
- '401 Unauthorized: Recheck API token'
- 'Inactive run: Ensure run is active to log data'
- 'Inactive run: Ensure the run is active'
- 'Connection lost: Check network connection.'
- 'Limit exceeded: Ensure not exceeding usage limits.'
- 'Inactive run: Ensure run is active before logging.'
- 'Connection lost: Check your internet connection.'
- 'Limit exceeded: Reduce the number of requests.'
- 'HTTP Too many requests: Reduce the frequency of requests.'
- 'Inactive run: Ensure the run is active before logging data.'
- '401 Unauthorized: Check your API token'
- 'HTTP Too many requests: Reduce request frequency.'
- 'Inactive run: Ensure the run is active before logging.'
- 'Limit exceeded: Check your project limits.'
- If Neptune can't find your project name or API token
- 'Limit exceeded: Check usage limits'
- 'HTTP Too many requests: Throttle your requests or check your usage limits.'
- 'Inactive run: Ensure your run is active before attempting any operations.'
- 'INVALID_PROJECT: Check the provided project name.'
- 'INVALID_API_TOKEN: Ensure the API token is correct.'
- 'Limit exceeded: Ensure usage is within allowed limits'
- 'Inactive run: Ensure the run is active.'
- 'Connection lost: Ensure your network connection is stable.'
- 'HTTP Too many requests: Throttle your requests to avoid hitting the rate limit.'
- 'Connection lost: Check network connection'
- 'Limit exceeded: Adjust resource usage'
- 'HTTP Too many requests: Reduce frequency'
- 'Limit exceeded: Ensure limits are adhered to'
- '401 Unauthorized: Check your API token and project name.'
- '401 Unauthorized: Check API token.'
- 'Inactive run: Ensure the run is active before logging'
- Neptune can't find your project name or API token
- '401 Unauthorized: Check your API token.'
- 'Limit exceeded: Check for limits on API usage'
- 'Inactive run: Check if the run is still active.'
- 'Limit exceeded: Ensure limits are not breached.'
- 'HTTP Too many requests: Reduce requests frequency'
- 'Limit exceeded: Check API usage limits'
- 'HTTP Too many requests: Throttle API calls or reduce frequency'
- 'Connection lost: Check your internet connection or server availability.'
- 'Field count limit exceeded: Reduce the number of fields logged per run.'
- 'Limit exceeded: Check your usage against your plan limits'
- Threshold for disrupted synchronization exceeded.
- 'Connection lost: Check your network connection.'
- 'Connection lost: Check your internet connection or server status'
- 'Limit exceeded: Reduce the number of requests or increase your plan'
- 'Limit exceeded: Throttle requests or optimize usage'
- 'NeptuneConnectionLostException: ...'
- 'NeptuneFieldCountLimitExceedException: There are too many fields (more than 9000)
  in the <Neptune object>.'
- 'ERROR: Error occurred during asynchronous operation processing: Value of float
  attribute cannot be malformed.'
- Neptune does not support Inf or NaN values.
- 'AttributeError: ''Handler'' object has no attribute ''append'''
- 'HTTPTooManyRequests: Indicates too many requests sent to the server'
- 'InactiveRunException: It seems you are trying to log metadata to (or fetch it from)
  a run that was stopped'
- 'NeptuneLimitExceedException: Data synchronization was interrupted because you exceeded
  some limit related to your workspace or project.'
- You can still fetch and delete data from your projects, but your workspace will
  remain in read-only mode until the reason for exceeded limits is resolved.
- 'Error occurred during asynchronous operation processing: Max string attribute length
  (16384) exceeded'
- 'ModuleNotFoundError: No module named ''neptune'''
- 'NVML Shared Library Not Found: GPU usage metrics may not be reported.'
- 'Error occurred during asynchronous operation processing: Timestamp must be non-decreasing
  for series attribute'
- 'Error occurred during asynchronous operation processing: X-coordinates (step) must
  be strictly increasing for series attribute'
- 'TypeDoesNotSupportAttributeException: <object type> has no attribute <attribute>'
- 'NeptuneUnsupportedType: You''re attempting to log a type that is not directly supported
  by Neptune.'
- 'WritingToArchivedProjectException: You''re trying to write to a project that was
  archived.'
- X-coordinates (step) must be strictly increasing for series attribute.
- 'Error occurred during asynchronous operation processing: X-coordinates (step) must
  be strictly increasing for series attribute.'
- 'Limit exceeded: Check account limits'
- 'Limit exceeded: Upgrade your subscription or archive another project.'
- 'Limit exceeded: Check project limits or quotas'
- 'Limit exceeded: Check account limitations'
- Storage quota was exceeded
- Quota of projects or users was exceeded
- Neptune was not able to charge the monthly fee
auth_info:
  mentioned_objects:
  - API token
  - Service accounts
  - Model
  - ModelVersion
  - NeptuneObjectCallback
  - ANONYMOUS_API_TOKEN
  - ANONYMOUS
  - neptune-client
  - Run
  - Project
  - NEPTUNE_API_TOKEN
  - NEPTUNE_PROJECT
  - API tokens
  - service accounts
  - service_accounts
  - NeptuneCallback
  - NeptuneLogger
  - OauthToken
  - workspace
  - project
  - Workspace
  - init_run
  - Project name
  - Environment variables
  - AuthProvider
  - workspace settings
  - project-level access control
  - NeptuneException
  - credentials
  - GitRef
  - neptune.init_run()
  - NamedCredential
  - neptune.yaml
  - neptune.init
client:
  base_url: https://api.neptune.ai
source_metadata: null
