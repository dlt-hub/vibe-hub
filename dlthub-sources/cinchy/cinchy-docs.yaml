resources:
- name: comments
  endpoint:
    path: /Cinchy/Comments
    method: GET
    data_selector: comments
    params: {}
- name: Forms
  endpoint:
    path: /forms
    method: GET
- name: Form Sections
  endpoint:
    path: /form_sections
    method: GET
- name: Form Fields
  endpoint:
    path: /form_fields
    method: GET
- name: Get Form Metadata
  endpoint:
    path: /get_form_metadata
    method: GET
- name: Get Form Sections Metadata
  endpoint:
    path: /get_form_sections_metadata
    method: GET
- name: Forms
  endpoint:
    path: /api/forms
    method: GET
- name: Form Sections
  endpoint:
    path: /api/form_sections
    method: GET
- name: Form Fields
  endpoint:
    path: /api/form_fields
    method: GET
- name: Get Form Metadata
  endpoint:
    path: /api/form_metadata
    method: GET
- name: Get Form Sections Metadata
  endpoint:
    path: /api/form_sections_metadata
    method: GET
- name: Get Form Fields Metadata
  endpoint:
    path: /api/form_fields_metadata
    method: GET
- name: jobs
  endpoint:
    path: /api/jobs
    method: POST
- name: secrets-manager
  endpoint:
    path: /api/v1.0/secrets-manager/secret
    method: GET
- name: upgrade_utility
  endpoint:
    path: /cinchy.upgrade-utility.dll
    method: POST
    params:
      d: TSQL
      s: Server=LAPTOP-4SUPR0L6;Database=T6;User ID=cinchy;Password=cinchy;Trusted_Connection=False;Connection
        Timeout=30;Min Pool Size=10;Encrypt=False
      v: '5.2'
- name: system_properties
  endpoint:
    path: /system/properties
    method: GET
    data_selector: properties
    params: {}
- name: Network Map
  endpoint:
    path: /apps/datanetworkvisualizer
    method: GET
    data_selector: nodes
    params:
      targetNode: ''
      maxDepth: ''
      depthLevel: ''
- name: admin_panel
  endpoint:
    path: /admin/index
    method: GET
- name: saved_query
  endpoint:
    path: /Query/Execute
    method: GET
    data_selector: null
    params: {}
- name: Cinchy
  endpoint:
    path: /Cinchy
    method: GET
- name: CinchySSO
  endpoint:
    path: /CinchySSO
    method: GET
- name: table_creation
  endpoint:
    path: /create/table
    method: POST
    data_selector: table_info
    params:
      domain: selected_domain
- name: csv_import
  endpoint:
    path: /import/csv
    method: POST
    data_selector: import_info
    params:
      domain: selected_domain
      file: uploaded_file.csv
- name: translation
  endpoint:
    path: /Translate
    method: POST
    data_selector: data
    params: {}
- name: Contacts
  endpoint:
    path: /contacts
    method: GET
    data_selector: records
- name: Forms
  endpoint:
    path: /forms
    method: GET
    data_selector: records
- name: Form Sections
  endpoint:
    path: /form_sections
    method: GET
    data_selector: records
- name: Form Fields
  endpoint:
    path: /form_fields
    method: GET
    data_selector: records
- name: Cinchy Applets
  endpoint:
    path: /cinchy_applets
    method: GET
    data_selector: records
- name: queries
  endpoint:
    path: /API/YourQueryDomain/API Test
    method: GET
- name: basic_auth_queries
  endpoint:
    path: /BasicAuthAPI/YourQueryDomain/API Test
    method: GET
    params:
      ResultFormat: CSV
- name: CQL
  endpoint:
    path: /overview/cql
    method: GET
    data_selector: data_types
    params: {}
- name: JavaScript
  endpoint:
    path: /overview/javascript
    method: GET
    data_selector: data_types
    params: {}
- name: JSON
  endpoint:
    path: /overview/json
    method: GET
    data_selector: data_types
    params: {}
- name: XML
  endpoint:
    path: /overview/xml
    method: GET
    data_selector: data_types
    params: {}
- name: ImageUrl
  endpoint:
    path: /overview/imageurl
    method: GET
    data_selector: data_types
    params: {}
- name: Rich text
  endpoint:
    path: /overview/rich-text
    method: GET
    data_selector: data_types
    params: {}
- name: iFrames
  endpoint:
    path: /overview/iframes
    method: GET
    data_selector: data_types
    params: {}
- name: rich_text_editor
  endpoint:
    path: /rich-text-editor
    method: POST
    data_selector: editorData
    params:
      max_characters: 10000
- name: People
  endpoint:
    path: /People
    method: GET
    data_selector: records
    params: {}
- name: New Employees
  endpoint:
    path: /NewEmployees
    method: GET
    data_selector: records
    params: {}
- name: tables
  endpoint:
    path: /Cinchy/Tables
    method: GET
    data_selector: '*'
    params:
      deleted: IS NOT NULL AND Domain != 'Sandbox'
- name: policies
  endpoint:
    path: /Compliance/Policies
    method: GET
    data_selector: '*'
    params:
      deleted: IS NULL
- name: Cinchy Integrated Clients
  endpoint:
    path: '[Cinchy].[Integrated Clients]'
    method: GET
- name: Cinchy Applets
  endpoint:
    path: '[Cinchy].[Applets]'
    method: GET
- name: People
  endpoint:
    path: /path/to/people
    method: POST
    data_selector: data
    params: {}
- name: Salesforce object (bulk API)
  endpoint:
    path: /services/data/vXX.X/sobjects
    method: GET
- name: Salesforce platform event
  endpoint:
    path: /services/data/vXX.X/sobjects/PlatformEvent
    method: GET
- name: Salesforce push topic
  endpoint:
    path: /services/data/vXX.X/sobjects/PushTopic
    method: GET
- name: Open Approval Tasks
  endpoint:
    path: /CinchyQuery/OpenTasks
    method: GET
    data_selector: data
    params:
      timeout: 120
- name: Companies
  endpoint:
    path: Entity
    method: GET
- name: Q1 Sales
  endpoint:
    path: /services/data/vXX.X/sobjects/Q1_Sales
    method: GET
    data_selector: records
    params: {}
- name: Companies
- name: employees
  endpoint:
    path: dbo.employees
    method: SELECT
    data_selector: records
- name: notification
  endpoint:
    path: /services/data/vXX.X/sobjects/Notification__e
    method: POST
- name: Companies
  endpoint:
    path: /api/data/v9.0/Companies
    method: GET
- name: Metrics
  endpoint:
    path: /path/to/metrics
    method: GET
- name: employees
  endpoint:
    data_selector: records
    params:
      query: Select * from dbo.employees
- name: Employees
  endpoint:
    params:
      ID Column: Employee ID
      ID Column Data Type: Number
- name: data_sync
  endpoint:
    path: /sync
    method: POST
    params:
      source: LDAP
      server: Company-1
      object_category: Internal-Metrics
      admin_group: mandatory_admin_group
- name: Article
  endpoint:
    path: /db/Blog/Article
    method: db.collection.find()
- name: Cinchy Event
  endpoint:
    path: MongoDB Collection (Cinchy Event Triggered)
    method: db.collection.find()
    data_selector: records
- name: Employees
  endpoint:
    path: null
    method: null
    data_selector: null
    params: {}
- name: Query
  endpoint:
    path: null
    method: null
    data_selector: null
    params:
      query: Select * from dbo.employees
- name: Employees
  endpoint:
    path: /path/to/employees
    method: SELECT
    data_selector: data
    params: {}
- name: Query
  endpoint:
    path: /path/to/query
    method: SELECT
    data_selector: data
    params: {}
- name: entity
  endpoint:
    path: SAML Assertion URL
    method: GET
- name: Website Metrics
  endpoint:
    path: /kafka/topic/website_metrics
    method: GET
    data_selector: records
    params: {}
- name: data
  endpoint:
    path: /api/v3/datatables/CLS/IDHP
    method: GET
    data_selector: $.data
- name: Table
  endpoint:
    path: null
    method: null
    data_selector: null
    params: {}
- name: Query
  endpoint:
    path: null
    method: null
    data_selector: null
    params: {}
- name: db2_table
  endpoint:
    path: /destination/db2_table
    method: POST
    data_selector: data
    params:
      connection_string: encrypted_connection_string
      table: dbo.employees
- name: Kafka Topic
  endpoint:
    path: /
    method: POST
- name: employees
  endpoint:
    path: /dbo.employees
    method: GET
- name: listener_config
  endpoint:
    path: /listener/config
    method: GET
    data_selector: configs
    params: {}
- name: Listener Config
  endpoint:
    path: /listener/config
    method: INSERT
    data_selector: data
    params:
      name: Listener Name
      event_connector_type: Cinchy CDC
      topic: '{}'
      connection_attributes: '{}'
      status: Disabled
      data_sync_config: CDC Data Sync
      auto_offset_reset: Latest
- name: Cinchy CDC
  endpoint:
    path: /services/data/v1.0/sync
    method: POST
    data_selector: records
- name: Q1 Sales
- name: entity
  endpoint:
    path: /api/data/v9.0/
    method: GET
    params: {}
- name: Employees
  endpoint:
    path: /<database>/Employees
    method: POST
- name: Listener Config
  endpoint:
    path: /services/data/vXX.X/sobjects/ListenerConfig
    method: POST
    data_selector: records
    params: {}
- name: Listener Config
  endpoint:
    path: /services/data/vXX.X/platformEvents
    method: POST
- name: executeCQL
  endpoint:
    path: /api/jobs
    method: POST
- name: Listener Config
  endpoint:
    path: /listener/config
    method: POST
    data_selector: listenerConfigs
    params:
      status: Disabled
      data_sync: Data Polling Data Sync
      auto_offset_reset: Latest
- name: syncdata
  endpoint:
    params:
      server: cinchy.co/Cinchy
      userid: admin
      password: cinchy
      feed: feed configuration
      tempdirectory: temporary directory path
- name: exportdata
  endpoint:
    params:
      server: cinchy.co/Cinchy
      userid: admin
      password: cinchy
      domain: saved query domain
      name: saved query name
      outputpath: output file path
- name: encrypt
  endpoint:
    params:
      server: cinchy.co/Cinchy
      userid: admin
      password: cinchy
      text: text to encrypt
notes:
- To run a real-time sync, enable your Listener from the Execution tab.
- Deleting a table results in your data becoming inaccessible, however it will technically
  still be available on the underlying database.
- Erroneously deleted tables can be restored via the Tables table.
- Warning messages during listener deployment can be safely ignored.
- Updated POST endpoint for Saved Queries now automatically serializes hierarchical
  JSON to text when the content-type is `application/json`.
- You can now pull specific data from REST API response headers using .NET regex capture
  groups.
- The Cinchy session timeout has changed to 7 days for new environments.
- Maximum default file size for uploads has increased to 1GB.
- Bearer tokens or Personal Access Tokens can be used for authentication.
- The jobs endpoint doesn't support Personal Access Tokens.
- Cinchy platform now comes with a new way to store secrets — the Cinchy Secrets Table.
- Using the below endpoint, fill in your <base-url>, <secret-name>, and the <domain-name>
  to retrieve the referenced secret.
- Mandatory changes must be made within your platform appsettings.json files.
- For Kubernetes deployment, changes will reconcile automatically if deploying the
  new 5.6 template.
- 'If you want to move to gp3 storage or gp3 storage and volume encryption: delete
  existing volumes/pvc''s for Kafka, Redis, OpenSearch, Logging Operator and Event
  Listener with StatefulSets.'
- You now have the option to use personal access tokens (PATs) in Cinchy.
- A single user can have up to 5 PATs active at one time.
- You can use PowerShell to count the lines in a delimited file and based on the result
  decide if you will run the CLI.
- If you run a CLI without performing the sync, there is currently no way for you
  to find out how many records will be inserted/updated/deleted.
- Installation instructions for deploying Cinchy v5 on Kubernetes.
- You must create a service account with read/write permissions to the git repositories.
- Turn off your Cinchy platform before running the upgrade.
- Create a backup snapshot of your platform before proceeding.
- 'Default Time Zone: Eastern Standard Time'
- 'Password Attempts Allowed: 3'
- 'System Lockout Duration: 15 minutes'
- 'Minimum Password Length: 8'
- 'Password Requires Symbols: 1'
- 'Password Requires Numbers: 1'
- 'Password Expiration: 90 days'
- 'Maintenance Enabled: 0'
- To use data at rest encryption, your database administrator will need to create
  a database master key.
- You will need the password you used to create your master key to complete backup
  and restore operations.
- You can now deploy Cinchy v5 on Kubernetes
- Added the ability to ingest S3 data sources for delimited or parquet files
- Cinchy version 5 on IIS comes bundled with common components such as Connections,
  Meta Forms, and the Event Listener.
- Cinchy maintains historical versions of data and performs soft deletes which will
  add to the storage requirements.
- Cinchy doesn't delete any data or metadata from within the Data Fabric.
- Table Name must be unique to the domain selected.
- Default Column Types created as text field with maximum length of the longest value.
- CinchyDXD 2.0 is still in development. Documentation might not reflect the actual
  behavior or process of the utility.
- Requires CLI v4.7+
- Webhook ingestion was introduced in Cinchy platform v4.21.
- You will need administrator access to your Cinchy platform to perform Step 3.
- Cinchy exposes a Tableau Web Data Connector that provides access to Cinchy Saved
  Queries as data sources in Tableau.
- Using GraphQL on Cinchy means you still need to adhere to the Cinchy data structure.
- You must first hit the domain and then the table when writing your queries.
- API calls made using a bearer token will run under the privileges of the authenticated
  user.
- You must include the token in each request in the Authorization header.
- Enable text formatting to use the rich text editor in Forms.
- Check 'Save text as HTML' to store data in HTML format.
- Cinchy Change Data Capture feature must be enabled for real-time updates.
- You don't have to set up an exact 1:1 relationship between source columns/data and
  schema columns.
- If a source column (of any type) is syncing into a Cinchy Target Table link column,
  the source column must be dataType="Text".
- If a Destination column is being used as a sync key, its source column must be set
  to type=Text, regardless of its actual type.
- You can use any task/job scheduling application to automatically run data syncs
  on a schedule.
- Currently, form links will only populate on existing records. They won't appear
  on a blank form.
- You can set this to your link if you want a single URL to populate as the default.
  This value can always be updated in the table.
- Add this column to your form by navigating to the Form Fields table and inputting
  your new column as a row.
- Set <DroppedRecordBehaviour type="DELETE" /> for full data synchronization.
- Set <DroppedRecordBehaviour type="IGNORE" /> for partial data synchronization.
- You can create a full data synchronization on a partial dataset by filtering the
  source and target.
- When syncing data that's linked to other data, order the sync to the data that is
  linked to first.
- To create a reference data set based on a set of shipping labels, run the data against
  the Country Codes table first.
- When syncing from different sources into the same data set, add the source of the
  data as a column to avoid overwriting records.
- To use different sources to enrich different fields on the same record, set the
  dropped record behaviour to ignore.
- You can add post sync scripts to a data sync configuration that run after the data
  sync has been completed.
- If you have a file source and want to sync data into Cinchy that doesn't have a
  sync key, add a calculated column for the row number of that record.
- To run a bi-directional sync, identify a source system unique identifier and run
  four data syncs for bidirectional syncing.
- To run intensive summary queries on the platform, create a data sync to cache the
  data in a Cinchy table.
- 'When configuring a data sync you must set your sync behaviour. You have two options
  for this: Full File or Delta.'
- Source is a local CSV file.
- The sync key is based on the Name column.
- Data syncs are role based access systems where you can give specific groups read,
  write, execute, and/or all of the above with admin access.
- The SOAP body is a sub-element of the SOAP envelope, which contains information
  intended for the ultimate recipient of the message.
- Inputting at least an Admin Group is mandatory.
- Parameters use the column name or alias as defined in the CDC Event's Listener Config
  prefixed with an `@`
- Parameter names are case sensitive when used in the Connection configuration.
- Column names in the listener config shouldn't contain spaces.
- You must flatten the MongoDB source document prior to sync by using a projection.
- By default, MongoDB batch size is 101.
- By default, bulk operations size is 5000.
- To use change streams in MongoDB, the database must be in a replica set or sharded
  cluster.
- The database must use the WiredTiger storage engine.
- The replica set or sharded cluster must use replica set protocol version 1.
- The MongoDB Event source supports real-time syncs.
- Due to a conversion of doubles to decimals that occurs during the sync process,
  minor data losses may occur.
- Inputting at least an Admin Group is mandatory
- Check this if you want to connect to Kafka over SSL
- The maximum number of retries is capped at 10.
- Make sure you keep this set to Disabled until you are confident you have the rest
  of your data sync properly configured first.
- Keep status set to Disabled until confident about data sync configuration.
- Keep listener config set to Disabled until properly configured.
- Column names in the listener config shouldn't be prefixes of other column names.
- Use SSL for x.509 certificate authentication if required.
- Keep status set to Disabled until configuration is verified.
- Keep Status set to Disabled until configuration is confirmed.
- Auto Offset Reset can be reconfigured after initial setup.
- The access token can be either a Bearer token or a Personal Access token.
- Keep Status set to Disabled until configuration is complete.
- Auto Offset Reset can be changed after initial configuration.
- Disabled
- Have your credentials changed in either the source or target? (For example, an expired
  password).
- Is your sync key unique in your source and target?
- Is the configuration entered in the [Cinchy].[Data Sync Configurations] table?
- If source is a file, does it exist at the specified location?
errors:
- '400: The request couldn''t be understood, the client is sending a request with
  incomplete data, poorly constructed data or invalid data.'
- '401: Invalid credentials, including not providing credentials, expired credentials
  and incorrect credentials.'
- '400 Bad Request: The request couldn''t be understood, the client is sending a request
  with incomplete data, poorly constructed data or invalid data.'
- '401 Unauthorized: errors likely mean you haven''t added the user to the list of
  Anonymous users that can execute the query.'
- 'Server can''t be reached: Log out and log back in to Cinchy.'
- '400: For invalid parameters, a 400 error will be returned with a description of
  the error.'
- Execution Errors table logs any errors that may occur in a data sync.
- '400: Invalid username or password'
- '401: Invalid credentials'
- 'Duplicate Key: The sync key values aren''t unique & duplicated records are rejected'
- 'Malformed Row: The row couldn''t be parsed based on the source schema.'
- 'Invalid Format Exception: Check the value for this column, there may be a mismatched
  data type.'
- 'Max Length Violation: The text you are trying to insert or update a target field
  with is too long'
- 'Mandatory Rule Violation: No (or incorrect) value provided for a mandatory column'
- 'Unresolved Link: Check if the values the CLI is trying to insert/update exist in
  the linked Cinchy table target'
- 'Value must be a number: Check the value for this column, there may be a mismatched
  data type.'
- 'Value must be a valid date: No (or incorrect) value provided for a mandatory column'
- 'Value must be Yes or No: The value passed wasn''t a Boolean'
- 'Value must be selected from the available options: The value from the source doesn''t
  correspond to the values in the Cinchy Target choice column'
auth_info:
  mentioned_objects:
  - Integrated Clients
client:
  auth:
    type: basic
    token_url: null
    client_id: '{{ dlt.secrets[''encrypted_client_id''] }}'
    client_secret: '{{ dlt.secrets[''encrypted_client_secret''] }}'
    location: header
    header_name: Authorization
    flow: null
    refresh_token: null
  base_url: ''
  headers:
    Accept: application/json
    Content-Type: application/json
  paginator: {}
  connection_string: encrypted Connection String
  table: dbo.employees
source_metadata: null
