resources:
- name: posts
  endpoint:
    path: /posts
    method: GET
    data_selector: commit
    params: {}
- name: jobs
  endpoint:
    path: /api/pipelines/{PIPELINE_ID}/components/{COMPONENT_ID}/jobs
    method: GET
    params:
      ready: 'true'
- name: jobs
  endpoint:
    path: /api/pipelines/{pipeline_id}/components/{step_id}/jobs
    method: POST
    data_selector: jobs
    params:
      ready: 'true'
- name: bulk_jobs
  endpoint:
    path: /api/pipelines/{pipeline_id}/components/{step_id}/jobs/bulk
    method: POST
    data_selector: jobs
    params:
      ready: 'true'
- name: Job Update
  endpoint:
    path: /api/pipelines/:PipelineId/components/:ComponentId/jobs/:JobId
    method: PUT
- name: jobs
  endpoint:
    path: /api/pipelines/:PipelineId/components/:ComponentId/jobs
    method: GET
    params:
      count: '50'
- name: job_details
  endpoint:
    path: /api/pipelines/:PipelineId/components/:ComponentId/jobs/:JobId
    method: GET
    data_selector: job_properties
    params: {}
- name: cancel_job
  endpoint:
    path: /api/pipelines/:PipelineId/components/:ComponentId/jobs/:JobId/state/cancelled
    method: PATCH
- name: cancel_job
  endpoint:
    path: /api/pipelines/:PipelineId/components/:ComponentId/jobs/:JobId
    method: DELETE
    params: {}
- name: job_search
  endpoint:
    path: /api/pipelines/jobs/search
    method: POST
    data_selector: records
- name: tiktok_data_extractor
  endpoint:
    path: /v2/actor/clockworks/free-tiktok-scraper/jobs
    method: POST
    data_selector: result
    params:
      Actor ID: clockworks/free-tiktok-scraper
      Actor Input:
        searchQueries:
        - kanata
        resultsPerPage: 10
        excludePinnedPosts: false
        shouldDownloadCovers: false
        shouldDownloadSlideshowImages: false
        shouldDownloadSubtitles: false
        shouldDownloadVideos: false
      Job Type: ''
- name: jobs
  endpoint:
    path: /api/pipelines/{PIPELINE_ID}/components/{COMPONENT_ID}/jobs
    method: GET
    params:
      ready: 'true'
- name: data365_instagram_profile_posts_feed
  endpoint:
    path: /api/pipelines/{PIPELINE_ID}/components/{COMPONENT_ID}/jobs
    method: GET
    data_selector: jobs
    params:
      ready: 'true'
- name: jobs
  endpoint:
    path: /api/pipelines/{PIPELINE_ID}/components/{COMPONENT_ID}/jobs
    method: GET
    data_selector: profiles
    params:
      ready: 'true'
- name: jobs
  endpoint:
    path: /api/pipelines/{PIPELINE_ID}/components/{COMPONENT_ID}/jobs
    method: GET
    data_selector: data
    params:
      ready: 'true'
- name: jobs
  endpoint:
    path: /api/pipelines/{PIPELINE_ID}/components/{COMPONENT_ID}/jobs
    method: GET
    data_selector: jobs
    params:
      ready: 'true'
- name: jobs
  endpoint:
    path: /api/pipelines/{PIPELINE_ID}/components/{COMPONENT_ID}/jobs
    method: GET
    params:
      ready: 'true'
- name: jobs
  endpoint:
    path: /api/pipelines/{PIPELINE_ID}/components/{COMPONENT_ID}/jobs
    method: GET
    params:
      ready: 'true'
- name: jobs
  endpoint:
    path: /api/pipelines/{PIPELINE_ID}/components/{COMPONENT_ID}/jobs
    method: GET
    data_selector: results
- name: search_queries
  endpoint:
    path: /api/pipelines/{PIPELINE_ID}/components/{COMPONENT_ID}/jobs
    method: GET
    data_selector: jobs
    params:
      ready: 'true'
- name: jobs
  endpoint:
    path: /api/pipelines/{PIPELINE_ID}/components/{COMPONENT_ID}/jobs
    method: GET
    params:
      ready: 'true'
- name: jobs
  endpoint:
    path: /api/pipelines/{PIPELINE_ID}/components/{COMPONENT_ID}/jobs
    method: GET
    data_selector: jobs
    params:
      ready: 'true'
- name: jobs
  endpoint:
    path: /api/pipelines/{PIPELINE_ID}/components/{COMPONENT_ID}/jobs
    method: POST
    data_selector: data
    params: {}
- name: search_queries
  endpoint:
    path: /api/pipelines/{PIPELINE_ID}/components/{COMPONENT_ID}/jobs
    method: POST
    data_selector: data
    params: {}
- name: jobs
  endpoint:
    path: /api/pipelines/{PIPELINE_ID}/components/{COMPONENT_ID}/jobs
    method: GET
    data_selector: results
- name: jobs
  endpoint:
    path: /api/pipelines/{PIPELINE_ID}/components/{COMPONENT_ID}/jobs
    method: GET
    params:
      ready: 'true'
- name: jobs
  endpoint:
    path: /api/pipelines/{PIPELINE_ID}/components/{COMPONENT_ID}/jobs
    method: POST
    data_selector: jobs
    params:
      ready: 'true'
- name: detect_language
  endpoint:
    path: /operations/detect_language
    method: POST
    data_selector: operations.language
    params:
      main: content.body
- name: Monitor Folder
  endpoint:
    permissions_required:
    - LIST
    - READ
    - WRITE
- name: Monitor Folder Daily
  endpoint:
    permissions_required:
    - LIST
    - READ
    - WRITE
- name: Folder
  endpoint:
    permissions_required:
    - LIST
    - READ
    - WRITE
- name: Files
  endpoint:
    permissions_required:
    - READ
- name: jobs
  endpoint:
    path: /api/pipelines/{PIPELINE_ID}/components/{COMPONENT_ID}/jobs
    method: GET
    data_selector: jobs
    params:
      ready: 'true'
- name: Searchable Storage
  endpoint:
    path: /searchable_storage
    method: GET
    data_selector: documents
    params:
      query: content.title:*pizza* AND content.followers:{72470 TO *}
      mode: Search
- name: Aggregation
  endpoint:
    path: /aggregation
    method: GET
    data_selector: buckets
    params:
      aggregation_query: '{"top_hashtags":{"terms":{"field":"content.hashtags.keyword","size":5}}}'
- name: langdetect
  endpoint:
    path: /operations/langdetect
    method: POST
    data_selector: operations.language
    params: {}
- name: concat
  endpoint:
    path: /concat
    method: POST
    data_selector: operations
    params: {}
- name: Lucene Query
  endpoint:
    path: /lucene/query
    method: POST
    data_selector: documents
    params: {}
- name: translation
  endpoint:
    path: /translate
    method: POST
    data_selector: enrichment.text_translation
    params: {}
- name: hard_news
  endpoint:
    path: /hard_news_classifier
    method: POST
    data_selector: enrichment.hard_news
    params: {}
- name: wsl_Instagram
  endpoint:
    path: /wsl_Instagram
    method: POST
    data_selector: media_posts
    params: {}
- name: wsl_blogs
  endpoint:
    path: /wsl_blogs
    method: POST
    data_selector: media_posts
    params: {}
- name: wsl_forums
  endpoint:
    path: /wsl_forums
    method: POST
    data_selector: media_posts
    params: {}
- name: data365_twitter_keywords
  endpoint:
    path: /data365_twitter_keywords
    method: POST
    data_selector: media_posts
    params: {}
- name: sentiment_analysis
  endpoint:
    path: /enrichment.sentiment
    method: POST
    data_selector: sentiment_output
    params: {}
- name: sentiment
  endpoint:
    path: /operations/sentiment
    method: POST
    data_selector: enrichment.sentiment
    params: {}
- name: category_classifier
  endpoint:
    path: /enrichment.category
    method: POST
    data_selector: output
    params: {}
- name: Translation
  endpoint:
    path: /translate
    method: POST
    data_selector: enrichment.text_translation
    params:
      destination_path: enrichment
      target_language: FR
      target_text: content.body
- name: intent_classifier
  endpoint:
    path: /intent/classifier
    method: POST
    data_selector: enrichment.intent
    params: {}
- name: enrichment.emotions
  endpoint:
    path: enrichment.emotions
    method: POST
    data_selector: emotions
    params: {}
- name: product_sentiment
  endpoint:
    path: /enrichment.product_sentiment
    method: POST
    data_selector: output
    params:
      target_text: content.body
- name: category_classifier
  endpoint:
    path: /classifiers/category
    method: POST
    data_selector: operations.category
    params: {}
- name: esg_output
  endpoint:
    path: /enrichment/esg
    method: POST
- name: entity_recognition
  endpoint:
    path: /enrichment/entities
    method: POST
    data_selector: entities
    params: {}
- name: AI Brand Recognition Classifier
  endpoint:
    path: /enrichment/brands
    method: POST
    data_selector: brands
    params:
      target_text: content.body
- name: wsl_news
  endpoint:
    path: /wsl_news
    method: GET
    data_selector: records
    params: {}
- name: opoint_news
  endpoint:
    path: /opoint_news
    method: GET
    data_selector: records
    params: {}
- name: Get Pipeline Content
  endpoint:
    path: /pipeline-gateway/<your-pipeline-id>/<your-step-id>/api/content
    method: GET
    params:
      autoAck: 'false'
- name: Acknowledge Pipeline Content
  endpoint:
    path: /pipeline-gateway/<your-pipeline-id>/<your-step-id>/api/content/:ack_id/ack
    method: PUT
- name: Decline Pipeline Content
  endpoint:
    path: /pipeline-gateway/<your-pipeline-id>/<your-step-id>/api/content/:ack_id/nack
    method: PUT
- name: location_inference
  endpoint:
    path: /location/inference
    method: POST
    data_selector: location_inference
    params: {}
- name: dominant_location
  endpoint:
    path: /dominant_location
    method: POST
    data_selector: dominant_location
    params: {}
- name: content_similarity_clustering
  endpoint:
    path: /enrichment/content_similarity_clustering
    method: POST
- name: pdf_report
  endpoint:
    path: /pdf/report
    method: POST
    data_selector: results
- name: file_fetcher
  endpoint:
    path: /wsl-file-fetcher
    method: GET
    data_selector: files
    params: {}
- name: aggregations
  endpoint:
    path: /aggregations
    method: POST
    data_selector: aggregations
    params: {}
- name: search
  endpoint:
    path: /api/search
    method: POST
    data_selector: results
- name: count
  endpoint:
    path: /api/count
    method: POST
    data_selector: total
    params: {}
- name: social_posts
  endpoint:
    data_selector: posts
    params: {}
- name: trend_alerts
  endpoint:
    data_selector: posts
    params: {}
- name: egress_data
  endpoint:
    path: /path/to/egress/endpoint
    method: POST
- name: egress_configuration
  endpoint:
    path: /azure/blob/storage/egress/configuration
    method: POST
- name: index_alias
  endpoint:
    path: /my_index
    method: POST
- name: schema_definition
  endpoint:
    data_selector: columns
- name: enrichment
  endpoint:
    path: /enrichment/product_sentiment
    method: POST
    data_selector: enrichment.product_sentiment
    params: {}
notes:
- Configure required fields to apply PII Redaction on.
- Set Destination Path and Text to the same value, in order to replace original unredacted
  content.
- By default, routes allow all documents unless a filter is defined.
- Enable Allow Multi-route to send the same document through all routes that match,
  including those without filters.
- Pricing details can be viewed at https://datastreamer.io/pricing/
- The Inspector will cache the latest 1,000 documents per job, as well as up to 1,000
  documents not associated with any job.
- The Clear Cache button will remove all documents stored in the Inspector component
  itself, this will not affect documents in other stages of the pipeline.
- The Inspector loads 100 documents at a time.
- Dynamic pipelines are designed to be easily modified, extended, and managed.
- Datastreamer is a serverless, self-healing pipeline platform where users can determine
  data workflows, and the platform continuously and automatically maintains them with
  minimal manual involvement.
- 'Scalable: Designed for growth — Orchestrator handles the scaling of ingestion workers,
  processors, or delivery agents.'
- 'Resilient: Survives individual service failures automatically.'
- 'Secure: Encryption, auth, and access control by default.'
- 'Efficient: Supports very high event throughput with minimal latency.'
- 1 DVU of any support metric is estimated to align to the size, complexity, and effort
  to process 100 Twitter posts.
- Job Name is used to identify this job in analytics and job management screens.
- Max documents is available for Jobs, and acts as a soft cap on the documents ingested.
- Only Periodic Jobs can be updated
- API calls to update Jobs require both correct Pipeline ID and Step ID
- If no field is specified, then query, label and tags will be searched.
- All string fields can match on the wildcard character *.
- Use the 'Restart' mode to collect and process all documents including any previously
  collected.
- Use the 'Recover' mode to continue from where the failure occurred.
- The maximum quantity of posts retrieved is 300 posts per query.
- Current version of this component does not provide a query search in the user posts
  data.
- Maximum allowed length of keywords string is 400 characters
- The maximum quantity of posts retrieved is 20,000 posts per query.
- The maximum quantity of posts retrieved is 500 posts per query.
- You will need a Opoint API key to use this component.
- You need to obtain an API Key from Socialgist directly.
- For TikTok integration, an API Key is not required.
- Datastreamer Portal account with access to add a new component
- Google Cloud Service Account required
- Bucket names are globally unique
- Service Account must have Storage Object Viewer and Storage Legacy Bucket Reader
  permissions
- You will need a Socialgist API key to use this component.
- Crawling is focused on user and hashtag pages.
- 'Available data: videos, hashtag stats, top level comments. Only 2 years of data
  is available at current rollout.'
- Unify Schema used for this data source.
- Use an API key to access the service.
- This data source already uses Unify Schema.
- Unify Schema
- The Socialgist VK allows you to search for vk.com posts.
- Available filters include query, language, and max_documents.
- Use Proxy option is required if your security policy requires whitelisting IP addresses.
- The available fields can be changed by the data provider (WebSightLines), but currently
  this is the possible field names.
- The deployed component has an Upload button, which opens a dedicated menu containing
  relevant options.
- 'You can interact with the HTTPS Endpoint in one of two ways: Upload a JSON file
  or JSON Lines file directly or paste/type your document.'
- Ensure the provided SAS has permission to view, list and write objects.
- Batches documents either by count or by size.
- Customizable split threshold to define batch limits.
- Ideal for downstream systems that prefer or require grouped input.
- Splitters = no setup, fixed output count (2, 3, or 4)
- For dynamic or high-output splitting, use a Document Router with Multi-route
- The Lucene Document Filter allows you to apply search-style logic to filter pipeline
  documents.
- Documents that do not match the query are dropped, not just bypassed.
- If the Gemini translation encounters safety issues with certain content, you will
  see the placeholder [translation_blocked_token_x_to_y] within the translated text.
- The Hard News classifier is designed to distinguish between factual, authoritative
  news from opinion-based content.
- The violence classifier is designed to uncover instances where people communicate
  violent threats.
- The 'enrichment.sentiment' field is designated to store the sentiment output.
- The 'content.body' field is specified as the Target Text for the AI Sentiment Classifier.
- This Operation allows a user to specify the destination field, source fields, and
  any separator.
- This classifier analyzes sentiment in English short-form content.
- Delivers optimal results when applied to short-form inputs.
- The 'enrichment.category' field holds the output from the Category AI Classifier.
- By default, the target text is set to 'content.body'.
- The enrichment.emotions field is designated to store the emotions output.
- The Target Text is set to content.body by default.
- If the Gemini Model encounters safety issues with certain content, you will find
  that Gemini API failed to generate output.
- This classifier categorizes media posts based on the IPTC 17 Media Topic NewsCodes.
- The enrichment.esg field is designated to store the ESG output.
- The content.body field is the default target text for ESG analysis.
- The NER classifier helps reduce the noise in the query results.
- The 'enrichment.entities' field holds the output from the AI Entity Recognition
  Classifier.
- The 'content.body' field is the default target text for entity recognition.
- Compatible with English only data sources for streaming usage.
- Uses city, region, and country labels with confidence scores.
- The classifier analyzes each location and extracts the most dominant one based on
  frequency.
- 'Compatible Data Sources: opoint_news'
- 'Optimal Usage: Trained on long form data, performs optimally on news and similar
  content.'
- Efficiently transforms unstructured PDF table from documents into structured JSON
  format.
- Adept at handling both digital PDFs and OCR PDFs.
- Two separate component choices for extraction based on speed and performance.
- Images URL’s are extracted from the json document using standard 'json path' rules.
- 'If no values are entered then the default is the standard Datastreamer image link
  location: content.image_urls[*]'
- Egress of one pipeline could be the ingress of another
- Some customers chain pipelines by having the egress of one be the ingress of the
  other
- Databricks Access Token is required for authentication.
- Aggregations is just available for private data sources
- It is necessary to add the suffix .keyword for the fields that will be used in the
  aggregation
- Make sure to replace API Key placeholder with your Datastreamer API Key
- JSON Field Detection enabled
- Unknown Field Handling enabled
- 'The component supports the following methods: PUT and POST.'
- Uses File Collation by default.
- Collation Size must be specified in bytes.
- Default egress data configuration is Documents.
- Datastreamer Portal account required
- Google Cloud Credentials with BigQuery Data Editor and User permissions needed
- Predefined Schema must be provided as a JSON file
- Deploying a Pipeline regionally ensures that Pipeline's data processing is occurring
  within that region.
- Pipeline management, reporting, support, alerting, or other Pipeline-supporting
  elements are not moved to that region.
- Access to data pipelines is managed through API keys, with optional key rotation
  support.
- API endpoints are accessible via whitelisted IP addresses only.
- Datastreamer is not HIPAA compliant; use in healthcare contexts should be carefully
  reviewed with your internal compliance team.
- Apply blacklist filtering after schema application
- Some use cases route the matching content into the 'Trash Can' component, others
  choose to apply a tag and route the content to merge back in at the end of the pipeline.
errors: []
auth_info:
  mentioned_objects: []
client:
  headers:
    Accept: application/json
    Content-Type: application/json
    Authorization: Bearer abc123
    apikey: <API_KEY>
    content-type: application/json
  base_url: https://example.com:9200
  auth:
    type: apikey
    location: header
    header_name: Authorization
  paginator:
    page_size_param: documents_per_page
  credentials:
    use_proxy: true
source_metadata: null
