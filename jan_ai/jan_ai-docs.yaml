resources:
- name: installation_guide
  endpoint:
    path: /docs/desktop/windows
    method: GET
    data_selector: installation_steps
- name: jan_nano_32k
  endpoint:
    path: /jan-nano-32k
    method: GET
    data_selector: data
    params: {}
- name: model_settings
  endpoint:
    path: /settings/local_engine/llama.cpp
    method: GET
    data_selector: settings
    params: {}
- name: chat_completions
  endpoint:
    path: /v1/chat/completions
    method: POST
    data_selector: ''
    params: {}
- name: app_log
  endpoint:
    path: /data/logs/app.log
    method: GET
- name: chat_completions
  endpoint:
    path: /v1/chat/completions
    method: POST
    data_selector: messages
    params:
      model: tinyllama-1.1b
      stream: true
      max_tokens: 2048
      stop:
      - hello
      frequency_penalty: 0
      presence_penalty: 0
      temperature: 0.7
      top_p: 0.95
- name: model.chat.http
  endpoint:
    path: /model/chat/http
    method: GET
- name: assistants
  endpoint:
    path: /assistants/
    method: GET
    data_selector: assistants
    params: {}
- name: extensions
  endpoint:
    path: /extensions/
    method: GET
    data_selector: extensions
    params: {}
- name: logs
  endpoint:
    path: /logs/
    method: GET
    data_selector: logs
    params: {}
- name: models
  endpoint:
    path: /models/
    method: GET
    data_selector: models
    params: {}
- name: threads
  endpoint:
    path: /threads/
    method: GET
    data_selector: threads
    params: {}
notes:
- API keys are optional. No account needed. Just download and run.
- Some HuggingFace models require an access token.
- Jan runs natively on both Apple Silicon and Intel-based Macs.
- Minimum 6GB VRAM recommended for NVIDIA, AMD, or Intel Arc GPUs.
- 10GB free space minimum for app and models.
- Default installation directory is ~/.config/Jan/data
- Custom installation directory is $XDG_CONFIG_HOME = /home/username/custom_config
- NVIDIA Driver installation is recommended via package manager
- CUDA Toolkit version should be 11.7+
- Jan Nano is optimized to work seamlessly with Model Context Protocol (MCP) servers.
- Jan-v1 is a 4B parameter model based on Qwen3-4B-thinking, designed for reasoning
  and problem-solving tasks.
- Model size limits complex reasoning compared to larger models.
- 'Requires Internet: Web search functionality needs active connection'
- 'API Costs: Serper API has usage limits and costs'
- API keys are optional. No account needed. Just download and run. Bring your own
  API keys to connect your favorite cloud models.
- Ensure your API key has sufficient credits
- Ensure your API key has sufficient credits.
- Verify your API key is correct and not expired
- Check if you have billing set up on your Mistral AI account
- Ensure you have access to the model you're trying to use
- Ensure your API key has sufficient credits. OpenRouter credits work across all available
  models.
- Make sure to add /v1/ to the end of your endpoint URL. This is required by the OpenAI
  API.
- Models won't load if the wrong backend is selected.
- For most users, default backend settings are sufficient.
- Enable Tools if you want web search and code execution
- Set Temperature to 0.7 for balanced creativity
- Max out GPU Layers (reduce only if you get memory errors)
- Leave other settings at defaults
- Some models require a Hugging Face Access Token. Enter your token in Settings >
  Model Providers > Hugging Face before importing.
- MCP is an evolving standard, and its use requires careful consideration of security
  and resource management.
- A mandatory secret key to authenticate requests must be set.
- The default settings work well for most hardware. Only adjust these if you're experiencing
  specific issues or want to optimize for your particular setup.
- Uses OAuth2 with refresh token â€” requires setup of connected app in api
- Remove any personal information before sharing logs. We only keep logs for 24 hours.
- Desktop installations perform better than virtual machines. VMs need proper GPU
  passthrough setup.
- Create a new Discord bot at discord.com/developers/applications, obtain a token
  from the Bot tab, and enable MESSAGE CONTENT INTENT.
- Ensure to redact any private or sensitive information when sharing logs or error
  details.
- This will delete all chat history, models, and settings.
- Zero data collection until you say so.
- Jan will never peek at your chats, settings, or model choices.
- Menlo Research is committed to protecting your privacy and ensuring that your personal
  information is handled safely and responsibly.
- We do not share your personal information with third parties except as required
  by law or as necessary to provide you with the services you have requested.
errors:
- 'Failed to detect GPU: Ensure that the GPU drivers are installed correctly.'
- Verify your API key is correct and not expired
- Check if you have billing set up on your Cohere account
- Ensure you have access to the model you're trying to use
- Check if you have billing set up on your Google account
- 'API Key Issues: Verify your API key is correct and not expired'
- 'Connection Problems: Check your internet connection'
- 'Model Unavailable: Confirm your API key has access to the model'
- Check if you have billing set up on your OpenAI account
- Verify your API_KEY/HF_TOKEN is correct and not expired
- Ensure you have billing set up on your HF account
- Confirm your API key has access to the model
- 'Out of memory errors: Reduce context size or switch KV Cache Type.'
- 'Very slow performance: Ensure GPU acceleration is enabled.'
- Responses too repetitive? Increase Temperature or Repeat Penalty
- Out of memory errors? Reduce GPU Layers or Context Size
- Responses too random? Decrease Temperature
- Model running slowly? Increase GPU Layers (if you have VRAM) or reduce Context Size
- '401 Unauthorized: Your API Key is missing from the Authorization header or is incorrect.'
- '404 Not Found: The model ID in your request body does not match an available model
  in Jan.'
- 'REQUEST_LIMIT_EXCEEDED: Throttle API calls or reduce frequency'
- 'QUERY_TIMEOUT: Break down filters or add selectivity'
- '401 Unauthorized: Recheck OAuth scopes or token expiration'
- 'Failed to Fetch: When models won''t respond or show these errors'
- 'Bind address failed: Check if ports are in use'
- 'EACCES: permission denied'
- Failed to fetch
- Unexpected token
auth_info:
  mentioned_objects: []
client:
  base_url: http://localhost:1337/v1
source_metadata: null
