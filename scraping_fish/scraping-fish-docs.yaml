resources:
- name: scrape_website
  endpoint:
    path: /api/v1/
    method: PUT
    data_selector: json
    params: {}
- name: scrape_website
  endpoint:
    path: /api/v1/
    method: GET
    data_selector: response
    params:
      api_key: '[your API key]'
      url: https://example.com
- name: scrape_url
  endpoint:
    path: /
    method: GET
    data_selector: content
    params:
      api_key: '[your API key]'
      url: https://example.com
- name: scraping
  endpoint:
    path: /
    method: GET
    data_selector: content
    params:
      api_key: '[your API key]'
      url: https://example.com
- name: render_js
  endpoint:
    path: /
    method: GET
    params:
      render_js: 'true'
- name: render_js_timeout
  endpoint:
    path: /
    method: GET
    params:
      render_js: 'true'
      render_js_timeout_ms: 15000
- name: request_without_browser
  endpoint:
    path: /
    method: GET
    params:
      browser_type: none
- name: javascript_rendering
  endpoint:
    path: /
    method: GET
    data_selector: content
    params:
      render_js: 'true'
- name: js_scenario
  endpoint:
    path: /api/v1/
    method: GET
    data_selector: response.content
    params: {}
- name: js_scenario
  endpoint:
    path: /api/v1/
    method: GET
    data_selector: ''
    params: {}
- name: solve_captcha
  endpoint:
    path: /api/v1/
    method: GET
    data_selector: verification_message
    params:
      api_key: '[your API key]'
      url: https://www.google.com/recaptcha/api2/demo
      js_scenario: '{"steps":[{"solve_captchas":"[2Cpatcha API key]"},{"click_and_wait_for_navigation":"#recaptcha-demo-submit"}]}'
- name: solve_captcha
  endpoint:
    path: /api/v1/
    method: GET
    data_selector: verification
    params:
      api_key: '[your API key]'
      url: https://www.google.com/recaptcha/api2/demo
      js_scenario: '{"steps":[{"solve_captchas":"[2Cpatcha API key]"},{"click_and_wait_for_navigation":"#recaptcha-demo-submit"}]}'
- name: intercept_request
  endpoint:
    path: /api/v1/
    method: GET
    data_selector: response
    params:
      intercept_request: '**/spec*'
- name: wait_for_response
  endpoint:
    path: /api/v1/
    method: GET
    data_selector: response
    params:
      js_scenario: '{"steps":[{"wait_for_response":"**/spec**"}]}'
- name: intercept_request
  endpoint:
    path: /api/v1/
    method: GET
    data_selector: response
    params:
      intercept_request: '**/spec**'
- name: wait_for_response
  endpoint:
    path: /api/v1/
    method: GET
    data_selector: response
    params:
      js_scenario: '{"steps":[{"wait_for_response":"**/spec**"}]}'
- name: response_headers
  endpoint:
    path: /api/v1/
    method: GET
- name: set_cookies
  endpoint:
    path: /api/v1/
    method: GET
    data_selector: cookies
- name: get_cookies
  endpoint:
    path: /api/v1/
    method: GET
    data_selector: Sf-Cookies
- name: set_cookies
  endpoint:
    path: /api/v1/
    method: GET
    data_selector: response
    params: {}
- name: get_cookies
  endpoint:
    path: /api/v1/
    method: GET
    data_selector: response
    params: {}
- name: preload_local_storage
  endpoint:
    path: /api/v1/
    method: GET
    data_selector: payload
- name: cookies
  endpoint:
    path: /api/v1/
    method: GET
    params: {}
- name: screenshot
  endpoint:
    path: /api/v1/
    method: GET
    data_selector: content
    params:
      screenshot: 'true'
- name: screenshot_with_html
  endpoint:
    path: /api/v1/
    method: GET
    data_selector: content
    params:
      screenshot_base64: 'true'
- name: screenshot
  endpoint:
    path: /api/v1/
    method: GET
    data_selector: content
    params:
      screenshot: 'true'
- name: screenshot_with_html
  endpoint:
    path: /api/v1/
    method: GET
    data_selector: content
    params:
      screenshot_base64: 'true'
- name: pdf_generation
  endpoint:
    path: /api/v1/
    method: GET
    data_selector: response
    params:
      pdf: 'true'
- name: api_v1
  endpoint:
    path: /api/v1/
    method: POST
- name: generate_pdf
  endpoint:
    path: /api/v1/
    method: GET
    data_selector: response.content
    params:
      pdf: 'true'
- name: api_v1
  endpoint:
    path: /api/v1/
    method: POST
    data_selector: response
    params: {}
- name: total_timeout
  endpoint:
    params:
      total_timeout_ms: 90000
- name: trial_timeout
  endpoint:
    params:
      trial_timeout_ms: 30000
- name: js_rendering_timeout
  endpoint:
    params:
      render_js_timeout_ms: 5000
- name: usage
  endpoint:
    path: /api/v1/usage
    method: GET
    data_selector: records
    params:
      api_key: '[your API key]'
- name: usage
  endpoint:
    path: /api/v1/usage
    method: GET
    data_selector: records
    params: {}
- name: scraping_benchmark
  endpoint:
    path: /v1/general/
    method: GET
    data_selector: results
    params:
      proxy_type: residential
notes:
- Your Scraping Fish API key is required.
- You don't even need to set up an account
- All new accounts are set up with a limit of 25 concurrent requests per domain by
  default
- To enable JavaScript rendering, add render_js=true query parameter.
- The request with JS rendering enabled is likely to take slightly more time.
- Steps to perform are passed as JSON in js_scenario query parameter.
- All the steps from your JavaScript scenario must complete within single trial timeout,
  otherwise the request will time out.
- All requests with CAPTCHA solving step are charged regardless of result.
- Scraping Fish returns its own headers but preserves all the headers from the original
  website as well.
- The original headers are prefixed with `Sf-` prefix.
- Scraping Fish returns its own headers but preserves all the headers from the original
  website.
- When `forward_original_status` is enabled, all requests are considered successful
  and will be deducted from your pack of API requests regardless of the status code.
- Set your origin with care. It's not necessarily the same as your url origin.
- A sticky session preserves cookies, local and session storage between requests.
- Session value must be a string of length between 1 and 512 characters.
- A session expires after 24 hours since it was last used.
- Extraction rules allow you to specify rules which will be applied to resulting HTML
  to extract values in JSON format.
- Timeouts should be specified in milliseconds, and it is possible to set all trial_timeout_ms,
  trial_timeout_ms, and render_js_timeout_ms for the same request.
- Timeouts should be specified in milliseconds
- The total request timeout is by default set to 90,000 ms (90 seconds) and can be
  set to any value between 10 and 600 seconds
- The value of total_timeout_ms must be larger or equal to the value of trial_timeout_ms
- Each successful request to Scraping Fish API is worth exactly one API request regardless
  of query parameters or other options.
- Unlimited API requests available with different maximum concurrency options.
- First purchase creates an account and sends an API key via email.
- Scraping Fish offers the best proxies available - 4G/LTE mobile proxies by default,
  at no additional cost.
- You can scrape with JS rendering at no additional cost.
- This document was last updated on April 14, 2022
- Uses pay as you go pricing model
- Scraping Fish works for scraping websites protected by Cloudflare, DataDome, and
  Kasada. No configuration needed.
- Achieved the highest total success rate of 99.96% with the best average processing
  time of 3.23 seconds/URL.
- Scraping Instagram is not allowed and returns 403 status code.
errors:
- '500: Check the error message in the response for details'
- '200: Everything''s OK - desired URL has been scraped successfully'
- '400: Bad request, e.g. no API key provided - details in the response'
- '401: Bad API key or no more credits available'
- '404: Desired website returned 404 Not Found'
- '429: Too many concurrent requests - contact us if you need to increase this limit'
- '500: General error - details in the response'
- The value of total_timeout_ms must be larger or equal to the value of trial_timeout_ms.
- '403 Forbidden: Scraping Instagram is not allowed.'
- '403 Forbidden: Scraping Instagram is not allowed'
auth_info:
  mentioned_objects: []
client:
  base_url: https://scraping.narf.ai
  headers:
    Accept: application/json
source_metadata: null
